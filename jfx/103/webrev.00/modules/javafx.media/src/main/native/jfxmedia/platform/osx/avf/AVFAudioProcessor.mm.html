<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2014, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.  Oracle designates this
  8  * particular file as subject to the &quot;Classpath&quot; exception as provided
  9  * by Oracle in the LICENSE file that accompanied this code.
 10  *
 11  * This code is distributed in the hope that it will be useful, but WITHOUT
 12  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 13  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 14  * version 2 for more details (a copy is included in the LICENSE file that
 15  * accompanied this code).
 16  *
 17  * You should have received a copy of the GNU General Public License version
 18  * 2 along with this work; if not, write to the Free Software Foundation,
 19  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 20  *
 21  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 22  * or visit www.oracle.com if you need additional information or have any
 23  * questions.
 24  */
 25 
 26 #import &quot;AVFAudioProcessor.h&quot;
 27 #import &quot;AVFMediaPlayer.h&quot;
 28 
 29 #import &lt;AVFoundation/AVFoundation.h&gt;
 30 #import &lt;MediaToolbox/MediaToolbox.h&gt;
 31 
 32 #import &lt;CoreFoundation/CoreFoundation.h&gt;
 33 
 34 #import &lt;pthread.h&gt;
 35 #import &lt;objc/message.h&gt;
 36 
 37 static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
 38 static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
 39 static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
 40         CMItemCount maxFrames,
 41         const AudioStreamBasicDescription *processingFormat);
 42 static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
 43 static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
 44         MTAudioProcessingTapFlags flags,
 45         AudioBufferList *bufferListInOut,
 46         CMItemCount *numberFramesOut,
 47         MTAudioProcessingTapFlags *flagsOut);
 48 static OSStatus AVFTapRenderCallback(void *inRefCon,
 49                                      AudioUnitRenderActionFlags *ioActionFlags,
 50                                      const AudioTimeStamp *inTimeStamp,
 51                                      UInt32 inBusNumber,
 52                                      UInt32 inNumberFrames,
 53                                      AudioBufferList *ioData);
 54 
 55 @implementation AVFAudioProcessor
 56 
 57 - (id) init {
 58     if ((self = [super init]) != nil) {
 59         _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
 60         _audioSpectrum = AVFAudioSpectrumUnitPtr(new AVFAudioSpectrumUnit());
 61         _audioEqualizer = AVFAudioEqualizerPtr(new AVFAudioEqualizer());
 62 
 63         _volume = 1.0f;
 64         _balance = 0.0f;
 65         _audioDelay = 0LL;
 66     }
 67     return self;
 68 }
 69 
 70 -(void) dealloc {
 71     _soundLevelUnit = nullptr;
 72     _audioSpectrum = nullptr;
 73     _audioEqualizer = nullptr;
 74 }
 75 
 76 -(void) setAudioTrack : (AVAssetTrack *) track {
 77     if (track != _audioTrack) {
 78         // reset the audio mixer if it&#39;s already been created
 79         // this theoretically should never happen...
 80         _mixer = nil;
 81     }
 82     _audioTrack = track;
 83 }
 84 
 85 -(AVAudioMix*) mixer {
 86     if (!self.audioTrack) {
 87         return nil;
 88     }
 89 
 90     if (!_mixer) {
 91         AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
 92         if (mixer) {
 93             AVMutableAudioMixInputParameters *audioMixInputParameters =
 94                     [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack : self.audioTrack];
 95             if (audioMixInputParameters &amp;&amp;
 96                     [audioMixInputParameters respondsToSelector : @selector(setAudioTapProcessor :)]) {
 97                 MTAudioProcessingTapCallbacks callbacks;
 98 
 99                 callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
100                 callbacks.clientInfo = (__bridge void *) self;
101                 callbacks.init = InitAudioTap;
102                 callbacks.finalize = FinalizeAudioTap;
103                 callbacks.prepare = PrepareAudioTap;
104                 callbacks.unprepare = UnprepareAudioTap;
105                 callbacks.process = ProcessAudioTap;
106 
107                 MTAudioProcessingTapRef audioProcessingTap;
108                 if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
109                         kMTAudioProcessingTapCreationFlag_PreEffects,
110                         &amp;audioProcessingTap)) {
111                     objc_msgSend(audioMixInputParameters,
112                             @selector(setAudioTapProcessor :),
113                             audioProcessingTap);
114 
115                     CFRelease(audioProcessingTap); // owned by the mixer now
116                     mixer.inputParameters = @[audioMixInputParameters];
117 
118                     _mixer = mixer;
119                 }
120             }
121         }
122     }
123     return _mixer;
124 }
125 
126 -(void) setVolume : (float) volume {
127     _volume = volume;
128     if (_soundLevelUnit != nullptr) {
129         _soundLevelUnit-&gt;setVolume(volume);
130     }
131 }
132 
133 -(void) setBalance : (float) balance {
134     _balance = balance;
135     if (_soundLevelUnit != nullptr) {
136         _soundLevelUnit-&gt;setBalance(balance);
137     }
138 }
139 
140 @end
141 
142 AVFTapContext::AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum,
143                              AVFAudioEqualizerPtr eq) : audioSLU(slu),
144                                                         audioSpectrum(spectrum),
145                                                         audioEQ(eq),
146                                                         // Some reasonable defaults
147                                                         mSampleRate(48000),
148                                                         mChannels(2) {
149 }
150 
151 AVFTapContext::~AVFTapContext() {
152     // AudioUnits have already been deallocated by now
153     // shared_ptrs get freed automatically
154 }
155 
156 void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut) {
157     // retain the AU kernels so they don&#39;t get freed while we&#39;re running
158     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *) clientInfo;
159     if (processor) {
160         AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
161                 processor.audioSpectrum,
162                 processor.audioEqualizer);
163         *tapStorageOut = context;
164     }
165 }
166 
167 void FinalizeAudioTap(MTAudioProcessingTapRef tapRef) {
168     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);
169     if (context) {
170         delete context;
171     }
172 }
173 
174 static OSStatus SetupAudioUnit(AudioUnit unit,
175                                const AudioStreamBasicDescription *processingFormat,
176                                UInt32 maxFrames) {
177     OSStatus status = noErr;
178     if (noErr == status) {
179         status = AudioUnitSetProperty(unit,
180                                       kAudioUnitProperty_StreamFormat,
181                                       kAudioUnitScope_Input, 0,
182                                       processingFormat, sizeof(AudioStreamBasicDescription));
183     }
184     if (noErr == status) {
185         status = AudioUnitSetProperty(unit,
186                                       kAudioUnitProperty_StreamFormat,
187                                       kAudioUnitScope_Output, 0,
188                                       processingFormat, sizeof(AudioStreamBasicDescription));
189     }
190     if (noErr == status) {
191         status = AudioUnitSetProperty(unit,
192                                       kAudioUnitProperty_MaximumFramesPerSlice,
193                                       kAudioUnitScope_Global, 0,
194                                       &amp;maxFrames, sizeof(UInt32));
195     }
196     if (noErr == status) {
197         status = AudioUnitInitialize(unit);
198     }
199     return status;
200 }
201 
202 void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
203         CMItemCount maxFrames,
204         const AudioStreamBasicDescription *processingFormat) {
205     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);
206 
207     // Validate the audio format before we enable the processor
208     // Failures here should rarely, if ever, happen so leave the NSLogs in for
209     // easier diagnosis in the field
210     if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
211         NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
212         return;
213     }
214 
215     // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
216     // process the incoming audio
217     if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
218             != kAudioFormatFlagsNativeFloatPacked) {
219         NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
220         return;
221     }
222 
223     context-&gt;mSampleRate = processingFormat-&gt;mSampleRate;
224     context-&gt;mChannels = processingFormat-&gt;mChannelsPerFrame;
225     context-&gt;mMaxFrames = maxFrames;
226 
227     // Configure audio equalizer
228     if (context-&gt;audioEQ != nullptr) {
229         context-&gt;audioEQ.get()-&gt;SetSampleRate(context-&gt;mSampleRate);
230         context-&gt;audioEQ.get()-&gt;SetChannels(context-&gt;mChannels);
231         context-&gt;audioEQ.get()-&gt;ResetBandParameters();
232     }
233 
234     // Configure spectrum
235     if (context-&gt;audioSpectrum != nullptr) {
236         context-&gt;audioSpectrum.get()-&gt;SetSampleRate(context-&gt;mSampleRate);
237         context-&gt;audioSpectrum.get()-&gt;SetChannels(context-&gt;mChannels);
238         context-&gt;audioSpectrum.get()-&gt;SetMaxFrames(context-&gt;mMaxFrames);
239     }
240 
241     if (context-&gt;audioSLU != nullptr) {
242         context-&gt;audioSLU.get()-&gt;SetChannels(context-&gt;mChannels);
243     }
244 }
245 
246 void UnprepareAudioTap(MTAudioProcessingTapRef tapRef) {
247     // We do not need it anymore
248 }
249 
250 void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
251         CMItemCount numberFrames,
252         uint32_t flags,
253         AudioBufferList *bufferListInOut,
254         CMItemCount *numberFramesOut,
255         uint32_t *flagsOut) {
256     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);
257     OSStatus status = MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,
258             flagsOut, NULL, numberFramesOut);
259     if (status != noErr) {
260         NSLog(@&quot;MTAudioProcessingTapGetSourceAudio failed: %d&quot;, status);
261         return;
262     }
263 
264     if (context-&gt;audioEQ != nullptr) {
265         if (!context-&gt;audioEQ.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {
266             NSLog(@&quot;audioEQ ProcessBufferLists() failed&quot;);
267             return;
268         }
269     }
270 
271     if (context-&gt;audioSpectrum != nullptr) {
272         if (!context-&gt;audioSpectrum.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {
273             NSLog(@&quot;audioSpectrum ProcessBufferLists() failed&quot;);
274             return;
275         }
276     }
277 
278     if (context-&gt;audioSLU != nullptr) {
279         if (!context-&gt;audioSLU.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {
280             NSLog(@&quot;audioSLU ProcessBufferLists() failed&quot;);
281             return;
282         }
283     }
284 }
    </pre>
  </body>
</html>