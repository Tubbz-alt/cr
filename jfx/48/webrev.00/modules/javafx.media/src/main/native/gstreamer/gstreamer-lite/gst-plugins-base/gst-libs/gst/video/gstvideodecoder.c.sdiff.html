<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideodecoder.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="convertframe.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="gstvideodecoder.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideodecoder.c</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 271  *    gather queue:    1
 272  *    decode queue:
 273  *    output queue:    4  3  2
 274  *
 275  *  Leftover buffer 1 cannot be decoded and must be discarded.
 276  */
 277 
 278 #include &quot;gstvideodecoder.h&quot;
 279 #include &quot;gstvideoutils.h&quot;
 280 #include &quot;gstvideoutilsprivate.h&quot;
 281 
 282 #include &lt;gst/video/video.h&gt;
 283 #include &lt;gst/video/video-event.h&gt;
 284 #include &lt;gst/video/gstvideopool.h&gt;
 285 #include &lt;gst/video/gstvideometa.h&gt;
 286 #include &lt;string.h&gt;
 287 
 288 GST_DEBUG_CATEGORY (videodecoder_debug);
 289 #define GST_CAT_DEFAULT videodecoder_debug
 290 
<span class="line-removed"> 291 #define GST_VIDEO_DECODER_GET_PRIVATE(obj)  \</span>
<span class="line-removed"> 292     (G_TYPE_INSTANCE_GET_PRIVATE ((obj), GST_TYPE_VIDEO_DECODER, \</span>
<span class="line-removed"> 293         GstVideoDecoderPrivate))</span>
<span class="line-removed"> 294 </span>
 295 struct _GstVideoDecoderPrivate
 296 {
 297   /* FIXME introduce a context ? */
 298 
 299   GstBufferPool *pool;
 300   GstAllocator *allocator;
 301   GstAllocationParams params;
 302 
 303   /* parse tracking */
 304   /* input data */
 305   GstAdapter *input_adapter;
 306   /* assembles current frame */
 307   GstAdapter *output_adapter;
 308 
 309   /* Whether we attempt to convert newsegment from bytes to
 310    * time using a bitrate estimation */
 311   gboolean do_estimate_rate;
 312 
 313   /* Whether input is considered packetized or not */
 314   gboolean packetized;
</pre>
<hr />
<pre>
 393   /* upstream stream tags (global tags are passed through as-is) */
 394   GstTagList *upstream_tags;
 395 
 396   /* subclass tags */
 397   GstTagList *tags;
 398   GstTagMergeMode tags_merge_mode;
 399 
 400   gboolean tags_changed;
 401 
 402   /* flags */
 403   gboolean use_default_pad_acceptcaps;
 404 
 405 #ifndef GST_DISABLE_DEBUG
 406   /* Diagnostic time for reporting the time
 407    * from flush to first output */
 408   GstClockTime last_reset_time;
 409 #endif
 410 };
 411 
 412 static GstElementClass *parent_class = NULL;


 413 static void gst_video_decoder_class_init (GstVideoDecoderClass * klass);
 414 static void gst_video_decoder_init (GstVideoDecoder * dec,
 415     GstVideoDecoderClass * klass);
 416 
 417 static void gst_video_decoder_finalize (GObject * object);
 418 
 419 static gboolean gst_video_decoder_setcaps (GstVideoDecoder * dec,
 420     GstCaps * caps);
 421 static gboolean gst_video_decoder_sink_event (GstPad * pad, GstObject * parent,
 422     GstEvent * event);
 423 static gboolean gst_video_decoder_src_event (GstPad * pad, GstObject * parent,
 424     GstEvent * event);
 425 static GstFlowReturn gst_video_decoder_chain (GstPad * pad, GstObject * parent,
 426     GstBuffer * buf);
 427 static gboolean gst_video_decoder_sink_query (GstPad * pad, GstObject * parent,
 428     GstQuery * query);
 429 static GstStateChangeReturn gst_video_decoder_change_state (GstElement *
 430     element, GstStateChange transition);
 431 static gboolean gst_video_decoder_src_query (GstPad * pad, GstObject * parent,
 432     GstQuery * query);
</pre>
<hr />
<pre>
 476 gst_video_decoder_get_type (void)
 477 {
 478   static volatile gsize type = 0;
 479 
 480   if (g_once_init_enter (&amp;type)) {
 481     GType _type;
 482     static const GTypeInfo info = {
 483       sizeof (GstVideoDecoderClass),
 484       NULL,
 485       NULL,
 486       (GClassInitFunc) gst_video_decoder_class_init,
 487       NULL,
 488       NULL,
 489       sizeof (GstVideoDecoder),
 490       0,
 491       (GInstanceInitFunc) gst_video_decoder_init,
 492     };
 493 
 494     _type = g_type_register_static (GST_TYPE_ELEMENT,
 495         &quot;GstVideoDecoder&quot;, &amp;info, G_TYPE_FLAG_ABSTRACT);




 496     g_once_init_leave (&amp;type, _type);
 497   }
 498   return type;
 499 }
 500 






 501 static void
 502 gst_video_decoder_class_init (GstVideoDecoderClass * klass)
 503 {
 504   GObjectClass *gobject_class;
 505   GstElementClass *gstelement_class;
 506 
 507   gobject_class = G_OBJECT_CLASS (klass);
 508   gstelement_class = GST_ELEMENT_CLASS (klass);
 509 
 510   GST_DEBUG_CATEGORY_INIT (videodecoder_debug, &quot;videodecoder&quot;, 0,
 511       &quot;Base Video Decoder&quot;);
 512 
 513   parent_class = g_type_class_peek_parent (klass);
<span class="line-modified"> 514   g_type_class_add_private (klass, sizeof (GstVideoDecoderPrivate));</span>


 515 
 516   gobject_class-&gt;finalize = gst_video_decoder_finalize;
 517 
 518   gstelement_class-&gt;change_state =
 519       GST_DEBUG_FUNCPTR (gst_video_decoder_change_state);
 520 
 521   klass-&gt;sink_event = gst_video_decoder_sink_event_default;
 522   klass-&gt;src_event = gst_video_decoder_src_event_default;
 523   klass-&gt;decide_allocation = gst_video_decoder_decide_allocation_default;
 524   klass-&gt;propose_allocation = gst_video_decoder_propose_allocation_default;
 525   klass-&gt;negotiate = gst_video_decoder_negotiate_default;
 526   klass-&gt;sink_query = gst_video_decoder_sink_query_default;
 527   klass-&gt;src_query = gst_video_decoder_src_query_default;
 528   klass-&gt;transform_meta = gst_video_decoder_transform_meta_default;
 529 }
 530 
 531 static void
 532 gst_video_decoder_init (GstVideoDecoder * decoder, GstVideoDecoderClass * klass)
 533 {
 534   GstPadTemplate *pad_template;
 535   GstPad *pad;
 536 
 537   GST_DEBUG_OBJECT (decoder, &quot;gst_video_decoder_init&quot;);
 538 
<span class="line-modified"> 539   decoder-&gt;priv = GST_VIDEO_DECODER_GET_PRIVATE (decoder);</span>
 540 
 541   pad_template =
 542       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 543   g_return_if_fail (pad_template != NULL);
 544 
 545   decoder-&gt;sinkpad = pad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 546 
 547   gst_pad_set_chain_function (pad, GST_DEBUG_FUNCPTR (gst_video_decoder_chain));
 548   gst_pad_set_event_function (pad,
 549       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_event));
 550   gst_pad_set_query_function (pad,
 551       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_query));
 552   gst_element_add_pad (GST_ELEMENT (decoder), decoder-&gt;sinkpad);
 553 
 554   pad_template =
 555       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 556   g_return_if_fail (pad_template != NULL);
 557 
 558   decoder-&gt;srcpad = pad = gst_pad_new_from_template (pad_template, &quot;src&quot;);
 559 
</pre>
<hr />
<pre>
 592   if (G_UNLIKELY (!gst_video_info_from_caps (&amp;state-&gt;info, caps)))
 593     goto parse_fail;
 594   state-&gt;caps = gst_caps_ref (caps);
 595 
 596   structure = gst_caps_get_structure (caps, 0);
 597 
 598   codec_data = gst_structure_get_value (structure, &quot;codec_data&quot;);
 599   if (codec_data &amp;&amp; G_VALUE_TYPE (codec_data) == GST_TYPE_BUFFER)
 600     state-&gt;codec_data = GST_BUFFER (g_value_dup_boxed (codec_data));
 601 
 602   return state;
 603 
 604 parse_fail:
 605   {
 606     g_slice_free (GstVideoCodecState, state);
 607     return NULL;
 608   }
 609 }
 610 
 611 static GstVideoCodecState *
<span class="line-modified"> 612 _new_output_state (GstVideoFormat fmt, guint width, guint height,</span>
<span class="line-modified"> 613     GstVideoCodecState * reference)</span>
 614 {
 615   GstVideoCodecState *state;
 616 
 617   state = g_slice_new0 (GstVideoCodecState);
 618   state-&gt;ref_count = 1;
 619   gst_video_info_init (&amp;state-&gt;info);
<span class="line-modified"> 620   if (!gst_video_info_set_format (&amp;state-&gt;info, fmt, width, height)) {</span>

 621     g_slice_free (GstVideoCodecState, state);
 622     return NULL;
 623   }
 624 
 625   if (reference) {
 626     GstVideoInfo *tgt, *ref;
 627 
 628     tgt = &amp;state-&gt;info;
 629     ref = &amp;reference-&gt;info;
 630 
 631     /* Copy over extra fields from reference state */
 632     tgt-&gt;interlace_mode = ref-&gt;interlace_mode;
 633     tgt-&gt;flags = ref-&gt;flags;
 634     /* only copy values that are not unknown so that we don&#39;t override the
 635      * defaults. subclasses should really fill these in when they know. */
 636     if (ref-&gt;chroma_site)
 637       tgt-&gt;chroma_site = ref-&gt;chroma_site;
 638     if (ref-&gt;colorimetry.range)
 639       tgt-&gt;colorimetry.range = ref-&gt;colorimetry.range;
 640     if (ref-&gt;colorimetry.matrix)
</pre>
<hr />
<pre>
 973   templcaps = gst_pad_get_pad_template_caps (decoder-&gt;srcpad);
 974   caps = gst_pad_peer_query_caps (decoder-&gt;srcpad, templcaps);
 975   if (caps)
 976     gst_caps_unref (templcaps);
 977   else
 978     caps = templcaps;
 979   templcaps = NULL;
 980 
 981   if (!caps || gst_caps_is_empty (caps) || gst_caps_is_any (caps))
 982     goto caps_error;
 983 
 984   GST_LOG_OBJECT (decoder, &quot;peer caps %&quot; GST_PTR_FORMAT, caps);
 985 
 986   /* before fixating, try to use whatever upstream provided */
 987   caps = gst_caps_make_writable (caps);
 988   caps_size = gst_caps_get_size (caps);
 989   if (decoder-&gt;priv-&gt;input_state &amp;&amp; decoder-&gt;priv-&gt;input_state-&gt;caps) {
 990     GstCaps *sinkcaps = decoder-&gt;priv-&gt;input_state-&gt;caps;
 991     GstStructure *structure = gst_caps_get_structure (sinkcaps, 0);
 992     gint width, height;
<span class="line-removed"> 993     gint par_n, par_d;</span>
<span class="line-removed"> 994     gint fps_n, fps_d;</span>
 995 
 996     if (gst_structure_get_int (structure, &quot;width&quot;, &amp;width)) {
 997       for (i = 0; i &lt; caps_size; i++) {
 998         gst_structure_set (gst_caps_get_structure (caps, i), &quot;width&quot;,
 999             G_TYPE_INT, width, NULL);
1000       }
1001     }
1002 
1003     if (gst_structure_get_int (structure, &quot;height&quot;, &amp;height)) {
1004       for (i = 0; i &lt; caps_size; i++) {
1005         gst_structure_set (gst_caps_get_structure (caps, i), &quot;height&quot;,
1006             G_TYPE_INT, height, NULL);
1007       }
1008     }
<span class="line-removed">1009 </span>
<span class="line-removed">1010     if (gst_structure_get_fraction (structure, &quot;framerate&quot;, &amp;fps_n, &amp;fps_d)) {</span>
<span class="line-removed">1011       for (i = 0; i &lt; caps_size; i++) {</span>
<span class="line-removed">1012         gst_structure_set (gst_caps_get_structure (caps, i), &quot;framerate&quot;,</span>
<span class="line-removed">1013             GST_TYPE_FRACTION, fps_n, fps_d, NULL);</span>
<span class="line-removed">1014       }</span>
<span class="line-removed">1015     }</span>
<span class="line-removed">1016 </span>
<span class="line-removed">1017     if (gst_structure_get_fraction (structure, &quot;pixel-aspect-ratio&quot;, &amp;par_n,</span>
<span class="line-removed">1018             &amp;par_d)) {</span>
<span class="line-removed">1019       for (i = 0; i &lt; caps_size; i++) {</span>
<span class="line-removed">1020         gst_structure_set (gst_caps_get_structure (caps, i),</span>
<span class="line-removed">1021             &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION, par_n, par_d, NULL);</span>
<span class="line-removed">1022       }</span>
<span class="line-removed">1023     }</span>
1024   }
1025 
1026   for (i = 0; i &lt; caps_size; i++) {
1027     structure = gst_caps_get_structure (caps, i);
<span class="line-modified">1028     /* Random I420 1280x720@30 for fixation */</span>
1029     if (gst_structure_has_field (structure, &quot;format&quot;))
1030       gst_structure_fixate_field_string (structure, &quot;format&quot;, &quot;I420&quot;);
1031     else
1032       gst_structure_set (structure, &quot;format&quot;, G_TYPE_STRING, &quot;I420&quot;, NULL);
1033 
1034     if (gst_structure_has_field (structure, &quot;width&quot;))
1035       gst_structure_fixate_field_nearest_int (structure, &quot;width&quot;, 1280);
1036     else
1037       gst_structure_set (structure, &quot;width&quot;, G_TYPE_INT, 1280, NULL);
1038 
1039     if (gst_structure_has_field (structure, &quot;height&quot;))
1040       gst_structure_fixate_field_nearest_int (structure, &quot;height&quot;, 720);
1041     else
1042       gst_structure_set (structure, &quot;height&quot;, G_TYPE_INT, 720, NULL);
<span class="line-removed">1043 </span>
<span class="line-removed">1044     if (gst_structure_has_field (structure, &quot;framerate&quot;))</span>
<span class="line-removed">1045       gst_structure_fixate_field_nearest_fraction (structure, &quot;framerate&quot;, 30,</span>
<span class="line-removed">1046           1);</span>
<span class="line-removed">1047     else</span>
<span class="line-removed">1048       gst_structure_set (structure, &quot;framerate&quot;, GST_TYPE_FRACTION, 30, 1,</span>
<span class="line-removed">1049           NULL);</span>
<span class="line-removed">1050 </span>
<span class="line-removed">1051     if (gst_structure_has_field (structure, &quot;pixel-aspect-ratio&quot;))</span>
<span class="line-removed">1052       gst_structure_fixate_field_nearest_fraction (structure,</span>
<span class="line-removed">1053           &quot;pixel-aspect-ratio&quot;, 1, 1);</span>
<span class="line-removed">1054     else</span>
<span class="line-removed">1055       gst_structure_set (structure, &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION,</span>
<span class="line-removed">1056           1, 1, NULL);</span>
1057   }
1058   caps = gst_caps_fixate (caps);
<span class="line-removed">1059   structure = gst_caps_get_structure (caps, 0);</span>
1060 
1061   if (!caps || !gst_video_info_from_caps (&amp;info, caps))
1062     goto caps_error;
1063 
1064   GST_INFO_OBJECT (decoder,
1065       &quot;Chose default caps %&quot; GST_PTR_FORMAT &quot; for initial gap&quot;, caps);
1066   state =
1067       gst_video_decoder_set_output_state (decoder, info.finfo-&gt;format,
1068       info.width, info.height, decoder-&gt;priv-&gt;input_state);
1069   gst_video_codec_state_unref (state);
1070   gst_caps_unref (caps);
1071 
1072   return TRUE;
1073 
1074 caps_error:
1075   {
1076     if (caps)
1077       gst_caps_unref (caps);
1078     return FALSE;
1079   }
</pre>
<hr />
<pre>
1163 
1164       /* Forward EOS immediately. This is required because no
1165        * buffer or serialized event will come after EOS and
1166        * nothing could trigger another _finish_frame() call.
1167        *
1168        * The subclass can override this behaviour by overriding
1169        * the ::sink_event() vfunc and not chaining up to the
1170        * parent class&#39; ::sink_event() until a later time.
1171        */
1172       forward_immediate = TRUE;
1173       break;
1174     }
1175     case GST_EVENT_GAP:
1176     {
1177       GstFlowReturn flow_ret = GST_FLOW_OK;
1178       gboolean needs_reconfigure = FALSE;
1179       GList *events;
1180       GList *frame_events;
1181 
1182       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
<span class="line-modified">1183       flow_ret = gst_video_decoder_drain_out (decoder, FALSE);</span>

1184       ret = (flow_ret == GST_FLOW_OK);
1185 
1186       /* Ensure we have caps before forwarding the event */
1187       if (!decoder-&gt;priv-&gt;output_state) {
1188         if (!gst_video_decoder_negotiate_default_caps (decoder)) {
1189           GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1190           GST_ELEMENT_ERROR (decoder, STREAM, FORMAT, (NULL),
1191               (&quot;Decoder output not negotiated before GAP event.&quot;));
1192           forward_immediate = TRUE;
1193           break;
1194         }
1195         needs_reconfigure = TRUE;
1196       }
1197 
1198       needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad)
1199           || needs_reconfigure;
1200       if (decoder-&gt;priv-&gt;output_state_changed || needs_reconfigure) {
1201         if (!gst_video_decoder_negotiate_unlocked (decoder)) {
1202           GST_WARNING_OBJECT (decoder, &quot;Failed to negotiate with downstream&quot;);
1203           gst_pad_mark_reconfigure (decoder-&gt;srcpad);
</pre>
<hr />
<pre>
2097 
2098   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2099 }
2100 
2101 static GstFlowReturn
2102 gst_video_decoder_chain_forward (GstVideoDecoder * decoder,
2103     GstBuffer * buf, gboolean at_eos)
2104 {
2105   GstVideoDecoderPrivate *priv;
2106   GstVideoDecoderClass *klass;
2107   GstFlowReturn ret = GST_FLOW_OK;
2108 
2109   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
2110   priv = decoder-&gt;priv;
2111 
2112   g_return_val_if_fail (priv-&gt;packetized || klass-&gt;parse, GST_FLOW_ERROR);
2113 
2114   /* Draining on DISCONT is handled in chain_reverse() for reverse playback,
2115    * and this function would only be called to get everything collected GOP
2116    * by GOP in the parse_gather list */
<span class="line-modified">2117   if (decoder-&gt;input_segment.rate &gt; 0.0 &amp;&amp; GST_BUFFER_IS_DISCONT (buf))</span>

2118     ret = gst_video_decoder_drain_out (decoder, FALSE);
2119 
2120   if (priv-&gt;current_frame == NULL)
2121     priv-&gt;current_frame = gst_video_decoder_new_frame (decoder);
2122 
2123   if (!priv-&gt;packetized)
2124     gst_video_decoder_add_buffer_info (decoder, buf);
2125 
2126   priv-&gt;input_offset += gst_buffer_get_size (buf);
2127 
2128   if (priv-&gt;packetized) {
2129     gboolean was_keyframe = FALSE;
2130     if (!GST_BUFFER_FLAG_IS_SET (buf, GST_BUFFER_FLAG_DELTA_UNIT)) {
2131       was_keyframe = TRUE;
2132       GST_LOG_OBJECT (decoder, &quot;Marking current_frame as sync point&quot;);
2133       GST_VIDEO_CODEC_FRAME_SET_SYNC_POINT (priv-&gt;current_frame);
2134     }
2135 
2136     priv-&gt;current_frame-&gt;input_buffer = buf;
2137 
</pre>
<hr />
<pre>
2322       /* We need to tell the subclass to drain now.
2323        * We prefer the drain vfunc, but for backward-compat
2324        * we use a finish() vfunc if drain isn&#39;t implemented */
2325       if (decoder_class-&gt;drain) {
2326         GST_DEBUG_OBJECT (dec, &quot;Draining&quot;);
2327         res = decoder_class-&gt;drain (dec);
2328       } else if (decoder_class-&gt;finish) {
2329         GST_FIXME_OBJECT (dec, &quot;Sub-class should implement drain(). &quot;
2330             &quot;Calling finish() for backwards-compat&quot;);
2331         res = decoder_class-&gt;finish (dec);
2332       }
2333 
2334       if (res != GST_FLOW_OK)
2335         goto done;
2336 
2337       /* now send queued data downstream */
2338       walk = priv-&gt;output_queued;
2339       while (walk) {
2340         GstBuffer *buf = GST_BUFFER_CAST (walk-&gt;data);
2341 



2342         if (G_LIKELY (res == GST_FLOW_OK)) {
2343           /* avoid stray DISCONT from forward processing,
2344            * which have no meaning in reverse pushing */
2345           GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DISCONT);
2346 
2347           /* Last chance to calculate a timestamp as we loop backwards
2348            * through the list */
2349           if (GST_BUFFER_TIMESTAMP (buf) != GST_CLOCK_TIME_NONE)
2350             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2351           else if (priv-&gt;last_timestamp_out != GST_CLOCK_TIME_NONE &amp;&amp;
2352               GST_BUFFER_DURATION (buf) != GST_CLOCK_TIME_NONE) {
2353             GST_BUFFER_TIMESTAMP (buf) =
2354                 priv-&gt;last_timestamp_out - GST_BUFFER_DURATION (buf);
2355             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2356             GST_LOG_OBJECT (dec,
2357                 &quot;Calculated TS %&quot; GST_TIME_FORMAT &quot; working backwards&quot;,
2358                 GST_TIME_ARGS (priv-&gt;last_timestamp_out));
2359           }
2360 
2361           res = gst_video_decoder_clip_and_push_buf (dec, buf);
2362         } else {
2363           gst_buffer_unref (buf);
2364         }
2365 
<span class="line-removed">2366         priv-&gt;output_queued =</span>
<span class="line-removed">2367             g_list_delete_link (priv-&gt;output_queued, priv-&gt;output_queued);</span>
2368         walk = priv-&gt;output_queued;
2369       }
2370 
2371       /* clear buffer and decoder state again
2372        * before moving to the previous keyframe */
2373       gst_video_decoder_flush (dec, FALSE);
2374     }
2375 
2376     walk = priv-&gt;parse_gather;
2377   }
2378 
2379 done:
2380   return res;
2381 }
2382 
2383 static GstFlowReturn
2384 gst_video_decoder_chain_reverse (GstVideoDecoder * dec, GstBuffer * buf)
2385 {
2386   GstVideoDecoderPrivate *priv = dec-&gt;priv;
2387   GstFlowReturn result = GST_FLOW_OK;
</pre>
<hr />
<pre>
3186       gst_buffer_get_size (buf),
3187       GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
3188       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
3189 
3190   /* we got data, so note things are looking up again, reduce
3191    * the error count, if there is one */
3192   if (G_UNLIKELY (priv-&gt;error_count))
3193     priv-&gt;error_count = 0;
3194 
3195 #ifndef GST_DISABLE_DEBUG
3196   if (G_UNLIKELY (priv-&gt;last_reset_time != GST_CLOCK_TIME_NONE)) {
3197     GstClockTime elapsed = gst_util_get_timestamp () - priv-&gt;last_reset_time;
3198 
3199     /* First buffer since reset, report how long we took */
3200     GST_INFO_OBJECT (decoder, &quot;First buffer since flush took %&quot; GST_TIME_FORMAT
3201         &quot; to produce&quot;, GST_TIME_ARGS (elapsed));
3202     priv-&gt;last_reset_time = GST_CLOCK_TIME_NONE;
3203   }
3204 #endif
3205 



3206   ret = gst_pad_push (decoder-&gt;srcpad, buf);

3207 
3208 done:
3209   return ret;
3210 }
3211 
3212 /**
3213  * gst_video_decoder_add_to_frame:
3214  * @decoder: a #GstVideoDecoder
3215  * @n_bytes: the number of bytes to add
3216  *
3217  * Removes next @n_bytes of input data and adds it to currently parsed frame.
3218  */
3219 void
3220 gst_video_decoder_add_to_frame (GstVideoDecoder * decoder, int n_bytes)
3221 {
3222   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3223   GstBuffer *buf;
3224 
3225   GST_LOG_OBJECT (decoder, &quot;add %d bytes to frame&quot;, n_bytes);
3226 
</pre>
<hr />
<pre>
3456  * as the output state for the decoder.
3457  * Any previously set output state on @decoder will be replaced by the newly
3458  * created one.
3459  *
3460  * If the subclass wishes to copy over existing fields (like pixel aspec ratio,
3461  * or framerate) from an existing #GstVideoCodecState, it can be provided as a
3462  * @reference.
3463  *
3464  * If the subclass wishes to override some fields from the output state (like
3465  * pixel-aspect-ratio or framerate) it can do so on the returned #GstVideoCodecState.
3466  *
3467  * The new output state will only take effect (set on pads and buffers) starting
3468  * from the next call to #gst_video_decoder_finish_frame().
3469  *
3470  * Returns: (transfer full): the newly configured output state.
3471  */
3472 GstVideoCodecState *
3473 gst_video_decoder_set_output_state (GstVideoDecoder * decoder,
3474     GstVideoFormat fmt, guint width, guint height,
3475     GstVideoCodecState * reference)

























3476 {
3477   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3478   GstVideoCodecState *state;
3479 
3480   GST_DEBUG_OBJECT (decoder, &quot;fmt:%d, width:%d, height:%d, reference:%p&quot;,
3481       fmt, width, height, reference);
3482 
3483   /* Create the new output state */
<span class="line-modified">3484   state = _new_output_state (fmt, width, height, reference);</span>
3485   if (!state)
3486     return NULL;
3487 
3488   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3489 
3490   GST_OBJECT_LOCK (decoder);
3491   /* Replace existing output state by new one */
3492   if (priv-&gt;output_state)
3493     gst_video_codec_state_unref (priv-&gt;output_state);
3494   priv-&gt;output_state = gst_video_codec_state_ref (state);
3495 
3496   if (priv-&gt;output_state != NULL &amp;&amp; priv-&gt;output_state-&gt;info.fps_n &gt; 0) {
3497     priv-&gt;qos_frame_duration =
3498         gst_util_uint64_scale (GST_SECOND, priv-&gt;output_state-&gt;info.fps_d,
3499         priv-&gt;output_state-&gt;info.fps_n);
3500   } else {
3501     priv-&gt;qos_frame_duration = 0;
3502   }
3503   priv-&gt;output_state_changed = TRUE;
3504   GST_OBJECT_UNLOCK (decoder);
</pre>
<hr />
<pre>
4374  * Returns: (transfer full): the instance of the #GstBufferPool used
4375  * by the decoder; free it after use it
4376  */
4377 GstBufferPool *
4378 gst_video_decoder_get_buffer_pool (GstVideoDecoder * decoder)
4379 {
4380   g_return_val_if_fail (GST_IS_VIDEO_DECODER (decoder), NULL);
4381 
4382   if (decoder-&gt;priv-&gt;pool)
4383     return gst_object_ref (decoder-&gt;priv-&gt;pool);
4384 
4385   return NULL;
4386 }
4387 
4388 /**
4389  * gst_video_decoder_get_allocator:
4390  * @decoder: a #GstVideoDecoder
4391  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
4392  * used
4393  * @params: (out) (allow-none) (transfer full): the
<span class="line-modified">4394  * #GstAllocatorParams of @allocator</span>
4395  *
4396  * Lets #GstVideoDecoder sub-classes to know the memory @allocator
4397  * used by the base class and its @params.
4398  *
4399  * Unref the @allocator after use it.
4400  */
4401 void
4402 gst_video_decoder_get_allocator (GstVideoDecoder * decoder,
4403     GstAllocator ** allocator, GstAllocationParams * params)
4404 {
4405   g_return_if_fail (GST_IS_VIDEO_DECODER (decoder));
4406 
4407   if (allocator)
4408     *allocator = decoder-&gt;priv-&gt;allocator ?
4409         gst_object_ref (decoder-&gt;priv-&gt;allocator) : NULL;
4410 
4411   if (params)
4412     *params = decoder-&gt;priv-&gt;params;
4413 }
4414 
</pre>
</td>
<td>
<hr />
<pre>
 271  *    gather queue:    1
 272  *    decode queue:
 273  *    output queue:    4  3  2
 274  *
 275  *  Leftover buffer 1 cannot be decoded and must be discarded.
 276  */
 277 
 278 #include &quot;gstvideodecoder.h&quot;
 279 #include &quot;gstvideoutils.h&quot;
 280 #include &quot;gstvideoutilsprivate.h&quot;
 281 
 282 #include &lt;gst/video/video.h&gt;
 283 #include &lt;gst/video/video-event.h&gt;
 284 #include &lt;gst/video/gstvideopool.h&gt;
 285 #include &lt;gst/video/gstvideometa.h&gt;
 286 #include &lt;string.h&gt;
 287 
 288 GST_DEBUG_CATEGORY (videodecoder_debug);
 289 #define GST_CAT_DEFAULT videodecoder_debug
 290 




 291 struct _GstVideoDecoderPrivate
 292 {
 293   /* FIXME introduce a context ? */
 294 
 295   GstBufferPool *pool;
 296   GstAllocator *allocator;
 297   GstAllocationParams params;
 298 
 299   /* parse tracking */
 300   /* input data */
 301   GstAdapter *input_adapter;
 302   /* assembles current frame */
 303   GstAdapter *output_adapter;
 304 
 305   /* Whether we attempt to convert newsegment from bytes to
 306    * time using a bitrate estimation */
 307   gboolean do_estimate_rate;
 308 
 309   /* Whether input is considered packetized or not */
 310   gboolean packetized;
</pre>
<hr />
<pre>
 389   /* upstream stream tags (global tags are passed through as-is) */
 390   GstTagList *upstream_tags;
 391 
 392   /* subclass tags */
 393   GstTagList *tags;
 394   GstTagMergeMode tags_merge_mode;
 395 
 396   gboolean tags_changed;
 397 
 398   /* flags */
 399   gboolean use_default_pad_acceptcaps;
 400 
 401 #ifndef GST_DISABLE_DEBUG
 402   /* Diagnostic time for reporting the time
 403    * from flush to first output */
 404   GstClockTime last_reset_time;
 405 #endif
 406 };
 407 
 408 static GstElementClass *parent_class = NULL;
<span class="line-added"> 409 static gint private_offset = 0;</span>
<span class="line-added"> 410 </span>
 411 static void gst_video_decoder_class_init (GstVideoDecoderClass * klass);
 412 static void gst_video_decoder_init (GstVideoDecoder * dec,
 413     GstVideoDecoderClass * klass);
 414 
 415 static void gst_video_decoder_finalize (GObject * object);
 416 
 417 static gboolean gst_video_decoder_setcaps (GstVideoDecoder * dec,
 418     GstCaps * caps);
 419 static gboolean gst_video_decoder_sink_event (GstPad * pad, GstObject * parent,
 420     GstEvent * event);
 421 static gboolean gst_video_decoder_src_event (GstPad * pad, GstObject * parent,
 422     GstEvent * event);
 423 static GstFlowReturn gst_video_decoder_chain (GstPad * pad, GstObject * parent,
 424     GstBuffer * buf);
 425 static gboolean gst_video_decoder_sink_query (GstPad * pad, GstObject * parent,
 426     GstQuery * query);
 427 static GstStateChangeReturn gst_video_decoder_change_state (GstElement *
 428     element, GstStateChange transition);
 429 static gboolean gst_video_decoder_src_query (GstPad * pad, GstObject * parent,
 430     GstQuery * query);
</pre>
<hr />
<pre>
 474 gst_video_decoder_get_type (void)
 475 {
 476   static volatile gsize type = 0;
 477 
 478   if (g_once_init_enter (&amp;type)) {
 479     GType _type;
 480     static const GTypeInfo info = {
 481       sizeof (GstVideoDecoderClass),
 482       NULL,
 483       NULL,
 484       (GClassInitFunc) gst_video_decoder_class_init,
 485       NULL,
 486       NULL,
 487       sizeof (GstVideoDecoder),
 488       0,
 489       (GInstanceInitFunc) gst_video_decoder_init,
 490     };
 491 
 492     _type = g_type_register_static (GST_TYPE_ELEMENT,
 493         &quot;GstVideoDecoder&quot;, &amp;info, G_TYPE_FLAG_ABSTRACT);
<span class="line-added"> 494 </span>
<span class="line-added"> 495     private_offset =</span>
<span class="line-added"> 496         g_type_add_instance_private (_type, sizeof (GstVideoDecoderPrivate));</span>
<span class="line-added"> 497 </span>
 498     g_once_init_leave (&amp;type, _type);
 499   }
 500   return type;
 501 }
 502 
<span class="line-added"> 503 static inline GstVideoDecoderPrivate *</span>
<span class="line-added"> 504 gst_video_decoder_get_instance_private (GstVideoDecoder * self)</span>
<span class="line-added"> 505 {</span>
<span class="line-added"> 506   return (G_STRUCT_MEMBER_P (self, private_offset));</span>
<span class="line-added"> 507 }</span>
<span class="line-added"> 508 </span>
 509 static void
 510 gst_video_decoder_class_init (GstVideoDecoderClass * klass)
 511 {
 512   GObjectClass *gobject_class;
 513   GstElementClass *gstelement_class;
 514 
 515   gobject_class = G_OBJECT_CLASS (klass);
 516   gstelement_class = GST_ELEMENT_CLASS (klass);
 517 
 518   GST_DEBUG_CATEGORY_INIT (videodecoder_debug, &quot;videodecoder&quot;, 0,
 519       &quot;Base Video Decoder&quot;);
 520 
 521   parent_class = g_type_class_peek_parent (klass);
<span class="line-modified"> 522 </span>
<span class="line-added"> 523   if (private_offset != 0)</span>
<span class="line-added"> 524     g_type_class_adjust_private_offset (klass, &amp;private_offset);</span>
 525 
 526   gobject_class-&gt;finalize = gst_video_decoder_finalize;
 527 
 528   gstelement_class-&gt;change_state =
 529       GST_DEBUG_FUNCPTR (gst_video_decoder_change_state);
 530 
 531   klass-&gt;sink_event = gst_video_decoder_sink_event_default;
 532   klass-&gt;src_event = gst_video_decoder_src_event_default;
 533   klass-&gt;decide_allocation = gst_video_decoder_decide_allocation_default;
 534   klass-&gt;propose_allocation = gst_video_decoder_propose_allocation_default;
 535   klass-&gt;negotiate = gst_video_decoder_negotiate_default;
 536   klass-&gt;sink_query = gst_video_decoder_sink_query_default;
 537   klass-&gt;src_query = gst_video_decoder_src_query_default;
 538   klass-&gt;transform_meta = gst_video_decoder_transform_meta_default;
 539 }
 540 
 541 static void
 542 gst_video_decoder_init (GstVideoDecoder * decoder, GstVideoDecoderClass * klass)
 543 {
 544   GstPadTemplate *pad_template;
 545   GstPad *pad;
 546 
 547   GST_DEBUG_OBJECT (decoder, &quot;gst_video_decoder_init&quot;);
 548 
<span class="line-modified"> 549   decoder-&gt;priv = gst_video_decoder_get_instance_private (decoder);</span>
 550 
 551   pad_template =
 552       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 553   g_return_if_fail (pad_template != NULL);
 554 
 555   decoder-&gt;sinkpad = pad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 556 
 557   gst_pad_set_chain_function (pad, GST_DEBUG_FUNCPTR (gst_video_decoder_chain));
 558   gst_pad_set_event_function (pad,
 559       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_event));
 560   gst_pad_set_query_function (pad,
 561       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_query));
 562   gst_element_add_pad (GST_ELEMENT (decoder), decoder-&gt;sinkpad);
 563 
 564   pad_template =
 565       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 566   g_return_if_fail (pad_template != NULL);
 567 
 568   decoder-&gt;srcpad = pad = gst_pad_new_from_template (pad_template, &quot;src&quot;);
 569 
</pre>
<hr />
<pre>
 602   if (G_UNLIKELY (!gst_video_info_from_caps (&amp;state-&gt;info, caps)))
 603     goto parse_fail;
 604   state-&gt;caps = gst_caps_ref (caps);
 605 
 606   structure = gst_caps_get_structure (caps, 0);
 607 
 608   codec_data = gst_structure_get_value (structure, &quot;codec_data&quot;);
 609   if (codec_data &amp;&amp; G_VALUE_TYPE (codec_data) == GST_TYPE_BUFFER)
 610     state-&gt;codec_data = GST_BUFFER (g_value_dup_boxed (codec_data));
 611 
 612   return state;
 613 
 614 parse_fail:
 615   {
 616     g_slice_free (GstVideoCodecState, state);
 617     return NULL;
 618   }
 619 }
 620 
 621 static GstVideoCodecState *
<span class="line-modified"> 622 _new_output_state (GstVideoFormat fmt, GstVideoInterlaceMode mode, guint width,</span>
<span class="line-modified"> 623     guint height, GstVideoCodecState * reference)</span>
 624 {
 625   GstVideoCodecState *state;
 626 
 627   state = g_slice_new0 (GstVideoCodecState);
 628   state-&gt;ref_count = 1;
 629   gst_video_info_init (&amp;state-&gt;info);
<span class="line-modified"> 630   if (!gst_video_info_set_interlaced_format (&amp;state-&gt;info, fmt, mode, width,</span>
<span class="line-added"> 631           height)) {</span>
 632     g_slice_free (GstVideoCodecState, state);
 633     return NULL;
 634   }
 635 
 636   if (reference) {
 637     GstVideoInfo *tgt, *ref;
 638 
 639     tgt = &amp;state-&gt;info;
 640     ref = &amp;reference-&gt;info;
 641 
 642     /* Copy over extra fields from reference state */
 643     tgt-&gt;interlace_mode = ref-&gt;interlace_mode;
 644     tgt-&gt;flags = ref-&gt;flags;
 645     /* only copy values that are not unknown so that we don&#39;t override the
 646      * defaults. subclasses should really fill these in when they know. */
 647     if (ref-&gt;chroma_site)
 648       tgt-&gt;chroma_site = ref-&gt;chroma_site;
 649     if (ref-&gt;colorimetry.range)
 650       tgt-&gt;colorimetry.range = ref-&gt;colorimetry.range;
 651     if (ref-&gt;colorimetry.matrix)
</pre>
<hr />
<pre>
 984   templcaps = gst_pad_get_pad_template_caps (decoder-&gt;srcpad);
 985   caps = gst_pad_peer_query_caps (decoder-&gt;srcpad, templcaps);
 986   if (caps)
 987     gst_caps_unref (templcaps);
 988   else
 989     caps = templcaps;
 990   templcaps = NULL;
 991 
 992   if (!caps || gst_caps_is_empty (caps) || gst_caps_is_any (caps))
 993     goto caps_error;
 994 
 995   GST_LOG_OBJECT (decoder, &quot;peer caps %&quot; GST_PTR_FORMAT, caps);
 996 
 997   /* before fixating, try to use whatever upstream provided */
 998   caps = gst_caps_make_writable (caps);
 999   caps_size = gst_caps_get_size (caps);
1000   if (decoder-&gt;priv-&gt;input_state &amp;&amp; decoder-&gt;priv-&gt;input_state-&gt;caps) {
1001     GstCaps *sinkcaps = decoder-&gt;priv-&gt;input_state-&gt;caps;
1002     GstStructure *structure = gst_caps_get_structure (sinkcaps, 0);
1003     gint width, height;


1004 
1005     if (gst_structure_get_int (structure, &quot;width&quot;, &amp;width)) {
1006       for (i = 0; i &lt; caps_size; i++) {
1007         gst_structure_set (gst_caps_get_structure (caps, i), &quot;width&quot;,
1008             G_TYPE_INT, width, NULL);
1009       }
1010     }
1011 
1012     if (gst_structure_get_int (structure, &quot;height&quot;, &amp;height)) {
1013       for (i = 0; i &lt; caps_size; i++) {
1014         gst_structure_set (gst_caps_get_structure (caps, i), &quot;height&quot;,
1015             G_TYPE_INT, height, NULL);
1016       }
1017     }















1018   }
1019 
1020   for (i = 0; i &lt; caps_size; i++) {
1021     structure = gst_caps_get_structure (caps, i);
<span class="line-modified">1022     /* Random I420 1280x720 for fixation */</span>
1023     if (gst_structure_has_field (structure, &quot;format&quot;))
1024       gst_structure_fixate_field_string (structure, &quot;format&quot;, &quot;I420&quot;);
1025     else
1026       gst_structure_set (structure, &quot;format&quot;, G_TYPE_STRING, &quot;I420&quot;, NULL);
1027 
1028     if (gst_structure_has_field (structure, &quot;width&quot;))
1029       gst_structure_fixate_field_nearest_int (structure, &quot;width&quot;, 1280);
1030     else
1031       gst_structure_set (structure, &quot;width&quot;, G_TYPE_INT, 1280, NULL);
1032 
1033     if (gst_structure_has_field (structure, &quot;height&quot;))
1034       gst_structure_fixate_field_nearest_int (structure, &quot;height&quot;, 720);
1035     else
1036       gst_structure_set (structure, &quot;height&quot;, G_TYPE_INT, 720, NULL);














1037   }
1038   caps = gst_caps_fixate (caps);

1039 
1040   if (!caps || !gst_video_info_from_caps (&amp;info, caps))
1041     goto caps_error;
1042 
1043   GST_INFO_OBJECT (decoder,
1044       &quot;Chose default caps %&quot; GST_PTR_FORMAT &quot; for initial gap&quot;, caps);
1045   state =
1046       gst_video_decoder_set_output_state (decoder, info.finfo-&gt;format,
1047       info.width, info.height, decoder-&gt;priv-&gt;input_state);
1048   gst_video_codec_state_unref (state);
1049   gst_caps_unref (caps);
1050 
1051   return TRUE;
1052 
1053 caps_error:
1054   {
1055     if (caps)
1056       gst_caps_unref (caps);
1057     return FALSE;
1058   }
</pre>
<hr />
<pre>
1142 
1143       /* Forward EOS immediately. This is required because no
1144        * buffer or serialized event will come after EOS and
1145        * nothing could trigger another _finish_frame() call.
1146        *
1147        * The subclass can override this behaviour by overriding
1148        * the ::sink_event() vfunc and not chaining up to the
1149        * parent class&#39; ::sink_event() until a later time.
1150        */
1151       forward_immediate = TRUE;
1152       break;
1153     }
1154     case GST_EVENT_GAP:
1155     {
1156       GstFlowReturn flow_ret = GST_FLOW_OK;
1157       gboolean needs_reconfigure = FALSE;
1158       GList *events;
1159       GList *frame_events;
1160 
1161       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
<span class="line-modified">1162       if (decoder-&gt;input_segment.flags &amp; GST_SEEK_FLAG_TRICKMODE_KEY_UNITS)</span>
<span class="line-added">1163         flow_ret = gst_video_decoder_drain_out (decoder, FALSE);</span>
1164       ret = (flow_ret == GST_FLOW_OK);
1165 
1166       /* Ensure we have caps before forwarding the event */
1167       if (!decoder-&gt;priv-&gt;output_state) {
1168         if (!gst_video_decoder_negotiate_default_caps (decoder)) {
1169           GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1170           GST_ELEMENT_ERROR (decoder, STREAM, FORMAT, (NULL),
1171               (&quot;Decoder output not negotiated before GAP event.&quot;));
1172           forward_immediate = TRUE;
1173           break;
1174         }
1175         needs_reconfigure = TRUE;
1176       }
1177 
1178       needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad)
1179           || needs_reconfigure;
1180       if (decoder-&gt;priv-&gt;output_state_changed || needs_reconfigure) {
1181         if (!gst_video_decoder_negotiate_unlocked (decoder)) {
1182           GST_WARNING_OBJECT (decoder, &quot;Failed to negotiate with downstream&quot;);
1183           gst_pad_mark_reconfigure (decoder-&gt;srcpad);
</pre>
<hr />
<pre>
2077 
2078   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2079 }
2080 
2081 static GstFlowReturn
2082 gst_video_decoder_chain_forward (GstVideoDecoder * decoder,
2083     GstBuffer * buf, gboolean at_eos)
2084 {
2085   GstVideoDecoderPrivate *priv;
2086   GstVideoDecoderClass *klass;
2087   GstFlowReturn ret = GST_FLOW_OK;
2088 
2089   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
2090   priv = decoder-&gt;priv;
2091 
2092   g_return_val_if_fail (priv-&gt;packetized || klass-&gt;parse, GST_FLOW_ERROR);
2093 
2094   /* Draining on DISCONT is handled in chain_reverse() for reverse playback,
2095    * and this function would only be called to get everything collected GOP
2096    * by GOP in the parse_gather list */
<span class="line-modified">2097   if (decoder-&gt;input_segment.rate &gt; 0.0 &amp;&amp; GST_BUFFER_IS_DISCONT (buf)</span>
<span class="line-added">2098       &amp;&amp; (decoder-&gt;input_segment.flags &amp; GST_SEEK_FLAG_TRICKMODE_KEY_UNITS))</span>
2099     ret = gst_video_decoder_drain_out (decoder, FALSE);
2100 
2101   if (priv-&gt;current_frame == NULL)
2102     priv-&gt;current_frame = gst_video_decoder_new_frame (decoder);
2103 
2104   if (!priv-&gt;packetized)
2105     gst_video_decoder_add_buffer_info (decoder, buf);
2106 
2107   priv-&gt;input_offset += gst_buffer_get_size (buf);
2108 
2109   if (priv-&gt;packetized) {
2110     gboolean was_keyframe = FALSE;
2111     if (!GST_BUFFER_FLAG_IS_SET (buf, GST_BUFFER_FLAG_DELTA_UNIT)) {
2112       was_keyframe = TRUE;
2113       GST_LOG_OBJECT (decoder, &quot;Marking current_frame as sync point&quot;);
2114       GST_VIDEO_CODEC_FRAME_SET_SYNC_POINT (priv-&gt;current_frame);
2115     }
2116 
2117     priv-&gt;current_frame-&gt;input_buffer = buf;
2118 
</pre>
<hr />
<pre>
2303       /* We need to tell the subclass to drain now.
2304        * We prefer the drain vfunc, but for backward-compat
2305        * we use a finish() vfunc if drain isn&#39;t implemented */
2306       if (decoder_class-&gt;drain) {
2307         GST_DEBUG_OBJECT (dec, &quot;Draining&quot;);
2308         res = decoder_class-&gt;drain (dec);
2309       } else if (decoder_class-&gt;finish) {
2310         GST_FIXME_OBJECT (dec, &quot;Sub-class should implement drain(). &quot;
2311             &quot;Calling finish() for backwards-compat&quot;);
2312         res = decoder_class-&gt;finish (dec);
2313       }
2314 
2315       if (res != GST_FLOW_OK)
2316         goto done;
2317 
2318       /* now send queued data downstream */
2319       walk = priv-&gt;output_queued;
2320       while (walk) {
2321         GstBuffer *buf = GST_BUFFER_CAST (walk-&gt;data);
2322 
<span class="line-added">2323         priv-&gt;output_queued =</span>
<span class="line-added">2324             g_list_delete_link (priv-&gt;output_queued, priv-&gt;output_queued);</span>
<span class="line-added">2325 </span>
2326         if (G_LIKELY (res == GST_FLOW_OK)) {
2327           /* avoid stray DISCONT from forward processing,
2328            * which have no meaning in reverse pushing */
2329           GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DISCONT);
2330 
2331           /* Last chance to calculate a timestamp as we loop backwards
2332            * through the list */
2333           if (GST_BUFFER_TIMESTAMP (buf) != GST_CLOCK_TIME_NONE)
2334             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2335           else if (priv-&gt;last_timestamp_out != GST_CLOCK_TIME_NONE &amp;&amp;
2336               GST_BUFFER_DURATION (buf) != GST_CLOCK_TIME_NONE) {
2337             GST_BUFFER_TIMESTAMP (buf) =
2338                 priv-&gt;last_timestamp_out - GST_BUFFER_DURATION (buf);
2339             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2340             GST_LOG_OBJECT (dec,
2341                 &quot;Calculated TS %&quot; GST_TIME_FORMAT &quot; working backwards&quot;,
2342                 GST_TIME_ARGS (priv-&gt;last_timestamp_out));
2343           }
2344 
2345           res = gst_video_decoder_clip_and_push_buf (dec, buf);
2346         } else {
2347           gst_buffer_unref (buf);
2348         }
2349 


2350         walk = priv-&gt;output_queued;
2351       }
2352 
2353       /* clear buffer and decoder state again
2354        * before moving to the previous keyframe */
2355       gst_video_decoder_flush (dec, FALSE);
2356     }
2357 
2358     walk = priv-&gt;parse_gather;
2359   }
2360 
2361 done:
2362   return res;
2363 }
2364 
2365 static GstFlowReturn
2366 gst_video_decoder_chain_reverse (GstVideoDecoder * dec, GstBuffer * buf)
2367 {
2368   GstVideoDecoderPrivate *priv = dec-&gt;priv;
2369   GstFlowReturn result = GST_FLOW_OK;
</pre>
<hr />
<pre>
3168       gst_buffer_get_size (buf),
3169       GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
3170       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
3171 
3172   /* we got data, so note things are looking up again, reduce
3173    * the error count, if there is one */
3174   if (G_UNLIKELY (priv-&gt;error_count))
3175     priv-&gt;error_count = 0;
3176 
3177 #ifndef GST_DISABLE_DEBUG
3178   if (G_UNLIKELY (priv-&gt;last_reset_time != GST_CLOCK_TIME_NONE)) {
3179     GstClockTime elapsed = gst_util_get_timestamp () - priv-&gt;last_reset_time;
3180 
3181     /* First buffer since reset, report how long we took */
3182     GST_INFO_OBJECT (decoder, &quot;First buffer since flush took %&quot; GST_TIME_FORMAT
3183         &quot; to produce&quot;, GST_TIME_ARGS (elapsed));
3184     priv-&gt;last_reset_time = GST_CLOCK_TIME_NONE;
3185   }
3186 #endif
3187 
<span class="line-added">3188   /* release STREAM_LOCK not to block upstream</span>
<span class="line-added">3189    * while pushing buffer downstream */</span>
<span class="line-added">3190   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);</span>
3191   ret = gst_pad_push (decoder-&gt;srcpad, buf);
<span class="line-added">3192   GST_VIDEO_DECODER_STREAM_LOCK (decoder);</span>
3193 
3194 done:
3195   return ret;
3196 }
3197 
3198 /**
3199  * gst_video_decoder_add_to_frame:
3200  * @decoder: a #GstVideoDecoder
3201  * @n_bytes: the number of bytes to add
3202  *
3203  * Removes next @n_bytes of input data and adds it to currently parsed frame.
3204  */
3205 void
3206 gst_video_decoder_add_to_frame (GstVideoDecoder * decoder, int n_bytes)
3207 {
3208   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3209   GstBuffer *buf;
3210 
3211   GST_LOG_OBJECT (decoder, &quot;add %d bytes to frame&quot;, n_bytes);
3212 
</pre>
<hr />
<pre>
3442  * as the output state for the decoder.
3443  * Any previously set output state on @decoder will be replaced by the newly
3444  * created one.
3445  *
3446  * If the subclass wishes to copy over existing fields (like pixel aspec ratio,
3447  * or framerate) from an existing #GstVideoCodecState, it can be provided as a
3448  * @reference.
3449  *
3450  * If the subclass wishes to override some fields from the output state (like
3451  * pixel-aspect-ratio or framerate) it can do so on the returned #GstVideoCodecState.
3452  *
3453  * The new output state will only take effect (set on pads and buffers) starting
3454  * from the next call to #gst_video_decoder_finish_frame().
3455  *
3456  * Returns: (transfer full): the newly configured output state.
3457  */
3458 GstVideoCodecState *
3459 gst_video_decoder_set_output_state (GstVideoDecoder * decoder,
3460     GstVideoFormat fmt, guint width, guint height,
3461     GstVideoCodecState * reference)
<span class="line-added">3462 {</span>
<span class="line-added">3463   return gst_video_decoder_set_interlaced_output_state (decoder, fmt,</span>
<span class="line-added">3464       GST_VIDEO_INTERLACE_MODE_PROGRESSIVE, width, height, reference);</span>
<span class="line-added">3465 }</span>
<span class="line-added">3466 </span>
<span class="line-added">3467 /**</span>
<span class="line-added">3468  * gst_video_decoder_set_interlaced_output_state:</span>
<span class="line-added">3469  * @decoder: a #GstVideoDecoder</span>
<span class="line-added">3470  * @fmt: a #GstVideoFormat</span>
<span class="line-added">3471  * @width: The width in pixels</span>
<span class="line-added">3472  * @height: The height in pixels</span>
<span class="line-added">3473  * @mode: A #GstVideoInterlaceMode</span>
<span class="line-added">3474  * @reference: (allow-none) (transfer none): An optional reference #GstVideoCodecState</span>
<span class="line-added">3475  *</span>
<span class="line-added">3476  * Same as #gst_video_decoder_set_output_state() but also allows you to also set</span>
<span class="line-added">3477  * the interlacing mode.</span>
<span class="line-added">3478  *</span>
<span class="line-added">3479  * Returns: (transfer full): the newly configured output state.</span>
<span class="line-added">3480  *</span>
<span class="line-added">3481  * Since: 1.16.</span>
<span class="line-added">3482  */</span>
<span class="line-added">3483 GstVideoCodecState *</span>
<span class="line-added">3484 gst_video_decoder_set_interlaced_output_state (GstVideoDecoder * decoder,</span>
<span class="line-added">3485     GstVideoFormat fmt, GstVideoInterlaceMode mode, guint width, guint height,</span>
<span class="line-added">3486     GstVideoCodecState * reference)</span>
3487 {
3488   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3489   GstVideoCodecState *state;
3490 
3491   GST_DEBUG_OBJECT (decoder, &quot;fmt:%d, width:%d, height:%d, reference:%p&quot;,
3492       fmt, width, height, reference);
3493 
3494   /* Create the new output state */
<span class="line-modified">3495   state = _new_output_state (fmt, mode, width, height, reference);</span>
3496   if (!state)
3497     return NULL;
3498 
3499   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3500 
3501   GST_OBJECT_LOCK (decoder);
3502   /* Replace existing output state by new one */
3503   if (priv-&gt;output_state)
3504     gst_video_codec_state_unref (priv-&gt;output_state);
3505   priv-&gt;output_state = gst_video_codec_state_ref (state);
3506 
3507   if (priv-&gt;output_state != NULL &amp;&amp; priv-&gt;output_state-&gt;info.fps_n &gt; 0) {
3508     priv-&gt;qos_frame_duration =
3509         gst_util_uint64_scale (GST_SECOND, priv-&gt;output_state-&gt;info.fps_d,
3510         priv-&gt;output_state-&gt;info.fps_n);
3511   } else {
3512     priv-&gt;qos_frame_duration = 0;
3513   }
3514   priv-&gt;output_state_changed = TRUE;
3515   GST_OBJECT_UNLOCK (decoder);
</pre>
<hr />
<pre>
4385  * Returns: (transfer full): the instance of the #GstBufferPool used
4386  * by the decoder; free it after use it
4387  */
4388 GstBufferPool *
4389 gst_video_decoder_get_buffer_pool (GstVideoDecoder * decoder)
4390 {
4391   g_return_val_if_fail (GST_IS_VIDEO_DECODER (decoder), NULL);
4392 
4393   if (decoder-&gt;priv-&gt;pool)
4394     return gst_object_ref (decoder-&gt;priv-&gt;pool);
4395 
4396   return NULL;
4397 }
4398 
4399 /**
4400  * gst_video_decoder_get_allocator:
4401  * @decoder: a #GstVideoDecoder
4402  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
4403  * used
4404  * @params: (out) (allow-none) (transfer full): the
<span class="line-modified">4405  * #GstAllocationParams of @allocator</span>
4406  *
4407  * Lets #GstVideoDecoder sub-classes to know the memory @allocator
4408  * used by the base class and its @params.
4409  *
4410  * Unref the @allocator after use it.
4411  */
4412 void
4413 gst_video_decoder_get_allocator (GstVideoDecoder * decoder,
4414     GstAllocator ** allocator, GstAllocationParams * params)
4415 {
4416   g_return_if_fail (GST_IS_VIDEO_DECODER (decoder));
4417 
4418   if (allocator)
4419     *allocator = decoder-&gt;priv-&gt;allocator ?
4420         gst_object_ref (decoder-&gt;priv-&gt;allocator) : NULL;
4421 
4422   if (params)
4423     *params = decoder-&gt;priv-&gt;params;
4424 }
4425 
</pre>
</td>
</tr>
</table>
<center><a href="convertframe.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="gstvideodecoder.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>