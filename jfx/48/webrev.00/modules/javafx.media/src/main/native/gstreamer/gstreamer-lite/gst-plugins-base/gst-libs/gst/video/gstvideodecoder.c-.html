<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideodecoder.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /* GStreamer
   2  * Copyright (C) 2008 David Schleef &lt;ds@schleef.org&gt;
   3  * Copyright (C) 2011 Mark Nauwelaerts &lt;mark.nauwelaerts@collabora.co.uk&gt;.
   4  * Copyright (C) 2011 Nokia Corporation. All rights reserved.
   5  *   Contact: Stefan Kost &lt;stefan.kost@nokia.com&gt;
   6  * Copyright (C) 2012 Collabora Ltd.
   7  *  Author : Edward Hervey &lt;edward@collabora.com&gt;
   8  *
   9  * This library is free software; you can redistribute it and/or
  10  * modify it under the terms of the GNU Library General Public
  11  * License as published by the Free Software Foundation; either
  12  * version 2 of the License, or (at your option) any later version.
  13  *
  14  * This library is distributed in the hope that it will be useful,
  15  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  16  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  17  * Library General Public License for more details.
  18  *
  19  * You should have received a copy of the GNU Library General Public
  20  * License along with this library; if not, write to the
  21  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
  22  * Boston, MA 02110-1301, USA.
  23  */
  24 
  25 /**
  26  * SECTION:gstvideodecoder
  27  * @title: GstVideoDecoder
  28  * @short_description: Base class for video decoders
  29  * @see_also:
  30  *
  31  * This base class is for video decoders turning encoded data into raw video
  32  * frames.
  33  *
  34  * The GstVideoDecoder base class and derived subclasses should cooperate as
  35  * follows:
  36  *
  37  * ## Configuration
  38  *
  39  *   * Initially, GstVideoDecoder calls @start when the decoder element
  40  *     is activated, which allows the subclass to perform any global setup.
  41  *
  42  *   * GstVideoDecoder calls @set_format to inform the subclass of caps
  43  *     describing input video data that it is about to receive, including
  44  *     possibly configuration data.
  45  *     While unlikely, it might be called more than once, if changing input
  46  *     parameters require reconfiguration.
  47  *
  48  *   * Incoming data buffers are processed as needed, described in Data
  49  *     Processing below.
  50  *
  51  *   * GstVideoDecoder calls @stop at end of all processing.
  52  *
  53  * ## Data processing
  54  *
  55  *     * The base class gathers input data, and optionally allows subclass
  56  *       to parse this into subsequently manageable chunks, typically
  57  *       corresponding to and referred to as &#39;frames&#39;.
  58  *
  59  *     * Each input frame is provided in turn to the subclass&#39; @handle_frame
  60  *       callback.
  61  *       The ownership of the frame is given to the @handle_frame callback.
  62  *
  63  *     * If codec processing results in decoded data, the subclass should call
  64  *       @gst_video_decoder_finish_frame to have decoded data pushed.
  65  *       downstream. Otherwise, the subclass must call
  66  *       @gst_video_decoder_drop_frame, to allow the base class to do timestamp
  67  *       and offset tracking, and possibly to requeue the frame for a later
  68  *       attempt in the case of reverse playback.
  69  *
  70  * ## Shutdown phase
  71  *
  72  *   * The GstVideoDecoder class calls @stop to inform the subclass that data
  73  *     parsing will be stopped.
  74  *
  75  * ## Additional Notes
  76  *
  77  *   * Seeking/Flushing
  78  *
  79  *     * When the pipeline is seeked or otherwise flushed, the subclass is
  80  *       informed via a call to its @reset callback, with the hard parameter
  81  *       set to true. This indicates the subclass should drop any internal data
  82  *       queues and timestamps and prepare for a fresh set of buffers to arrive
  83  *       for parsing and decoding.
  84  *
  85  *   * End Of Stream
  86  *
  87  *     * At end-of-stream, the subclass @parse function may be called some final
  88  *       times with the at_eos parameter set to true, indicating that the element
  89  *       should not expect any more data to be arriving, and it should parse and
  90  *       remaining frames and call gst_video_decoder_have_frame() if possible.
  91  *
  92  * The subclass is responsible for providing pad template caps for
  93  * source and sink pads. The pads need to be named &quot;sink&quot; and &quot;src&quot;. It also
  94  * needs to provide information about the ouptput caps, when they are known.
  95  * This may be when the base class calls the subclass&#39; @set_format function,
  96  * though it might be during decoding, before calling
  97  * @gst_video_decoder_finish_frame. This is done via
  98  * @gst_video_decoder_set_output_state
  99  *
 100  * The subclass is also responsible for providing (presentation) timestamps
 101  * (likely based on corresponding input ones).  If that is not applicable
 102  * or possible, the base class provides limited framerate based interpolation.
 103  *
 104  * Similarly, the base class provides some limited (legacy) seeking support
 105  * if specifically requested by the subclass, as full-fledged support
 106  * should rather be left to upstream demuxer, parser or alike.  This simple
 107  * approach caters for seeking and duration reporting using estimated input
 108  * bitrates. To enable it, a subclass should call
 109  * @gst_video_decoder_set_estimate_rate to enable handling of incoming
 110  * byte-streams.
 111  *
 112  * The base class provides some support for reverse playback, in particular
 113  * in case incoming data is not packetized or upstream does not provide
 114  * fragments on keyframe boundaries.  However, the subclass should then be
 115  * prepared for the parsing and frame processing stage to occur separately
 116  * (in normal forward processing, the latter immediately follows the former),
 117  * The subclass also needs to ensure the parsing stage properly marks
 118  * keyframes, unless it knows the upstream elements will do so properly for
 119  * incoming data.
 120  *
 121  * The bare minimum that a functional subclass needs to implement is:
 122  *
 123  *   * Provide pad templates
 124  *   * Inform the base class of output caps via
 125  *      @gst_video_decoder_set_output_state
 126  *
 127  *   * Parse input data, if it is not considered packetized from upstream
 128  *      Data will be provided to @parse which should invoke
 129  *      @gst_video_decoder_add_to_frame and @gst_video_decoder_have_frame to
 130  *      separate the data belonging to each video frame.
 131  *
 132  *   * Accept data in @handle_frame and provide decoded results to
 133  *      @gst_video_decoder_finish_frame, or call @gst_video_decoder_drop_frame.
 134  */
 135 
 136 #ifdef HAVE_CONFIG_H
 137 #include &quot;config.h&quot;
 138 #endif
 139 
 140 /* TODO
 141  *
 142  * * Add a flag/boolean for I-frame-only/image decoders so we can do extra
 143  *   features, like applying QoS on input (as opposed to after the frame is
 144  *   decoded).
 145  * * Add a flag/boolean for decoders that require keyframes, so the base
 146  *   class can automatically discard non-keyframes before one has arrived
 147  * * Detect reordered frame/timestamps and fix the pts/dts
 148  * * Support for GstIndex (or shall we not care ?)
 149  * * Calculate actual latency based on input/output timestamp/frame_number
 150  *   and if it exceeds the recorded one, save it and emit a GST_MESSAGE_LATENCY
 151  * * Emit latency message when it changes
 152  *
 153  */
 154 
 155 /* Implementation notes:
 156  * The Video Decoder base class operates in 2 primary processing modes, depending
 157  * on whether forward or reverse playback is requested.
 158  *
 159  * Forward playback:
 160  *   * Incoming buffer -&gt; @parse() -&gt; add_to_frame()/have_frame() -&gt;
 161  *     handle_frame() -&gt; push downstream
 162  *
 163  * Reverse playback is more complicated, since it involves gathering incoming
 164  * data regions as we loop backwards through the upstream data. The processing
 165  * concept (using incoming buffers as containing one frame each to simplify
 166  * things) is:
 167  *
 168  * Upstream data we want to play:
 169  *  Buffer encoded order:  1  2  3  4  5  6  7  8  9  EOS
 170  *  Keyframe flag:            K        K
 171  *  Groupings:             AAAAAAA  BBBBBBB  CCCCCCC
 172  *
 173  * Input:
 174  *  Buffer reception order:  7  8  9  4  5  6  1  2  3  EOS
 175  *  Keyframe flag:                       K        K
 176  *  Discont flag:            D        D        D
 177  *
 178  * - Each Discont marks a discont in the decoding order.
 179  * - The keyframes mark where we can start decoding.
 180  *
 181  * Initially, we prepend incoming buffers to the gather queue. Whenever the
 182  * discont flag is set on an incoming buffer, the gather queue is flushed out
 183  * before the new buffer is collected.
 184  *
 185  * The above data will be accumulated in the gather queue like this:
 186  *
 187  *   gather queue:  9  8  7
 188  *                        D
 189  *
 190  * When buffer 4 is received (with a DISCONT), we flush the gather queue like
 191  * this:
 192  *
 193  *   while (gather)
 194  *     take head of queue and prepend to parse queue (this reverses the
 195  *     sequence, so parse queue is 7 -&gt; 8 -&gt; 9)
 196  *
 197  *   Next, we process the parse queue, which now contains all un-parsed packets
 198  *   (including any leftover ones from the previous decode section)
 199  *
 200  *   for each buffer now in the parse queue:
 201  *     Call the subclass parse function, prepending each resulting frame to
 202  *     the parse_gather queue. Buffers which precede the first one that
 203  *     produces a parsed frame are retained in the parse queue for
 204  *     re-processing on the next cycle of parsing.
 205  *
 206  *   The parse_gather queue now contains frame objects ready for decoding,
 207  *   in reverse order.
 208  *   parse_gather: 9 -&gt; 8 -&gt; 7
 209  *
 210  *   while (parse_gather)
 211  *     Take the head of the queue and prepend it to the decode queue
 212  *     If the frame was a keyframe, process the decode queue
 213  *   decode is now 7-8-9
 214  *
 215  *  Processing the decode queue results in frames with attached output buffers
 216  *  stored in the &#39;output_queue&#39; ready for outputting in reverse order.
 217  *
 218  * After we flushed the gather queue and parsed it, we add 4 to the (now empty)
 219  * gather queue. We get the following situation:
 220  *
 221  *  gather queue:    4
 222  *  decode queue:    7  8  9
 223  *
 224  * After we received 5 (Keyframe) and 6:
 225  *
 226  *  gather queue:    6  5  4
 227  *  decode queue:    7  8  9
 228  *
 229  * When we receive 1 (DISCONT) which triggers a flush of the gather queue:
 230  *
 231  *   Copy head of the gather queue (6) to decode queue:
 232  *
 233  *    gather queue:    5  4
 234  *    decode queue:    6  7  8  9
 235  *
 236  *   Copy head of the gather queue (5) to decode queue. This is a keyframe so we
 237  *   can start decoding.
 238  *
 239  *    gather queue:    4
 240  *    decode queue:    5  6  7  8  9
 241  *
 242  *   Decode frames in decode queue, store raw decoded data in output queue, we
 243  *   can take the head of the decode queue and prepend the decoded result in the
 244  *   output queue:
 245  *
 246  *    gather queue:    4
 247  *    decode queue:
 248  *    output queue:    9  8  7  6  5
 249  *
 250  *   Now output all the frames in the output queue, picking a frame from the
 251  *   head of the queue.
 252  *
 253  *   Copy head of the gather queue (4) to decode queue, we flushed the gather
 254  *   queue and can now store input buffer in the gather queue:
 255  *
 256  *    gather queue:    1
 257  *    decode queue:    4
 258  *
 259  *  When we receive EOS, the queue looks like:
 260  *
 261  *    gather queue:    3  2  1
 262  *    decode queue:    4
 263  *
 264  *  Fill decode queue, first keyframe we copy is 2:
 265  *
 266  *    gather queue:    1
 267  *    decode queue:    2  3  4
 268  *
 269  *  Decoded output:
 270  *
 271  *    gather queue:    1
 272  *    decode queue:
 273  *    output queue:    4  3  2
 274  *
 275  *  Leftover buffer 1 cannot be decoded and must be discarded.
 276  */
 277 
 278 #include &quot;gstvideodecoder.h&quot;
 279 #include &quot;gstvideoutils.h&quot;
 280 #include &quot;gstvideoutilsprivate.h&quot;
 281 
 282 #include &lt;gst/video/video.h&gt;
 283 #include &lt;gst/video/video-event.h&gt;
 284 #include &lt;gst/video/gstvideopool.h&gt;
 285 #include &lt;gst/video/gstvideometa.h&gt;
 286 #include &lt;string.h&gt;
 287 
 288 GST_DEBUG_CATEGORY (videodecoder_debug);
 289 #define GST_CAT_DEFAULT videodecoder_debug
 290 
 291 #define GST_VIDEO_DECODER_GET_PRIVATE(obj)  \
 292     (G_TYPE_INSTANCE_GET_PRIVATE ((obj), GST_TYPE_VIDEO_DECODER, \
 293         GstVideoDecoderPrivate))
 294 
 295 struct _GstVideoDecoderPrivate
 296 {
 297   /* FIXME introduce a context ? */
 298 
 299   GstBufferPool *pool;
 300   GstAllocator *allocator;
 301   GstAllocationParams params;
 302 
 303   /* parse tracking */
 304   /* input data */
 305   GstAdapter *input_adapter;
 306   /* assembles current frame */
 307   GstAdapter *output_adapter;
 308 
 309   /* Whether we attempt to convert newsegment from bytes to
 310    * time using a bitrate estimation */
 311   gboolean do_estimate_rate;
 312 
 313   /* Whether input is considered packetized or not */
 314   gboolean packetized;
 315 
 316   /* Error handling */
 317   gint max_errors;
 318   gint error_count;
 319   gboolean had_output_data;
 320   gboolean had_input_data;
 321 
 322   gboolean needs_format;
 323   /* input_segment are output_segment identical */
 324   gboolean in_out_segment_sync;
 325 
 326   /* ... being tracked here;
 327    * only available during parsing */
 328   GstVideoCodecFrame *current_frame;
 329   /* events that should apply to the current frame */
 330   GList *current_frame_events;
 331   /* events that should be pushed before the next frame */
 332   GList *pending_events;
 333 
 334   /* relative offset of input data */
 335   guint64 input_offset;
 336   /* relative offset of frame */
 337   guint64 frame_offset;
 338   /* tracking ts and offsets */
 339   GList *timestamps;
 340 
 341   /* last outgoing ts */
 342   GstClockTime last_timestamp_out;
 343   /* incoming pts - dts */
 344   GstClockTime pts_delta;
 345   gboolean reordered_output;
 346 
 347   /* reverse playback */
 348   /* collect input */
 349   GList *gather;
 350   /* to-be-parsed */
 351   GList *parse;
 352   /* collected parsed frames */
 353   GList *parse_gather;
 354   /* frames to be handled == decoded */
 355   GList *decode;
 356   /* collected output - of buffer objects, not frames */
 357   GList *output_queued;
 358 
 359 
 360   /* base_picture_number is the picture number of the reference picture */
 361   guint64 base_picture_number;
 362   /* combine with base_picture_number, framerate and calcs to yield (presentation) ts */
 363   GstClockTime base_timestamp;
 364 
 365   /* FIXME : reorder_depth is never set */
 366   int reorder_depth;
 367   int distance_from_sync;
 368 
 369   guint32 system_frame_number;
 370   guint32 decode_frame_number;
 371 
 372   GList *frames;                /* Protected with OBJECT_LOCK */
 373   GstVideoCodecState *input_state;
 374   GstVideoCodecState *output_state;     /* OBJECT_LOCK and STREAM_LOCK */
 375   gboolean output_state_changed;
 376 
 377   /* QoS properties */
 378   gdouble proportion;           /* OBJECT_LOCK */
 379   GstClockTime earliest_time;   /* OBJECT_LOCK */
 380   GstClockTime qos_frame_duration;      /* OBJECT_LOCK */
 381   gboolean discont;
 382   /* qos messages: frames dropped/processed */
 383   guint dropped;
 384   guint processed;
 385 
 386   /* Outgoing byte size ? */
 387   gint64 bytes_out;
 388   gint64 time;
 389 
 390   gint64 min_latency;
 391   gint64 max_latency;
 392 
 393   /* upstream stream tags (global tags are passed through as-is) */
 394   GstTagList *upstream_tags;
 395 
 396   /* subclass tags */
 397   GstTagList *tags;
 398   GstTagMergeMode tags_merge_mode;
 399 
 400   gboolean tags_changed;
 401 
 402   /* flags */
 403   gboolean use_default_pad_acceptcaps;
 404 
 405 #ifndef GST_DISABLE_DEBUG
 406   /* Diagnostic time for reporting the time
 407    * from flush to first output */
 408   GstClockTime last_reset_time;
 409 #endif
 410 };
 411 
 412 static GstElementClass *parent_class = NULL;
 413 static void gst_video_decoder_class_init (GstVideoDecoderClass * klass);
 414 static void gst_video_decoder_init (GstVideoDecoder * dec,
 415     GstVideoDecoderClass * klass);
 416 
 417 static void gst_video_decoder_finalize (GObject * object);
 418 
 419 static gboolean gst_video_decoder_setcaps (GstVideoDecoder * dec,
 420     GstCaps * caps);
 421 static gboolean gst_video_decoder_sink_event (GstPad * pad, GstObject * parent,
 422     GstEvent * event);
 423 static gboolean gst_video_decoder_src_event (GstPad * pad, GstObject * parent,
 424     GstEvent * event);
 425 static GstFlowReturn gst_video_decoder_chain (GstPad * pad, GstObject * parent,
 426     GstBuffer * buf);
 427 static gboolean gst_video_decoder_sink_query (GstPad * pad, GstObject * parent,
 428     GstQuery * query);
 429 static GstStateChangeReturn gst_video_decoder_change_state (GstElement *
 430     element, GstStateChange transition);
 431 static gboolean gst_video_decoder_src_query (GstPad * pad, GstObject * parent,
 432     GstQuery * query);
 433 static void gst_video_decoder_reset (GstVideoDecoder * decoder, gboolean full,
 434     gboolean flush_hard);
 435 
 436 static GstFlowReturn gst_video_decoder_decode_frame (GstVideoDecoder * decoder,
 437     GstVideoCodecFrame * frame);
 438 
 439 static void gst_video_decoder_push_event_list (GstVideoDecoder * decoder,
 440     GList * events);
 441 static GstClockTime gst_video_decoder_get_frame_duration (GstVideoDecoder *
 442     decoder, GstVideoCodecFrame * frame);
 443 static GstVideoCodecFrame *gst_video_decoder_new_frame (GstVideoDecoder *
 444     decoder);
 445 static GstFlowReturn gst_video_decoder_clip_and_push_buf (GstVideoDecoder *
 446     decoder, GstBuffer * buf);
 447 static GstFlowReturn gst_video_decoder_flush_parse (GstVideoDecoder * dec,
 448     gboolean at_eos);
 449 
 450 static void gst_video_decoder_clear_queues (GstVideoDecoder * dec);
 451 
 452 static gboolean gst_video_decoder_sink_event_default (GstVideoDecoder * decoder,
 453     GstEvent * event);
 454 static gboolean gst_video_decoder_src_event_default (GstVideoDecoder * decoder,
 455     GstEvent * event);
 456 static gboolean gst_video_decoder_decide_allocation_default (GstVideoDecoder *
 457     decoder, GstQuery * query);
 458 static gboolean gst_video_decoder_propose_allocation_default (GstVideoDecoder *
 459     decoder, GstQuery * query);
 460 static gboolean gst_video_decoder_negotiate_default (GstVideoDecoder * decoder);
 461 static GstFlowReturn gst_video_decoder_parse_available (GstVideoDecoder * dec,
 462     gboolean at_eos, gboolean new_buffer);
 463 static gboolean gst_video_decoder_negotiate_unlocked (GstVideoDecoder *
 464     decoder);
 465 static gboolean gst_video_decoder_sink_query_default (GstVideoDecoder * decoder,
 466     GstQuery * query);
 467 static gboolean gst_video_decoder_src_query_default (GstVideoDecoder * decoder,
 468     GstQuery * query);
 469 
 470 static gboolean gst_video_decoder_transform_meta_default (GstVideoDecoder *
 471     decoder, GstVideoCodecFrame * frame, GstMeta * meta);
 472 
 473 /* we can&#39;t use G_DEFINE_ABSTRACT_TYPE because we need the klass in the _init
 474  * method to get to the padtemplates */
 475 GType
 476 gst_video_decoder_get_type (void)
 477 {
 478   static volatile gsize type = 0;
 479 
 480   if (g_once_init_enter (&amp;type)) {
 481     GType _type;
 482     static const GTypeInfo info = {
 483       sizeof (GstVideoDecoderClass),
 484       NULL,
 485       NULL,
 486       (GClassInitFunc) gst_video_decoder_class_init,
 487       NULL,
 488       NULL,
 489       sizeof (GstVideoDecoder),
 490       0,
 491       (GInstanceInitFunc) gst_video_decoder_init,
 492     };
 493 
 494     _type = g_type_register_static (GST_TYPE_ELEMENT,
 495         &quot;GstVideoDecoder&quot;, &amp;info, G_TYPE_FLAG_ABSTRACT);
 496     g_once_init_leave (&amp;type, _type);
 497   }
 498   return type;
 499 }
 500 
 501 static void
 502 gst_video_decoder_class_init (GstVideoDecoderClass * klass)
 503 {
 504   GObjectClass *gobject_class;
 505   GstElementClass *gstelement_class;
 506 
 507   gobject_class = G_OBJECT_CLASS (klass);
 508   gstelement_class = GST_ELEMENT_CLASS (klass);
 509 
 510   GST_DEBUG_CATEGORY_INIT (videodecoder_debug, &quot;videodecoder&quot;, 0,
 511       &quot;Base Video Decoder&quot;);
 512 
 513   parent_class = g_type_class_peek_parent (klass);
 514   g_type_class_add_private (klass, sizeof (GstVideoDecoderPrivate));
 515 
 516   gobject_class-&gt;finalize = gst_video_decoder_finalize;
 517 
 518   gstelement_class-&gt;change_state =
 519       GST_DEBUG_FUNCPTR (gst_video_decoder_change_state);
 520 
 521   klass-&gt;sink_event = gst_video_decoder_sink_event_default;
 522   klass-&gt;src_event = gst_video_decoder_src_event_default;
 523   klass-&gt;decide_allocation = gst_video_decoder_decide_allocation_default;
 524   klass-&gt;propose_allocation = gst_video_decoder_propose_allocation_default;
 525   klass-&gt;negotiate = gst_video_decoder_negotiate_default;
 526   klass-&gt;sink_query = gst_video_decoder_sink_query_default;
 527   klass-&gt;src_query = gst_video_decoder_src_query_default;
 528   klass-&gt;transform_meta = gst_video_decoder_transform_meta_default;
 529 }
 530 
 531 static void
 532 gst_video_decoder_init (GstVideoDecoder * decoder, GstVideoDecoderClass * klass)
 533 {
 534   GstPadTemplate *pad_template;
 535   GstPad *pad;
 536 
 537   GST_DEBUG_OBJECT (decoder, &quot;gst_video_decoder_init&quot;);
 538 
 539   decoder-&gt;priv = GST_VIDEO_DECODER_GET_PRIVATE (decoder);
 540 
 541   pad_template =
 542       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 543   g_return_if_fail (pad_template != NULL);
 544 
 545   decoder-&gt;sinkpad = pad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 546 
 547   gst_pad_set_chain_function (pad, GST_DEBUG_FUNCPTR (gst_video_decoder_chain));
 548   gst_pad_set_event_function (pad,
 549       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_event));
 550   gst_pad_set_query_function (pad,
 551       GST_DEBUG_FUNCPTR (gst_video_decoder_sink_query));
 552   gst_element_add_pad (GST_ELEMENT (decoder), decoder-&gt;sinkpad);
 553 
 554   pad_template =
 555       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 556   g_return_if_fail (pad_template != NULL);
 557 
 558   decoder-&gt;srcpad = pad = gst_pad_new_from_template (pad_template, &quot;src&quot;);
 559 
 560   gst_pad_set_event_function (pad,
 561       GST_DEBUG_FUNCPTR (gst_video_decoder_src_event));
 562   gst_pad_set_query_function (pad,
 563       GST_DEBUG_FUNCPTR (gst_video_decoder_src_query));
 564   gst_element_add_pad (GST_ELEMENT (decoder), decoder-&gt;srcpad);
 565 
 566   gst_segment_init (&amp;decoder-&gt;input_segment, GST_FORMAT_TIME);
 567   gst_segment_init (&amp;decoder-&gt;output_segment, GST_FORMAT_TIME);
 568 
 569   g_rec_mutex_init (&amp;decoder-&gt;stream_lock);
 570 
 571   decoder-&gt;priv-&gt;input_adapter = gst_adapter_new ();
 572   decoder-&gt;priv-&gt;output_adapter = gst_adapter_new ();
 573   decoder-&gt;priv-&gt;packetized = TRUE;
 574   decoder-&gt;priv-&gt;needs_format = FALSE;
 575 
 576   decoder-&gt;priv-&gt;min_latency = 0;
 577   decoder-&gt;priv-&gt;max_latency = 0;
 578 
 579   gst_video_decoder_reset (decoder, TRUE, TRUE);
 580 }
 581 
 582 static GstVideoCodecState *
 583 _new_input_state (GstCaps * caps)
 584 {
 585   GstVideoCodecState *state;
 586   GstStructure *structure;
 587   const GValue *codec_data;
 588 
 589   state = g_slice_new0 (GstVideoCodecState);
 590   state-&gt;ref_count = 1;
 591   gst_video_info_init (&amp;state-&gt;info);
 592   if (G_UNLIKELY (!gst_video_info_from_caps (&amp;state-&gt;info, caps)))
 593     goto parse_fail;
 594   state-&gt;caps = gst_caps_ref (caps);
 595 
 596   structure = gst_caps_get_structure (caps, 0);
 597 
 598   codec_data = gst_structure_get_value (structure, &quot;codec_data&quot;);
 599   if (codec_data &amp;&amp; G_VALUE_TYPE (codec_data) == GST_TYPE_BUFFER)
 600     state-&gt;codec_data = GST_BUFFER (g_value_dup_boxed (codec_data));
 601 
 602   return state;
 603 
 604 parse_fail:
 605   {
 606     g_slice_free (GstVideoCodecState, state);
 607     return NULL;
 608   }
 609 }
 610 
 611 static GstVideoCodecState *
 612 _new_output_state (GstVideoFormat fmt, guint width, guint height,
 613     GstVideoCodecState * reference)
 614 {
 615   GstVideoCodecState *state;
 616 
 617   state = g_slice_new0 (GstVideoCodecState);
 618   state-&gt;ref_count = 1;
 619   gst_video_info_init (&amp;state-&gt;info);
 620   if (!gst_video_info_set_format (&amp;state-&gt;info, fmt, width, height)) {
 621     g_slice_free (GstVideoCodecState, state);
 622     return NULL;
 623   }
 624 
 625   if (reference) {
 626     GstVideoInfo *tgt, *ref;
 627 
 628     tgt = &amp;state-&gt;info;
 629     ref = &amp;reference-&gt;info;
 630 
 631     /* Copy over extra fields from reference state */
 632     tgt-&gt;interlace_mode = ref-&gt;interlace_mode;
 633     tgt-&gt;flags = ref-&gt;flags;
 634     /* only copy values that are not unknown so that we don&#39;t override the
 635      * defaults. subclasses should really fill these in when they know. */
 636     if (ref-&gt;chroma_site)
 637       tgt-&gt;chroma_site = ref-&gt;chroma_site;
 638     if (ref-&gt;colorimetry.range)
 639       tgt-&gt;colorimetry.range = ref-&gt;colorimetry.range;
 640     if (ref-&gt;colorimetry.matrix)
 641       tgt-&gt;colorimetry.matrix = ref-&gt;colorimetry.matrix;
 642     if (ref-&gt;colorimetry.transfer)
 643       tgt-&gt;colorimetry.transfer = ref-&gt;colorimetry.transfer;
 644     if (ref-&gt;colorimetry.primaries)
 645       tgt-&gt;colorimetry.primaries = ref-&gt;colorimetry.primaries;
 646     GST_DEBUG (&quot;reference par %d/%d fps %d/%d&quot;,
 647         ref-&gt;par_n, ref-&gt;par_d, ref-&gt;fps_n, ref-&gt;fps_d);
 648     tgt-&gt;par_n = ref-&gt;par_n;
 649     tgt-&gt;par_d = ref-&gt;par_d;
 650     tgt-&gt;fps_n = ref-&gt;fps_n;
 651     tgt-&gt;fps_d = ref-&gt;fps_d;
 652     tgt-&gt;views = ref-&gt;views;
 653 
 654     GST_VIDEO_INFO_FIELD_ORDER (tgt) = GST_VIDEO_INFO_FIELD_ORDER (ref);
 655 
 656     if (GST_VIDEO_INFO_MULTIVIEW_MODE (ref) != GST_VIDEO_MULTIVIEW_MODE_NONE) {
 657       GST_VIDEO_INFO_MULTIVIEW_MODE (tgt) = GST_VIDEO_INFO_MULTIVIEW_MODE (ref);
 658       GST_VIDEO_INFO_MULTIVIEW_FLAGS (tgt) =
 659           GST_VIDEO_INFO_MULTIVIEW_FLAGS (ref);
 660     } else {
 661       /* Default to MONO, overridden as needed by sub-classes */
 662       GST_VIDEO_INFO_MULTIVIEW_MODE (tgt) = GST_VIDEO_MULTIVIEW_MODE_MONO;
 663       GST_VIDEO_INFO_MULTIVIEW_FLAGS (tgt) = GST_VIDEO_MULTIVIEW_FLAGS_NONE;
 664     }
 665   }
 666 
 667   GST_DEBUG (&quot;reference par %d/%d fps %d/%d&quot;,
 668       state-&gt;info.par_n, state-&gt;info.par_d,
 669       state-&gt;info.fps_n, state-&gt;info.fps_d);
 670 
 671   return state;
 672 }
 673 
 674 static gboolean
 675 gst_video_decoder_setcaps (GstVideoDecoder * decoder, GstCaps * caps)
 676 {
 677   GstVideoDecoderClass *decoder_class;
 678   GstVideoCodecState *state;
 679   gboolean ret = TRUE;
 680 
 681   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
 682 
 683   GST_DEBUG_OBJECT (decoder, &quot;setcaps %&quot; GST_PTR_FORMAT, caps);
 684 
 685   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
 686 
 687   if (decoder-&gt;priv-&gt;input_state) {
 688     GST_DEBUG_OBJECT (decoder,
 689         &quot;Checking if caps changed old %&quot; GST_PTR_FORMAT &quot; new %&quot; GST_PTR_FORMAT,
 690         decoder-&gt;priv-&gt;input_state-&gt;caps, caps);
 691     if (gst_caps_is_equal (decoder-&gt;priv-&gt;input_state-&gt;caps, caps))
 692       goto caps_not_changed;
 693   }
 694 
 695   state = _new_input_state (caps);
 696 
 697   if (G_UNLIKELY (state == NULL))
 698     goto parse_fail;
 699 
 700   if (decoder_class-&gt;set_format)
 701     ret = decoder_class-&gt;set_format (decoder, state);
 702 
 703   if (!ret)
 704     goto refused_format;
 705 
 706   if (decoder-&gt;priv-&gt;input_state)
 707     gst_video_codec_state_unref (decoder-&gt;priv-&gt;input_state);
 708   decoder-&gt;priv-&gt;input_state = state;
 709 
 710   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
 711 
 712   return ret;
 713 
 714 caps_not_changed:
 715   {
 716     GST_DEBUG_OBJECT (decoder, &quot;Caps did not change - ignore&quot;);
 717     GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
 718     return TRUE;
 719   }
 720 
 721   /* ERRORS */
 722 parse_fail:
 723   {
 724     GST_WARNING_OBJECT (decoder, &quot;Failed to parse caps&quot;);
 725     GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
 726     return FALSE;
 727   }
 728 
 729 refused_format:
 730   {
 731     GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
 732     GST_WARNING_OBJECT (decoder, &quot;Subclass refused caps&quot;);
 733     gst_video_codec_state_unref (state);
 734     return FALSE;
 735   }
 736 }
 737 
 738 static void
 739 gst_video_decoder_finalize (GObject * object)
 740 {
 741   GstVideoDecoder *decoder;
 742 
 743   decoder = GST_VIDEO_DECODER (object);
 744 
 745   GST_DEBUG_OBJECT (object, &quot;finalize&quot;);
 746 
 747   g_rec_mutex_clear (&amp;decoder-&gt;stream_lock);
 748 
 749   if (decoder-&gt;priv-&gt;input_adapter) {
 750     g_object_unref (decoder-&gt;priv-&gt;input_adapter);
 751     decoder-&gt;priv-&gt;input_adapter = NULL;
 752   }
 753   if (decoder-&gt;priv-&gt;output_adapter) {
 754     g_object_unref (decoder-&gt;priv-&gt;output_adapter);
 755     decoder-&gt;priv-&gt;output_adapter = NULL;
 756   }
 757 
 758   if (decoder-&gt;priv-&gt;input_state)
 759     gst_video_codec_state_unref (decoder-&gt;priv-&gt;input_state);
 760   if (decoder-&gt;priv-&gt;output_state)
 761     gst_video_codec_state_unref (decoder-&gt;priv-&gt;output_state);
 762 
 763   if (decoder-&gt;priv-&gt;pool) {
 764     gst_object_unref (decoder-&gt;priv-&gt;pool);
 765     decoder-&gt;priv-&gt;pool = NULL;
 766   }
 767 
 768   if (decoder-&gt;priv-&gt;allocator) {
 769     gst_object_unref (decoder-&gt;priv-&gt;allocator);
 770     decoder-&gt;priv-&gt;allocator = NULL;
 771   }
 772 
 773   G_OBJECT_CLASS (parent_class)-&gt;finalize (object);
 774 }
 775 
 776 /* hard == FLUSH, otherwise discont */
 777 static GstFlowReturn
 778 gst_video_decoder_flush (GstVideoDecoder * dec, gboolean hard)
 779 {
 780   GstVideoDecoderClass *klass = GST_VIDEO_DECODER_GET_CLASS (dec);
 781   GstFlowReturn ret = GST_FLOW_OK;
 782 
 783   GST_LOG_OBJECT (dec, &quot;flush hard %d&quot;, hard);
 784 
 785   /* Inform subclass */
 786   if (klass-&gt;reset) {
 787     GST_FIXME_OBJECT (dec, &quot;GstVideoDecoder::reset() is deprecated&quot;);
 788     klass-&gt;reset (dec, hard);
 789   }
 790 
 791   if (klass-&gt;flush)
 792     klass-&gt;flush (dec);
 793 
 794   /* and get (re)set for the sequel */
 795   gst_video_decoder_reset (dec, FALSE, hard);
 796 
 797   return ret;
 798 }
 799 
 800 static GstEvent *
 801 gst_video_decoder_create_merged_tags_event (GstVideoDecoder * dec)
 802 {
 803   GstTagList *merged_tags;
 804 
 805   GST_LOG_OBJECT (dec, &quot;upstream : %&quot; GST_PTR_FORMAT, dec-&gt;priv-&gt;upstream_tags);
 806   GST_LOG_OBJECT (dec, &quot;decoder  : %&quot; GST_PTR_FORMAT, dec-&gt;priv-&gt;tags);
 807   GST_LOG_OBJECT (dec, &quot;mode     : %d&quot;, dec-&gt;priv-&gt;tags_merge_mode);
 808 
 809   merged_tags =
 810       gst_tag_list_merge (dec-&gt;priv-&gt;upstream_tags, dec-&gt;priv-&gt;tags,
 811       dec-&gt;priv-&gt;tags_merge_mode);
 812 
 813   GST_DEBUG_OBJECT (dec, &quot;merged   : %&quot; GST_PTR_FORMAT, merged_tags);
 814 
 815   if (merged_tags == NULL)
 816     return NULL;
 817 
 818   if (gst_tag_list_is_empty (merged_tags)) {
 819     gst_tag_list_unref (merged_tags);
 820     return NULL;
 821   }
 822 
 823   return gst_event_new_tag (merged_tags);
 824 }
 825 
 826 static gboolean
 827 gst_video_decoder_push_event (GstVideoDecoder * decoder, GstEvent * event)
 828 {
 829   switch (GST_EVENT_TYPE (event)) {
 830     case GST_EVENT_SEGMENT:
 831     {
 832       GstSegment segment;
 833 
 834       gst_event_copy_segment (event, &amp;segment);
 835 
 836       GST_DEBUG_OBJECT (decoder, &quot;segment %&quot; GST_SEGMENT_FORMAT, &amp;segment);
 837 
 838       if (segment.format != GST_FORMAT_TIME) {
 839         GST_DEBUG_OBJECT (decoder, &quot;received non TIME newsegment&quot;);
 840         break;
 841       }
 842 
 843       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
 844       decoder-&gt;output_segment = segment;
 845       decoder-&gt;priv-&gt;in_out_segment_sync =
 846           gst_segment_is_equal (&amp;decoder-&gt;input_segment, &amp;segment);
 847       decoder-&gt;priv-&gt;last_timestamp_out = GST_CLOCK_TIME_NONE;
 848       decoder-&gt;priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
 849       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
 850       break;
 851     }
 852     default:
 853       break;
 854   }
 855 
 856   GST_DEBUG_OBJECT (decoder, &quot;pushing event %s&quot;,
 857       gst_event_type_get_name (GST_EVENT_TYPE (event)));
 858 
 859   return gst_pad_push_event (decoder-&gt;srcpad, event);
 860 }
 861 
 862 static GstFlowReturn
 863 gst_video_decoder_parse_available (GstVideoDecoder * dec, gboolean at_eos,
 864     gboolean new_buffer)
 865 {
 866   GstVideoDecoderClass *decoder_class = GST_VIDEO_DECODER_GET_CLASS (dec);
 867   GstVideoDecoderPrivate *priv = dec-&gt;priv;
 868   GstFlowReturn ret = GST_FLOW_OK;
 869   gsize was_available, available;
 870   guint inactive = 0;
 871 
 872   available = gst_adapter_available (priv-&gt;input_adapter);
 873 
 874   while (available || new_buffer) {
 875     new_buffer = FALSE;
 876     /* current frame may have been parsed and handled,
 877      * so we need to set up a new one when asking subclass to parse */
 878     if (priv-&gt;current_frame == NULL)
 879       priv-&gt;current_frame = gst_video_decoder_new_frame (dec);
 880 
 881     was_available = available;
 882     ret = decoder_class-&gt;parse (dec, priv-&gt;current_frame,
 883         priv-&gt;input_adapter, at_eos);
 884     if (ret != GST_FLOW_OK)
 885       break;
 886 
 887     /* if the subclass returned success (GST_FLOW_OK), it is expected
 888      * to have collected and submitted a frame, i.e. it should have
 889      * called gst_video_decoder_have_frame(), or at least consumed a
 890      * few bytes through gst_video_decoder_add_to_frame().
 891      *
 892      * Otherwise, this is an implementation bug, and we error out
 893      * after 2 failed attempts */
 894     available = gst_adapter_available (priv-&gt;input_adapter);
 895     if (!priv-&gt;current_frame || available != was_available)
 896       inactive = 0;
 897     else if (++inactive == 2)
 898       goto error_inactive;
 899   }
 900 
 901   return ret;
 902 
 903   /* ERRORS */
 904 error_inactive:
 905   {
 906     GST_ERROR_OBJECT (dec, &quot;Failed to consume data. Error in subclass?&quot;);
 907     return GST_FLOW_ERROR;
 908   }
 909 }
 910 
 911 /* This function has to be called with the stream lock taken. */
 912 static GstFlowReturn
 913 gst_video_decoder_drain_out (GstVideoDecoder * dec, gboolean at_eos)
 914 {
 915   GstVideoDecoderClass *decoder_class = GST_VIDEO_DECODER_GET_CLASS (dec);
 916   GstVideoDecoderPrivate *priv = dec-&gt;priv;
 917   GstFlowReturn ret = GST_FLOW_OK;
 918 
 919   if (dec-&gt;input_segment.rate &gt; 0.0) {
 920     /* Forward mode, if unpacketized, give the child class
 921      * a final chance to flush out packets */
 922     if (!priv-&gt;packetized) {
 923       ret = gst_video_decoder_parse_available (dec, TRUE, FALSE);
 924     }
 925 
 926     if (at_eos) {
 927       if (decoder_class-&gt;finish)
 928         ret = decoder_class-&gt;finish (dec);
 929     } else {
 930       if (decoder_class-&gt;drain) {
 931         ret = decoder_class-&gt;drain (dec);
 932       } else {
 933         GST_FIXME_OBJECT (dec, &quot;Sub-class should implement drain()&quot;);
 934       }
 935     }
 936   } else {
 937     /* Reverse playback mode */
 938     ret = gst_video_decoder_flush_parse (dec, TRUE);
 939   }
 940 
 941   return ret;
 942 }
 943 
 944 static GList *
 945 _flush_events (GstPad * pad, GList * events)
 946 {
 947   GList *tmp;
 948 
 949   for (tmp = events; tmp; tmp = tmp-&gt;next) {
 950     if (GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_EOS &amp;&amp;
 951         GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_SEGMENT &amp;&amp;
 952         GST_EVENT_IS_STICKY (tmp-&gt;data)) {
 953       gst_pad_store_sticky_event (pad, GST_EVENT_CAST (tmp-&gt;data));
 954     }
 955     gst_event_unref (tmp-&gt;data);
 956   }
 957   g_list_free (events);
 958 
 959   return NULL;
 960 }
 961 
 962 /* Must be called holding the GST_VIDEO_DECODER_STREAM_LOCK */
 963 static gboolean
 964 gst_video_decoder_negotiate_default_caps (GstVideoDecoder * decoder)
 965 {
 966   GstCaps *caps, *templcaps;
 967   GstVideoCodecState *state;
 968   GstVideoInfo info;
 969   gint i;
 970   gint caps_size;
 971   GstStructure *structure;
 972 
 973   templcaps = gst_pad_get_pad_template_caps (decoder-&gt;srcpad);
 974   caps = gst_pad_peer_query_caps (decoder-&gt;srcpad, templcaps);
 975   if (caps)
 976     gst_caps_unref (templcaps);
 977   else
 978     caps = templcaps;
 979   templcaps = NULL;
 980 
 981   if (!caps || gst_caps_is_empty (caps) || gst_caps_is_any (caps))
 982     goto caps_error;
 983 
 984   GST_LOG_OBJECT (decoder, &quot;peer caps %&quot; GST_PTR_FORMAT, caps);
 985 
 986   /* before fixating, try to use whatever upstream provided */
 987   caps = gst_caps_make_writable (caps);
 988   caps_size = gst_caps_get_size (caps);
 989   if (decoder-&gt;priv-&gt;input_state &amp;&amp; decoder-&gt;priv-&gt;input_state-&gt;caps) {
 990     GstCaps *sinkcaps = decoder-&gt;priv-&gt;input_state-&gt;caps;
 991     GstStructure *structure = gst_caps_get_structure (sinkcaps, 0);
 992     gint width, height;
 993     gint par_n, par_d;
 994     gint fps_n, fps_d;
 995 
 996     if (gst_structure_get_int (structure, &quot;width&quot;, &amp;width)) {
 997       for (i = 0; i &lt; caps_size; i++) {
 998         gst_structure_set (gst_caps_get_structure (caps, i), &quot;width&quot;,
 999             G_TYPE_INT, width, NULL);
1000       }
1001     }
1002 
1003     if (gst_structure_get_int (structure, &quot;height&quot;, &amp;height)) {
1004       for (i = 0; i &lt; caps_size; i++) {
1005         gst_structure_set (gst_caps_get_structure (caps, i), &quot;height&quot;,
1006             G_TYPE_INT, height, NULL);
1007       }
1008     }
1009 
1010     if (gst_structure_get_fraction (structure, &quot;framerate&quot;, &amp;fps_n, &amp;fps_d)) {
1011       for (i = 0; i &lt; caps_size; i++) {
1012         gst_structure_set (gst_caps_get_structure (caps, i), &quot;framerate&quot;,
1013             GST_TYPE_FRACTION, fps_n, fps_d, NULL);
1014       }
1015     }
1016 
1017     if (gst_structure_get_fraction (structure, &quot;pixel-aspect-ratio&quot;, &amp;par_n,
1018             &amp;par_d)) {
1019       for (i = 0; i &lt; caps_size; i++) {
1020         gst_structure_set (gst_caps_get_structure (caps, i),
1021             &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION, par_n, par_d, NULL);
1022       }
1023     }
1024   }
1025 
1026   for (i = 0; i &lt; caps_size; i++) {
1027     structure = gst_caps_get_structure (caps, i);
1028     /* Random I420 1280x720@30 for fixation */
1029     if (gst_structure_has_field (structure, &quot;format&quot;))
1030       gst_structure_fixate_field_string (structure, &quot;format&quot;, &quot;I420&quot;);
1031     else
1032       gst_structure_set (structure, &quot;format&quot;, G_TYPE_STRING, &quot;I420&quot;, NULL);
1033 
1034     if (gst_structure_has_field (structure, &quot;width&quot;))
1035       gst_structure_fixate_field_nearest_int (structure, &quot;width&quot;, 1280);
1036     else
1037       gst_structure_set (structure, &quot;width&quot;, G_TYPE_INT, 1280, NULL);
1038 
1039     if (gst_structure_has_field (structure, &quot;height&quot;))
1040       gst_structure_fixate_field_nearest_int (structure, &quot;height&quot;, 720);
1041     else
1042       gst_structure_set (structure, &quot;height&quot;, G_TYPE_INT, 720, NULL);
1043 
1044     if (gst_structure_has_field (structure, &quot;framerate&quot;))
1045       gst_structure_fixate_field_nearest_fraction (structure, &quot;framerate&quot;, 30,
1046           1);
1047     else
1048       gst_structure_set (structure, &quot;framerate&quot;, GST_TYPE_FRACTION, 30, 1,
1049           NULL);
1050 
1051     if (gst_structure_has_field (structure, &quot;pixel-aspect-ratio&quot;))
1052       gst_structure_fixate_field_nearest_fraction (structure,
1053           &quot;pixel-aspect-ratio&quot;, 1, 1);
1054     else
1055       gst_structure_set (structure, &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION,
1056           1, 1, NULL);
1057   }
1058   caps = gst_caps_fixate (caps);
1059   structure = gst_caps_get_structure (caps, 0);
1060 
1061   if (!caps || !gst_video_info_from_caps (&amp;info, caps))
1062     goto caps_error;
1063 
1064   GST_INFO_OBJECT (decoder,
1065       &quot;Chose default caps %&quot; GST_PTR_FORMAT &quot; for initial gap&quot;, caps);
1066   state =
1067       gst_video_decoder_set_output_state (decoder, info.finfo-&gt;format,
1068       info.width, info.height, decoder-&gt;priv-&gt;input_state);
1069   gst_video_codec_state_unref (state);
1070   gst_caps_unref (caps);
1071 
1072   return TRUE;
1073 
1074 caps_error:
1075   {
1076     if (caps)
1077       gst_caps_unref (caps);
1078     return FALSE;
1079   }
1080 }
1081 
1082 static gboolean
1083 gst_video_decoder_sink_event_default (GstVideoDecoder * decoder,
1084     GstEvent * event)
1085 {
1086   GstVideoDecoderPrivate *priv;
1087   gboolean ret = FALSE;
1088   gboolean forward_immediate = FALSE;
1089 
1090   priv = decoder-&gt;priv;
1091 
1092   switch (GST_EVENT_TYPE (event)) {
1093     case GST_EVENT_STREAM_START:
1094     {
1095       GstFlowReturn flow_ret = GST_FLOW_OK;
1096 
1097       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1098       flow_ret = gst_video_decoder_drain_out (decoder, FALSE);
1099       ret = (flow_ret == GST_FLOW_OK);
1100 
1101       GST_DEBUG_OBJECT (decoder, &quot;received STREAM_START. Clearing taglist&quot;);
1102       /* Flush upstream tags after a STREAM_START */
1103       if (priv-&gt;upstream_tags) {
1104         gst_tag_list_unref (priv-&gt;upstream_tags);
1105         priv-&gt;upstream_tags = NULL;
1106         priv-&gt;tags_changed = TRUE;
1107       }
1108       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1109 
1110       /* Forward STREAM_START immediately. Everything is drained after
1111        * the STREAM_START event and we can forward this event immediately
1112        * now without having buffers out of order.
1113        */
1114       forward_immediate = TRUE;
1115       break;
1116     }
1117     case GST_EVENT_CAPS:
1118     {
1119       GstCaps *caps;
1120 
1121       gst_event_parse_caps (event, &amp;caps);
1122       ret = gst_video_decoder_setcaps (decoder, caps);
1123       gst_event_unref (event);
1124       event = NULL;
1125       break;
1126     }
1127     case GST_EVENT_SEGMENT_DONE:
1128     {
1129       GstFlowReturn flow_ret = GST_FLOW_OK;
1130 
1131       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1132       flow_ret = gst_video_decoder_drain_out (decoder, TRUE);
1133       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1134       ret = (flow_ret == GST_FLOW_OK);
1135 
1136       /* Forward SEGMENT_DONE immediately. This is required
1137        * because no buffer or serialized event might come
1138        * after SEGMENT_DONE and nothing could trigger another
1139        * _finish_frame() call.
1140        *
1141        * The subclass can override this behaviour by overriding
1142        * the ::sink_event() vfunc and not chaining up to the
1143        * parent class&#39; ::sink_event() until a later time.
1144        */
1145       forward_immediate = TRUE;
1146       break;
1147     }
1148     case GST_EVENT_EOS:
1149     {
1150       GstFlowReturn flow_ret = GST_FLOW_OK;
1151 
1152       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1153       flow_ret = gst_video_decoder_drain_out (decoder, TRUE);
1154       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1155       ret = (flow_ret == GST_FLOW_OK);
1156 
1157       /* Error out even if EOS was ok when we had input, but no output */
1158       if (ret &amp;&amp; priv-&gt;had_input_data &amp;&amp; !priv-&gt;had_output_data) {
1159         GST_ELEMENT_ERROR (decoder, STREAM, DECODE,
1160             (&quot;No valid frames decoded before end of stream&quot;),
1161             (&quot;no valid frames found&quot;));
1162       }
1163 
1164       /* Forward EOS immediately. This is required because no
1165        * buffer or serialized event will come after EOS and
1166        * nothing could trigger another _finish_frame() call.
1167        *
1168        * The subclass can override this behaviour by overriding
1169        * the ::sink_event() vfunc and not chaining up to the
1170        * parent class&#39; ::sink_event() until a later time.
1171        */
1172       forward_immediate = TRUE;
1173       break;
1174     }
1175     case GST_EVENT_GAP:
1176     {
1177       GstFlowReturn flow_ret = GST_FLOW_OK;
1178       gboolean needs_reconfigure = FALSE;
1179       GList *events;
1180       GList *frame_events;
1181 
1182       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1183       flow_ret = gst_video_decoder_drain_out (decoder, FALSE);
1184       ret = (flow_ret == GST_FLOW_OK);
1185 
1186       /* Ensure we have caps before forwarding the event */
1187       if (!decoder-&gt;priv-&gt;output_state) {
1188         if (!gst_video_decoder_negotiate_default_caps (decoder)) {
1189           GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1190           GST_ELEMENT_ERROR (decoder, STREAM, FORMAT, (NULL),
1191               (&quot;Decoder output not negotiated before GAP event.&quot;));
1192           forward_immediate = TRUE;
1193           break;
1194         }
1195         needs_reconfigure = TRUE;
1196       }
1197 
1198       needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad)
1199           || needs_reconfigure;
1200       if (decoder-&gt;priv-&gt;output_state_changed || needs_reconfigure) {
1201         if (!gst_video_decoder_negotiate_unlocked (decoder)) {
1202           GST_WARNING_OBJECT (decoder, &quot;Failed to negotiate with downstream&quot;);
1203           gst_pad_mark_reconfigure (decoder-&gt;srcpad);
1204         }
1205       }
1206 
1207       GST_DEBUG_OBJECT (decoder, &quot;Pushing all pending serialized events&quot;
1208           &quot; before the gap&quot;);
1209       events = decoder-&gt;priv-&gt;pending_events;
1210       frame_events = decoder-&gt;priv-&gt;current_frame_events;
1211       decoder-&gt;priv-&gt;pending_events = NULL;
1212       decoder-&gt;priv-&gt;current_frame_events = NULL;
1213 
1214       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1215 
1216       gst_video_decoder_push_event_list (decoder, events);
1217       gst_video_decoder_push_event_list (decoder, frame_events);
1218 
1219       /* Forward GAP immediately. Everything is drained after
1220        * the GAP event and we can forward this event immediately
1221        * now without having buffers out of order.
1222        */
1223       forward_immediate = TRUE;
1224       break;
1225     }
1226     case GST_EVENT_CUSTOM_DOWNSTREAM:
1227     {
1228       gboolean in_still;
1229       GstFlowReturn flow_ret = GST_FLOW_OK;
1230 
1231       if (gst_video_event_parse_still_frame (event, &amp;in_still)) {
1232         if (in_still) {
1233           GST_DEBUG_OBJECT (decoder, &quot;draining current data for still-frame&quot;);
1234           GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1235           flow_ret = gst_video_decoder_drain_out (decoder, FALSE);
1236           GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1237           ret = (flow_ret == GST_FLOW_OK);
1238         }
1239         /* Forward STILL_FRAME immediately. Everything is drained after
1240          * the STILL_FRAME event and we can forward this event immediately
1241          * now without having buffers out of order.
1242          */
1243         forward_immediate = TRUE;
1244       }
1245       break;
1246     }
1247     case GST_EVENT_SEGMENT:
1248     {
1249       GstSegment segment;
1250 
1251       gst_event_copy_segment (event, &amp;segment);
1252 
1253       if (segment.format == GST_FORMAT_TIME) {
1254         GST_DEBUG_OBJECT (decoder,
1255             &quot;received TIME SEGMENT %&quot; GST_SEGMENT_FORMAT, &amp;segment);
1256       } else {
1257         gint64 start;
1258 
1259         GST_DEBUG_OBJECT (decoder,
1260             &quot;received SEGMENT %&quot; GST_SEGMENT_FORMAT, &amp;segment);
1261 
1262         /* handle newsegment as a result from our legacy simple seeking */
1263         /* note that initial 0 should convert to 0 in any case */
1264         if (priv-&gt;do_estimate_rate &amp;&amp;
1265             gst_pad_query_convert (decoder-&gt;sinkpad, GST_FORMAT_BYTES,
1266                 segment.start, GST_FORMAT_TIME, &amp;start)) {
1267           /* best attempt convert */
1268           /* as these are only estimates, stop is kept open-ended to avoid
1269            * premature cutting */
1270           GST_DEBUG_OBJECT (decoder,
1271               &quot;converted to TIME start %&quot; GST_TIME_FORMAT,
1272               GST_TIME_ARGS (start));
1273           segment.start = start;
1274           segment.stop = GST_CLOCK_TIME_NONE;
1275           segment.time = start;
1276           /* replace event */
1277           gst_event_unref (event);
1278           event = gst_event_new_segment (&amp;segment);
1279         } else {
1280           goto newseg_wrong_format;
1281         }
1282       }
1283 
1284       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1285 
1286       priv-&gt;base_timestamp = GST_CLOCK_TIME_NONE;
1287       priv-&gt;base_picture_number = 0;
1288 
1289       decoder-&gt;input_segment = segment;
1290       decoder-&gt;priv-&gt;in_out_segment_sync = FALSE;
1291 
1292       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1293       break;
1294     }
1295     case GST_EVENT_FLUSH_STOP:
1296     {
1297       GList *l;
1298 
1299       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1300       for (l = priv-&gt;frames; l; l = l-&gt;next) {
1301         GstVideoCodecFrame *frame = l-&gt;data;
1302 
1303         frame-&gt;events = _flush_events (decoder-&gt;srcpad, frame-&gt;events);
1304       }
1305       priv-&gt;current_frame_events = _flush_events (decoder-&gt;srcpad,
1306           decoder-&gt;priv-&gt;current_frame_events);
1307 
1308       /* well, this is kind of worse than a DISCONT */
1309       gst_video_decoder_flush (decoder, TRUE);
1310       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1311       /* Forward FLUSH_STOP immediately. This is required because it is
1312        * expected to be forwarded immediately and no buffers are queued
1313        * anyway.
1314        */
1315       forward_immediate = TRUE;
1316       break;
1317     }
1318     case GST_EVENT_TAG:
1319     {
1320       GstTagList *tags;
1321 
1322       gst_event_parse_tag (event, &amp;tags);
1323 
1324       if (gst_tag_list_get_scope (tags) == GST_TAG_SCOPE_STREAM) {
1325         GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1326         if (priv-&gt;upstream_tags != tags) {
1327           if (priv-&gt;upstream_tags)
1328             gst_tag_list_unref (priv-&gt;upstream_tags);
1329           priv-&gt;upstream_tags = gst_tag_list_ref (tags);
1330           GST_INFO_OBJECT (decoder, &quot;upstream tags: %&quot; GST_PTR_FORMAT, tags);
1331         }
1332         gst_event_unref (event);
1333         event = gst_video_decoder_create_merged_tags_event (decoder);
1334         GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1335         if (!event)
1336           ret = TRUE;
1337       }
1338       break;
1339     }
1340     default:
1341       break;
1342   }
1343 
1344   /* Forward non-serialized events immediately, and all other
1345    * events which can be forwarded immediately without potentially
1346    * causing the event to go out of order with other events and
1347    * buffers as decided above.
1348    */
1349   if (event) {
1350     if (!GST_EVENT_IS_SERIALIZED (event) || forward_immediate) {
1351       ret = gst_video_decoder_push_event (decoder, event);
1352     } else {
1353       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
1354       decoder-&gt;priv-&gt;current_frame_events =
1355           g_list_prepend (decoder-&gt;priv-&gt;current_frame_events, event);
1356       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
1357       ret = TRUE;
1358     }
1359   }
1360 
1361   return ret;
1362 
1363 newseg_wrong_format:
1364   {
1365     GST_DEBUG_OBJECT (decoder, &quot;received non TIME newsegment&quot;);
1366     gst_event_unref (event);
1367     /* SWALLOW EVENT */
1368     return TRUE;
1369   }
1370 }
1371 
1372 static gboolean
1373 gst_video_decoder_sink_event (GstPad * pad, GstObject * parent,
1374     GstEvent * event)
1375 {
1376   GstVideoDecoder *decoder;
1377   GstVideoDecoderClass *decoder_class;
1378   gboolean ret = FALSE;
1379 
1380   decoder = GST_VIDEO_DECODER (parent);
1381   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
1382 
1383   GST_DEBUG_OBJECT (decoder, &quot;received event %d, %s&quot;, GST_EVENT_TYPE (event),
1384       GST_EVENT_TYPE_NAME (event));
1385 
1386   if (decoder_class-&gt;sink_event)
1387     ret = decoder_class-&gt;sink_event (decoder, event);
1388 
1389   return ret;
1390 }
1391 
1392 /* perform upstream byte &lt;-&gt; time conversion (duration, seeking)
1393  * if subclass allows and if enough data for moderately decent conversion */
1394 static inline gboolean
1395 gst_video_decoder_do_byte (GstVideoDecoder * dec)
1396 {
1397   gboolean ret;
1398 
1399   GST_OBJECT_LOCK (dec);
1400   ret = dec-&gt;priv-&gt;do_estimate_rate &amp;&amp; (dec-&gt;priv-&gt;bytes_out &gt; 0)
1401       &amp;&amp; (dec-&gt;priv-&gt;time &gt; GST_SECOND);
1402   GST_OBJECT_UNLOCK (dec);
1403 
1404   return ret;
1405 }
1406 
1407 static gboolean
1408 gst_video_decoder_do_seek (GstVideoDecoder * dec, GstEvent * event)
1409 {
1410   GstFormat format;
1411   GstSeekFlags flags;
1412   GstSeekType start_type, end_type;
1413   gdouble rate;
1414   gint64 start, start_time, end_time;
1415   GstSegment seek_segment;
1416   guint32 seqnum;
1417 
1418   gst_event_parse_seek (event, &amp;rate, &amp;format, &amp;flags, &amp;start_type,
1419       &amp;start_time, &amp;end_type, &amp;end_time);
1420 
1421   /* we&#39;ll handle plain open-ended flushing seeks with the simple approach */
1422   if (rate != 1.0) {
1423     GST_DEBUG_OBJECT (dec, &quot;unsupported seek: rate&quot;);
1424     return FALSE;
1425   }
1426 
1427   if (start_type != GST_SEEK_TYPE_SET) {
1428     GST_DEBUG_OBJECT (dec, &quot;unsupported seek: start time&quot;);
1429     return FALSE;
1430   }
1431 
1432   if ((end_type != GST_SEEK_TYPE_SET &amp;&amp; end_type != GST_SEEK_TYPE_NONE) ||
1433       (end_type == GST_SEEK_TYPE_SET &amp;&amp; end_time != GST_CLOCK_TIME_NONE)) {
1434     GST_DEBUG_OBJECT (dec, &quot;unsupported seek: end time&quot;);
1435     return FALSE;
1436   }
1437 
1438   if (!(flags &amp; GST_SEEK_FLAG_FLUSH)) {
1439     GST_DEBUG_OBJECT (dec, &quot;unsupported seek: not flushing&quot;);
1440     return FALSE;
1441   }
1442 
1443   memcpy (&amp;seek_segment, &amp;dec-&gt;output_segment, sizeof (seek_segment));
1444   gst_segment_do_seek (&amp;seek_segment, rate, format, flags, start_type,
1445       start_time, end_type, end_time, NULL);
1446   start_time = seek_segment.position;
1447 
1448   if (!gst_pad_query_convert (dec-&gt;sinkpad, GST_FORMAT_TIME, start_time,
1449           GST_FORMAT_BYTES, &amp;start)) {
1450     GST_DEBUG_OBJECT (dec, &quot;conversion failed&quot;);
1451     return FALSE;
1452   }
1453 
1454   seqnum = gst_event_get_seqnum (event);
1455   event = gst_event_new_seek (1.0, GST_FORMAT_BYTES, flags,
1456       GST_SEEK_TYPE_SET, start, GST_SEEK_TYPE_NONE, -1);
1457   gst_event_set_seqnum (event, seqnum);
1458 
1459   GST_DEBUG_OBJECT (dec, &quot;seeking to %&quot; GST_TIME_FORMAT &quot; at byte offset %&quot;
1460       G_GINT64_FORMAT, GST_TIME_ARGS (start_time), start);
1461 
1462   return gst_pad_push_event (dec-&gt;sinkpad, event);
1463 }
1464 
1465 static gboolean
1466 gst_video_decoder_src_event_default (GstVideoDecoder * decoder,
1467     GstEvent * event)
1468 {
1469   GstVideoDecoderPrivate *priv;
1470   gboolean res = FALSE;
1471 
1472   priv = decoder-&gt;priv;
1473 
1474   GST_DEBUG_OBJECT (decoder,
1475       &quot;received event %d, %s&quot;, GST_EVENT_TYPE (event),
1476       GST_EVENT_TYPE_NAME (event));
1477 
1478   switch (GST_EVENT_TYPE (event)) {
1479     case GST_EVENT_SEEK:
1480     {
1481       GstFormat format;
1482       gdouble rate;
1483       GstSeekFlags flags;
1484       GstSeekType start_type, stop_type;
1485       gint64 start, stop;
1486       gint64 tstart, tstop;
1487       guint32 seqnum;
1488 
1489       gst_event_parse_seek (event, &amp;rate, &amp;format, &amp;flags, &amp;start_type, &amp;start,
1490           &amp;stop_type, &amp;stop);
1491       seqnum = gst_event_get_seqnum (event);
1492 
1493       /* upstream gets a chance first */
1494       if ((res = gst_pad_push_event (decoder-&gt;sinkpad, event)))
1495         break;
1496 
1497       /* if upstream fails for a time seek, maybe we can help if allowed */
1498       if (format == GST_FORMAT_TIME) {
1499         if (gst_video_decoder_do_byte (decoder))
1500           res = gst_video_decoder_do_seek (decoder, event);
1501         break;
1502       }
1503 
1504       /* ... though a non-time seek can be aided as well */
1505       /* First bring the requested format to time */
1506       if (!(res =
1507               gst_pad_query_convert (decoder-&gt;srcpad, format, start,
1508                   GST_FORMAT_TIME, &amp;tstart)))
1509         goto convert_error;
1510       if (!(res =
1511               gst_pad_query_convert (decoder-&gt;srcpad, format, stop,
1512                   GST_FORMAT_TIME, &amp;tstop)))
1513         goto convert_error;
1514 
1515       /* then seek with time on the peer */
1516       event = gst_event_new_seek (rate, GST_FORMAT_TIME,
1517           flags, start_type, tstart, stop_type, tstop);
1518       gst_event_set_seqnum (event, seqnum);
1519 
1520       res = gst_pad_push_event (decoder-&gt;sinkpad, event);
1521       break;
1522     }
1523     case GST_EVENT_QOS:
1524     {
1525       GstQOSType type;
1526       gdouble proportion;
1527       GstClockTimeDiff diff;
1528       GstClockTime timestamp;
1529 
1530       gst_event_parse_qos (event, &amp;type, &amp;proportion, &amp;diff, &amp;timestamp);
1531 
1532       GST_OBJECT_LOCK (decoder);
1533       priv-&gt;proportion = proportion;
1534       if (G_LIKELY (GST_CLOCK_TIME_IS_VALID (timestamp))) {
1535         if (G_UNLIKELY (diff &gt; 0)) {
1536           priv-&gt;earliest_time = timestamp + 2 * diff + priv-&gt;qos_frame_duration;
1537         } else {
1538           priv-&gt;earliest_time = timestamp + diff;
1539         }
1540       } else {
1541         priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
1542       }
1543       GST_OBJECT_UNLOCK (decoder);
1544 
1545       GST_DEBUG_OBJECT (decoder,
1546           &quot;got QoS %&quot; GST_TIME_FORMAT &quot;, %&quot; GST_STIME_FORMAT &quot;, %g&quot;,
1547           GST_TIME_ARGS (timestamp), GST_STIME_ARGS (diff), proportion);
1548 
1549       res = gst_pad_push_event (decoder-&gt;sinkpad, event);
1550       break;
1551     }
1552     default:
1553       res = gst_pad_push_event (decoder-&gt;sinkpad, event);
1554       break;
1555   }
1556 done:
1557   return res;
1558 
1559 convert_error:
1560   GST_DEBUG_OBJECT (decoder, &quot;could not convert format&quot;);
1561   goto done;
1562 }
1563 
1564 static gboolean
1565 gst_video_decoder_src_event (GstPad * pad, GstObject * parent, GstEvent * event)
1566 {
1567   GstVideoDecoder *decoder;
1568   GstVideoDecoderClass *decoder_class;
1569   gboolean ret = FALSE;
1570 
1571   decoder = GST_VIDEO_DECODER (parent);
1572   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
1573 
1574   GST_DEBUG_OBJECT (decoder, &quot;received event %d, %s&quot;, GST_EVENT_TYPE (event),
1575       GST_EVENT_TYPE_NAME (event));
1576 
1577   if (decoder_class-&gt;src_event)
1578     ret = decoder_class-&gt;src_event (decoder, event);
1579 
1580   return ret;
1581 }
1582 
1583 static gboolean
1584 gst_video_decoder_src_query_default (GstVideoDecoder * dec, GstQuery * query)
1585 {
1586   GstPad *pad = GST_VIDEO_DECODER_SRC_PAD (dec);
1587   gboolean res = TRUE;
1588 
1589   GST_LOG_OBJECT (dec, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
1590 
1591   switch (GST_QUERY_TYPE (query)) {
1592     case GST_QUERY_POSITION:
1593     {
1594       GstFormat format;
1595       gint64 time, value;
1596 
1597       /* upstream gets a chance first */
1598       if ((res = gst_pad_peer_query (dec-&gt;sinkpad, query))) {
1599         GST_LOG_OBJECT (dec, &quot;returning peer response&quot;);
1600         break;
1601       }
1602 
1603       /* Refuse BYTES format queries. If it made sense to
1604        * answer them, upstream would have already */
1605       gst_query_parse_position (query, &amp;format, NULL);
1606 
1607       if (format == GST_FORMAT_BYTES) {
1608         GST_LOG_OBJECT (dec, &quot;Ignoring BYTES position query&quot;);
1609         break;
1610       }
1611 
1612       /* we start from the last seen time */
1613       time = dec-&gt;priv-&gt;last_timestamp_out;
1614       /* correct for the segment values */
1615       time = gst_segment_to_stream_time (&amp;dec-&gt;output_segment,
1616           GST_FORMAT_TIME, time);
1617 
1618       GST_LOG_OBJECT (dec,
1619           &quot;query %p: our time: %&quot; GST_TIME_FORMAT, query, GST_TIME_ARGS (time));
1620 
1621       /* and convert to the final format */
1622       if (!(res = gst_pad_query_convert (pad, GST_FORMAT_TIME, time,
1623                   format, &amp;value)))
1624         break;
1625 
1626       gst_query_set_position (query, format, value);
1627 
1628       GST_LOG_OBJECT (dec,
1629           &quot;query %p: we return %&quot; G_GINT64_FORMAT &quot; (format %u)&quot;, query, value,
1630           format);
1631       break;
1632     }
1633     case GST_QUERY_DURATION:
1634     {
1635       GstFormat format;
1636 
1637       /* upstream in any case */
1638       if ((res = gst_pad_query_default (pad, GST_OBJECT (dec), query)))
1639         break;
1640 
1641       gst_query_parse_duration (query, &amp;format, NULL);
1642       /* try answering TIME by converting from BYTE if subclass allows  */
1643       if (format == GST_FORMAT_TIME &amp;&amp; gst_video_decoder_do_byte (dec)) {
1644         gint64 value;
1645 
1646         if (gst_pad_peer_query_duration (dec-&gt;sinkpad, GST_FORMAT_BYTES,
1647                 &amp;value)) {
1648           GST_LOG_OBJECT (dec, &quot;upstream size %&quot; G_GINT64_FORMAT, value);
1649           if (gst_pad_query_convert (dec-&gt;sinkpad,
1650                   GST_FORMAT_BYTES, value, GST_FORMAT_TIME, &amp;value)) {
1651             gst_query_set_duration (query, GST_FORMAT_TIME, value);
1652             res = TRUE;
1653           }
1654         }
1655       }
1656       break;
1657     }
1658     case GST_QUERY_CONVERT:
1659     {
1660       GstFormat src_fmt, dest_fmt;
1661       gint64 src_val, dest_val;
1662 
1663       GST_DEBUG_OBJECT (dec, &quot;convert query&quot;);
1664 
1665       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
1666       GST_OBJECT_LOCK (dec);
1667       if (dec-&gt;priv-&gt;output_state != NULL)
1668         res = __gst_video_rawvideo_convert (dec-&gt;priv-&gt;output_state,
1669             src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
1670       else
1671         res = FALSE;
1672       GST_OBJECT_UNLOCK (dec);
1673       if (!res)
1674         goto error;
1675       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
1676       break;
1677     }
1678     case GST_QUERY_LATENCY:
1679     {
1680       gboolean live;
1681       GstClockTime min_latency, max_latency;
1682 
1683       res = gst_pad_peer_query (dec-&gt;sinkpad, query);
1684       if (res) {
1685         gst_query_parse_latency (query, &amp;live, &amp;min_latency, &amp;max_latency);
1686         GST_DEBUG_OBJECT (dec, &quot;Peer qlatency: live %d, min %&quot;
1687             GST_TIME_FORMAT &quot; max %&quot; GST_TIME_FORMAT, live,
1688             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
1689 
1690         GST_OBJECT_LOCK (dec);
1691         min_latency += dec-&gt;priv-&gt;min_latency;
1692         if (max_latency == GST_CLOCK_TIME_NONE
1693             || dec-&gt;priv-&gt;max_latency == GST_CLOCK_TIME_NONE)
1694           max_latency = GST_CLOCK_TIME_NONE;
1695         else
1696           max_latency += dec-&gt;priv-&gt;max_latency;
1697         GST_OBJECT_UNLOCK (dec);
1698 
1699         gst_query_set_latency (query, live, min_latency, max_latency);
1700       }
1701     }
1702       break;
1703     default:
1704       res = gst_pad_query_default (pad, GST_OBJECT (dec), query);
1705   }
1706   return res;
1707 
1708 error:
1709   GST_ERROR_OBJECT (dec, &quot;query failed&quot;);
1710   return res;
1711 }
1712 
1713 static gboolean
1714 gst_video_decoder_src_query (GstPad * pad, GstObject * parent, GstQuery * query)
1715 {
1716   GstVideoDecoder *decoder;
1717   GstVideoDecoderClass *decoder_class;
1718   gboolean ret = FALSE;
1719 
1720   decoder = GST_VIDEO_DECODER (parent);
1721   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
1722 
1723   GST_DEBUG_OBJECT (decoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
1724       GST_QUERY_TYPE_NAME (query));
1725 
1726   if (decoder_class-&gt;src_query)
1727     ret = decoder_class-&gt;src_query (decoder, query);
1728 
1729   return ret;
1730 }
1731 
1732 /**
1733  * gst_video_decoder_proxy_getcaps:
1734  * @decoder: a #GstVideoDecoder
1735  * @caps: (allow-none): initial caps
1736  * @filter: (allow-none): filter caps
1737  *
1738  * Returns caps that express @caps (or sink template caps if @caps == NULL)
1739  * restricted to resolution/format/... combinations supported by downstream
1740  * elements.
1741  *
1742  * Returns: (transfer full): a #GstCaps owned by caller
1743  *
1744  * Since: 1.6
1745  */
1746 GstCaps *
1747 gst_video_decoder_proxy_getcaps (GstVideoDecoder * decoder, GstCaps * caps,
1748     GstCaps * filter)
1749 {
1750   return __gst_video_element_proxy_getcaps (GST_ELEMENT_CAST (decoder),
1751       GST_VIDEO_DECODER_SINK_PAD (decoder),
1752       GST_VIDEO_DECODER_SRC_PAD (decoder), caps, filter);
1753 }
1754 
1755 static GstCaps *
1756 gst_video_decoder_sink_getcaps (GstVideoDecoder * decoder, GstCaps * filter)
1757 {
1758   GstVideoDecoderClass *klass;
1759   GstCaps *caps;
1760 
1761   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
1762 
1763   if (klass-&gt;getcaps)
1764     caps = klass-&gt;getcaps (decoder, filter);
1765   else
1766     caps = gst_video_decoder_proxy_getcaps (decoder, NULL, filter);
1767 
1768   GST_LOG_OBJECT (decoder, &quot;Returning caps %&quot; GST_PTR_FORMAT, caps);
1769 
1770   return caps;
1771 }
1772 
1773 static gboolean
1774 gst_video_decoder_sink_query_default (GstVideoDecoder * decoder,
1775     GstQuery * query)
1776 {
1777   GstPad *pad = GST_VIDEO_DECODER_SINK_PAD (decoder);
1778   GstVideoDecoderPrivate *priv;
1779   gboolean res = FALSE;
1780 
1781   priv = decoder-&gt;priv;
1782 
1783   GST_LOG_OBJECT (decoder, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
1784 
1785   switch (GST_QUERY_TYPE (query)) {
1786     case GST_QUERY_CONVERT:
1787     {
1788       GstFormat src_fmt, dest_fmt;
1789       gint64 src_val, dest_val;
1790 
1791       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
1792       GST_OBJECT_LOCK (decoder);
1793       res =
1794           __gst_video_encoded_video_convert (priv-&gt;bytes_out, priv-&gt;time,
1795           src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
1796       GST_OBJECT_UNLOCK (decoder);
1797       if (!res)
1798         goto error;
1799       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
1800       break;
1801     }
1802     case GST_QUERY_ALLOCATION:{
1803       GstVideoDecoderClass *klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
1804 
1805       if (klass-&gt;propose_allocation)
1806         res = klass-&gt;propose_allocation (decoder, query);
1807       break;
1808     }
1809     case GST_QUERY_CAPS:{
1810       GstCaps *filter, *caps;
1811 
1812       gst_query_parse_caps (query, &amp;filter);
1813       caps = gst_video_decoder_sink_getcaps (decoder, filter);
1814       gst_query_set_caps_result (query, caps);
1815       gst_caps_unref (caps);
1816       res = TRUE;
1817       break;
1818     }
1819     case GST_QUERY_ACCEPT_CAPS:{
1820       if (decoder-&gt;priv-&gt;use_default_pad_acceptcaps) {
1821         res =
1822             gst_pad_query_default (GST_VIDEO_DECODER_SINK_PAD (decoder),
1823             GST_OBJECT_CAST (decoder), query);
1824       } else {
1825         GstCaps *caps;
1826         GstCaps *allowed_caps;
1827         GstCaps *template_caps;
1828         gboolean accept;
1829 
1830         gst_query_parse_accept_caps (query, &amp;caps);
1831 
1832         template_caps = gst_pad_get_pad_template_caps (pad);
1833         accept = gst_caps_is_subset (caps, template_caps);
1834         gst_caps_unref (template_caps);
1835 
1836         if (accept) {
1837           allowed_caps =
1838               gst_pad_query_caps (GST_VIDEO_DECODER_SINK_PAD (decoder), caps);
1839 
1840           accept = gst_caps_can_intersect (caps, allowed_caps);
1841 
1842           gst_caps_unref (allowed_caps);
1843         }
1844 
1845         gst_query_set_accept_caps_result (query, accept);
1846         res = TRUE;
1847       }
1848       break;
1849     }
1850     default:
1851       res = gst_pad_query_default (pad, GST_OBJECT (decoder), query);
1852       break;
1853   }
1854 done:
1855 
1856   return res;
1857 error:
1858   GST_DEBUG_OBJECT (decoder, &quot;query failed&quot;);
1859   goto done;
1860 
1861 }
1862 
1863 static gboolean
1864 gst_video_decoder_sink_query (GstPad * pad, GstObject * parent,
1865     GstQuery * query)
1866 {
1867   GstVideoDecoder *decoder;
1868   GstVideoDecoderClass *decoder_class;
1869   gboolean ret = FALSE;
1870 
1871   decoder = GST_VIDEO_DECODER (parent);
1872   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
1873 
1874   GST_DEBUG_OBJECT (decoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
1875       GST_QUERY_TYPE_NAME (query));
1876 
1877   if (decoder_class-&gt;sink_query)
1878     ret = decoder_class-&gt;sink_query (decoder, query);
1879 
1880   return ret;
1881 }
1882 
1883 typedef struct _Timestamp Timestamp;
1884 struct _Timestamp
1885 {
1886   guint64 offset;
1887   GstClockTime pts;
1888   GstClockTime dts;
1889   GstClockTime duration;
1890   guint flags;
1891 };
1892 
1893 static void
1894 timestamp_free (Timestamp * ts)
1895 {
1896   g_slice_free (Timestamp, ts);
1897 }
1898 
1899 static void
1900 gst_video_decoder_add_buffer_info (GstVideoDecoder * decoder,
1901     GstBuffer * buffer)
1902 {
1903   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
1904   Timestamp *ts;
1905 
1906   if (!GST_BUFFER_PTS_IS_VALID (buffer) &amp;&amp;
1907       !GST_BUFFER_DTS_IS_VALID (buffer) &amp;&amp;
1908       !GST_BUFFER_DURATION_IS_VALID (buffer) &amp;&amp;
1909       GST_BUFFER_FLAGS (buffer) == 0) {
1910     /* Save memory - don&#39;t bother storing info
1911      * for buffers with no distinguishing info */
1912     return;
1913   }
1914 
1915   ts = g_slice_new (Timestamp);
1916 
1917   GST_LOG_OBJECT (decoder,
1918       &quot;adding PTS %&quot; GST_TIME_FORMAT &quot; DTS %&quot; GST_TIME_FORMAT
1919       &quot; (offset:%&quot; G_GUINT64_FORMAT &quot;)&quot;,
1920       GST_TIME_ARGS (GST_BUFFER_PTS (buffer)),
1921       GST_TIME_ARGS (GST_BUFFER_DTS (buffer)), priv-&gt;input_offset);
1922 
1923   ts-&gt;offset = priv-&gt;input_offset;
1924   ts-&gt;pts = GST_BUFFER_PTS (buffer);
1925   ts-&gt;dts = GST_BUFFER_DTS (buffer);
1926   ts-&gt;duration = GST_BUFFER_DURATION (buffer);
1927   ts-&gt;flags = GST_BUFFER_FLAGS (buffer);
1928 
1929   priv-&gt;timestamps = g_list_append (priv-&gt;timestamps, ts);
1930 }
1931 
1932 static void
1933 gst_video_decoder_get_buffer_info_at_offset (GstVideoDecoder *
1934     decoder, guint64 offset, GstClockTime * pts, GstClockTime * dts,
1935     GstClockTime * duration, guint * flags)
1936 {
1937 #ifndef GST_DISABLE_GST_DEBUG
1938   guint64 got_offset = 0;
1939 #endif
1940   Timestamp *ts;
1941   GList *g;
1942 
1943   *pts = GST_CLOCK_TIME_NONE;
1944   *dts = GST_CLOCK_TIME_NONE;
1945   *duration = GST_CLOCK_TIME_NONE;
1946   *flags = 0;
1947 
1948   g = decoder-&gt;priv-&gt;timestamps;
1949   while (g) {
1950     ts = g-&gt;data;
1951     if (ts-&gt;offset &lt;= offset) {
1952 #ifndef GST_DISABLE_GST_DEBUG
1953       got_offset = ts-&gt;offset;
1954 #endif
1955       *pts = ts-&gt;pts;
1956       *dts = ts-&gt;dts;
1957       *duration = ts-&gt;duration;
1958       *flags = ts-&gt;flags;
1959       g = g-&gt;next;
1960       decoder-&gt;priv-&gt;timestamps = g_list_remove (decoder-&gt;priv-&gt;timestamps, ts);
1961       timestamp_free (ts);
1962     } else {
1963       break;
1964     }
1965   }
1966 
1967   GST_LOG_OBJECT (decoder,
1968       &quot;got PTS %&quot; GST_TIME_FORMAT &quot; DTS %&quot; GST_TIME_FORMAT &quot; flags %x @ offs %&quot;
1969       G_GUINT64_FORMAT &quot; (wanted offset:%&quot; G_GUINT64_FORMAT &quot;)&quot;,
1970       GST_TIME_ARGS (*pts), GST_TIME_ARGS (*dts), *flags, got_offset, offset);
1971 }
1972 
1973 static void
1974 gst_video_decoder_clear_queues (GstVideoDecoder * dec)
1975 {
1976   GstVideoDecoderPrivate *priv = dec-&gt;priv;
1977 
1978   g_list_free_full (priv-&gt;output_queued,
1979       (GDestroyNotify) gst_mini_object_unref);
1980   priv-&gt;output_queued = NULL;
1981 
1982   g_list_free_full (priv-&gt;gather, (GDestroyNotify) gst_mini_object_unref);
1983   priv-&gt;gather = NULL;
1984   g_list_free_full (priv-&gt;decode, (GDestroyNotify) gst_video_codec_frame_unref);
1985   priv-&gt;decode = NULL;
1986   g_list_free_full (priv-&gt;parse, (GDestroyNotify) gst_mini_object_unref);
1987   priv-&gt;parse = NULL;
1988   g_list_free_full (priv-&gt;parse_gather,
1989       (GDestroyNotify) gst_video_codec_frame_unref);
1990   priv-&gt;parse_gather = NULL;
1991   g_list_free_full (priv-&gt;frames, (GDestroyNotify) gst_video_codec_frame_unref);
1992   priv-&gt;frames = NULL;
1993 }
1994 
1995 static void
1996 gst_video_decoder_reset (GstVideoDecoder * decoder, gboolean full,
1997     gboolean flush_hard)
1998 {
1999   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
2000 
2001   GST_DEBUG_OBJECT (decoder, &quot;reset full %d&quot;, full);
2002 
2003   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2004 
2005   if (full || flush_hard) {
2006     gst_segment_init (&amp;decoder-&gt;input_segment, GST_FORMAT_UNDEFINED);
2007     gst_segment_init (&amp;decoder-&gt;output_segment, GST_FORMAT_UNDEFINED);
2008     gst_video_decoder_clear_queues (decoder);
2009     decoder-&gt;priv-&gt;in_out_segment_sync = TRUE;
2010 
2011     if (priv-&gt;current_frame) {
2012       gst_video_codec_frame_unref (priv-&gt;current_frame);
2013       priv-&gt;current_frame = NULL;
2014     }
2015 
2016     g_list_free_full (priv-&gt;current_frame_events,
2017         (GDestroyNotify) gst_event_unref);
2018     priv-&gt;current_frame_events = NULL;
2019     g_list_free_full (priv-&gt;pending_events, (GDestroyNotify) gst_event_unref);
2020     priv-&gt;pending_events = NULL;
2021 
2022     priv-&gt;error_count = 0;
2023     priv-&gt;max_errors = GST_VIDEO_DECODER_MAX_ERRORS;
2024     priv-&gt;had_output_data = FALSE;
2025     priv-&gt;had_input_data = FALSE;
2026 
2027     GST_OBJECT_LOCK (decoder);
2028     priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
2029     priv-&gt;proportion = 0.5;
2030     GST_OBJECT_UNLOCK (decoder);
2031   }
2032 
2033   if (full) {
2034     if (priv-&gt;input_state)
2035       gst_video_codec_state_unref (priv-&gt;input_state);
2036     priv-&gt;input_state = NULL;
2037     GST_OBJECT_LOCK (decoder);
2038     if (priv-&gt;output_state)
2039       gst_video_codec_state_unref (priv-&gt;output_state);
2040     priv-&gt;output_state = NULL;
2041 
2042     priv-&gt;qos_frame_duration = 0;
2043     GST_OBJECT_UNLOCK (decoder);
2044 
2045     if (priv-&gt;tags)
2046       gst_tag_list_unref (priv-&gt;tags);
2047     priv-&gt;tags = NULL;
2048     priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
2049     if (priv-&gt;upstream_tags) {
2050       gst_tag_list_unref (priv-&gt;upstream_tags);
2051       priv-&gt;upstream_tags = NULL;
2052     }
2053     priv-&gt;tags_changed = FALSE;
2054     priv-&gt;reordered_output = FALSE;
2055 
2056     priv-&gt;dropped = 0;
2057     priv-&gt;processed = 0;
2058 
2059     priv-&gt;decode_frame_number = 0;
2060     priv-&gt;base_picture_number = 0;
2061 
2062     if (priv-&gt;pool) {
2063       GST_DEBUG_OBJECT (decoder, &quot;deactivate pool %&quot; GST_PTR_FORMAT,
2064           priv-&gt;pool);
2065       gst_buffer_pool_set_active (priv-&gt;pool, FALSE);
2066       gst_object_unref (priv-&gt;pool);
2067       priv-&gt;pool = NULL;
2068     }
2069 
2070     if (priv-&gt;allocator) {
2071       gst_object_unref (priv-&gt;allocator);
2072       priv-&gt;allocator = NULL;
2073     }
2074   }
2075 
2076   priv-&gt;discont = TRUE;
2077 
2078   priv-&gt;base_timestamp = GST_CLOCK_TIME_NONE;
2079   priv-&gt;last_timestamp_out = GST_CLOCK_TIME_NONE;
2080   priv-&gt;pts_delta = GST_CLOCK_TIME_NONE;
2081 
2082   priv-&gt;input_offset = 0;
2083   priv-&gt;frame_offset = 0;
2084   gst_adapter_clear (priv-&gt;input_adapter);
2085   gst_adapter_clear (priv-&gt;output_adapter);
2086   g_list_free_full (priv-&gt;timestamps, (GDestroyNotify) timestamp_free);
2087   priv-&gt;timestamps = NULL;
2088 
2089   GST_OBJECT_LOCK (decoder);
2090   priv-&gt;bytes_out = 0;
2091   priv-&gt;time = 0;
2092   GST_OBJECT_UNLOCK (decoder);
2093 
2094 #ifndef GST_DISABLE_DEBUG
2095   priv-&gt;last_reset_time = gst_util_get_timestamp ();
2096 #endif
2097 
2098   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2099 }
2100 
2101 static GstFlowReturn
2102 gst_video_decoder_chain_forward (GstVideoDecoder * decoder,
2103     GstBuffer * buf, gboolean at_eos)
2104 {
2105   GstVideoDecoderPrivate *priv;
2106   GstVideoDecoderClass *klass;
2107   GstFlowReturn ret = GST_FLOW_OK;
2108 
2109   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
2110   priv = decoder-&gt;priv;
2111 
2112   g_return_val_if_fail (priv-&gt;packetized || klass-&gt;parse, GST_FLOW_ERROR);
2113 
2114   /* Draining on DISCONT is handled in chain_reverse() for reverse playback,
2115    * and this function would only be called to get everything collected GOP
2116    * by GOP in the parse_gather list */
2117   if (decoder-&gt;input_segment.rate &gt; 0.0 &amp;&amp; GST_BUFFER_IS_DISCONT (buf))
2118     ret = gst_video_decoder_drain_out (decoder, FALSE);
2119 
2120   if (priv-&gt;current_frame == NULL)
2121     priv-&gt;current_frame = gst_video_decoder_new_frame (decoder);
2122 
2123   if (!priv-&gt;packetized)
2124     gst_video_decoder_add_buffer_info (decoder, buf);
2125 
2126   priv-&gt;input_offset += gst_buffer_get_size (buf);
2127 
2128   if (priv-&gt;packetized) {
2129     gboolean was_keyframe = FALSE;
2130     if (!GST_BUFFER_FLAG_IS_SET (buf, GST_BUFFER_FLAG_DELTA_UNIT)) {
2131       was_keyframe = TRUE;
2132       GST_LOG_OBJECT (decoder, &quot;Marking current_frame as sync point&quot;);
2133       GST_VIDEO_CODEC_FRAME_SET_SYNC_POINT (priv-&gt;current_frame);
2134     }
2135 
2136     priv-&gt;current_frame-&gt;input_buffer = buf;
2137 
2138     if (decoder-&gt;input_segment.rate &lt; 0.0) {
2139       priv-&gt;parse_gather =
2140           g_list_prepend (priv-&gt;parse_gather, priv-&gt;current_frame);
2141     } else {
2142       ret = gst_video_decoder_decode_frame (decoder, priv-&gt;current_frame);
2143     }
2144     priv-&gt;current_frame = NULL;
2145     /* If in trick mode and it was a keyframe, drain decoder to avoid extra
2146      * latency. Only do this for forwards playback as reverse playback handles
2147      * draining on keyframes in flush_parse(), and would otherwise call back
2148      * from drain_out() to here causing an infinite loop.
2149      * Also this function is only called for reverse playback to gather frames
2150      * GOP by GOP, and does not do any actual decoding. That would be done by
2151      * flush_decode() */
2152     if (ret == GST_FLOW_OK &amp;&amp; was_keyframe &amp;&amp; decoder-&gt;input_segment.rate &gt; 0.0
2153         &amp;&amp; (decoder-&gt;input_segment.flags &amp; GST_SEEK_FLAG_TRICKMODE_KEY_UNITS))
2154       ret = gst_video_decoder_drain_out (decoder, FALSE);
2155   } else {
2156     gst_adapter_push (priv-&gt;input_adapter, buf);
2157 
2158     ret = gst_video_decoder_parse_available (decoder, at_eos, TRUE);
2159   }
2160 
2161   if (ret == GST_VIDEO_DECODER_FLOW_NEED_DATA)
2162     return GST_FLOW_OK;
2163 
2164   return ret;
2165 }
2166 
2167 static GstFlowReturn
2168 gst_video_decoder_flush_decode (GstVideoDecoder * dec)
2169 {
2170   GstVideoDecoderPrivate *priv = dec-&gt;priv;
2171   GstFlowReturn res = GST_FLOW_OK;
2172   GList *walk;
2173 
2174   GST_DEBUG_OBJECT (dec, &quot;flushing buffers to decode&quot;);
2175 
2176   walk = priv-&gt;decode;
2177   while (walk) {
2178     GList *next;
2179     GstVideoCodecFrame *frame = (GstVideoCodecFrame *) (walk-&gt;data);
2180 
2181     GST_DEBUG_OBJECT (dec, &quot;decoding frame %p buffer %p, PTS %&quot; GST_TIME_FORMAT
2182         &quot;, DTS %&quot; GST_TIME_FORMAT, frame, frame-&gt;input_buffer,
2183         GST_TIME_ARGS (GST_BUFFER_PTS (frame-&gt;input_buffer)),
2184         GST_TIME_ARGS (GST_BUFFER_DTS (frame-&gt;input_buffer)));
2185 
2186     next = walk-&gt;next;
2187 
2188     priv-&gt;decode = g_list_delete_link (priv-&gt;decode, walk);
2189 
2190     /* decode buffer, resulting data prepended to queue */
2191     res = gst_video_decoder_decode_frame (dec, frame);
2192     if (res != GST_FLOW_OK)
2193       break;
2194 
2195     walk = next;
2196   }
2197 
2198   return res;
2199 }
2200 
2201 /* gst_video_decoder_flush_parse is called from the
2202  * chain_reverse() function when a buffer containing
2203  * a DISCONT - indicating that reverse playback
2204  * looped back to the next data block, and therefore
2205  * all available data should be fed through the
2206  * decoder and frames gathered for reversed output
2207  */
2208 static GstFlowReturn
2209 gst_video_decoder_flush_parse (GstVideoDecoder * dec, gboolean at_eos)
2210 {
2211   GstVideoDecoderPrivate *priv = dec-&gt;priv;
2212   GstFlowReturn res = GST_FLOW_OK;
2213   GList *walk;
2214   GstVideoDecoderClass *decoder_class;
2215 
2216   decoder_class = GST_VIDEO_DECODER_GET_CLASS (dec);
2217 
2218   GST_DEBUG_OBJECT (dec, &quot;flushing buffers to parsing&quot;);
2219 
2220   /* Reverse the gather list, and prepend it to the parse list,
2221    * then flush to parse whatever we can */
2222   priv-&gt;gather = g_list_reverse (priv-&gt;gather);
2223   priv-&gt;parse = g_list_concat (priv-&gt;gather, priv-&gt;parse);
2224   priv-&gt;gather = NULL;
2225 
2226   /* clear buffer and decoder state */
2227   gst_video_decoder_flush (dec, FALSE);
2228 
2229   walk = priv-&gt;parse;
2230   while (walk) {
2231     GstBuffer *buf = GST_BUFFER_CAST (walk-&gt;data);
2232     GList *next = walk-&gt;next;
2233 
2234     GST_DEBUG_OBJECT (dec, &quot;parsing buffer %p, PTS %&quot; GST_TIME_FORMAT
2235         &quot;, DTS %&quot; GST_TIME_FORMAT &quot; flags %x&quot;, buf,
2236         GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
2237         GST_TIME_ARGS (GST_BUFFER_DTS (buf)), GST_BUFFER_FLAGS (buf));
2238 
2239     /* parse buffer, resulting frames prepended to parse_gather queue */
2240     gst_buffer_ref (buf);
2241     res = gst_video_decoder_chain_forward (dec, buf, at_eos);
2242 
2243     /* if we generated output, we can discard the buffer, else we
2244      * keep it in the queue */
2245     if (priv-&gt;parse_gather) {
2246       GST_DEBUG_OBJECT (dec, &quot;parsed buffer to %p&quot;, priv-&gt;parse_gather-&gt;data);
2247       priv-&gt;parse = g_list_delete_link (priv-&gt;parse, walk);
2248       gst_buffer_unref (buf);
2249     } else {
2250       GST_DEBUG_OBJECT (dec, &quot;buffer did not decode, keeping&quot;);
2251     }
2252     walk = next;
2253   }
2254 
2255   walk = priv-&gt;parse_gather;
2256   while (walk) {
2257     GstVideoCodecFrame *frame = (GstVideoCodecFrame *) (walk-&gt;data);
2258     GList *walk2;
2259 
2260     /* this is reverse playback, check if we need to apply some segment
2261      * to the output before decoding, as during decoding the segment.rate
2262      * must be used to determine if a buffer should be pushed or added to
2263      * the output list for reverse pushing.
2264      *
2265      * The new segment is not immediately pushed here because we must
2266      * wait for negotiation to happen before it can be pushed to avoid
2267      * pushing a segment before caps event. Negotiation only happens
2268      * when finish_frame is called.
2269      */
2270     for (walk2 = frame-&gt;events; walk2;) {
2271       GList *cur = walk2;
2272       GstEvent *event = walk2-&gt;data;
2273 
2274       walk2 = g_list_next (walk2);
2275       if (GST_EVENT_TYPE (event) &lt;= GST_EVENT_SEGMENT) {
2276 
2277         if (GST_EVENT_TYPE (event) == GST_EVENT_SEGMENT) {
2278           GstSegment segment;
2279 
2280           GST_DEBUG_OBJECT (dec, &quot;Segment at frame %p %&quot; GST_TIME_FORMAT,
2281               frame, GST_TIME_ARGS (GST_BUFFER_PTS (frame-&gt;input_buffer)));
2282           gst_event_copy_segment (event, &amp;segment);
2283           if (segment.format == GST_FORMAT_TIME) {
2284             dec-&gt;output_segment = segment;
2285             dec-&gt;priv-&gt;in_out_segment_sync =
2286                 gst_segment_is_equal (&amp;dec-&gt;input_segment, &amp;segment);
2287           }
2288         }
2289         dec-&gt;priv-&gt;pending_events =
2290             g_list_append (dec-&gt;priv-&gt;pending_events, event);
2291         frame-&gt;events = g_list_delete_link (frame-&gt;events, cur);
2292       }
2293     }
2294 
2295     walk = walk-&gt;next;
2296   }
2297 
2298   /* now we can process frames. Start by moving each frame from the parse_gather
2299    * to the decode list, reverse the order as we go, and stopping when/if we
2300    * copy a keyframe. */
2301   GST_DEBUG_OBJECT (dec, &quot;checking parsed frames for a keyframe to decode&quot;);
2302   walk = priv-&gt;parse_gather;
2303   while (walk) {
2304     GstVideoCodecFrame *frame = (GstVideoCodecFrame *) (walk-&gt;data);
2305 
2306     /* remove from the gather list */
2307     priv-&gt;parse_gather = g_list_remove_link (priv-&gt;parse_gather, walk);
2308 
2309     /* move it to the front of the decode queue */
2310     priv-&gt;decode = g_list_concat (walk, priv-&gt;decode);
2311 
2312     /* if we copied a keyframe, flush and decode the decode queue */
2313     if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame)) {
2314       GST_DEBUG_OBJECT (dec, &quot;found keyframe %p with PTS %&quot; GST_TIME_FORMAT
2315           &quot;, DTS %&quot; GST_TIME_FORMAT, frame,
2316           GST_TIME_ARGS (GST_BUFFER_PTS (frame-&gt;input_buffer)),
2317           GST_TIME_ARGS (GST_BUFFER_DTS (frame-&gt;input_buffer)));
2318       res = gst_video_decoder_flush_decode (dec);
2319       if (res != GST_FLOW_OK)
2320         goto done;
2321 
2322       /* We need to tell the subclass to drain now.
2323        * We prefer the drain vfunc, but for backward-compat
2324        * we use a finish() vfunc if drain isn&#39;t implemented */
2325       if (decoder_class-&gt;drain) {
2326         GST_DEBUG_OBJECT (dec, &quot;Draining&quot;);
2327         res = decoder_class-&gt;drain (dec);
2328       } else if (decoder_class-&gt;finish) {
2329         GST_FIXME_OBJECT (dec, &quot;Sub-class should implement drain(). &quot;
2330             &quot;Calling finish() for backwards-compat&quot;);
2331         res = decoder_class-&gt;finish (dec);
2332       }
2333 
2334       if (res != GST_FLOW_OK)
2335         goto done;
2336 
2337       /* now send queued data downstream */
2338       walk = priv-&gt;output_queued;
2339       while (walk) {
2340         GstBuffer *buf = GST_BUFFER_CAST (walk-&gt;data);
2341 
2342         if (G_LIKELY (res == GST_FLOW_OK)) {
2343           /* avoid stray DISCONT from forward processing,
2344            * which have no meaning in reverse pushing */
2345           GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DISCONT);
2346 
2347           /* Last chance to calculate a timestamp as we loop backwards
2348            * through the list */
2349           if (GST_BUFFER_TIMESTAMP (buf) != GST_CLOCK_TIME_NONE)
2350             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2351           else if (priv-&gt;last_timestamp_out != GST_CLOCK_TIME_NONE &amp;&amp;
2352               GST_BUFFER_DURATION (buf) != GST_CLOCK_TIME_NONE) {
2353             GST_BUFFER_TIMESTAMP (buf) =
2354                 priv-&gt;last_timestamp_out - GST_BUFFER_DURATION (buf);
2355             priv-&gt;last_timestamp_out = GST_BUFFER_TIMESTAMP (buf);
2356             GST_LOG_OBJECT (dec,
2357                 &quot;Calculated TS %&quot; GST_TIME_FORMAT &quot; working backwards&quot;,
2358                 GST_TIME_ARGS (priv-&gt;last_timestamp_out));
2359           }
2360 
2361           res = gst_video_decoder_clip_and_push_buf (dec, buf);
2362         } else {
2363           gst_buffer_unref (buf);
2364         }
2365 
2366         priv-&gt;output_queued =
2367             g_list_delete_link (priv-&gt;output_queued, priv-&gt;output_queued);
2368         walk = priv-&gt;output_queued;
2369       }
2370 
2371       /* clear buffer and decoder state again
2372        * before moving to the previous keyframe */
2373       gst_video_decoder_flush (dec, FALSE);
2374     }
2375 
2376     walk = priv-&gt;parse_gather;
2377   }
2378 
2379 done:
2380   return res;
2381 }
2382 
2383 static GstFlowReturn
2384 gst_video_decoder_chain_reverse (GstVideoDecoder * dec, GstBuffer * buf)
2385 {
2386   GstVideoDecoderPrivate *priv = dec-&gt;priv;
2387   GstFlowReturn result = GST_FLOW_OK;
2388 
2389   /* if we have a discont, move buffers to the decode list */
2390   if (!buf || GST_BUFFER_IS_DISCONT (buf)) {
2391     GST_DEBUG_OBJECT (dec, &quot;received discont&quot;);
2392 
2393     /* parse and decode stuff in the gather and parse queues */
2394     result = gst_video_decoder_flush_parse (dec, FALSE);
2395   }
2396 
2397   if (G_LIKELY (buf)) {
2398     GST_DEBUG_OBJECT (dec, &quot;gathering buffer %p of size %&quot; G_GSIZE_FORMAT &quot;, &quot;
2399         &quot;PTS %&quot; GST_TIME_FORMAT &quot;, DTS %&quot; GST_TIME_FORMAT &quot;, dur %&quot;
2400         GST_TIME_FORMAT, buf, gst_buffer_get_size (buf),
2401         GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
2402         GST_TIME_ARGS (GST_BUFFER_DTS (buf)),
2403         GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
2404 
2405     /* add buffer to gather queue */
2406     priv-&gt;gather = g_list_prepend (priv-&gt;gather, buf);
2407   }
2408 
2409   return result;
2410 }
2411 
2412 static GstFlowReturn
2413 gst_video_decoder_chain (GstPad * pad, GstObject * parent, GstBuffer * buf)
2414 {
2415   GstVideoDecoder *decoder;
2416   GstFlowReturn ret = GST_FLOW_OK;
2417 
2418   decoder = GST_VIDEO_DECODER (parent);
2419 
2420   if (G_UNLIKELY (!decoder-&gt;priv-&gt;input_state &amp;&amp; decoder-&gt;priv-&gt;needs_format))
2421     goto not_negotiated;
2422 
2423   GST_LOG_OBJECT (decoder,
2424       &quot;chain PTS %&quot; GST_TIME_FORMAT &quot;, DTS %&quot; GST_TIME_FORMAT &quot; duration %&quot;
2425       GST_TIME_FORMAT &quot; size %&quot; G_GSIZE_FORMAT &quot; flags %x&quot;,
2426       GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
2427       GST_TIME_ARGS (GST_BUFFER_DTS (buf)),
2428       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)),
2429       gst_buffer_get_size (buf), GST_BUFFER_FLAGS (buf));
2430 
2431   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2432 
2433   /* NOTE:
2434    * requiring the pad to be negotiated makes it impossible to use
2435    * oggdemux or filesrc ! decoder */
2436 
2437   if (decoder-&gt;input_segment.format == GST_FORMAT_UNDEFINED) {
2438     GstEvent *event;
2439     GstSegment *segment = &amp;decoder-&gt;input_segment;
2440 
2441     GST_WARNING_OBJECT (decoder,
2442         &quot;Received buffer without a new-segment. &quot;
2443         &quot;Assuming timestamps start from 0.&quot;);
2444 
2445     gst_segment_init (segment, GST_FORMAT_TIME);
2446 
2447     event = gst_event_new_segment (segment);
2448 
2449     decoder-&gt;priv-&gt;current_frame_events =
2450         g_list_prepend (decoder-&gt;priv-&gt;current_frame_events, event);
2451   }
2452 
2453   decoder-&gt;priv-&gt;had_input_data = TRUE;
2454 
2455   if (decoder-&gt;input_segment.rate &gt; 0.0)
2456     ret = gst_video_decoder_chain_forward (decoder, buf, FALSE);
2457   else
2458     ret = gst_video_decoder_chain_reverse (decoder, buf);
2459 
2460   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2461   return ret;
2462 
2463   /* ERRORS */
2464 not_negotiated:
2465   {
2466     GST_ELEMENT_ERROR (decoder, CORE, NEGOTIATION, (NULL),
2467         (&quot;decoder not initialized&quot;));
2468     gst_buffer_unref (buf);
2469     return GST_FLOW_NOT_NEGOTIATED;
2470   }
2471 }
2472 
2473 static GstStateChangeReturn
2474 gst_video_decoder_change_state (GstElement * element, GstStateChange transition)
2475 {
2476   GstVideoDecoder *decoder;
2477   GstVideoDecoderClass *decoder_class;
2478   GstStateChangeReturn ret;
2479 
2480   decoder = GST_VIDEO_DECODER (element);
2481   decoder_class = GST_VIDEO_DECODER_GET_CLASS (element);
2482 
2483   switch (transition) {
2484     case GST_STATE_CHANGE_NULL_TO_READY:
2485       /* open device/library if needed */
2486       if (decoder_class-&gt;open &amp;&amp; !decoder_class-&gt;open (decoder))
2487         goto open_failed;
2488       break;
2489     case GST_STATE_CHANGE_READY_TO_PAUSED:
2490       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2491       gst_video_decoder_reset (decoder, TRUE, TRUE);
2492       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2493 
2494       /* Initialize device/library if needed */
2495       if (decoder_class-&gt;start &amp;&amp; !decoder_class-&gt;start (decoder))
2496         goto start_failed;
2497       break;
2498     default:
2499       break;
2500   }
2501 
2502   ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition);
2503 
2504   switch (transition) {
2505     case GST_STATE_CHANGE_PAUSED_TO_READY:{
2506       gboolean stopped = TRUE;
2507 
2508       if (decoder_class-&gt;stop)
2509         stopped = decoder_class-&gt;stop (decoder);
2510 
2511       GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2512       gst_video_decoder_reset (decoder, TRUE, TRUE);
2513       GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2514 
2515       if (!stopped)
2516         goto stop_failed;
2517 
2518       break;
2519     }
2520     case GST_STATE_CHANGE_READY_TO_NULL:
2521       /* close device/library if needed */
2522       if (decoder_class-&gt;close &amp;&amp; !decoder_class-&gt;close (decoder))
2523         goto close_failed;
2524       break;
2525     default:
2526       break;
2527   }
2528 
2529   return ret;
2530 
2531   /* Errors */
2532 open_failed:
2533   {
2534     GST_ELEMENT_ERROR (decoder, LIBRARY, INIT, (NULL),
2535         (&quot;Failed to open decoder&quot;));
2536     return GST_STATE_CHANGE_FAILURE;
2537   }
2538 
2539 start_failed:
2540   {
2541     GST_ELEMENT_ERROR (decoder, LIBRARY, INIT, (NULL),
2542         (&quot;Failed to start decoder&quot;));
2543     return GST_STATE_CHANGE_FAILURE;
2544   }
2545 
2546 stop_failed:
2547   {
2548     GST_ELEMENT_ERROR (decoder, LIBRARY, INIT, (NULL),
2549         (&quot;Failed to stop decoder&quot;));
2550     return GST_STATE_CHANGE_FAILURE;
2551   }
2552 
2553 close_failed:
2554   {
2555     GST_ELEMENT_ERROR (decoder, LIBRARY, INIT, (NULL),
2556         (&quot;Failed to close decoder&quot;));
2557     return GST_STATE_CHANGE_FAILURE;
2558   }
2559 }
2560 
2561 static GstVideoCodecFrame *
2562 gst_video_decoder_new_frame (GstVideoDecoder * decoder)
2563 {
2564   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
2565   GstVideoCodecFrame *frame;
2566 
2567   frame = g_slice_new0 (GstVideoCodecFrame);
2568 
2569   frame-&gt;ref_count = 1;
2570 
2571   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2572   frame-&gt;system_frame_number = priv-&gt;system_frame_number;
2573   priv-&gt;system_frame_number++;
2574   frame-&gt;decode_frame_number = priv-&gt;decode_frame_number;
2575   priv-&gt;decode_frame_number++;
2576 
2577   frame-&gt;dts = GST_CLOCK_TIME_NONE;
2578   frame-&gt;pts = GST_CLOCK_TIME_NONE;
2579   frame-&gt;duration = GST_CLOCK_TIME_NONE;
2580   frame-&gt;events = priv-&gt;current_frame_events;
2581   priv-&gt;current_frame_events = NULL;
2582 
2583   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
2584 
2585   GST_LOG_OBJECT (decoder, &quot;Created new frame %p (sfn:%d)&quot;,
2586       frame, frame-&gt;system_frame_number);
2587 
2588   return frame;
2589 }
2590 
2591 static void
2592 gst_video_decoder_push_event_list (GstVideoDecoder * decoder, GList * events)
2593 {
2594   GList *l;
2595 
2596   /* events are stored in reverse order */
2597   for (l = g_list_last (events); l; l = g_list_previous (l)) {
2598     GST_LOG_OBJECT (decoder, &quot;pushing %s event&quot;, GST_EVENT_TYPE_NAME (l-&gt;data));
2599     gst_video_decoder_push_event (decoder, l-&gt;data);
2600   }
2601   g_list_free (events);
2602 }
2603 
2604 static void
2605 gst_video_decoder_prepare_finish_frame (GstVideoDecoder *
2606     decoder, GstVideoCodecFrame * frame, gboolean dropping)
2607 {
2608   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
2609   GList *l, *events = NULL;
2610   gboolean sync;
2611 
2612 #ifndef GST_DISABLE_GST_DEBUG
2613   GST_LOG_OBJECT (decoder, &quot;n %d in %&quot; G_GSIZE_FORMAT &quot; out %&quot; G_GSIZE_FORMAT,
2614       g_list_length (priv-&gt;frames),
2615       gst_adapter_available (priv-&gt;input_adapter),
2616       gst_adapter_available (priv-&gt;output_adapter));
2617 #endif
2618 
2619   sync = GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame);
2620 
2621   GST_LOG_OBJECT (decoder,
2622       &quot;finish frame %p (#%d) sync:%d PTS:%&quot; GST_TIME_FORMAT &quot; DTS:%&quot;
2623       GST_TIME_FORMAT,
2624       frame, frame-&gt;system_frame_number,
2625       sync, GST_TIME_ARGS (frame-&gt;pts), GST_TIME_ARGS (frame-&gt;dts));
2626 
2627   /* Push all pending events that arrived before this frame */
2628   for (l = priv-&gt;frames; l; l = l-&gt;next) {
2629     GstVideoCodecFrame *tmp = l-&gt;data;
2630 
2631     if (tmp-&gt;events) {
2632       events = g_list_concat (tmp-&gt;events, events);
2633       tmp-&gt;events = NULL;
2634     }
2635 
2636     if (tmp == frame)
2637       break;
2638   }
2639 
2640   if (dropping || !decoder-&gt;priv-&gt;output_state) {
2641     /* Push before the next frame that is not dropped */
2642     decoder-&gt;priv-&gt;pending_events =
2643         g_list_concat (events, decoder-&gt;priv-&gt;pending_events);
2644   } else {
2645     gst_video_decoder_push_event_list (decoder, decoder-&gt;priv-&gt;pending_events);
2646     decoder-&gt;priv-&gt;pending_events = NULL;
2647 
2648     gst_video_decoder_push_event_list (decoder, events);
2649   }
2650 
2651   /* Check if the data should not be displayed. For example altref/invisible
2652    * frame in vp8. In this case we should not update the timestamps. */
2653   if (GST_VIDEO_CODEC_FRAME_IS_DECODE_ONLY (frame))
2654     return;
2655 
2656   /* If the frame is meant to be output but we don&#39;t have an output_buffer
2657    * we have a problem :) */
2658   if (G_UNLIKELY ((frame-&gt;output_buffer == NULL) &amp;&amp; !dropping))
2659     goto no_output_buffer;
2660 
2661   if (GST_CLOCK_TIME_IS_VALID (frame-&gt;pts)) {
2662     if (frame-&gt;pts != priv-&gt;base_timestamp) {
2663       GST_DEBUG_OBJECT (decoder,
2664           &quot;sync timestamp %&quot; GST_TIME_FORMAT &quot; diff %&quot; GST_STIME_FORMAT,
2665           GST_TIME_ARGS (frame-&gt;pts),
2666           GST_STIME_ARGS (GST_CLOCK_DIFF (frame-&gt;pts,
2667                   decoder-&gt;output_segment.start)));
2668       priv-&gt;base_timestamp = frame-&gt;pts;
2669       priv-&gt;base_picture_number = frame-&gt;decode_frame_number;
2670     }
2671   }
2672 
2673   if (frame-&gt;duration == GST_CLOCK_TIME_NONE) {
2674     frame-&gt;duration = gst_video_decoder_get_frame_duration (decoder, frame);
2675     GST_LOG_OBJECT (decoder,
2676         &quot;Guessing duration %&quot; GST_TIME_FORMAT &quot; for frame...&quot;,
2677         GST_TIME_ARGS (frame-&gt;duration));
2678   }
2679 
2680   /* PTS is expected montone ascending,
2681    * so a good guess is lowest unsent DTS */
2682   {
2683     GstClockTime min_ts = GST_CLOCK_TIME_NONE;
2684     GstVideoCodecFrame *oframe = NULL;
2685     gboolean seen_none = FALSE;
2686 
2687     /* some maintenance regardless */
2688     for (l = priv-&gt;frames; l; l = l-&gt;next) {
2689       GstVideoCodecFrame *tmp = l-&gt;data;
2690 
2691       if (!GST_CLOCK_TIME_IS_VALID (tmp-&gt;abidata.ABI.ts)) {
2692         seen_none = TRUE;
2693         continue;
2694       }
2695 
2696       if (!GST_CLOCK_TIME_IS_VALID (min_ts) || tmp-&gt;abidata.ABI.ts &lt; min_ts) {
2697         min_ts = tmp-&gt;abidata.ABI.ts;
2698         oframe = tmp;
2699       }
2700     }
2701     /* save a ts if needed */
2702     if (oframe &amp;&amp; oframe != frame) {
2703       oframe-&gt;abidata.ABI.ts = frame-&gt;abidata.ABI.ts;
2704     }
2705 
2706     /* and set if needed;
2707      * valid delta means we have reasonable DTS input */
2708     /* also, if we ended up reordered, means this approach is conflicting
2709      * with some sparse existing PTS, and so it does not work out */
2710     if (!priv-&gt;reordered_output &amp;&amp;
2711         !GST_CLOCK_TIME_IS_VALID (frame-&gt;pts) &amp;&amp; !seen_none &amp;&amp;
2712         GST_CLOCK_TIME_IS_VALID (priv-&gt;pts_delta)) {
2713       frame-&gt;pts = min_ts + priv-&gt;pts_delta;
2714       GST_DEBUG_OBJECT (decoder,
2715           &quot;no valid PTS, using oldest DTS %&quot; GST_TIME_FORMAT,
2716           GST_TIME_ARGS (frame-&gt;pts));
2717     }
2718 
2719     /* some more maintenance, ts2 holds PTS */
2720     min_ts = GST_CLOCK_TIME_NONE;
2721     seen_none = FALSE;
2722     for (l = priv-&gt;frames; l; l = l-&gt;next) {
2723       GstVideoCodecFrame *tmp = l-&gt;data;
2724 
2725       if (!GST_CLOCK_TIME_IS_VALID (tmp-&gt;abidata.ABI.ts2)) {
2726         seen_none = TRUE;
2727         continue;
2728       }
2729 
2730       if (!GST_CLOCK_TIME_IS_VALID (min_ts) || tmp-&gt;abidata.ABI.ts2 &lt; min_ts) {
2731         min_ts = tmp-&gt;abidata.ABI.ts2;
2732         oframe = tmp;
2733       }
2734     }
2735     /* save a ts if needed */
2736     if (oframe &amp;&amp; oframe != frame) {
2737       oframe-&gt;abidata.ABI.ts2 = frame-&gt;abidata.ABI.ts2;
2738     }
2739 
2740     /* if we detected reordered output, then PTS are void,
2741      * however those were obtained; bogus input, subclass etc */
2742     if (priv-&gt;reordered_output &amp;&amp; !seen_none) {
2743       GST_DEBUG_OBJECT (decoder, &quot;invalidating PTS&quot;);
2744       frame-&gt;pts = GST_CLOCK_TIME_NONE;
2745     }
2746 
2747     if (!GST_CLOCK_TIME_IS_VALID (frame-&gt;pts) &amp;&amp; !seen_none) {
2748       frame-&gt;pts = min_ts;
2749       GST_DEBUG_OBJECT (decoder,
2750           &quot;no valid PTS, using oldest PTS %&quot; GST_TIME_FORMAT,
2751           GST_TIME_ARGS (frame-&gt;pts));
2752     }
2753   }
2754 
2755 
2756   if (frame-&gt;pts == GST_CLOCK_TIME_NONE) {
2757     /* Last ditch timestamp guess: Just add the duration to the previous
2758      * frame. If it&#39;s the first frame, just use the segment start. */
2759     if (frame-&gt;duration != GST_CLOCK_TIME_NONE) {
2760       if (GST_CLOCK_TIME_IS_VALID (priv-&gt;last_timestamp_out))
2761         frame-&gt;pts = priv-&gt;last_timestamp_out + frame-&gt;duration;
2762       else if (decoder-&gt;output_segment.rate &gt; 0.0)
2763         frame-&gt;pts = decoder-&gt;output_segment.start;
2764       GST_LOG_OBJECT (decoder,
2765           &quot;Guessing timestamp %&quot; GST_TIME_FORMAT &quot; for frame...&quot;,
2766           GST_TIME_ARGS (frame-&gt;pts));
2767     } else if (sync &amp;&amp; frame-&gt;dts != GST_CLOCK_TIME_NONE) {
2768       frame-&gt;pts = frame-&gt;dts;
2769       GST_LOG_OBJECT (decoder,
2770           &quot;Setting DTS as PTS %&quot; GST_TIME_FORMAT &quot; for frame...&quot;,
2771           GST_TIME_ARGS (frame-&gt;pts));
2772     }
2773   }
2774 
2775   if (GST_CLOCK_TIME_IS_VALID (priv-&gt;last_timestamp_out)) {
2776     if (frame-&gt;pts &lt; priv-&gt;last_timestamp_out) {
2777       GST_WARNING_OBJECT (decoder,
2778           &quot;decreasing timestamp (%&quot; GST_TIME_FORMAT &quot; &lt; %&quot;
2779           GST_TIME_FORMAT &quot;)&quot;,
2780           GST_TIME_ARGS (frame-&gt;pts), GST_TIME_ARGS (priv-&gt;last_timestamp_out));
2781       priv-&gt;reordered_output = TRUE;
2782       /* make it a bit less weird downstream */
2783       frame-&gt;pts = priv-&gt;last_timestamp_out;
2784     }
2785   }
2786 
2787   if (GST_CLOCK_TIME_IS_VALID (frame-&gt;pts))
2788     priv-&gt;last_timestamp_out = frame-&gt;pts;
2789 
2790   return;
2791 
2792   /* ERRORS */
2793 no_output_buffer:
2794   {
2795     GST_ERROR_OBJECT (decoder, &quot;No buffer to output !&quot;);
2796   }
2797 }
2798 
2799 /**
2800  * gst_video_decoder_release_frame:
2801  * @dec: a #GstVideoDecoder
2802  * @frame: (transfer full): the #GstVideoCodecFrame to release
2803  *
2804  * Similar to gst_video_decoder_drop_frame(), but simply releases @frame
2805  * without any processing other than removing it from list of pending frames,
2806  * after which it is considered finished and released.
2807  *
2808  * Since: 1.2.2
2809  */
2810 void
2811 gst_video_decoder_release_frame (GstVideoDecoder * dec,
2812     GstVideoCodecFrame * frame)
2813 {
2814   GList *link;
2815 
2816   /* unref once from the list */
2817   GST_VIDEO_DECODER_STREAM_LOCK (dec);
2818   link = g_list_find (dec-&gt;priv-&gt;frames, frame);
2819   if (link) {
2820     gst_video_codec_frame_unref (frame);
2821     dec-&gt;priv-&gt;frames = g_list_delete_link (dec-&gt;priv-&gt;frames, link);
2822   }
2823   if (frame-&gt;events) {
2824     dec-&gt;priv-&gt;pending_events =
2825         g_list_concat (frame-&gt;events, dec-&gt;priv-&gt;pending_events);
2826     frame-&gt;events = NULL;
2827   }
2828   GST_VIDEO_DECODER_STREAM_UNLOCK (dec);
2829 
2830   /* unref because this function takes ownership */
2831   gst_video_codec_frame_unref (frame);
2832 }
2833 
2834 /**
2835  * gst_video_decoder_drop_frame:
2836  * @dec: a #GstVideoDecoder
2837  * @frame: (transfer full): the #GstVideoCodecFrame to drop
2838  *
2839  * Similar to gst_video_decoder_finish_frame(), but drops @frame in any
2840  * case and posts a QoS message with the frame&#39;s details on the bus.
2841  * In any case, the frame is considered finished and released.
2842  *
2843  * Returns: a #GstFlowReturn, usually GST_FLOW_OK.
2844  */
2845 GstFlowReturn
2846 gst_video_decoder_drop_frame (GstVideoDecoder * dec, GstVideoCodecFrame * frame)
2847 {
2848   GstClockTime stream_time, jitter, earliest_time, qostime, timestamp;
2849   GstSegment *segment;
2850   GstMessage *qos_msg;
2851   gdouble proportion;
2852 
2853   GST_LOG_OBJECT (dec, &quot;drop frame %p&quot;, frame);
2854 
2855   GST_VIDEO_DECODER_STREAM_LOCK (dec);
2856 
2857   gst_video_decoder_prepare_finish_frame (dec, frame, TRUE);
2858 
2859   GST_DEBUG_OBJECT (dec, &quot;dropping frame %&quot; GST_TIME_FORMAT,
2860       GST_TIME_ARGS (frame-&gt;pts));
2861 
2862   dec-&gt;priv-&gt;dropped++;
2863 
2864   /* post QoS message */
2865   GST_OBJECT_LOCK (dec);
2866   proportion = dec-&gt;priv-&gt;proportion;
2867   earliest_time = dec-&gt;priv-&gt;earliest_time;
2868   GST_OBJECT_UNLOCK (dec);
2869 
2870   timestamp = frame-&gt;pts;
2871   segment = &amp;dec-&gt;output_segment;
2872   if (G_UNLIKELY (segment-&gt;format == GST_FORMAT_UNDEFINED))
2873     segment = &amp;dec-&gt;input_segment;
2874   stream_time =
2875       gst_segment_to_stream_time (segment, GST_FORMAT_TIME, timestamp);
2876   qostime = gst_segment_to_running_time (segment, GST_FORMAT_TIME, timestamp);
2877   jitter = GST_CLOCK_DIFF (qostime, earliest_time);
2878   qos_msg =
2879       gst_message_new_qos (GST_OBJECT_CAST (dec), FALSE, qostime, stream_time,
2880       timestamp, GST_CLOCK_TIME_NONE);
2881   gst_message_set_qos_values (qos_msg, jitter, proportion, 1000000);
2882   gst_message_set_qos_stats (qos_msg, GST_FORMAT_BUFFERS,
2883       dec-&gt;priv-&gt;processed, dec-&gt;priv-&gt;dropped);
2884   gst_element_post_message (GST_ELEMENT_CAST (dec), qos_msg);
2885 
2886   /* now free the frame */
2887   gst_video_decoder_release_frame (dec, frame);
2888 
2889   GST_VIDEO_DECODER_STREAM_UNLOCK (dec);
2890 
2891   return GST_FLOW_OK;
2892 }
2893 
2894 static gboolean
2895 gst_video_decoder_transform_meta_default (GstVideoDecoder *
2896     decoder, GstVideoCodecFrame * frame, GstMeta * meta)
2897 {
2898   const GstMetaInfo *info = meta-&gt;info;
2899   const gchar *const *tags;
2900 
2901   tags = gst_meta_api_type_get_tags (info-&gt;api);
2902 
2903   if (!tags || (g_strv_length ((gchar **) tags) == 1
2904           &amp;&amp; gst_meta_api_type_has_tag (info-&gt;api,
2905               g_quark_from_string (GST_META_TAG_VIDEO_STR))))
2906     return TRUE;
2907 
2908   return FALSE;
2909 }
2910 
2911 typedef struct
2912 {
2913   GstVideoDecoder *decoder;
2914   GstVideoCodecFrame *frame;
2915 } CopyMetaData;
2916 
2917 static gboolean
2918 foreach_metadata (GstBuffer * inbuf, GstMeta ** meta, gpointer user_data)
2919 {
2920   CopyMetaData *data = user_data;
2921   GstVideoDecoder *decoder = data-&gt;decoder;
2922   GstVideoDecoderClass *klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
2923   GstVideoCodecFrame *frame = data-&gt;frame;
2924   const GstMetaInfo *info = (*meta)-&gt;info;
2925   gboolean do_copy = FALSE;
2926 
2927   if (gst_meta_api_type_has_tag (info-&gt;api, _gst_meta_tag_memory)) {
2928     /* never call the transform_meta with memory specific metadata */
2929     GST_DEBUG_OBJECT (decoder, &quot;not copying memory specific metadata %s&quot;,
2930         g_type_name (info-&gt;api));
2931     do_copy = FALSE;
2932   } else if (klass-&gt;transform_meta) {
2933     do_copy = klass-&gt;transform_meta (decoder, frame, *meta);
2934     GST_DEBUG_OBJECT (decoder, &quot;transformed metadata %s: copy: %d&quot;,
2935         g_type_name (info-&gt;api), do_copy);
2936   }
2937 
2938   /* we only copy metadata when the subclass implemented a transform_meta
2939    * function and when it returns %TRUE */
2940   if (do_copy &amp;&amp; info-&gt;transform_func) {
2941     GstMetaTransformCopy copy_data = { FALSE, 0, -1 };
2942     GST_DEBUG_OBJECT (decoder, &quot;copy metadata %s&quot;, g_type_name (info-&gt;api));
2943     /* simply copy then */
2944     info-&gt;transform_func (frame-&gt;output_buffer, *meta, inbuf,
2945         _gst_meta_transform_copy, &amp;copy_data);
2946   }
2947   return TRUE;
2948 }
2949 
2950 /**
2951  * gst_video_decoder_finish_frame:
2952  * @decoder: a #GstVideoDecoder
2953  * @frame: (transfer full): a decoded #GstVideoCodecFrame
2954  *
2955  * @frame should have a valid decoded data buffer, whose metadata fields
2956  * are then appropriately set according to frame data and pushed downstream.
2957  * If no output data is provided, @frame is considered skipped.
2958  * In any case, the frame is considered finished and released.
2959  *
2960  * After calling this function the output buffer of the frame is to be
2961  * considered read-only. This function will also change the metadata
2962  * of the buffer.
2963  *
2964  * Returns: a #GstFlowReturn resulting from sending data downstream
2965  */
2966 GstFlowReturn
2967 gst_video_decoder_finish_frame (GstVideoDecoder * decoder,
2968     GstVideoCodecFrame * frame)
2969 {
2970   GstFlowReturn ret = GST_FLOW_OK;
2971   GstVideoDecoderClass *decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
2972   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
2973   GstBuffer *output_buffer;
2974   gboolean needs_reconfigure = FALSE;
2975 
2976   GST_LOG_OBJECT (decoder, &quot;finish frame %p&quot;, frame);
2977 
2978   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
2979 
2980   needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad);
2981   if (G_UNLIKELY (priv-&gt;output_state_changed || (priv-&gt;output_state
2982               &amp;&amp; needs_reconfigure))) {
2983     if (!gst_video_decoder_negotiate_unlocked (decoder)) {
2984       gst_pad_mark_reconfigure (decoder-&gt;srcpad);
2985       if (GST_PAD_IS_FLUSHING (decoder-&gt;srcpad))
2986         ret = GST_FLOW_FLUSHING;
2987       else
2988         ret = GST_FLOW_NOT_NEGOTIATED;
2989       goto done;
2990     }
2991   }
2992 
2993   gst_video_decoder_prepare_finish_frame (decoder, frame, FALSE);
2994   priv-&gt;processed++;
2995 
2996   if (priv-&gt;tags_changed) {
2997     GstEvent *tags_event;
2998 
2999     tags_event = gst_video_decoder_create_merged_tags_event (decoder);
3000 
3001     if (tags_event != NULL)
3002       gst_video_decoder_push_event (decoder, tags_event);
3003 
3004     priv-&gt;tags_changed = FALSE;
3005   }
3006 
3007   /* no buffer data means this frame is skipped */
3008   if (!frame-&gt;output_buffer || GST_VIDEO_CODEC_FRAME_IS_DECODE_ONLY (frame)) {
3009     GST_DEBUG_OBJECT (decoder, &quot;skipping frame %&quot; GST_TIME_FORMAT,
3010         GST_TIME_ARGS (frame-&gt;pts));
3011     goto done;
3012   }
3013 
3014   /* We need a writable buffer for the metadata changes below */
3015   output_buffer = frame-&gt;output_buffer =
3016       gst_buffer_make_writable (frame-&gt;output_buffer);
3017 
3018   GST_BUFFER_FLAG_UNSET (output_buffer, GST_BUFFER_FLAG_DELTA_UNIT);
3019 
3020   GST_BUFFER_PTS (output_buffer) = frame-&gt;pts;
3021   GST_BUFFER_DTS (output_buffer) = GST_CLOCK_TIME_NONE;
3022   GST_BUFFER_DURATION (output_buffer) = frame-&gt;duration;
3023 
3024   GST_BUFFER_OFFSET (output_buffer) = GST_BUFFER_OFFSET_NONE;
3025   GST_BUFFER_OFFSET_END (output_buffer) = GST_BUFFER_OFFSET_NONE;
3026 
3027   if (priv-&gt;discont) {
3028     GST_BUFFER_FLAG_SET (output_buffer, GST_BUFFER_FLAG_DISCONT);
3029   }
3030 
3031   if (decoder_class-&gt;transform_meta) {
3032     if (G_LIKELY (frame-&gt;input_buffer)) {
3033       CopyMetaData data;
3034 
3035       data.decoder = decoder;
3036       data.frame = frame;
3037       gst_buffer_foreach_meta (frame-&gt;input_buffer, foreach_metadata, &amp;data);
3038     } else {
3039       GST_WARNING_OBJECT (decoder,
3040           &quot;Can&#39;t copy metadata because input frame disappeared&quot;);
3041     }
3042   }
3043 
3044   /* Get an additional ref to the buffer, which is going to be pushed
3045    * downstream, the original ref is owned by the frame
3046    */
3047   output_buffer = gst_buffer_ref (output_buffer);
3048 
3049   /* Release frame so the buffer is writable when we push it downstream
3050    * if possible, i.e. if the subclass does not hold additional references
3051    * to the frame
3052    */
3053   gst_video_decoder_release_frame (decoder, frame);
3054   frame = NULL;
3055 
3056   if (decoder-&gt;output_segment.rate &lt; 0.0
3057       &amp;&amp; !(decoder-&gt;output_segment.flags &amp; GST_SEEK_FLAG_TRICKMODE_KEY_UNITS)) {
3058     GST_LOG_OBJECT (decoder, &quot;queued frame&quot;);
3059     priv-&gt;output_queued = g_list_prepend (priv-&gt;output_queued, output_buffer);
3060   } else {
3061     ret = gst_video_decoder_clip_and_push_buf (decoder, output_buffer);
3062   }
3063 
3064 done:
3065   if (frame)
3066     gst_video_decoder_release_frame (decoder, frame);
3067   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3068   return ret;
3069 }
3070 
3071 /* With stream lock, takes the frame reference */
3072 static GstFlowReturn
3073 gst_video_decoder_clip_and_push_buf (GstVideoDecoder * decoder, GstBuffer * buf)
3074 {
3075   GstFlowReturn ret = GST_FLOW_OK;
3076   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3077   guint64 start, stop;
3078   guint64 cstart, cstop;
3079   GstSegment *segment;
3080   GstClockTime duration;
3081 
3082   /* Check for clipping */
3083   start = GST_BUFFER_PTS (buf);
3084   duration = GST_BUFFER_DURATION (buf);
3085 
3086   /* store that we have valid decoded data */
3087   priv-&gt;had_output_data = TRUE;
3088 
3089   stop = GST_CLOCK_TIME_NONE;
3090 
3091   if (GST_CLOCK_TIME_IS_VALID (start) &amp;&amp; GST_CLOCK_TIME_IS_VALID (duration)) {
3092     stop = start + duration;
3093   } else if (GST_CLOCK_TIME_IS_VALID (start)
3094       &amp;&amp; !GST_CLOCK_TIME_IS_VALID (duration)) {
3095     /* If we don&#39;t clip away buffers that far before the segment we
3096      * can cause the pipeline to lockup. This can happen if audio is
3097      * properly clipped, and thus the audio sink does not preroll yet
3098      * but the video sink prerolls because we already outputted a
3099      * buffer here... and then queues run full.
3100      *
3101      * In the worst case we will clip one buffer too many here now if no
3102      * framerate is given, no buffer duration is given and the actual
3103      * framerate is lower than 25fps */
3104     stop = start + 40 * GST_MSECOND;
3105   }
3106 
3107   segment = &amp;decoder-&gt;output_segment;
3108   if (gst_segment_clip (segment, GST_FORMAT_TIME, start, stop, &amp;cstart, &amp;cstop)) {
3109     GST_BUFFER_PTS (buf) = cstart;
3110 
3111     if (stop != GST_CLOCK_TIME_NONE &amp;&amp; GST_CLOCK_TIME_IS_VALID (duration))
3112       GST_BUFFER_DURATION (buf) = cstop - cstart;
3113 
3114     GST_LOG_OBJECT (decoder,
3115         &quot;accepting buffer inside segment: %&quot; GST_TIME_FORMAT &quot; %&quot;
3116         GST_TIME_FORMAT &quot; seg %&quot; GST_TIME_FORMAT &quot; to %&quot; GST_TIME_FORMAT
3117         &quot; time %&quot; GST_TIME_FORMAT,
3118         GST_TIME_ARGS (cstart),
3119         GST_TIME_ARGS (cstop),
3120         GST_TIME_ARGS (segment-&gt;start), GST_TIME_ARGS (segment-&gt;stop),
3121         GST_TIME_ARGS (segment-&gt;time));
3122   } else {
3123     GST_LOG_OBJECT (decoder,
3124         &quot;dropping buffer outside segment: %&quot; GST_TIME_FORMAT
3125         &quot; %&quot; GST_TIME_FORMAT
3126         &quot; seg %&quot; GST_TIME_FORMAT &quot; to %&quot; GST_TIME_FORMAT
3127         &quot; time %&quot; GST_TIME_FORMAT,
3128         GST_TIME_ARGS (start), GST_TIME_ARGS (stop),
3129         GST_TIME_ARGS (segment-&gt;start),
3130         GST_TIME_ARGS (segment-&gt;stop), GST_TIME_ARGS (segment-&gt;time));
3131     /* only check and return EOS if upstream still
3132      * in the same segment and interested as such */
3133     if (decoder-&gt;priv-&gt;in_out_segment_sync) {
3134       if (segment-&gt;rate &gt;= 0) {
3135         if (GST_BUFFER_PTS (buf) &gt;= segment-&gt;stop)
3136           ret = GST_FLOW_EOS;
3137       } else if (GST_BUFFER_PTS (buf) &lt; segment-&gt;start) {
3138         ret = GST_FLOW_EOS;
3139       }
3140     }
3141     gst_buffer_unref (buf);
3142     goto done;
3143   }
3144 
3145   /* Is buffer too late (QoS) ? */
3146   if (GST_CLOCK_TIME_IS_VALID (priv-&gt;earliest_time)
3147       &amp;&amp; GST_CLOCK_TIME_IS_VALID (cstart)) {
3148     GstClockTime deadline =
3149         gst_segment_to_running_time (segment, GST_FORMAT_TIME, cstart);
3150     if (GST_CLOCK_TIME_IS_VALID (deadline) &amp;&amp; deadline &lt; priv-&gt;earliest_time) {
3151       GST_DEBUG_OBJECT (decoder,
3152           &quot;Dropping frame due to QoS. start:%&quot; GST_TIME_FORMAT &quot; deadline:%&quot;
3153           GST_TIME_FORMAT &quot; earliest_time:%&quot; GST_TIME_FORMAT,
3154           GST_TIME_ARGS (start), GST_TIME_ARGS (deadline),
3155           GST_TIME_ARGS (priv-&gt;earliest_time));
3156       gst_buffer_unref (buf);
3157       priv-&gt;discont = TRUE;
3158       goto done;
3159     }
3160   }
3161 
3162   /* Set DISCONT flag here ! */
3163 
3164   if (priv-&gt;discont) {
3165     GST_DEBUG_OBJECT (decoder, &quot;Setting discont on output buffer&quot;);
3166     GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DISCONT);
3167     priv-&gt;discont = FALSE;
3168   }
3169 
3170   /* update rate estimate */
3171   GST_OBJECT_LOCK (decoder);
3172   priv-&gt;bytes_out += gst_buffer_get_size (buf);
3173   if (GST_CLOCK_TIME_IS_VALID (duration)) {
3174     priv-&gt;time += duration;
3175   } else {
3176     /* FIXME : Use difference between current and previous outgoing
3177      * timestamp, and relate to difference between current and previous
3178      * bytes */
3179     /* better none than nothing valid */
3180     priv-&gt;time = GST_CLOCK_TIME_NONE;
3181   }
3182   GST_OBJECT_UNLOCK (decoder);
3183 
3184   GST_DEBUG_OBJECT (decoder, &quot;pushing buffer %p of size %&quot; G_GSIZE_FORMAT &quot;, &quot;
3185       &quot;PTS %&quot; GST_TIME_FORMAT &quot;, dur %&quot; GST_TIME_FORMAT, buf,
3186       gst_buffer_get_size (buf),
3187       GST_TIME_ARGS (GST_BUFFER_PTS (buf)),
3188       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
3189 
3190   /* we got data, so note things are looking up again, reduce
3191    * the error count, if there is one */
3192   if (G_UNLIKELY (priv-&gt;error_count))
3193     priv-&gt;error_count = 0;
3194 
3195 #ifndef GST_DISABLE_DEBUG
3196   if (G_UNLIKELY (priv-&gt;last_reset_time != GST_CLOCK_TIME_NONE)) {
3197     GstClockTime elapsed = gst_util_get_timestamp () - priv-&gt;last_reset_time;
3198 
3199     /* First buffer since reset, report how long we took */
3200     GST_INFO_OBJECT (decoder, &quot;First buffer since flush took %&quot; GST_TIME_FORMAT
3201         &quot; to produce&quot;, GST_TIME_ARGS (elapsed));
3202     priv-&gt;last_reset_time = GST_CLOCK_TIME_NONE;
3203   }
3204 #endif
3205 
3206   ret = gst_pad_push (decoder-&gt;srcpad, buf);
3207 
3208 done:
3209   return ret;
3210 }
3211 
3212 /**
3213  * gst_video_decoder_add_to_frame:
3214  * @decoder: a #GstVideoDecoder
3215  * @n_bytes: the number of bytes to add
3216  *
3217  * Removes next @n_bytes of input data and adds it to currently parsed frame.
3218  */
3219 void
3220 gst_video_decoder_add_to_frame (GstVideoDecoder * decoder, int n_bytes)
3221 {
3222   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3223   GstBuffer *buf;
3224 
3225   GST_LOG_OBJECT (decoder, &quot;add %d bytes to frame&quot;, n_bytes);
3226 
3227   if (n_bytes == 0)
3228     return;
3229 
3230   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3231   if (gst_adapter_available (priv-&gt;output_adapter) == 0) {
3232     priv-&gt;frame_offset =
3233         priv-&gt;input_offset - gst_adapter_available (priv-&gt;input_adapter);
3234   }
3235   buf = gst_adapter_take_buffer (priv-&gt;input_adapter, n_bytes);
3236 
3237   gst_adapter_push (priv-&gt;output_adapter, buf);
3238   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3239 }
3240 
3241 /**
3242  * gst_video_decoder_get_pending_frame_size:
3243  * @decoder: a #GstVideoDecoder
3244  *
3245  * Returns the number of bytes previously added to the current frame
3246  * by calling gst_video_decoder_add_to_frame().
3247  *
3248  * Returns: The number of bytes pending for the current frame
3249  *
3250  * Since: 1.4
3251  */
3252 gsize
3253 gst_video_decoder_get_pending_frame_size (GstVideoDecoder * decoder)
3254 {
3255   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3256   gsize ret;
3257 
3258   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3259   ret = gst_adapter_available (priv-&gt;output_adapter);
3260   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3261 
3262   GST_LOG_OBJECT (decoder, &quot;Current pending frame has %&quot; G_GSIZE_FORMAT &quot;bytes&quot;,
3263       ret);
3264 
3265   return ret;
3266 }
3267 
3268 static guint64
3269 gst_video_decoder_get_frame_duration (GstVideoDecoder * decoder,
3270     GstVideoCodecFrame * frame)
3271 {
3272   GstVideoCodecState *state = decoder-&gt;priv-&gt;output_state;
3273 
3274   /* it&#39;s possible that we don&#39;t have a state yet when we are dropping the
3275    * initial buffers */
3276   if (state == NULL)
3277     return GST_CLOCK_TIME_NONE;
3278 
3279   if (state-&gt;info.fps_d == 0 || state-&gt;info.fps_n == 0) {
3280     return GST_CLOCK_TIME_NONE;
3281   }
3282 
3283   /* FIXME: For interlaced frames this needs to take into account
3284    * the number of valid fields in the frame
3285    */
3286 
3287   return gst_util_uint64_scale (GST_SECOND, state-&gt;info.fps_d,
3288       state-&gt;info.fps_n);
3289 }
3290 
3291 /**
3292  * gst_video_decoder_have_frame:
3293  * @decoder: a #GstVideoDecoder
3294  *
3295  * Gathers all data collected for currently parsed frame, gathers corresponding
3296  * metadata and passes it along for further processing, i.e. @handle_frame.
3297  *
3298  * Returns: a #GstFlowReturn
3299  */
3300 GstFlowReturn
3301 gst_video_decoder_have_frame (GstVideoDecoder * decoder)
3302 {
3303   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3304   GstBuffer *buffer;
3305   int n_available;
3306   GstClockTime pts, dts, duration;
3307   guint flags;
3308   GstFlowReturn ret = GST_FLOW_OK;
3309 
3310   GST_LOG_OBJECT (decoder, &quot;have_frame at offset %&quot; G_GUINT64_FORMAT,
3311       priv-&gt;frame_offset);
3312 
3313   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3314 
3315   n_available = gst_adapter_available (priv-&gt;output_adapter);
3316   if (n_available) {
3317     buffer = gst_adapter_take_buffer (priv-&gt;output_adapter, n_available);
3318   } else {
3319     buffer = gst_buffer_new_and_alloc (0);
3320   }
3321 
3322   priv-&gt;current_frame-&gt;input_buffer = buffer;
3323 
3324   gst_video_decoder_get_buffer_info_at_offset (decoder,
3325       priv-&gt;frame_offset, &amp;pts, &amp;dts, &amp;duration, &amp;flags);
3326 
3327   GST_BUFFER_PTS (buffer) = pts;
3328   GST_BUFFER_DTS (buffer) = dts;
3329   GST_BUFFER_DURATION (buffer) = duration;
3330   GST_BUFFER_FLAGS (buffer) = flags;
3331 
3332   GST_LOG_OBJECT (decoder, &quot;collected frame size %d, &quot;
3333       &quot;PTS %&quot; GST_TIME_FORMAT &quot;, DTS %&quot; GST_TIME_FORMAT &quot;, dur %&quot;
3334       GST_TIME_FORMAT, n_available, GST_TIME_ARGS (pts), GST_TIME_ARGS (dts),
3335       GST_TIME_ARGS (duration));
3336 
3337   if (!GST_BUFFER_FLAG_IS_SET (buffer, GST_BUFFER_FLAG_DELTA_UNIT)) {
3338     GST_LOG_OBJECT (decoder, &quot;Marking as sync point&quot;);
3339     GST_VIDEO_CODEC_FRAME_SET_SYNC_POINT (priv-&gt;current_frame);
3340   }
3341 
3342   /* In reverse playback, just capture and queue frames for later processing */
3343   if (decoder-&gt;input_segment.rate &lt; 0.0) {
3344     priv-&gt;parse_gather =
3345         g_list_prepend (priv-&gt;parse_gather, priv-&gt;current_frame);
3346   } else {
3347     /* Otherwise, decode the frame, which gives away our ref */
3348     ret = gst_video_decoder_decode_frame (decoder, priv-&gt;current_frame);
3349   }
3350   /* Current frame is gone now, either way */
3351   priv-&gt;current_frame = NULL;
3352 
3353   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3354 
3355   return ret;
3356 }
3357 
3358 /* Pass the frame in priv-&gt;current_frame through the
3359  * handle_frame() callback for decoding and passing to gvd_finish_frame(),
3360  * or dropping by passing to gvd_drop_frame() */
3361 static GstFlowReturn
3362 gst_video_decoder_decode_frame (GstVideoDecoder * decoder,
3363     GstVideoCodecFrame * frame)
3364 {
3365   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3366   GstVideoDecoderClass *decoder_class;
3367   GstFlowReturn ret = GST_FLOW_OK;
3368 
3369   decoder_class = GST_VIDEO_DECODER_GET_CLASS (decoder);
3370 
3371   /* FIXME : This should only have to be checked once (either the subclass has an
3372    * implementation, or it doesn&#39;t) */
3373   g_return_val_if_fail (decoder_class-&gt;handle_frame != NULL, GST_FLOW_ERROR);
3374 
3375   frame-&gt;distance_from_sync = priv-&gt;distance_from_sync;
3376   priv-&gt;distance_from_sync++;
3377   frame-&gt;pts = GST_BUFFER_PTS (frame-&gt;input_buffer);
3378   frame-&gt;dts = GST_BUFFER_DTS (frame-&gt;input_buffer);
3379   frame-&gt;duration = GST_BUFFER_DURATION (frame-&gt;input_buffer);
3380 
3381   /* For keyframes, PTS = DTS + constant_offset, usually 0 to 3 frame
3382    * durations. */
3383   /* FIXME upstream can be quite wrong about the keyframe aspect,
3384    * so we could be going off here as well,
3385    * maybe let subclass decide if it really is/was a keyframe */
3386   if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame) &amp;&amp;
3387       GST_CLOCK_TIME_IS_VALID (frame-&gt;pts)
3388       &amp;&amp; GST_CLOCK_TIME_IS_VALID (frame-&gt;dts)) {
3389     /* just in case they are not equal as might ideally be,
3390      * e.g. quicktime has a (positive) delta approach */
3391     priv-&gt;pts_delta = frame-&gt;pts - frame-&gt;dts;
3392     GST_DEBUG_OBJECT (decoder, &quot;PTS delta %d ms&quot;,
3393         (gint) (priv-&gt;pts_delta / GST_MSECOND));
3394   }
3395 
3396   frame-&gt;abidata.ABI.ts = frame-&gt;dts;
3397   frame-&gt;abidata.ABI.ts2 = frame-&gt;pts;
3398 
3399   GST_LOG_OBJECT (decoder, &quot;PTS %&quot; GST_TIME_FORMAT &quot;, DTS %&quot; GST_TIME_FORMAT
3400       &quot;, dist %d&quot;, GST_TIME_ARGS (frame-&gt;pts), GST_TIME_ARGS (frame-&gt;dts),
3401       frame-&gt;distance_from_sync);
3402 
3403   gst_video_codec_frame_ref (frame);
3404   priv-&gt;frames = g_list_append (priv-&gt;frames, frame);
3405 
3406   if (g_list_length (priv-&gt;frames) &gt; 10) {
3407     GST_DEBUG_OBJECT (decoder, &quot;decoder frame list getting long: %d frames,&quot;
3408         &quot;possible internal leaking?&quot;, g_list_length (priv-&gt;frames));
3409   }
3410 
3411   frame-&gt;deadline =
3412       gst_segment_to_running_time (&amp;decoder-&gt;input_segment, GST_FORMAT_TIME,
3413       frame-&gt;pts);
3414 
3415   /* do something with frame */
3416   ret = decoder_class-&gt;handle_frame (decoder, frame);
3417   if (ret != GST_FLOW_OK)
3418     GST_DEBUG_OBJECT (decoder, &quot;flow error %s&quot;, gst_flow_get_name (ret));
3419 
3420   /* the frame has either been added to parse_gather or sent to
3421      handle frame so there is no need to unref it */
3422   return ret;
3423 }
3424 
3425 
3426 /**
3427  * gst_video_decoder_get_output_state:
3428  * @decoder: a #GstVideoDecoder
3429  *
3430  * Get the #GstVideoCodecState currently describing the output stream.
3431  *
3432  * Returns: (transfer full): #GstVideoCodecState describing format of video data.
3433  */
3434 GstVideoCodecState *
3435 gst_video_decoder_get_output_state (GstVideoDecoder * decoder)
3436 {
3437   GstVideoCodecState *state = NULL;
3438 
3439   GST_OBJECT_LOCK (decoder);
3440   if (decoder-&gt;priv-&gt;output_state)
3441     state = gst_video_codec_state_ref (decoder-&gt;priv-&gt;output_state);
3442   GST_OBJECT_UNLOCK (decoder);
3443 
3444   return state;
3445 }
3446 
3447 /**
3448  * gst_video_decoder_set_output_state:
3449  * @decoder: a #GstVideoDecoder
3450  * @fmt: a #GstVideoFormat
3451  * @width: The width in pixels
3452  * @height: The height in pixels
3453  * @reference: (allow-none) (transfer none): An optional reference #GstVideoCodecState
3454  *
3455  * Creates a new #GstVideoCodecState with the specified @fmt, @width and @height
3456  * as the output state for the decoder.
3457  * Any previously set output state on @decoder will be replaced by the newly
3458  * created one.
3459  *
3460  * If the subclass wishes to copy over existing fields (like pixel aspec ratio,
3461  * or framerate) from an existing #GstVideoCodecState, it can be provided as a
3462  * @reference.
3463  *
3464  * If the subclass wishes to override some fields from the output state (like
3465  * pixel-aspect-ratio or framerate) it can do so on the returned #GstVideoCodecState.
3466  *
3467  * The new output state will only take effect (set on pads and buffers) starting
3468  * from the next call to #gst_video_decoder_finish_frame().
3469  *
3470  * Returns: (transfer full): the newly configured output state.
3471  */
3472 GstVideoCodecState *
3473 gst_video_decoder_set_output_state (GstVideoDecoder * decoder,
3474     GstVideoFormat fmt, guint width, guint height,
3475     GstVideoCodecState * reference)
3476 {
3477   GstVideoDecoderPrivate *priv = decoder-&gt;priv;
3478   GstVideoCodecState *state;
3479 
3480   GST_DEBUG_OBJECT (decoder, &quot;fmt:%d, width:%d, height:%d, reference:%p&quot;,
3481       fmt, width, height, reference);
3482 
3483   /* Create the new output state */
3484   state = _new_output_state (fmt, width, height, reference);
3485   if (!state)
3486     return NULL;
3487 
3488   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3489 
3490   GST_OBJECT_LOCK (decoder);
3491   /* Replace existing output state by new one */
3492   if (priv-&gt;output_state)
3493     gst_video_codec_state_unref (priv-&gt;output_state);
3494   priv-&gt;output_state = gst_video_codec_state_ref (state);
3495 
3496   if (priv-&gt;output_state != NULL &amp;&amp; priv-&gt;output_state-&gt;info.fps_n &gt; 0) {
3497     priv-&gt;qos_frame_duration =
3498         gst_util_uint64_scale (GST_SECOND, priv-&gt;output_state-&gt;info.fps_d,
3499         priv-&gt;output_state-&gt;info.fps_n);
3500   } else {
3501     priv-&gt;qos_frame_duration = 0;
3502   }
3503   priv-&gt;output_state_changed = TRUE;
3504   GST_OBJECT_UNLOCK (decoder);
3505 
3506   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3507 
3508   return state;
3509 }
3510 
3511 
3512 /**
3513  * gst_video_decoder_get_oldest_frame:
3514  * @decoder: a #GstVideoDecoder
3515  *
3516  * Get the oldest pending unfinished #GstVideoCodecFrame
3517  *
3518  * Returns: (transfer full): oldest pending unfinished #GstVideoCodecFrame.
3519  */
3520 GstVideoCodecFrame *
3521 gst_video_decoder_get_oldest_frame (GstVideoDecoder * decoder)
3522 {
3523   GstVideoCodecFrame *frame = NULL;
3524 
3525   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3526   if (decoder-&gt;priv-&gt;frames)
3527     frame = gst_video_codec_frame_ref (decoder-&gt;priv-&gt;frames-&gt;data);
3528   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3529 
3530   return (GstVideoCodecFrame *) frame;
3531 }
3532 
3533 /**
3534  * gst_video_decoder_get_frame:
3535  * @decoder: a #GstVideoDecoder
3536  * @frame_number: system_frame_number of a frame
3537  *
3538  * Get a pending unfinished #GstVideoCodecFrame
3539  *
3540  * Returns: (transfer full): pending unfinished #GstVideoCodecFrame identified by @frame_number.
3541  */
3542 GstVideoCodecFrame *
3543 gst_video_decoder_get_frame (GstVideoDecoder * decoder, int frame_number)
3544 {
3545   GList *g;
3546   GstVideoCodecFrame *frame = NULL;
3547 
3548   GST_DEBUG_OBJECT (decoder, &quot;frame_number : %d&quot;, frame_number);
3549 
3550   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3551   for (g = decoder-&gt;priv-&gt;frames; g; g = g-&gt;next) {
3552     GstVideoCodecFrame *tmp = g-&gt;data;
3553 
3554     if (tmp-&gt;system_frame_number == frame_number) {
3555       frame = gst_video_codec_frame_ref (tmp);
3556       break;
3557     }
3558   }
3559   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3560 
3561   return frame;
3562 }
3563 
3564 /**
3565  * gst_video_decoder_get_frames:
3566  * @decoder: a #GstVideoDecoder
3567  *
3568  * Get all pending unfinished #GstVideoCodecFrame
3569  *
3570  * Returns: (transfer full) (element-type GstVideoCodecFrame): pending unfinished #GstVideoCodecFrame.
3571  */
3572 GList *
3573 gst_video_decoder_get_frames (GstVideoDecoder * decoder)
3574 {
3575   GList *frames;
3576 
3577   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3578   frames = g_list_copy (decoder-&gt;priv-&gt;frames);
3579   g_list_foreach (frames, (GFunc) gst_video_codec_frame_ref, NULL);
3580   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3581 
3582   return frames;
3583 }
3584 
3585 static gboolean
3586 gst_video_decoder_decide_allocation_default (GstVideoDecoder * decoder,
3587     GstQuery * query)
3588 {
3589   GstCaps *outcaps = NULL;
3590   GstBufferPool *pool = NULL;
3591   guint size, min, max;
3592   GstAllocator *allocator = NULL;
3593   GstAllocationParams params;
3594   GstStructure *config;
3595   gboolean update_pool, update_allocator;
3596   GstVideoInfo vinfo;
3597 
3598   gst_query_parse_allocation (query, &amp;outcaps, NULL);
3599   gst_video_info_init (&amp;vinfo);
3600   if (outcaps)
3601     gst_video_info_from_caps (&amp;vinfo, outcaps);
3602 
3603   /* we got configuration from our peer or the decide_allocation method,
3604    * parse them */
3605   if (gst_query_get_n_allocation_params (query) &gt; 0) {
3606     /* try the allocator */
3607     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
3608     update_allocator = TRUE;
3609   } else {
3610     allocator = NULL;
3611     gst_allocation_params_init (&amp;params);
3612     update_allocator = FALSE;
3613   }
3614 
3615   if (gst_query_get_n_allocation_pools (query) &gt; 0) {
3616     gst_query_parse_nth_allocation_pool (query, 0, &amp;pool, &amp;size, &amp;min, &amp;max);
3617     size = MAX (size, vinfo.size);
3618     update_pool = TRUE;
3619   } else {
3620     pool = NULL;
3621     size = vinfo.size;
3622     min = max = 0;
3623 
3624     update_pool = FALSE;
3625   }
3626 
3627   if (pool == NULL) {
3628     /* no pool, we can make our own */
3629     GST_DEBUG_OBJECT (decoder, &quot;no pool, making new pool&quot;);
3630     pool = gst_video_buffer_pool_new ();
3631   }
3632 
3633   /* now configure */
3634   config = gst_buffer_pool_get_config (pool);
3635   gst_buffer_pool_config_set_params (config, outcaps, size, min, max);
3636   gst_buffer_pool_config_set_allocator (config, allocator, &amp;params);
3637 
3638   GST_DEBUG_OBJECT (decoder,
3639       &quot;setting config %&quot; GST_PTR_FORMAT &quot; in pool %&quot; GST_PTR_FORMAT, config,
3640       pool);
3641   if (!gst_buffer_pool_set_config (pool, config)) {
3642     config = gst_buffer_pool_get_config (pool);
3643 
3644     /* If change are not acceptable, fallback to generic pool */
3645     if (!gst_buffer_pool_config_validate_params (config, outcaps, size, min,
3646             max)) {
3647       GST_DEBUG_OBJECT (decoder, &quot;unsuported pool, making new pool&quot;);
3648 
3649       gst_object_unref (pool);
3650       pool = gst_video_buffer_pool_new ();
3651       gst_buffer_pool_config_set_params (config, outcaps, size, min, max);
3652       gst_buffer_pool_config_set_allocator (config, allocator, &amp;params);
3653     }
3654 
3655     if (!gst_buffer_pool_set_config (pool, config))
3656       goto config_failed;
3657   }
3658 
3659   if (update_allocator)
3660     gst_query_set_nth_allocation_param (query, 0, allocator, &amp;params);
3661   else
3662     gst_query_add_allocation_param (query, allocator, &amp;params);
3663   if (allocator)
3664     gst_object_unref (allocator);
3665 
3666   if (update_pool)
3667     gst_query_set_nth_allocation_pool (query, 0, pool, size, min, max);
3668   else
3669     gst_query_add_allocation_pool (query, pool, size, min, max);
3670 
3671   if (pool)
3672     gst_object_unref (pool);
3673 
3674   return TRUE;
3675 
3676 config_failed:
3677   if (allocator)
3678     gst_object_unref (allocator);
3679   if (pool)
3680     gst_object_unref (pool);
3681   GST_ELEMENT_ERROR (decoder, RESOURCE, SETTINGS,
3682       (&quot;Failed to configure the buffer pool&quot;),
3683       (&quot;Configuration is most likely invalid, please report this issue.&quot;));
3684   return FALSE;
3685 }
3686 
3687 static gboolean
3688 gst_video_decoder_propose_allocation_default (GstVideoDecoder * decoder,
3689     GstQuery * query)
3690 {
3691   return TRUE;
3692 }
3693 
3694 static gboolean
3695 gst_video_decoder_negotiate_pool (GstVideoDecoder * decoder, GstCaps * caps)
3696 {
3697   GstVideoDecoderClass *klass;
3698   GstQuery *query = NULL;
3699   GstBufferPool *pool = NULL;
3700   GstAllocator *allocator;
3701   GstAllocationParams params;
3702   gboolean ret = TRUE;
3703 
3704   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
3705 
3706   query = gst_query_new_allocation (caps, TRUE);
3707 
3708   GST_DEBUG_OBJECT (decoder, &quot;do query ALLOCATION&quot;);
3709 
3710   if (!gst_pad_peer_query (decoder-&gt;srcpad, query)) {
3711     GST_DEBUG_OBJECT (decoder, &quot;didn&#39;t get downstream ALLOCATION hints&quot;);
3712   }
3713 
3714   g_assert (klass-&gt;decide_allocation != NULL);
3715   ret = klass-&gt;decide_allocation (decoder, query);
3716 
3717   GST_DEBUG_OBJECT (decoder, &quot;ALLOCATION (%d) params: %&quot; GST_PTR_FORMAT, ret,
3718       query);
3719 
3720   if (!ret)
3721     goto no_decide_allocation;
3722 
3723   /* we got configuration from our peer or the decide_allocation method,
3724    * parse them */
3725   if (gst_query_get_n_allocation_params (query) &gt; 0) {
3726     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
3727   } else {
3728     allocator = NULL;
3729     gst_allocation_params_init (&amp;params);
3730   }
3731 
3732   if (gst_query_get_n_allocation_pools (query) &gt; 0)
3733     gst_query_parse_nth_allocation_pool (query, 0, &amp;pool, NULL, NULL, NULL);
3734   if (!pool) {
3735     if (allocator)
3736       gst_object_unref (allocator);
3737     ret = FALSE;
3738     goto no_decide_allocation;
3739   }
3740 
3741   if (decoder-&gt;priv-&gt;allocator)
3742     gst_object_unref (decoder-&gt;priv-&gt;allocator);
3743   decoder-&gt;priv-&gt;allocator = allocator;
3744   decoder-&gt;priv-&gt;params = params;
3745 
3746   if (decoder-&gt;priv-&gt;pool) {
3747     /* do not set the bufferpool to inactive here, it will be done
3748      * on its finalize function. As videodecoder do late renegotiation
3749      * it might happen that some element downstream is already using this
3750      * same bufferpool and deactivating it will make it fail.
3751      * Happens when a downstream element changes from passthrough to
3752      * non-passthrough and gets this same bufferpool to use */
3753     GST_DEBUG_OBJECT (decoder, &quot;unref pool %&quot; GST_PTR_FORMAT,
3754         decoder-&gt;priv-&gt;pool);
3755     gst_object_unref (decoder-&gt;priv-&gt;pool);
3756   }
3757   decoder-&gt;priv-&gt;pool = pool;
3758 
3759   /* and activate */
3760   GST_DEBUG_OBJECT (decoder, &quot;activate pool %&quot; GST_PTR_FORMAT, pool);
3761   gst_buffer_pool_set_active (pool, TRUE);
3762 
3763 done:
3764   if (query)
3765     gst_query_unref (query);
3766 
3767   return ret;
3768 
3769   /* Errors */
3770 no_decide_allocation:
3771   {
3772     GST_WARNING_OBJECT (decoder, &quot;Subclass failed to decide allocation&quot;);
3773     goto done;
3774   }
3775 }
3776 
3777 static gboolean
3778 gst_video_decoder_negotiate_default (GstVideoDecoder * decoder)
3779 {
3780   GstVideoCodecState *state = decoder-&gt;priv-&gt;output_state;
3781   gboolean ret = TRUE;
3782   GstVideoCodecFrame *frame;
3783   GstCaps *prevcaps;
3784 
3785   if (!state) {
3786     GST_DEBUG_OBJECT (decoder,
3787         &quot;Trying to negotiate the pool with out setting the o/p format&quot;);
3788     ret = gst_video_decoder_negotiate_pool (decoder, NULL);
3789     goto done;
3790   }
3791 
3792   g_return_val_if_fail (GST_VIDEO_INFO_WIDTH (&amp;state-&gt;info) != 0, FALSE);
3793   g_return_val_if_fail (GST_VIDEO_INFO_HEIGHT (&amp;state-&gt;info) != 0, FALSE);
3794 
3795   /* If the base class didn&#39;t set any multiview params, assume mono
3796    * now */
3797   if (GST_VIDEO_INFO_MULTIVIEW_MODE (&amp;state-&gt;info) ==
3798       GST_VIDEO_MULTIVIEW_MODE_NONE) {
3799     GST_VIDEO_INFO_MULTIVIEW_MODE (&amp;state-&gt;info) =
3800         GST_VIDEO_MULTIVIEW_MODE_MONO;
3801     GST_VIDEO_INFO_MULTIVIEW_FLAGS (&amp;state-&gt;info) =
3802         GST_VIDEO_MULTIVIEW_FLAGS_NONE;
3803   }
3804 
3805   GST_DEBUG_OBJECT (decoder, &quot;output_state par %d/%d fps %d/%d&quot;,
3806       state-&gt;info.par_n, state-&gt;info.par_d,
3807       state-&gt;info.fps_n, state-&gt;info.fps_d);
3808 
3809   if (state-&gt;caps == NULL)
3810     state-&gt;caps = gst_video_info_to_caps (&amp;state-&gt;info);
3811   if (state-&gt;allocation_caps == NULL)
3812     state-&gt;allocation_caps = gst_caps_ref (state-&gt;caps);
3813 
3814   GST_DEBUG_OBJECT (decoder, &quot;setting caps %&quot; GST_PTR_FORMAT, state-&gt;caps);
3815 
3816   /* Push all pending pre-caps events of the oldest frame before
3817    * setting caps */
3818   frame = decoder-&gt;priv-&gt;frames ? decoder-&gt;priv-&gt;frames-&gt;data : NULL;
3819   if (frame || decoder-&gt;priv-&gt;current_frame_events) {
3820     GList **events, *l;
3821 
3822     if (frame) {
3823       events = &amp;frame-&gt;events;
3824     } else {
3825       events = &amp;decoder-&gt;priv-&gt;current_frame_events;
3826     }
3827 
3828     for (l = g_list_last (*events); l;) {
3829       GstEvent *event = GST_EVENT (l-&gt;data);
3830       GList *tmp;
3831 
3832       if (GST_EVENT_TYPE (event) &lt; GST_EVENT_CAPS) {
3833         gst_video_decoder_push_event (decoder, event);
3834         tmp = l;
3835         l = l-&gt;prev;
3836         *events = g_list_delete_link (*events, tmp);
3837       } else {
3838         l = l-&gt;prev;
3839       }
3840     }
3841   }
3842 
3843   prevcaps = gst_pad_get_current_caps (decoder-&gt;srcpad);
3844   if (!prevcaps || !gst_caps_is_equal (prevcaps, state-&gt;caps)) {
3845     if (!prevcaps) {
3846       GST_DEBUG_OBJECT (decoder, &quot;decoder src pad has currently NULL caps&quot;);
3847     }
3848     ret = gst_pad_set_caps (decoder-&gt;srcpad, state-&gt;caps);
3849   } else {
3850     ret = TRUE;
3851     GST_DEBUG_OBJECT (decoder,
3852         &quot;current src pad and output state caps are the same&quot;);
3853   }
3854   if (prevcaps)
3855     gst_caps_unref (prevcaps);
3856 
3857   if (!ret)
3858     goto done;
3859   decoder-&gt;priv-&gt;output_state_changed = FALSE;
3860   /* Negotiate pool */
3861   ret = gst_video_decoder_negotiate_pool (decoder, state-&gt;allocation_caps);
3862 
3863 done:
3864   return ret;
3865 }
3866 
3867 static gboolean
3868 gst_video_decoder_negotiate_unlocked (GstVideoDecoder * decoder)
3869 {
3870   GstVideoDecoderClass *klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
3871   gboolean ret = TRUE;
3872 
3873   if (G_LIKELY (klass-&gt;negotiate))
3874     ret = klass-&gt;negotiate (decoder);
3875 
3876   return ret;
3877 }
3878 
3879 /**
3880  * gst_video_decoder_negotiate:
3881  * @decoder: a #GstVideoDecoder
3882  *
3883  * Negotiate with downstream elements to currently configured #GstVideoCodecState.
3884  * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
3885  * negotiate fails.
3886  *
3887  * Returns: %TRUE if the negotiation succeeded, else %FALSE.
3888  */
3889 gboolean
3890 gst_video_decoder_negotiate (GstVideoDecoder * decoder)
3891 {
3892   GstVideoDecoderClass *klass;
3893   gboolean ret = TRUE;
3894 
3895   g_return_val_if_fail (GST_IS_VIDEO_DECODER (decoder), FALSE);
3896 
3897   klass = GST_VIDEO_DECODER_GET_CLASS (decoder);
3898 
3899   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3900   gst_pad_check_reconfigure (decoder-&gt;srcpad);
3901   if (klass-&gt;negotiate) {
3902     ret = klass-&gt;negotiate (decoder);
3903     if (!ret)
3904       gst_pad_mark_reconfigure (decoder-&gt;srcpad);
3905   }
3906   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3907 
3908   return ret;
3909 }
3910 
3911 /**
3912  * gst_video_decoder_allocate_output_buffer:
3913  * @decoder: a #GstVideoDecoder
3914  *
3915  * Helper function that allocates a buffer to hold a video frame for @decoder&#39;s
3916  * current #GstVideoCodecState.
3917  *
3918  * You should use gst_video_decoder_allocate_output_frame() instead of this
3919  * function, if possible at all.
3920  *
3921  * Returns: (transfer full): allocated buffer, or NULL if no buffer could be
3922  *     allocated (e.g. when downstream is flushing or shutting down)
3923  */
3924 GstBuffer *
3925 gst_video_decoder_allocate_output_buffer (GstVideoDecoder * decoder)
3926 {
3927   GstFlowReturn flow;
3928   GstBuffer *buffer = NULL;
3929   gboolean needs_reconfigure = FALSE;
3930 
3931   GST_DEBUG (&quot;alloc src buffer&quot;);
3932 
3933   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
3934   needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad);
3935   if (G_UNLIKELY (!decoder-&gt;priv-&gt;output_state
3936           || decoder-&gt;priv-&gt;output_state_changed || needs_reconfigure)) {
3937     if (!gst_video_decoder_negotiate_unlocked (decoder)) {
3938       if (decoder-&gt;priv-&gt;output_state) {
3939         GST_DEBUG_OBJECT (decoder, &quot;Failed to negotiate, fallback allocation&quot;);
3940         gst_pad_mark_reconfigure (decoder-&gt;srcpad);
3941         goto fallback;
3942       } else {
3943         GST_DEBUG_OBJECT (decoder, &quot;Failed to negotiate, output_buffer=NULL&quot;);
3944         goto failed_allocation;
3945       }
3946     }
3947   }
3948 
3949   flow = gst_buffer_pool_acquire_buffer (decoder-&gt;priv-&gt;pool, &amp;buffer, NULL);
3950 
3951   if (flow != GST_FLOW_OK) {
3952     GST_INFO_OBJECT (decoder, &quot;couldn&#39;t allocate output buffer, flow %s&quot;,
3953         gst_flow_get_name (flow));
3954     if (decoder-&gt;priv-&gt;output_state &amp;&amp; decoder-&gt;priv-&gt;output_state-&gt;info.size)
3955       goto fallback;
3956     else
3957       goto failed_allocation;
3958   }
3959   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3960 
3961   return buffer;
3962 
3963 fallback:
3964   GST_INFO_OBJECT (decoder,
3965       &quot;Fallback allocation, creating new buffer which doesn&#39;t belongs to any buffer pool&quot;);
3966   buffer =
3967       gst_buffer_new_allocate (NULL, decoder-&gt;priv-&gt;output_state-&gt;info.size,
3968       NULL);
3969 
3970 failed_allocation:
3971   GST_ERROR_OBJECT (decoder, &quot;Failed to allocate the buffer..&quot;);
3972   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
3973 
3974   return buffer;
3975 }
3976 
3977 /**
3978  * gst_video_decoder_allocate_output_frame:
3979  * @decoder: a #GstVideoDecoder
3980  * @frame: a #GstVideoCodecFrame
3981  *
3982  * Helper function that allocates a buffer to hold a video frame for @decoder&#39;s
3983  * current #GstVideoCodecState.  Subclass should already have configured video
3984  * state and set src pad caps.
3985  *
3986  * The buffer allocated here is owned by the frame and you should only
3987  * keep references to the frame, not the buffer.
3988  *
3989  * Returns: %GST_FLOW_OK if an output buffer could be allocated
3990  */
3991 GstFlowReturn
3992 gst_video_decoder_allocate_output_frame (GstVideoDecoder *
3993     decoder, GstVideoCodecFrame * frame)
3994 {
3995   return gst_video_decoder_allocate_output_frame_with_params (decoder, frame,
3996       NULL);
3997 }
3998 
3999 /**
4000  * gst_video_decoder_allocate_output_frame_with_params:
4001  * @decoder: a #GstVideoDecoder
4002  * @frame: a #GstVideoCodecFrame
4003  * @params: a #GstBufferPoolAcquireParams
4004  *
4005  * Same as #gst_video_decoder_allocate_output_frame except it allows passing
4006  * #GstBufferPoolAcquireParams to the sub call gst_buffer_pool_acquire_buffer.
4007  *
4008  * Returns: %GST_FLOW_OK if an output buffer could be allocated
4009  *
4010  * Since: 1.12
4011  */
4012 GstFlowReturn
4013 gst_video_decoder_allocate_output_frame_with_params (GstVideoDecoder *
4014     decoder, GstVideoCodecFrame * frame, GstBufferPoolAcquireParams * params)
4015 {
4016   GstFlowReturn flow_ret;
4017   GstVideoCodecState *state;
4018   int num_bytes;
4019   gboolean needs_reconfigure = FALSE;
4020 
4021   g_return_val_if_fail (decoder-&gt;priv-&gt;output_state, GST_FLOW_NOT_NEGOTIATED);
4022   g_return_val_if_fail (frame-&gt;output_buffer == NULL, GST_FLOW_ERROR);
4023 
4024   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
4025 
4026   state = decoder-&gt;priv-&gt;output_state;
4027   if (state == NULL) {
4028     g_warning (&quot;Output state should be set before allocating frame&quot;);
4029     goto error;
4030   }
4031   num_bytes = GST_VIDEO_INFO_SIZE (&amp;state-&gt;info);
4032   if (num_bytes == 0) {
4033     g_warning (&quot;Frame size should not be 0&quot;);
4034     goto error;
4035   }
4036 
4037   needs_reconfigure = gst_pad_check_reconfigure (decoder-&gt;srcpad);
4038   if (G_UNLIKELY (decoder-&gt;priv-&gt;output_state_changed || needs_reconfigure)) {
4039     if (!gst_video_decoder_negotiate_unlocked (decoder)) {
4040       GST_DEBUG_OBJECT (decoder, &quot;Failed to negotiate, fallback allocation&quot;);
4041       gst_pad_mark_reconfigure (decoder-&gt;srcpad);
4042     }
4043   }
4044 
4045   GST_LOG_OBJECT (decoder, &quot;alloc buffer size %d&quot;, num_bytes);
4046 
4047   flow_ret = gst_buffer_pool_acquire_buffer (decoder-&gt;priv-&gt;pool,
4048       &amp;frame-&gt;output_buffer, params);
4049 
4050   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
4051 
4052   return flow_ret;
4053 
4054 error:
4055   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
4056   return GST_FLOW_ERROR;
4057 }
4058 
4059 /**
4060  * gst_video_decoder_get_max_decode_time:
4061  * @decoder: a #GstVideoDecoder
4062  * @frame: a #GstVideoCodecFrame
4063  *
4064  * Determines maximum possible decoding time for @frame that will
4065  * allow it to decode and arrive in time (as determined by QoS events).
4066  * In particular, a negative result means decoding in time is no longer possible
4067  * and should therefore occur as soon/skippy as possible.
4068  *
4069  * Returns: max decoding time.
4070  */
4071 GstClockTimeDiff
4072 gst_video_decoder_get_max_decode_time (GstVideoDecoder *
4073     decoder, GstVideoCodecFrame * frame)
4074 {
4075   GstClockTimeDiff deadline;
4076   GstClockTime earliest_time;
4077 
4078   GST_OBJECT_LOCK (decoder);
4079   earliest_time = decoder-&gt;priv-&gt;earliest_time;
4080   if (GST_CLOCK_TIME_IS_VALID (earliest_time)
4081       &amp;&amp; GST_CLOCK_TIME_IS_VALID (frame-&gt;deadline))
4082     deadline = GST_CLOCK_DIFF (earliest_time, frame-&gt;deadline);
4083   else
4084     deadline = G_MAXINT64;
4085 
4086   GST_LOG_OBJECT (decoder, &quot;earliest %&quot; GST_TIME_FORMAT
4087       &quot;, frame deadline %&quot; GST_TIME_FORMAT &quot;, deadline %&quot; GST_STIME_FORMAT,
4088       GST_TIME_ARGS (earliest_time), GST_TIME_ARGS (frame-&gt;deadline),
4089       GST_STIME_ARGS (deadline));
4090 
4091   GST_OBJECT_UNLOCK (decoder);
4092 
4093   return deadline;
4094 }
4095 
4096 /**
4097  * gst_video_decoder_get_qos_proportion:
4098  * @decoder: a #GstVideoDecoder
4099  *     current QoS proportion, or %NULL
4100  *
4101  * Returns: The current QoS proportion.
4102  *
4103  * Since: 1.0.3
4104  */
4105 gdouble
4106 gst_video_decoder_get_qos_proportion (GstVideoDecoder * decoder)
4107 {
4108   gdouble proportion;
4109 
4110   g_return_val_if_fail (GST_IS_VIDEO_DECODER (decoder), 1.0);
4111 
4112   GST_OBJECT_LOCK (decoder);
4113   proportion = decoder-&gt;priv-&gt;proportion;
4114   GST_OBJECT_UNLOCK (decoder);
4115 
4116   return proportion;
4117 }
4118 
4119 GstFlowReturn
4120 _gst_video_decoder_error (GstVideoDecoder * dec, gint weight,
4121     GQuark domain, gint code, gchar * txt, gchar * dbg, const gchar * file,
4122     const gchar * function, gint line)
4123 {
4124   if (txt)
4125     GST_WARNING_OBJECT (dec, &quot;error: %s&quot;, txt);
4126   if (dbg)
4127     GST_WARNING_OBJECT (dec, &quot;error: %s&quot;, dbg);
4128   dec-&gt;priv-&gt;error_count += weight;
4129   dec-&gt;priv-&gt;discont = TRUE;
4130   if (dec-&gt;priv-&gt;max_errors &gt;= 0 &amp;&amp;
4131       dec-&gt;priv-&gt;error_count &gt; dec-&gt;priv-&gt;max_errors) {
4132     gst_element_message_full (GST_ELEMENT (dec), GST_MESSAGE_ERROR,
4133         domain, code, txt, dbg, file, function, line);
4134     return GST_FLOW_ERROR;
4135   } else {
4136     g_free (txt);
4137     g_free (dbg);
4138     return GST_FLOW_OK;
4139   }
4140 }
4141 
4142 /**
4143  * gst_video_decoder_set_max_errors:
4144  * @dec: a #GstVideoDecoder
4145  * @num: max tolerated errors
4146  *
4147  * Sets numbers of tolerated decoder errors, where a tolerated one is then only
4148  * warned about, but more than tolerated will lead to fatal error.  You can set
4149  * -1 for never returning fatal errors. Default is set to
4150  * GST_VIDEO_DECODER_MAX_ERRORS.
4151  *
4152  * The &#39;-1&#39; option was added in 1.4
4153  */
4154 void
4155 gst_video_decoder_set_max_errors (GstVideoDecoder * dec, gint num)
4156 {
4157   g_return_if_fail (GST_IS_VIDEO_DECODER (dec));
4158 
4159   dec-&gt;priv-&gt;max_errors = num;
4160 }
4161 
4162 /**
4163  * gst_video_decoder_get_max_errors:
4164  * @dec: a #GstVideoDecoder
4165  *
4166  * Returns: currently configured decoder tolerated error count.
4167  */
4168 gint
4169 gst_video_decoder_get_max_errors (GstVideoDecoder * dec)
4170 {
4171   g_return_val_if_fail (GST_IS_VIDEO_DECODER (dec), 0);
4172 
4173   return dec-&gt;priv-&gt;max_errors;
4174 }
4175 
4176 /**
4177  * gst_video_decoder_set_needs_format:
4178  * @dec: a #GstVideoDecoder
4179  * @enabled: new state
4180  *
4181  * Configures decoder format needs.  If enabled, subclass needs to be
4182  * negotiated with format caps before it can process any data.  It will then
4183  * never be handed any data before it has been configured.
4184  * Otherwise, it might be handed data without having been configured and
4185  * is then expected being able to do so either by default
4186  * or based on the input data.
4187  *
4188  * Since: 1.4
4189  */
4190 void
4191 gst_video_decoder_set_needs_format (GstVideoDecoder * dec, gboolean enabled)
4192 {
4193   g_return_if_fail (GST_IS_VIDEO_DECODER (dec));
4194 
4195   dec-&gt;priv-&gt;needs_format = enabled;
4196 }
4197 
4198 /**
4199  * gst_video_decoder_get_needs_format:
4200  * @dec: a #GstVideoDecoder
4201  *
4202  * Queries decoder required format handling.
4203  *
4204  * Returns: %TRUE if required format handling is enabled.
4205  *
4206  * Since: 1.4
4207  */
4208 gboolean
4209 gst_video_decoder_get_needs_format (GstVideoDecoder * dec)
4210 {
4211   gboolean result;
4212 
4213   g_return_val_if_fail (GST_IS_VIDEO_DECODER (dec), FALSE);
4214 
4215   result = dec-&gt;priv-&gt;needs_format;
4216 
4217   return result;
4218 }
4219 
4220 /**
4221  * gst_video_decoder_set_packetized:
4222  * @decoder: a #GstVideoDecoder
4223  * @packetized: whether the input data should be considered as packetized.
4224  *
4225  * Allows baseclass to consider input data as packetized or not. If the
4226  * input is packetized, then the @parse method will not be called.
4227  */
4228 void
4229 gst_video_decoder_set_packetized (GstVideoDecoder * decoder,
4230     gboolean packetized)
4231 {
4232   decoder-&gt;priv-&gt;packetized = packetized;
4233 }
4234 
4235 /**
4236  * gst_video_decoder_get_packetized:
4237  * @decoder: a #GstVideoDecoder
4238  *
4239  * Queries whether input data is considered packetized or not by the
4240  * base class.
4241  *
4242  * Returns: TRUE if input data is considered packetized.
4243  */
4244 gboolean
4245 gst_video_decoder_get_packetized (GstVideoDecoder * decoder)
4246 {
4247   return decoder-&gt;priv-&gt;packetized;
4248 }
4249 
4250 /**
4251  * gst_video_decoder_set_estimate_rate:
4252  * @dec: a #GstVideoDecoder
4253  * @enabled: whether to enable byte to time conversion
4254  *
4255  * Allows baseclass to perform byte to time estimated conversion.
4256  */
4257 void
4258 gst_video_decoder_set_estimate_rate (GstVideoDecoder * dec, gboolean enabled)
4259 {
4260   g_return_if_fail (GST_IS_VIDEO_DECODER (dec));
4261 
4262   dec-&gt;priv-&gt;do_estimate_rate = enabled;
4263 }
4264 
4265 /**
4266  * gst_video_decoder_get_estimate_rate:
4267  * @dec: a #GstVideoDecoder
4268  *
4269  * Returns: currently configured byte to time conversion setting
4270  */
4271 gboolean
4272 gst_video_decoder_get_estimate_rate (GstVideoDecoder * dec)
4273 {
4274   g_return_val_if_fail (GST_IS_VIDEO_DECODER (dec), 0);
4275 
4276   return dec-&gt;priv-&gt;do_estimate_rate;
4277 }
4278 
4279 /**
4280  * gst_video_decoder_set_latency:
4281  * @decoder: a #GstVideoDecoder
4282  * @min_latency: minimum latency
4283  * @max_latency: maximum latency
4284  *
4285  * Lets #GstVideoDecoder sub-classes tell the baseclass what the decoder
4286  * latency is. Will also post a LATENCY message on the bus so the pipeline
4287  * can reconfigure its global latency.
4288  */
4289 void
4290 gst_video_decoder_set_latency (GstVideoDecoder * decoder,
4291     GstClockTime min_latency, GstClockTime max_latency)
4292 {
4293   g_return_if_fail (GST_CLOCK_TIME_IS_VALID (min_latency));
4294   g_return_if_fail (max_latency &gt;= min_latency);
4295 
4296   GST_OBJECT_LOCK (decoder);
4297   decoder-&gt;priv-&gt;min_latency = min_latency;
4298   decoder-&gt;priv-&gt;max_latency = max_latency;
4299   GST_OBJECT_UNLOCK (decoder);
4300 
4301   gst_element_post_message (GST_ELEMENT_CAST (decoder),
4302       gst_message_new_latency (GST_OBJECT_CAST (decoder)));
4303 }
4304 
4305 /**
4306  * gst_video_decoder_get_latency:
4307  * @decoder: a #GstVideoDecoder
4308  * @min_latency: (out) (allow-none): address of variable in which to store the
4309  *     configured minimum latency, or %NULL
4310  * @max_latency: (out) (allow-none): address of variable in which to store the
4311  *     configured mximum latency, or %NULL
4312  *
4313  * Query the configured decoder latency. Results will be returned via
4314  * @min_latency and @max_latency.
4315  */
4316 void
4317 gst_video_decoder_get_latency (GstVideoDecoder * decoder,
4318     GstClockTime * min_latency, GstClockTime * max_latency)
4319 {
4320   GST_OBJECT_LOCK (decoder);
4321   if (min_latency)
4322     *min_latency = decoder-&gt;priv-&gt;min_latency;
4323   if (max_latency)
4324     *max_latency = decoder-&gt;priv-&gt;max_latency;
4325   GST_OBJECT_UNLOCK (decoder);
4326 }
4327 
4328 /**
4329  * gst_video_decoder_merge_tags:
4330  * @decoder: a #GstVideoDecoder
4331  * @tags: (allow-none): a #GstTagList to merge, or NULL to unset
4332  *     previously-set tags
4333  * @mode: the #GstTagMergeMode to use, usually #GST_TAG_MERGE_REPLACE
4334  *
4335  * Sets the audio decoder tags and how they should be merged with any
4336  * upstream stream tags. This will override any tags previously-set
4337  * with gst_audio_decoder_merge_tags().
4338  *
4339  * Note that this is provided for convenience, and the subclass is
4340  * not required to use this and can still do tag handling on its own.
4341  *
4342  * MT safe.
4343  */
4344 void
4345 gst_video_decoder_merge_tags (GstVideoDecoder * decoder,
4346     const GstTagList * tags, GstTagMergeMode mode)
4347 {
4348   g_return_if_fail (GST_IS_VIDEO_DECODER (decoder));
4349   g_return_if_fail (tags == NULL || GST_IS_TAG_LIST (tags));
4350   g_return_if_fail (tags == NULL || mode != GST_TAG_MERGE_UNDEFINED);
4351 
4352   GST_VIDEO_DECODER_STREAM_LOCK (decoder);
4353   if (decoder-&gt;priv-&gt;tags != tags) {
4354     if (decoder-&gt;priv-&gt;tags) {
4355       gst_tag_list_unref (decoder-&gt;priv-&gt;tags);
4356       decoder-&gt;priv-&gt;tags = NULL;
4357       decoder-&gt;priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
4358     }
4359     if (tags) {
4360       decoder-&gt;priv-&gt;tags = gst_tag_list_ref ((GstTagList *) tags);
4361       decoder-&gt;priv-&gt;tags_merge_mode = mode;
4362     }
4363 
4364     GST_DEBUG_OBJECT (decoder, &quot;set decoder tags to %&quot; GST_PTR_FORMAT, tags);
4365     decoder-&gt;priv-&gt;tags_changed = TRUE;
4366   }
4367   GST_VIDEO_DECODER_STREAM_UNLOCK (decoder);
4368 }
4369 
4370 /**
4371  * gst_video_decoder_get_buffer_pool:
4372  * @decoder: a #GstVideoDecoder
4373  *
4374  * Returns: (transfer full): the instance of the #GstBufferPool used
4375  * by the decoder; free it after use it
4376  */
4377 GstBufferPool *
4378 gst_video_decoder_get_buffer_pool (GstVideoDecoder * decoder)
4379 {
4380   g_return_val_if_fail (GST_IS_VIDEO_DECODER (decoder), NULL);
4381 
4382   if (decoder-&gt;priv-&gt;pool)
4383     return gst_object_ref (decoder-&gt;priv-&gt;pool);
4384 
4385   return NULL;
4386 }
4387 
4388 /**
4389  * gst_video_decoder_get_allocator:
4390  * @decoder: a #GstVideoDecoder
4391  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
4392  * used
4393  * @params: (out) (allow-none) (transfer full): the
4394  * #GstAllocatorParams of @allocator
4395  *
4396  * Lets #GstVideoDecoder sub-classes to know the memory @allocator
4397  * used by the base class and its @params.
4398  *
4399  * Unref the @allocator after use it.
4400  */
4401 void
4402 gst_video_decoder_get_allocator (GstVideoDecoder * decoder,
4403     GstAllocator ** allocator, GstAllocationParams * params)
4404 {
4405   g_return_if_fail (GST_IS_VIDEO_DECODER (decoder));
4406 
4407   if (allocator)
4408     *allocator = decoder-&gt;priv-&gt;allocator ?
4409         gst_object_ref (decoder-&gt;priv-&gt;allocator) : NULL;
4410 
4411   if (params)
4412     *params = decoder-&gt;priv-&gt;params;
4413 }
4414 
4415 /**
4416  * gst_video_decoder_set_use_default_pad_acceptcaps:
4417  * @decoder: a #GstVideoDecoder
4418  * @use: if the default pad accept-caps query handling should be used
4419  *
4420  * Lets #GstVideoDecoder sub-classes decide if they want the sink pad
4421  * to use the default pad query handler to reply to accept-caps queries.
4422  *
4423  * By setting this to true it is possible to further customize the default
4424  * handler with %GST_PAD_SET_ACCEPT_INTERSECT and
4425  * %GST_PAD_SET_ACCEPT_TEMPLATE
4426  *
4427  * Since: 1.6
4428  */
4429 void
4430 gst_video_decoder_set_use_default_pad_acceptcaps (GstVideoDecoder * decoder,
4431     gboolean use)
4432 {
4433   decoder-&gt;priv-&gt;use_default_pad_acceptcaps = use;
4434 }
    </pre>
  </body>
</html>