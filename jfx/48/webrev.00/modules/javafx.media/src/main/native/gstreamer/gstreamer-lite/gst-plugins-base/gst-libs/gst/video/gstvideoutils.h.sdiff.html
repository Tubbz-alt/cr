<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideoutils.h</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="gstvideoutils.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="navigation.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideoutils.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
210  *       to the library and get back the frame using gst_video_decoder_get_frame()
211  * @distance_from_sync: Distance in frames from the last synchronization point.
212  * @input_buffer: the input #GstBuffer that created this frame. The buffer is owned
213  *           by the frame and references to the frame instead of the buffer should
214  *           be kept.
215  * @output_buffer: the output #GstBuffer. Implementations should set this either
216  *           directly, or by using the
217  *           @gst_video_decoder_allocate_output_frame() or
218  *           @gst_video_decoder_allocate_output_buffer() methods. The buffer is
219  *           owned by the frame and references to the frame instead of the
220  *           buffer should be kept.
221  * @deadline: Running time when the frame will be used.
222  *
223  * A #GstVideoCodecFrame represents a video frame both in raw and
224  * encoded form.
225  */
226 struct _GstVideoCodecFrame
227 {
228   /*&lt; private &gt;*/
229   gint ref_count;
<span class="line-removed">230 </span>
231   guint32 flags;
232 
233   /*&lt; public &gt;*/
234   guint32 system_frame_number;  /* ED */


235   guint32 decode_frame_number;  /* ED */
236   guint32 presentation_frame_number; /* ED */
237 

238   GstClockTime dts;       /* ED */
239   GstClockTime pts;       /* ED */
240   GstClockTime duration;  /* ED */
241 
<span class="line-modified">242   int distance_from_sync;   /* ED */</span>
243 
244   GstBuffer *input_buffer;  /* ED */
245   GstBuffer *output_buffer; /* ED */
246 
<span class="line-modified">247   GstClockTime deadline;    /* D */</span>
248 
249   /*&lt; private &gt;*/
250 
251   /* Events that should be pushed downstream *before*
252    * the next output_buffer */
<span class="line-modified">253   GList *events;        /* ED */</span>
254 
255   gpointer       user_data;
256   GDestroyNotify user_data_destroy_notify;
257 
258   union {
259     struct {
260       GstClockTime ts;
261       GstClockTime ts2;
262     } ABI;
263     gpointer padding[GST_PADDING_LARGE];
264   } abidata;
265 };
266 
267 /* GstVideoCodecState */
268 
269 GST_VIDEO_API
270 GType           gst_video_codec_state_get_type (void);
271 
272 GST_VIDEO_API
273 GstVideoCodecState *gst_video_codec_state_ref (GstVideoCodecState * state);
274 
275 GST_VIDEO_API
276 void                gst_video_codec_state_unref (GstVideoCodecState * state);
277 
278 
279 /* GstVideoCodecFrame */
280 
281 GST_VIDEO_API
282 GType                gst_video_codec_frame_get_type (void);
283 
284 GST_VIDEO_API
285 GstVideoCodecFrame  *gst_video_codec_frame_ref (GstVideoCodecFrame * frame);
286 
287 GST_VIDEO_API
288 void                 gst_video_codec_frame_unref (GstVideoCodecFrame * frame);
289 
290 GST_VIDEO_API
291 void                 gst_video_codec_frame_set_user_data (GstVideoCodecFrame *frame,
<span class="line-modified">292                                   gpointer user_data,</span>
<span class="line-modified">293                                           GDestroyNotify notify);</span>
294 
295 GST_VIDEO_API
296 gpointer             gst_video_codec_frame_get_user_data (GstVideoCodecFrame *frame);
297 
298 #ifdef G_DEFINE_AUTOPTR_CLEANUP_FUNC
299 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstVideoCodecFrame, gst_video_codec_frame_unref)
300 #endif
301 
302 #ifdef G_DEFINE_AUTOPTR_CLEANUP_FUNC
303 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstVideoCodecState, gst_video_codec_state_unref)
304 #endif
305 
306 G_END_DECLS
307 
308 #endif
</pre>
</td>
<td>
<hr />
<pre>
210  *       to the library and get back the frame using gst_video_decoder_get_frame()
211  * @distance_from_sync: Distance in frames from the last synchronization point.
212  * @input_buffer: the input #GstBuffer that created this frame. The buffer is owned
213  *           by the frame and references to the frame instead of the buffer should
214  *           be kept.
215  * @output_buffer: the output #GstBuffer. Implementations should set this either
216  *           directly, or by using the
217  *           @gst_video_decoder_allocate_output_frame() or
218  *           @gst_video_decoder_allocate_output_buffer() methods. The buffer is
219  *           owned by the frame and references to the frame instead of the
220  *           buffer should be kept.
221  * @deadline: Running time when the frame will be used.
222  *
223  * A #GstVideoCodecFrame represents a video frame both in raw and
224  * encoded form.
225  */
226 struct _GstVideoCodecFrame
227 {
228   /*&lt; private &gt;*/
229   gint ref_count;

230   guint32 flags;
231 
232   /*&lt; public &gt;*/
233   guint32 system_frame_number;  /* ED */
<span class="line-added">234 </span>
<span class="line-added">235   /*&lt; private &gt;*/</span>
236   guint32 decode_frame_number;  /* ED */
237   guint32 presentation_frame_number; /* ED */
238 
<span class="line-added">239   /*&lt; public &gt;*/</span>
240   GstClockTime dts;       /* ED */
241   GstClockTime pts;       /* ED */
242   GstClockTime duration;  /* ED */
243 
<span class="line-modified">244   int distance_from_sync; /* ED */</span>
245 
246   GstBuffer *input_buffer;  /* ED */
247   GstBuffer *output_buffer; /* ED */
248 
<span class="line-modified">249   GstClockTime deadline;  /* D */</span>
250 
251   /*&lt; private &gt;*/
252 
253   /* Events that should be pushed downstream *before*
254    * the next output_buffer */
<span class="line-modified">255   GList *events;    /* ED */</span>
256 
257   gpointer       user_data;
258   GDestroyNotify user_data_destroy_notify;
259 
260   union {
261     struct {
262       GstClockTime ts;
263       GstClockTime ts2;
264     } ABI;
265     gpointer padding[GST_PADDING_LARGE];
266   } abidata;
267 };
268 
269 /* GstVideoCodecState */
270 
271 GST_VIDEO_API
272 GType           gst_video_codec_state_get_type (void);
273 
274 GST_VIDEO_API
275 GstVideoCodecState *gst_video_codec_state_ref (GstVideoCodecState * state);
276 
277 GST_VIDEO_API
278 void                gst_video_codec_state_unref (GstVideoCodecState * state);
279 
280 
281 /* GstVideoCodecFrame */
282 
283 GST_VIDEO_API
284 GType                gst_video_codec_frame_get_type (void);
285 
286 GST_VIDEO_API
287 GstVideoCodecFrame  *gst_video_codec_frame_ref (GstVideoCodecFrame * frame);
288 
289 GST_VIDEO_API
290 void                 gst_video_codec_frame_unref (GstVideoCodecFrame * frame);
291 
292 GST_VIDEO_API
293 void                 gst_video_codec_frame_set_user_data (GstVideoCodecFrame *frame,
<span class="line-modified">294                       gpointer user_data,</span>
<span class="line-modified">295                                   GDestroyNotify notify);</span>
296 
297 GST_VIDEO_API
298 gpointer             gst_video_codec_frame_get_user_data (GstVideoCodecFrame *frame);
299 
300 #ifdef G_DEFINE_AUTOPTR_CLEANUP_FUNC
301 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstVideoCodecFrame, gst_video_codec_frame_unref)
302 #endif
303 
304 #ifdef G_DEFINE_AUTOPTR_CLEANUP_FUNC
305 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstVideoCodecState, gst_video_codec_state_unref)
306 #endif
307 
308 G_END_DECLS
309 
310 #endif
</pre>
</td>
</tr>
</table>
<center><a href="gstvideoutils.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="navigation.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>