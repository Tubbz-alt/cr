<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/video-converter.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /* GStreamer
   2  * Copyright (C) 2010 David Schleef &lt;ds@schleef.org&gt;
   3  * Copyright (C) 2010 Sebastian Dr√∂ge &lt;sebastian.droege@collabora.co.uk&gt;
   4  *
   5  * This library is free software; you can redistribute it and/or
   6  * modify it under the terms of the GNU Library General Public
   7  * License as published by the Free Software Foundation; either
   8  * version 2 of the License, or (at your option) any later version.
   9  *
  10  * This library is distributed in the hope that it will be useful,
  11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  13  * Library General Public License for more details.
  14  *
  15  * You should have received a copy of the GNU Library General Public
  16  * License along with this library; if not, write to the
  17  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
  18  * Boston, MA 02110-1301, USA.
  19  */
  20 
  21 #ifdef HAVE_CONFIG_H
  22 #include &quot;config.h&quot;
  23 #endif
  24 
  25 #if 0
  26 #ifdef HAVE_PTHREAD
  27 #define _GNU_SOURCE
  28 #include &lt;pthread.h&gt;
  29 #endif
  30 #endif
  31 
  32 #include &quot;video-converter.h&quot;
  33 
  34 #include &lt;glib.h&gt;
  35 #include &lt;string.h&gt;
  36 #include &lt;math.h&gt;
  37 
  38 #include &quot;video-orc.h&quot;
  39 
  40 /**
  41  * SECTION:videoconverter
  42  * @title: GstVideoConverter
  43  * @short_description: Generic video conversion
  44  *
  45  * This object is used to convert video frames from one format to another.
  46  * The object can perform conversion of:
  47  *
  48  *  * video format
  49  *  * video colorspace
  50  *  * chroma-siting
  51  *  * video size
  52  *
  53  */
  54 
  55 /*
  56  * (a)  unpack
  57  * (b)  chroma upsample
  58  * (c)  (convert Y&#39;CbCr to R&#39;G&#39;B&#39;)
  59  * (d)  gamma decode
  60  * (e)  downscale
  61  * (f)  colorspace convert through XYZ
  62  * (g)  upscale
  63  * (h)  gamma encode
  64  * (i)  (convert R&#39;G&#39;B&#39; to Y&#39;CbCr)
  65  * (j)  chroma downsample
  66  * (k)  pack
  67  *
  68  * quality options
  69  *
  70  *  (a) range truncate, range expand
  71  *  (b) full upsample, 1-1 non-cosited upsample, no upsample
  72  *  (c) 8 bits, 16 bits
  73  *  (d)
  74  *  (e) 8 bits, 16 bits
  75  *  (f) 8 bits, 16 bits
  76  *  (g) 8 bits, 16 bits
  77  *  (h)
  78  *  (i) 8 bits, 16 bits
  79  *  (j) 1-1 cosited downsample, no downsample
  80  *  (k)
  81  *
  82  *
  83  *         1 : a -&gt;   -&gt;   -&gt;   -&gt; e  -&gt; f  -&gt; g  -&gt;   -&gt;   -&gt;   -&gt; k
  84  *         2 : a -&gt;   -&gt;   -&gt;   -&gt; e  -&gt; f* -&gt; g  -&gt;   -&gt;   -&gt;   -&gt; k
  85  *         3 : a -&gt;   -&gt;   -&gt;   -&gt; e* -&gt; f* -&gt; g* -&gt;   -&gt;   -&gt;   -&gt; k
  86  *         4 : a -&gt; b -&gt;   -&gt;   -&gt; e  -&gt; f  -&gt; g  -&gt;   -&gt;   -&gt; j -&gt; k
  87  *         5 : a -&gt; b -&gt;   -&gt;   -&gt; e* -&gt; f* -&gt; g* -&gt;   -&gt;   -&gt; j -&gt; k
  88  *         6 : a -&gt; b -&gt; c -&gt; d -&gt; e  -&gt; f  -&gt; g  -&gt; h -&gt; i -&gt; j -&gt; k
  89  *         7 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  90  *
  91  *         8 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  92  *         9 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  93  *        10 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  94  */
  95 
  96 #ifndef GSTREAMER_LITE
  97 
  98 #ifndef GST_DISABLE_GST_DEBUG
  99 #define GST_CAT_DEFAULT ensure_debug_category()
 100 static GstDebugCategory *
 101 ensure_debug_category (void)
 102 {
 103   static gsize cat_gonce = 0;
 104 
 105   if (g_once_init_enter (&amp;cat_gonce)) {
 106     gsize cat_done;
 107 
 108     cat_done = (gsize) _gst_debug_category_new (&quot;video-converter&quot;, 0,
 109         &quot;video-converter object&quot;);
 110 
 111     g_once_init_leave (&amp;cat_gonce, cat_done);
 112   }
 113 
 114   return (GstDebugCategory *) cat_gonce;
 115 }
 116 #else
 117 #define ensure_debug_category() /* NOOP */
 118 #endif /* GST_DISABLE_GST_DEBUG */
 119 
 120 typedef void (*GstParallelizedTaskFunc) (gpointer user_data);
 121 
 122 typedef struct _GstParallelizedTaskRunner GstParallelizedTaskRunner;
 123 typedef struct _GstParallelizedTaskThread GstParallelizedTaskThread;
 124 
 125 struct _GstParallelizedTaskThread
 126 {
 127   GstParallelizedTaskRunner *runner;
 128   guint idx;
 129   GThread *thread;
 130 };
 131 
 132 struct _GstParallelizedTaskRunner
 133 {
 134   guint n_threads;
 135 
 136   GstParallelizedTaskThread *threads;
 137 
 138   GstParallelizedTaskFunc func;
 139   gpointer *task_data;
 140 
 141   GMutex lock;
 142   GCond cond_todo, cond_done;
 143   gint n_todo, n_done;
 144   gboolean quit;
 145 };
 146 
 147 static gpointer
 148 gst_parallelized_task_thread_func (gpointer data)
 149 {
 150   GstParallelizedTaskThread *self = data;
 151 
 152 #if 0
 153 #ifdef HAVE_PTHREAD
 154   {
 155     pthread_t thread = pthread_self ();
 156     cpu_set_t cpuset;
 157     int r;
 158 
 159     CPU_ZERO (&amp;cpuset);
 160     CPU_SET (self-&gt;idx, &amp;cpuset);
 161     if ((r = pthread_setaffinity_np (thread, sizeof (cpuset), &amp;cpuset)) != 0)
 162       GST_ERROR (&quot;Failed to set thread affinity for thread %d: %s&quot;, self-&gt;idx,
 163           g_strerror (r));
 164   }
 165 #endif
 166 #endif
 167 
 168   g_mutex_lock (&amp;self-&gt;runner-&gt;lock);
 169   self-&gt;runner-&gt;n_done++;
 170   if (self-&gt;runner-&gt;n_done == self-&gt;runner-&gt;n_threads - 1)
 171     g_cond_signal (&amp;self-&gt;runner-&gt;cond_done);
 172 
 173   do {
 174     gint idx;
 175 
 176     while (self-&gt;runner-&gt;n_todo == -1 &amp;&amp; !self-&gt;runner-&gt;quit)
 177       g_cond_wait (&amp;self-&gt;runner-&gt;cond_todo, &amp;self-&gt;runner-&gt;lock);
 178 
 179     if (self-&gt;runner-&gt;quit)
 180       break;
 181 
 182     idx = self-&gt;runner-&gt;n_todo--;
 183     g_assert (self-&gt;runner-&gt;n_todo &gt;= -1);
 184     g_mutex_unlock (&amp;self-&gt;runner-&gt;lock);
 185 
 186     g_assert (self-&gt;runner-&gt;func != NULL);
 187 
 188     self-&gt;runner-&gt;func (self-&gt;runner-&gt;task_data[idx]);
 189 
 190     g_mutex_lock (&amp;self-&gt;runner-&gt;lock);
 191     self-&gt;runner-&gt;n_done++;
 192     if (self-&gt;runner-&gt;n_done == self-&gt;runner-&gt;n_threads - 1)
 193       g_cond_signal (&amp;self-&gt;runner-&gt;cond_done);
 194   } while (TRUE);
 195 
 196   g_mutex_unlock (&amp;self-&gt;runner-&gt;lock);
 197 
 198   return NULL;
 199 }
 200 
 201 static void
 202 gst_parallelized_task_runner_free (GstParallelizedTaskRunner * self)
 203 {
 204   guint i;
 205 
 206   g_mutex_lock (&amp;self-&gt;lock);
 207   self-&gt;quit = TRUE;
 208   g_cond_broadcast (&amp;self-&gt;cond_todo);
 209   g_mutex_unlock (&amp;self-&gt;lock);
 210 
 211   for (i = 1; i &lt; self-&gt;n_threads; i++) {
 212     if (!self-&gt;threads[i].thread)
 213       continue;
 214 
 215     g_thread_join (self-&gt;threads[i].thread);
 216   }
 217 
 218   g_mutex_clear (&amp;self-&gt;lock);
 219   g_cond_clear (&amp;self-&gt;cond_todo);
 220   g_cond_clear (&amp;self-&gt;cond_done);
 221   g_free (self-&gt;threads);
 222   g_free (self);
 223 }
 224 
 225 static GstParallelizedTaskRunner *
 226 gst_parallelized_task_runner_new (guint n_threads)
 227 {
 228   GstParallelizedTaskRunner *self;
 229   guint i;
 230   GError *err = NULL;
 231 
 232   if (n_threads == 0)
 233     n_threads = g_get_num_processors ();
 234 
 235   self = g_new0 (GstParallelizedTaskRunner, 1);
 236   self-&gt;n_threads = n_threads;
 237   self-&gt;threads = g_new0 (GstParallelizedTaskThread, n_threads);
 238 
 239   self-&gt;quit = FALSE;
 240   self-&gt;n_todo = -1;
 241   self-&gt;n_done = 0;
 242   g_mutex_init (&amp;self-&gt;lock);
 243   g_cond_init (&amp;self-&gt;cond_todo);
 244   g_cond_init (&amp;self-&gt;cond_done);
 245 
 246   /* Set when scheduling a job */
 247   self-&gt;func = NULL;
 248   self-&gt;task_data = NULL;
 249 
 250   for (i = 0; i &lt; n_threads; i++) {
 251     self-&gt;threads[i].runner = self;
 252     self-&gt;threads[i].idx = i;
 253 
 254     /* First thread is the one calling run() */
 255     if (i &gt; 0) {
 256       self-&gt;threads[i].thread =
 257           g_thread_try_new (&quot;videoconvert&quot;, gst_parallelized_task_thread_func,
 258           &amp;self-&gt;threads[i], &amp;err);
 259       if (!self-&gt;threads[i].thread)
 260         goto error;
 261     }
 262   }
 263 
 264   g_mutex_lock (&amp;self-&gt;lock);
 265   while (self-&gt;n_done &lt; self-&gt;n_threads - 1)
 266     g_cond_wait (&amp;self-&gt;cond_done, &amp;self-&gt;lock);
 267   self-&gt;n_done = 0;
 268   g_mutex_unlock (&amp;self-&gt;lock);
 269 
 270   return self;
 271 
 272 error:
 273   {
 274     GST_ERROR (&quot;Failed to start thread %u: %s&quot;, i, err-&gt;message);
 275     g_clear_error (&amp;err);
 276 
 277     gst_parallelized_task_runner_free (self);
 278     return NULL;
 279   }
 280 }
 281 
 282 static void
 283 gst_parallelized_task_runner_run (GstParallelizedTaskRunner * self,
 284     GstParallelizedTaskFunc func, gpointer * task_data)
 285 {
 286   guint n_threads = self-&gt;n_threads;
 287 
 288   self-&gt;func = func;
 289   self-&gt;task_data = task_data;
 290 
 291   if (n_threads &gt; 1) {
 292     g_mutex_lock (&amp;self-&gt;lock);
 293     self-&gt;n_todo = self-&gt;n_threads - 2;
 294     self-&gt;n_done = 0;
 295     g_cond_broadcast (&amp;self-&gt;cond_todo);
 296     g_mutex_unlock (&amp;self-&gt;lock);
 297   }
 298 
 299   self-&gt;func (self-&gt;task_data[self-&gt;n_threads - 1]);
 300 
 301   if (n_threads &gt; 1) {
 302     g_mutex_lock (&amp;self-&gt;lock);
 303     while (self-&gt;n_done &lt; self-&gt;n_threads - 1)
 304       g_cond_wait (&amp;self-&gt;cond_done, &amp;self-&gt;lock);
 305     self-&gt;n_done = 0;
 306     g_mutex_unlock (&amp;self-&gt;lock);
 307   }
 308 
 309   self-&gt;func = NULL;
 310   self-&gt;task_data = NULL;
 311 }
 312 
 313 typedef struct _GstLineCache GstLineCache;
 314 
 315 #endif // GSTREAMER_LITE
 316 
 317 #define SCALE    (8)
 318 #define SCALE_F  ((float) (1 &lt;&lt; SCALE))
 319 
 320 #ifndef GSTREAMER_LITE
 321 
 322 typedef struct _MatrixData MatrixData;
 323 
 324 struct _MatrixData
 325 {
 326   gdouble dm[4][4];
 327   gint im[4][4];
 328   gint width;
 329   guint64 orc_p1;
 330   guint64 orc_p2;
 331   guint64 orc_p3;
 332   guint64 orc_p4;
 333   gint64 *t_r;
 334   gint64 *t_g;
 335   gint64 *t_b;
 336   gint64 t_c;
 337   void (*matrix_func) (MatrixData * data, gpointer pixels);
 338 };
 339 
 340 typedef struct _GammaData GammaData;
 341 
 342 struct _GammaData
 343 {
 344   gpointer gamma_table;
 345   gint width;
 346   void (*gamma_func) (GammaData * data, gpointer dest, gpointer src);
 347 };
 348 
 349 typedef enum
 350 {
 351   ALPHA_MODE_NONE = 0,
 352   ALPHA_MODE_COPY = (1 &lt;&lt; 0),
 353   ALPHA_MODE_SET = (1 &lt;&lt; 1),
 354   ALPHA_MODE_MULT = (1 &lt;&lt; 2)
 355 } AlphaMode;
 356 
 357 typedef struct
 358 {
 359   guint8 *data;
 360   guint stride;
 361   guint n_lines;
 362   guint idx;
 363   gpointer user_data;
 364   GDestroyNotify notify;
 365 } ConverterAlloc;
 366 
 367 typedef void (*FastConvertFunc) (GstVideoConverter * convert,
 368     const GstVideoFrame * src, GstVideoFrame * dest, gint plane);
 369 
 370 struct _GstVideoConverter
 371 {
 372   gint flags;
 373 
 374   GstVideoInfo in_info;
 375   GstVideoInfo out_info;
 376 
 377   gint in_x;
 378   gint in_y;
 379   gint in_width;
 380   gint in_height;
 381   gint in_maxwidth;
 382   gint in_maxheight;
 383   gint out_x;
 384   gint out_y;
 385   gint out_width;
 386   gint out_height;
 387   gint out_maxwidth;
 388   gint out_maxheight;
 389 
 390   gint current_pstride;
 391   gint current_width;
 392   gint current_height;
 393   GstVideoFormat current_format;
 394   gint current_bits;
 395 
 396   GstStructure *config;
 397 
 398   GstParallelizedTaskRunner *conversion_runner;
 399 
 400   guint16 **tmpline;
 401 
 402   gboolean fill_border;
 403   gpointer borderline;
 404   guint64 borders[4];
 405   guint32 border_argb;
 406   guint32 alpha_value;
 407   AlphaMode alpha_mode;
 408 
 409   void (*convert) (GstVideoConverter * convert, const GstVideoFrame * src,
 410       GstVideoFrame * dest);
 411 
 412   /* data for unpack */
 413   GstLineCache **unpack_lines;
 414   GstVideoFormat unpack_format;
 415   guint unpack_bits;
 416   gboolean unpack_rgb;
 417   gboolean identity_unpack;
 418   gint unpack_pstride;
 419 
 420   /* chroma upsample */
 421   GstLineCache **upsample_lines;
 422   GstVideoChromaResample **upsample;
 423   GstVideoChromaResample **upsample_p;
 424   GstVideoChromaResample **upsample_i;
 425   guint up_n_lines;
 426   gint up_offset;
 427 
 428   /* to R&#39;G&#39;B */
 429   GstLineCache **to_RGB_lines;
 430   MatrixData to_RGB_matrix;
 431   /* gamma decode */
 432   GammaData gamma_dec;
 433 
 434   /* scaling */
 435   GstLineCache **hscale_lines;
 436   GstVideoScaler **h_scaler;
 437   gint h_scale_format;
 438   GstLineCache **vscale_lines;
 439   GstVideoScaler **v_scaler;
 440   GstVideoScaler **v_scaler_p;
 441   GstVideoScaler **v_scaler_i;
 442   gint v_scale_width;
 443   gint v_scale_format;
 444 
 445   /* color space conversion */
 446   GstLineCache **convert_lines;
 447   MatrixData convert_matrix;
 448   gint in_bits;
 449   gint out_bits;
 450 
 451   /* alpha correction */
 452   GstLineCache **alpha_lines;
 453   void (*alpha_func) (GstVideoConverter * convert, gpointer pixels, gint width);
 454 
 455   /* gamma encode */
 456   GammaData gamma_enc;
 457   /* to Y&#39;CbCr */
 458   GstLineCache **to_YUV_lines;
 459   MatrixData to_YUV_matrix;
 460 
 461   /* chroma downsample */
 462   GstLineCache **downsample_lines;
 463   GstVideoChromaResample **downsample;
 464   GstVideoChromaResample **downsample_p;
 465   GstVideoChromaResample **downsample_i;
 466   guint down_n_lines;
 467   gint down_offset;
 468 
 469   /* dither */
 470   GstLineCache **dither_lines;
 471   GstVideoDither **dither;
 472 
 473   /* pack */
 474   GstLineCache **pack_lines;
 475   guint pack_nlines;
 476   GstVideoFormat pack_format;
 477   guint pack_bits;
 478   gboolean pack_rgb;
 479   gboolean identity_pack;
 480   gint pack_pstride;
 481   gconstpointer pack_pal;
 482   gsize pack_palsize;
 483 
 484   const GstVideoFrame *src;
 485   GstVideoFrame *dest;
 486 
 487   /* fastpath */
 488   GstVideoFormat fformat[4];
 489   gint fin_x[4];
 490   gint fin_y[4];
 491   gint fout_x[4];
 492   gint fout_y[4];
 493   gint fout_width[4];
 494   gint fout_height[4];
 495   gint fsplane[4];
 496   gint ffill[4];
 497 
 498   struct
 499   {
 500     GstVideoScaler **scaler;
 501   } fh_scaler[4];
 502   struct
 503   {
 504     GstVideoScaler **scaler;
 505   } fv_scaler[4];
 506   FastConvertFunc fconvert[4];
 507 };
 508 
 509 typedef gpointer (*GstLineCacheAllocLineFunc) (GstLineCache * cache, gint idx,
 510     gpointer user_data);
 511 typedef gboolean (*GstLineCacheNeedLineFunc) (GstLineCache * cache, gint idx,
 512     gint out_line, gint in_line, gpointer user_data);
 513 
 514 struct _GstLineCache
 515 {
 516   gint first;
 517   gint backlog;
 518   GPtrArray *lines;
 519 
 520   GstLineCache *prev;
 521   gboolean write_input;
 522   gboolean pass_alloc;
 523   gboolean alloc_writable;
 524 
 525   GstLineCacheNeedLineFunc need_line;
 526   gint need_line_idx;
 527   gpointer need_line_data;
 528   GDestroyNotify need_line_notify;
 529 
 530   guint n_lines;
 531   guint stride;
 532   GstLineCacheAllocLineFunc alloc_line;
 533   gpointer alloc_line_data;
 534   GDestroyNotify alloc_line_notify;
 535 };
 536 
 537 static GstLineCache *
 538 gst_line_cache_new (GstLineCache * prev)
 539 {
 540   GstLineCache *result;
 541 
 542   result = g_slice_new0 (GstLineCache);
 543   result-&gt;lines = g_ptr_array_new ();
 544   result-&gt;prev = prev;
 545 
 546   return result;
 547 }
 548 
 549 static void
 550 gst_line_cache_clear (GstLineCache * cache)
 551 {
 552   g_return_if_fail (cache != NULL);
 553 
 554   g_ptr_array_set_size (cache-&gt;lines, 0);
 555   cache-&gt;first = 0;
 556 }
 557 
 558 static void
 559 gst_line_cache_free (GstLineCache * cache)
 560 {
 561   if (cache-&gt;need_line_notify)
 562     cache-&gt;need_line_notify (cache-&gt;need_line_data);
 563   if (cache-&gt;alloc_line_notify)
 564     cache-&gt;alloc_line_notify (cache-&gt;alloc_line_data);
 565   gst_line_cache_clear (cache);
 566   g_ptr_array_unref (cache-&gt;lines);
 567   g_slice_free (GstLineCache, cache);
 568 }
 569 
 570 static void
 571 gst_line_cache_set_need_line_func (GstLineCache * cache,
 572     GstLineCacheNeedLineFunc need_line, gint idx, gpointer user_data,
 573     GDestroyNotify notify)
 574 {
 575   cache-&gt;need_line = need_line;
 576   cache-&gt;need_line_idx = idx;
 577   cache-&gt;need_line_data = user_data;
 578   cache-&gt;need_line_notify = notify;
 579 }
 580 
 581 static void
 582 gst_line_cache_set_alloc_line_func (GstLineCache * cache,
 583     GstLineCacheAllocLineFunc alloc_line, gpointer user_data,
 584     GDestroyNotify notify)
 585 {
 586   cache-&gt;alloc_line = alloc_line;
 587   cache-&gt;alloc_line_data = user_data;
 588   cache-&gt;alloc_line_notify = notify;
 589 }
 590 
 591 /* keep this much backlog for interlaced video */
 592 #define BACKLOG 2
 593 
 594 static gpointer *
 595 gst_line_cache_get_lines (GstLineCache * cache, gint idx, gint out_line,
 596     gint in_line, gint n_lines)
 597 {
 598   if (cache-&gt;first + cache-&gt;backlog &lt; in_line) {
 599     gint to_remove =
 600         MIN (in_line - (cache-&gt;first + cache-&gt;backlog), cache-&gt;lines-&gt;len);
 601     if (to_remove &gt; 0) {
 602       g_ptr_array_remove_range (cache-&gt;lines, 0, to_remove);
 603     }
 604     cache-&gt;first += to_remove;
 605   } else if (in_line &lt; cache-&gt;first) {
 606     gst_line_cache_clear (cache);
 607     cache-&gt;first = in_line;
 608   }
 609 
 610   while (TRUE) {
 611     gint oline;
 612 
 613     if (cache-&gt;first &lt;= in_line
 614         &amp;&amp; in_line + n_lines &lt;= cache-&gt;first + (gint) cache-&gt;lines-&gt;len) {
 615       return cache-&gt;lines-&gt;pdata + (in_line - cache-&gt;first);
 616     }
 617 
 618     if (cache-&gt;need_line == NULL)
 619       break;
 620 
 621     oline = out_line + cache-&gt;first + cache-&gt;lines-&gt;len - in_line;
 622 
 623     if (!cache-&gt;need_line (cache, idx, oline, cache-&gt;first + cache-&gt;lines-&gt;len,
 624             cache-&gt;need_line_data))
 625       break;
 626   }
 627   GST_DEBUG (&quot;no lines&quot;);
 628   return NULL;
 629 }
 630 
 631 static void
 632 gst_line_cache_add_line (GstLineCache * cache, gint idx, gpointer line)
 633 {
 634   if (cache-&gt;first + cache-&gt;lines-&gt;len != idx) {
 635     gst_line_cache_clear (cache);
 636     cache-&gt;first = idx;
 637   }
 638   g_ptr_array_add (cache-&gt;lines, line);
 639 }
 640 
 641 static gpointer
 642 gst_line_cache_alloc_line (GstLineCache * cache, gint idx)
 643 {
 644   gpointer res;
 645 
 646   if (cache-&gt;alloc_line)
 647     res = cache-&gt;alloc_line (cache, idx, cache-&gt;alloc_line_data);
 648   else
 649     res = NULL;
 650 
 651   return res;
 652 }
 653 
 654 static void video_converter_generic (GstVideoConverter * convert,
 655     const GstVideoFrame * src, GstVideoFrame * dest);
 656 static gboolean video_converter_lookup_fastpath (GstVideoConverter * convert);
 657 static void video_converter_compute_matrix (GstVideoConverter * convert);
 658 static void video_converter_compute_resample (GstVideoConverter * convert,
 659     gint idx);
 660 
 661 static gpointer get_dest_line (GstLineCache * cache, gint idx,
 662     gpointer user_data);
 663 
 664 static gboolean do_unpack_lines (GstLineCache * cache, gint idx, gint out_line,
 665     gint in_line, gpointer user_data);
 666 static gboolean do_downsample_lines (GstLineCache * cache, gint idx,
 667     gint out_line, gint in_line, gpointer user_data);
 668 static gboolean do_convert_to_RGB_lines (GstLineCache * cache, gint idx,
 669     gint out_line, gint in_line, gpointer user_data);
 670 static gboolean do_convert_lines (GstLineCache * cache, gint idx, gint out_line,
 671     gint in_line, gpointer user_data);
 672 static gboolean do_alpha_lines (GstLineCache * cache, gint idx, gint out_line,
 673     gint in_line, gpointer user_data);
 674 static gboolean do_convert_to_YUV_lines (GstLineCache * cache, gint idx,
 675     gint out_line, gint in_line, gpointer user_data);
 676 static gboolean do_upsample_lines (GstLineCache * cache, gint idx,
 677     gint out_line, gint in_line, gpointer user_data);
 678 static gboolean do_vscale_lines (GstLineCache * cache, gint idx, gint out_line,
 679     gint in_line, gpointer user_data);
 680 static gboolean do_hscale_lines (GstLineCache * cache, gint idx, gint out_line,
 681     gint in_line, gpointer user_data);
 682 static gboolean do_dither_lines (GstLineCache * cache, gint idx, gint out_line,
 683     gint in_line, gpointer user_data);
 684 
 685 static ConverterAlloc *
 686 converter_alloc_new (guint stride, guint n_lines, gpointer user_data,
 687     GDestroyNotify notify)
 688 {
 689   ConverterAlloc *alloc;
 690 
 691   GST_DEBUG (&quot;stride %d, n_lines %d&quot;, stride, n_lines);
 692   alloc = g_slice_new0 (ConverterAlloc);
 693   alloc-&gt;data = g_malloc (stride * n_lines);
 694   alloc-&gt;stride = stride;
 695   alloc-&gt;n_lines = n_lines;
 696   alloc-&gt;idx = 0;
 697   alloc-&gt;user_data = user_data;
 698   alloc-&gt;notify = notify;
 699 
 700   return alloc;
 701 }
 702 
 703 static void
 704 converter_alloc_free (ConverterAlloc * alloc)
 705 {
 706   if (alloc-&gt;notify)
 707     alloc-&gt;notify (alloc-&gt;user_data);
 708   g_free (alloc-&gt;data);
 709   g_slice_free (ConverterAlloc, alloc);
 710 }
 711 
 712 static void
 713 setup_border_alloc (GstVideoConverter * convert, ConverterAlloc * alloc)
 714 {
 715   gint i;
 716 
 717   if (convert-&gt;borderline) {
 718     for (i = 0; i &lt; alloc-&gt;n_lines; i++)
 719       memcpy (&amp;alloc-&gt;data[i * alloc-&gt;stride], convert-&gt;borderline,
 720           alloc-&gt;stride);
 721   }
 722 }
 723 
 724 static gpointer
 725 get_temp_line (GstLineCache * cache, gint idx, gpointer user_data)
 726 {
 727   ConverterAlloc *alloc = user_data;
 728   gpointer tmpline;
 729 
 730   GST_DEBUG (&quot;get temp line %d (%p %d)&quot;, idx, alloc, alloc-&gt;idx);
 731   tmpline = &amp;alloc-&gt;data[alloc-&gt;stride * alloc-&gt;idx];
 732   alloc-&gt;idx = (alloc-&gt;idx + 1) % alloc-&gt;n_lines;
 733 
 734   return tmpline;
 735 }
 736 
 737 static gpointer
 738 get_border_temp_line (GstLineCache * cache, gint idx, gpointer user_data)
 739 {
 740   ConverterAlloc *alloc = user_data;
 741   GstVideoConverter *convert = alloc-&gt;user_data;
 742   gpointer tmpline;
 743 
 744   GST_DEBUG (&quot;get temp line %d (%p %d)&quot;, idx, alloc, alloc-&gt;idx);
 745   tmpline = &amp;alloc-&gt;data[alloc-&gt;stride * alloc-&gt;idx] +
 746       (convert-&gt;out_x * convert-&gt;pack_pstride);
 747   alloc-&gt;idx = (alloc-&gt;idx + 1) % alloc-&gt;n_lines;
 748 
 749   return tmpline;
 750 }
 751 
 752 static gint
 753 get_opt_int (GstVideoConverter * convert, const gchar * opt, gint def)
 754 {
 755   gint res;
 756   if (!gst_structure_get_int (convert-&gt;config, opt, &amp;res))
 757     res = def;
 758   return res;
 759 }
 760 
 761 static guint
 762 get_opt_uint (GstVideoConverter * convert, const gchar * opt, guint def)
 763 {
 764   guint res;
 765   if (!gst_structure_get_uint (convert-&gt;config, opt, &amp;res))
 766     res = def;
 767   return res;
 768 }
 769 
 770 static gdouble
 771 get_opt_double (GstVideoConverter * convert, const gchar * opt, gdouble def)
 772 {
 773   gdouble res;
 774   if (!gst_structure_get_double (convert-&gt;config, opt, &amp;res))
 775     res = def;
 776   return res;
 777 }
 778 
 779 static gboolean
 780 get_opt_bool (GstVideoConverter * convert, const gchar * opt, gboolean def)
 781 {
 782   gboolean res;
 783   if (!gst_structure_get_boolean (convert-&gt;config, opt, &amp;res))
 784     res = def;
 785   return res;
 786 }
 787 
 788 static gint
 789 get_opt_enum (GstVideoConverter * convert, const gchar * opt, GType type,
 790     gint def)
 791 {
 792   gint res;
 793   if (!gst_structure_get_enum (convert-&gt;config, opt, type, &amp;res))
 794     res = def;
 795   return res;
 796 }
 797 
 798 #define DEFAULT_OPT_FILL_BORDER TRUE
 799 #define DEFAULT_OPT_ALPHA_VALUE 1.0
 800 /* options copy, set, mult */
 801 #define DEFAULT_OPT_ALPHA_MODE GST_VIDEO_ALPHA_MODE_COPY
 802 #define DEFAULT_OPT_BORDER_ARGB 0xff000000
 803 /* options full, input-only, output-only, none */
 804 #define DEFAULT_OPT_MATRIX_MODE GST_VIDEO_MATRIX_MODE_FULL
 805 /* none, remap */
 806 #define DEFAULT_OPT_GAMMA_MODE GST_VIDEO_GAMMA_MODE_NONE
 807 /* none, merge-only, fast */
 808 #define DEFAULT_OPT_PRIMARIES_MODE GST_VIDEO_PRIMARIES_MODE_NONE
 809 /* options full, upsample-only, downsample-only, none */
 810 #define DEFAULT_OPT_CHROMA_MODE GST_VIDEO_CHROMA_MODE_FULL
 811 #define DEFAULT_OPT_RESAMPLER_METHOD GST_VIDEO_RESAMPLER_METHOD_CUBIC
 812 #define DEFAULT_OPT_CHROMA_RESAMPLER_METHOD GST_VIDEO_RESAMPLER_METHOD_LINEAR
 813 #define DEFAULT_OPT_RESAMPLER_TAPS 0
 814 #define DEFAULT_OPT_DITHER_METHOD GST_VIDEO_DITHER_BAYER
 815 #define DEFAULT_OPT_DITHER_QUANTIZATION 1
 816 
 817 #define GET_OPT_FILL_BORDER(c) get_opt_bool(c, \
 818     GST_VIDEO_CONVERTER_OPT_FILL_BORDER, DEFAULT_OPT_FILL_BORDER)
 819 #define GET_OPT_ALPHA_VALUE(c) get_opt_double(c, \
 820     GST_VIDEO_CONVERTER_OPT_ALPHA_VALUE, DEFAULT_OPT_ALPHA_VALUE)
 821 #define GET_OPT_ALPHA_MODE(c) get_opt_enum(c, \
 822     GST_VIDEO_CONVERTER_OPT_ALPHA_MODE, GST_TYPE_VIDEO_ALPHA_MODE, DEFAULT_OPT_ALPHA_MODE)
 823 #define GET_OPT_BORDER_ARGB(c) get_opt_uint(c, \
 824     GST_VIDEO_CONVERTER_OPT_BORDER_ARGB, DEFAULT_OPT_BORDER_ARGB)
 825 #define GET_OPT_MATRIX_MODE(c) get_opt_enum(c, \
 826     GST_VIDEO_CONVERTER_OPT_MATRIX_MODE, GST_TYPE_VIDEO_MATRIX_MODE, DEFAULT_OPT_MATRIX_MODE)
 827 #define GET_OPT_GAMMA_MODE(c) get_opt_enum(c, \
 828     GST_VIDEO_CONVERTER_OPT_GAMMA_MODE, GST_TYPE_VIDEO_GAMMA_MODE, DEFAULT_OPT_GAMMA_MODE)
 829 #define GET_OPT_PRIMARIES_MODE(c) get_opt_enum(c, \
 830     GST_VIDEO_CONVERTER_OPT_PRIMARIES_MODE, GST_TYPE_VIDEO_PRIMARIES_MODE, DEFAULT_OPT_PRIMARIES_MODE)
 831 #define GET_OPT_CHROMA_MODE(c) get_opt_enum(c, \
 832     GST_VIDEO_CONVERTER_OPT_CHROMA_MODE, GST_TYPE_VIDEO_CHROMA_MODE, DEFAULT_OPT_CHROMA_MODE)
 833 #define GET_OPT_RESAMPLER_METHOD(c) get_opt_enum(c, \
 834     GST_VIDEO_CONVERTER_OPT_RESAMPLER_METHOD, GST_TYPE_VIDEO_RESAMPLER_METHOD, \
 835     DEFAULT_OPT_RESAMPLER_METHOD)
 836 #define GET_OPT_CHROMA_RESAMPLER_METHOD(c) get_opt_enum(c, \
 837     GST_VIDEO_CONVERTER_OPT_CHROMA_RESAMPLER_METHOD, GST_TYPE_VIDEO_RESAMPLER_METHOD, \
 838     DEFAULT_OPT_CHROMA_RESAMPLER_METHOD)
 839 #define GET_OPT_RESAMPLER_TAPS(c) get_opt_uint(c, \
 840     GST_VIDEO_CONVERTER_OPT_RESAMPLER_TAPS, DEFAULT_OPT_RESAMPLER_TAPS)
 841 #define GET_OPT_DITHER_METHOD(c) get_opt_enum(c, \
 842     GST_VIDEO_CONVERTER_OPT_DITHER_METHOD, GST_TYPE_VIDEO_DITHER_METHOD, \
 843     DEFAULT_OPT_DITHER_METHOD)
 844 #define GET_OPT_DITHER_QUANTIZATION(c) get_opt_uint(c, \
 845     GST_VIDEO_CONVERTER_OPT_DITHER_QUANTIZATION, DEFAULT_OPT_DITHER_QUANTIZATION)
 846 
 847 #define CHECK_ALPHA_COPY(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_COPY)
 848 #define CHECK_ALPHA_SET(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_SET)
 849 #define CHECK_ALPHA_MULT(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_MULT)
 850 
 851 #define CHECK_MATRIX_FULL(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_FULL)
 852 #define CHECK_MATRIX_INPUT(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_INPUT_ONLY)
 853 #define CHECK_MATRIX_OUTPUT(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_OUTPUT_ONLY)
 854 #define CHECK_MATRIX_NONE(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_NONE)
 855 
 856 #define CHECK_GAMMA_NONE(c) (GET_OPT_GAMMA_MODE(c) == GST_VIDEO_GAMMA_MODE_NONE)
 857 #define CHECK_GAMMA_REMAP(c) (GET_OPT_GAMMA_MODE(c) == GST_VIDEO_GAMMA_MODE_REMAP)
 858 
 859 #define CHECK_PRIMARIES_NONE(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_NONE)
 860 #define CHECK_PRIMARIES_MERGE(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_MERGE_ONLY)
 861 #define CHECK_PRIMARIES_FAST(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_FAST)
 862 
 863 #define CHECK_CHROMA_FULL(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_FULL)
 864 #define CHECK_CHROMA_UPSAMPLE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_UPSAMPLE_ONLY)
 865 #define CHECK_CHROMA_DOWNSAMPLE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_DOWNSAMPLE_ONLY)
 866 #define CHECK_CHROMA_NONE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_NONE)
 867 
 868 static GstLineCache *
 869 chain_unpack_line (GstVideoConverter * convert, gint idx)
 870 {
 871   GstLineCache *prev;
 872   GstVideoInfo *info;
 873 
 874   info = &amp;convert-&gt;in_info;
 875 
 876   convert-&gt;current_format = convert-&gt;unpack_format;
 877   convert-&gt;current_bits = convert-&gt;unpack_bits;
 878   convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
 879 
 880   convert-&gt;unpack_pstride = convert-&gt;current_pstride;
 881   convert-&gt;identity_unpack = (convert-&gt;current_format == info-&gt;finfo-&gt;format);
 882 
 883   GST_DEBUG (&quot;chain unpack line format %s, pstride %d, identity_unpack %d&quot;,
 884       gst_video_format_to_string (convert-&gt;current_format),
 885       convert-&gt;current_pstride, convert-&gt;identity_unpack);
 886 
 887   prev = convert-&gt;unpack_lines[idx] = gst_line_cache_new (NULL);
 888   prev-&gt;write_input = FALSE;
 889   prev-&gt;pass_alloc = FALSE;
 890   prev-&gt;n_lines = 1;
 891   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
 892   gst_line_cache_set_need_line_func (prev, do_unpack_lines, idx, convert, NULL);
 893 
 894   return prev;
 895 }
 896 
 897 static GstLineCache *
 898 chain_upsample (GstVideoConverter * convert, GstLineCache * prev, gint idx)
 899 {
 900   video_converter_compute_resample (convert, idx);
 901 
 902   if (convert-&gt;upsample_p[idx] || convert-&gt;upsample_i[idx]) {
 903     GST_DEBUG (&quot;chain upsample&quot;);
 904     prev = convert-&gt;upsample_lines[idx] = gst_line_cache_new (prev);
 905     prev-&gt;write_input = TRUE;
 906     prev-&gt;pass_alloc = TRUE;
 907     prev-&gt;n_lines = 4;
 908     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
 909     gst_line_cache_set_need_line_func (prev,
 910         do_upsample_lines, idx, convert, NULL);
 911   }
 912   return prev;
 913 }
 914 
 915 static void
 916 color_matrix_set_identity (MatrixData * m)
 917 {
 918   int i, j;
 919 
 920   for (i = 0; i &lt; 4; i++) {
 921     for (j = 0; j &lt; 4; j++) {
 922       m-&gt;dm[i][j] = (i == j);
 923     }
 924   }
 925 }
 926 
 927 static void
 928 color_matrix_copy (MatrixData * d, const MatrixData * s)
 929 {
 930   gint i, j;
 931 
 932   for (i = 0; i &lt; 4; i++)
 933     for (j = 0; j &lt; 4; j++)
 934       d-&gt;dm[i][j] = s-&gt;dm[i][j];
 935 }
 936 
 937 /* Perform 4x4 matrix multiplication:
 938  *  - @dst@ = @a@ * @b@
 939  *  - @dst@ may be a pointer to @a@ andor @b@
 940  */
 941 static void
 942 color_matrix_multiply (MatrixData * dst, MatrixData * a, MatrixData * b)
 943 {
 944   MatrixData tmp;
 945   int i, j, k;
 946 
 947   for (i = 0; i &lt; 4; i++) {
 948     for (j = 0; j &lt; 4; j++) {
 949       double x = 0;
 950       for (k = 0; k &lt; 4; k++) {
 951         x += a-&gt;dm[i][k] * b-&gt;dm[k][j];
 952       }
 953       tmp.dm[i][j] = x;
 954     }
 955   }
 956   color_matrix_copy (dst, &amp;tmp);
 957 }
 958 
 959 static void
 960 color_matrix_invert (MatrixData * d, MatrixData * s)
 961 {
 962   MatrixData tmp;
 963   int i, j;
 964   double det;
 965 
 966   color_matrix_set_identity (&amp;tmp);
 967   for (j = 0; j &lt; 3; j++) {
 968     for (i = 0; i &lt; 3; i++) {
 969       tmp.dm[j][i] =
 970           s-&gt;dm[(i + 1) % 3][(j + 1) % 3] * s-&gt;dm[(i + 2) % 3][(j + 2) % 3] -
 971           s-&gt;dm[(i + 1) % 3][(j + 2) % 3] * s-&gt;dm[(i + 2) % 3][(j + 1) % 3];
 972     }
 973   }
 974   det =
 975       tmp.dm[0][0] * s-&gt;dm[0][0] + tmp.dm[0][1] * s-&gt;dm[1][0] +
 976       tmp.dm[0][2] * s-&gt;dm[2][0];
 977   for (j = 0; j &lt; 3; j++) {
 978     for (i = 0; i &lt; 3; i++) {
 979       tmp.dm[i][j] /= det;
 980     }
 981   }
 982   color_matrix_copy (d, &amp;tmp);
 983 }
 984 
 985 static void
 986 color_matrix_offset_components (MatrixData * m, double a1, double a2, double a3)
 987 {
 988   MatrixData a;
 989 
 990   color_matrix_set_identity (&amp;a);
 991   a.dm[0][3] = a1;
 992   a.dm[1][3] = a2;
 993   a.dm[2][3] = a3;
 994   color_matrix_multiply (m, &amp;a, m);
 995 }
 996 
 997 static void
 998 color_matrix_scale_components (MatrixData * m, double a1, double a2, double a3)
 999 {
1000   MatrixData a;
1001 
1002   color_matrix_set_identity (&amp;a);
1003   a.dm[0][0] = a1;
1004   a.dm[1][1] = a2;
1005   a.dm[2][2] = a3;
1006   color_matrix_multiply (m, &amp;a, m);
1007 }
1008 
1009 static void
1010 color_matrix_debug (const MatrixData * s)
1011 {
1012   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[0][0], s-&gt;dm[0][1], s-&gt;dm[0][2],
1013       s-&gt;dm[0][3]);
1014   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[1][0], s-&gt;dm[1][1], s-&gt;dm[1][2],
1015       s-&gt;dm[1][3]);
1016   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[2][0], s-&gt;dm[2][1], s-&gt;dm[2][2],
1017       s-&gt;dm[2][3]);
1018   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[3][0], s-&gt;dm[3][1], s-&gt;dm[3][2],
1019       s-&gt;dm[3][3]);
1020 }
1021 
1022 static void
1023 color_matrix_convert (MatrixData * s)
1024 {
1025   gint i, j;
1026 
1027   for (i = 0; i &lt; 4; i++)
1028     for (j = 0; j &lt; 4; j++)
1029       s-&gt;im[i][j] = rint (s-&gt;dm[i][j]);
1030 
1031   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[0][0], s-&gt;im[0][1], s-&gt;im[0][2],
1032       s-&gt;im[0][3]);
1033   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[1][0], s-&gt;im[1][1], s-&gt;im[1][2],
1034       s-&gt;im[1][3]);
1035   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[2][0], s-&gt;im[2][1], s-&gt;im[2][2],
1036       s-&gt;im[2][3]);
1037   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[3][0], s-&gt;im[3][1], s-&gt;im[3][2],
1038       s-&gt;im[3][3]);
1039 }
1040 
1041 static void
1042 color_matrix_YCbCr_to_RGB (MatrixData * m, double Kr, double Kb)
1043 {
1044   double Kg = 1.0 - Kr - Kb;
1045   MatrixData k = {
1046     {
1047           {1., 0., 2 * (1 - Kr), 0.},
1048           {1., -2 * Kb * (1 - Kb) / Kg, -2 * Kr * (1 - Kr) / Kg, 0.},
1049           {1., 2 * (1 - Kb), 0., 0.},
1050           {0., 0., 0., 1.},
1051         }
1052   };
1053 
1054   color_matrix_multiply (m, &amp;k, m);
1055 }
1056 
1057 static void
1058 color_matrix_RGB_to_YCbCr (MatrixData * m, double Kr, double Kb)
1059 {
1060   double Kg = 1.0 - Kr - Kb;
1061   MatrixData k;
1062   double x;
1063 
1064   k.dm[0][0] = Kr;
1065   k.dm[0][1] = Kg;
1066   k.dm[0][2] = Kb;
1067   k.dm[0][3] = 0;
1068 
1069   x = 1 / (2 * (1 - Kb));
1070   k.dm[1][0] = -x * Kr;
1071   k.dm[1][1] = -x * Kg;
1072   k.dm[1][2] = x * (1 - Kb);
1073   k.dm[1][3] = 0;
1074 
1075   x = 1 / (2 * (1 - Kr));
1076   k.dm[2][0] = x * (1 - Kr);
1077   k.dm[2][1] = -x * Kg;
1078   k.dm[2][2] = -x * Kb;
1079   k.dm[2][3] = 0;
1080 
1081   k.dm[3][0] = 0;
1082   k.dm[3][1] = 0;
1083   k.dm[3][2] = 0;
1084   k.dm[3][3] = 1;
1085 
1086   color_matrix_multiply (m, &amp;k, m);
1087 }
1088 
1089 static void
1090 color_matrix_RGB_to_XYZ (MatrixData * dst, double Rx, double Ry, double Gx,
1091     double Gy, double Bx, double By, double Wx, double Wy)
1092 {
1093   MatrixData m, im;
1094   double sx, sy, sz;
1095   double wx, wy, wz;
1096 
1097   color_matrix_set_identity (&amp;m);
1098 
1099   m.dm[0][0] = Rx;
1100   m.dm[1][0] = Ry;
1101   m.dm[2][0] = (1.0 - Rx - Ry);
1102   m.dm[0][1] = Gx;
1103   m.dm[1][1] = Gy;
1104   m.dm[2][1] = (1.0 - Gx - Gy);
1105   m.dm[0][2] = Bx;
1106   m.dm[1][2] = By;
1107   m.dm[2][2] = (1.0 - Bx - By);
1108 
1109   color_matrix_invert (&amp;im, &amp;m);
1110 
1111   wx = Wx / Wy;
1112   wy = 1.0;
1113   wz = (1.0 - Wx - Wy) / Wy;
1114 
1115   sx = im.dm[0][0] * wx + im.dm[0][1] * wy + im.dm[0][2] * wz;
1116   sy = im.dm[1][0] * wx + im.dm[1][1] * wy + im.dm[1][2] * wz;
1117   sz = im.dm[2][0] * wx + im.dm[2][1] * wy + im.dm[2][2] * wz;
1118 
1119   m.dm[0][0] *= sx;
1120   m.dm[1][0] *= sx;
1121   m.dm[2][0] *= sx;
1122   m.dm[0][1] *= sy;
1123   m.dm[1][1] *= sy;
1124   m.dm[2][1] *= sy;
1125   m.dm[0][2] *= sz;
1126   m.dm[1][2] *= sz;
1127   m.dm[2][2] *= sz;
1128 
1129   color_matrix_copy (dst, &amp;m);
1130 }
1131 
1132 static void
1133 videoconvert_convert_init_tables (MatrixData * data)
1134 {
1135   gint i, j;
1136 
1137   data-&gt;t_r = g_new (gint64, 256);
1138   data-&gt;t_g = g_new (gint64, 256);
1139   data-&gt;t_b = g_new (gint64, 256);
1140 
1141   for (i = 0; i &lt; 256; i++) {
1142     gint64 r = 0, g = 0, b = 0;
1143 
1144     for (j = 0; j &lt; 3; j++) {
1145       r = (r &lt;&lt; 16) + data-&gt;im[j][0] * i;
1146       g = (g &lt;&lt; 16) + data-&gt;im[j][1] * i;
1147       b = (b &lt;&lt; 16) + data-&gt;im[j][2] * i;
1148     }
1149     data-&gt;t_r[i] = r;
1150     data-&gt;t_g[i] = g;
1151     data-&gt;t_b[i] = b;
1152   }
1153   data-&gt;t_c = ((gint64) data-&gt;im[0][3] &lt;&lt; 32)
1154       + ((gint64) data-&gt;im[1][3] &lt;&lt; 16)
1155       + ((gint64) data-&gt;im[2][3] &lt;&lt; 0);
1156 }
1157 
1158 #endif // GSTREAMER_LITE
1159 
1160 void
1161 _custom_video_orc_matrix8 (guint8 * ORC_RESTRICT d1,
1162     const guint8 * ORC_RESTRICT s1, orc_int64 p1, orc_int64 p2, orc_int64 p3,
1163     orc_int64 p4, int n)
1164 {
1165   gint i;
1166   gint r, g, b;
1167   gint y, u, v;
1168   gint a00, a01, a02, a03;
1169   gint a10, a11, a12, a13;
1170   gint a20, a21, a22, a23;
1171 
1172   a00 = (gint16) (p1 &gt;&gt; 16);
1173   a01 = (gint16) (p2 &gt;&gt; 16);
1174   a02 = (gint16) (p3 &gt;&gt; 16);
1175   a03 = (gint16) (p4 &gt;&gt; 16);
1176   a10 = (gint16) (p1 &gt;&gt; 32);
1177   a11 = (gint16) (p2 &gt;&gt; 32);
1178   a12 = (gint16) (p3 &gt;&gt; 32);
1179   a13 = (gint16) (p4 &gt;&gt; 32);
1180   a20 = (gint16) (p1 &gt;&gt; 48);
1181   a21 = (gint16) (p2 &gt;&gt; 48);
1182   a22 = (gint16) (p3 &gt;&gt; 48);
1183   a23 = (gint16) (p4 &gt;&gt; 48);
1184 
1185   for (i = 0; i &lt; n; i++) {
1186     r = s1[i * 4 + 1];
1187     g = s1[i * 4 + 2];
1188     b = s1[i * 4 + 3];
1189 
1190     y = ((a00 * r + a01 * g + a02 * b) &gt;&gt; SCALE) + a03;
1191     u = ((a10 * r + a11 * g + a12 * b) &gt;&gt; SCALE) + a13;
1192     v = ((a20 * r + a21 * g + a22 * b) &gt;&gt; SCALE) + a23;
1193 
1194     d1[i * 4 + 1] = CLAMP (y, 0, 255);
1195     d1[i * 4 + 2] = CLAMP (u, 0, 255);
1196     d1[i * 4 + 3] = CLAMP (v, 0, 255);
1197   }
1198 }
1199 
1200 #ifndef GSTREAMER_LITE
1201 
1202 static void
1203 video_converter_matrix8 (MatrixData * data, gpointer pixels)
1204 {
1205   gpointer d = pixels;
1206   video_orc_matrix8 (d, pixels, data-&gt;orc_p1, data-&gt;orc_p2,
1207       data-&gt;orc_p3, data-&gt;orc_p4, data-&gt;width);
1208 }
1209 
1210 static void
1211 video_converter_matrix8_table (MatrixData * data, gpointer pixels)
1212 {
1213   gint i, width = data-&gt;width * 4;
1214   guint8 r, g, b;
1215   gint64 c = data-&gt;t_c;
1216   guint8 *p = pixels;
1217   gint64 x;
1218 
1219   for (i = 0; i &lt; width; i += 4) {
1220     r = p[i + 1];
1221     g = p[i + 2];
1222     b = p[i + 3];
1223 
1224     x = data-&gt;t_r[r] + data-&gt;t_g[g] + data-&gt;t_b[b] + c;
1225 
1226     p[i + 1] = x &gt;&gt; (32 + SCALE);
1227     p[i + 2] = x &gt;&gt; (16 + SCALE);
1228     p[i + 3] = x &gt;&gt; (0 + SCALE);
1229   }
1230 }
1231 
1232 static void
1233 video_converter_matrix8_AYUV_ARGB (MatrixData * data, gpointer pixels)
1234 {
1235   gpointer d = pixels;
1236 
1237   video_orc_convert_AYUV_ARGB (d, 0, pixels, 0,
1238       data-&gt;im[0][0], data-&gt;im[0][2],
1239       data-&gt;im[2][1], data-&gt;im[1][1], data-&gt;im[1][2], data-&gt;width, 1);
1240 }
1241 
1242 static gboolean
1243 is_ayuv_to_rgb_matrix (MatrixData * data)
1244 {
1245   if (data-&gt;im[0][0] != data-&gt;im[1][0] || data-&gt;im[1][0] != data-&gt;im[2][0])
1246     return FALSE;
1247 
1248   if (data-&gt;im[0][1] != 0 || data-&gt;im[2][2] != 0)
1249     return FALSE;
1250 
1251   return TRUE;
1252 }
1253 
1254 static gboolean
1255 is_identity_matrix (MatrixData * data)
1256 {
1257   gint i, j;
1258   gint c = data-&gt;im[0][0];
1259 
1260   /* not really checking identity because of rounding errors but given
1261    * the conversions we do we just check for anything that looks like:
1262    *
1263    *  c 0 0 0
1264    *  0 c 0 0
1265    *  0 0 c 0
1266    *  0 0 0 1
1267    */
1268   for (i = 0; i &lt; 4; i++) {
1269     for (j = 0; j &lt; 4; j++) {
1270       if (i == j) {
1271         if (i == 3 &amp;&amp; data-&gt;im[i][j] != 1)
1272           return FALSE;
1273         else if (data-&gt;im[i][j] != c)
1274           return FALSE;
1275       } else if (data-&gt;im[i][j] != 0)
1276         return FALSE;
1277     }
1278   }
1279   return TRUE;
1280 }
1281 
1282 static gboolean
1283 is_no_clip_matrix (MatrixData * data)
1284 {
1285   gint i;
1286   static const guint8 test[8][3] = {
1287     {0, 0, 0},
1288     {0, 0, 255},
1289     {0, 255, 0},
1290     {0, 255, 255},
1291     {255, 0, 0},
1292     {255, 0, 255},
1293     {255, 255, 0},
1294     {255, 255, 255}
1295   };
1296 
1297   for (i = 0; i &lt; 8; i++) {
1298     gint r, g, b;
1299     gint y, u, v;
1300 
1301     r = test[i][0];
1302     g = test[i][1];
1303     b = test[i][2];
1304 
1305     y = (data-&gt;im[0][0] * r + data-&gt;im[0][1] * g +
1306         data-&gt;im[0][2] * b + data-&gt;im[0][3]) &gt;&gt; SCALE;
1307     u = (data-&gt;im[1][0] * r + data-&gt;im[1][1] * g +
1308         data-&gt;im[1][2] * b + data-&gt;im[1][3]) &gt;&gt; SCALE;
1309     v = (data-&gt;im[2][0] * r + data-&gt;im[2][1] * g +
1310         data-&gt;im[2][2] * b + data-&gt;im[2][3]) &gt;&gt; SCALE;
1311 
1312     if (y != CLAMP (y, 0, 255) || u != CLAMP (u, 0, 255)
1313         || v != CLAMP (v, 0, 255))
1314       return FALSE;
1315   }
1316   return TRUE;
1317 }
1318 
1319 static void
1320 video_converter_matrix16 (MatrixData * data, gpointer pixels)
1321 {
1322   int i;
1323   int r, g, b;
1324   int y, u, v;
1325   guint16 *p = pixels;
1326   gint width = data-&gt;width;
1327 
1328   for (i = 0; i &lt; width; i++) {
1329     r = p[i * 4 + 1];
1330     g = p[i * 4 + 2];
1331     b = p[i * 4 + 3];
1332 
1333     y = (data-&gt;im[0][0] * r + data-&gt;im[0][1] * g +
1334         data-&gt;im[0][2] * b + data-&gt;im[0][3]) &gt;&gt; SCALE;
1335     u = (data-&gt;im[1][0] * r + data-&gt;im[1][1] * g +
1336         data-&gt;im[1][2] * b + data-&gt;im[1][3]) &gt;&gt; SCALE;
1337     v = (data-&gt;im[2][0] * r + data-&gt;im[2][1] * g +
1338         data-&gt;im[2][2] * b + data-&gt;im[2][3]) &gt;&gt; SCALE;
1339 
1340     p[i * 4 + 1] = CLAMP (y, 0, 65535);
1341     p[i * 4 + 2] = CLAMP (u, 0, 65535);
1342     p[i * 4 + 3] = CLAMP (v, 0, 65535);
1343   }
1344 }
1345 
1346 
1347 static void
1348 prepare_matrix (GstVideoConverter * convert, MatrixData * data)
1349 {
1350   if (is_identity_matrix (data))
1351     return;
1352 
1353   color_matrix_scale_components (data, SCALE_F, SCALE_F, SCALE_F);
1354   color_matrix_convert (data);
1355 
1356   data-&gt;width = convert-&gt;current_width;
1357 
1358   if (convert-&gt;current_bits == 8) {
1359     if (!convert-&gt;unpack_rgb &amp;&amp; convert-&gt;pack_rgb
1360         &amp;&amp; is_ayuv_to_rgb_matrix (data)) {
1361       GST_DEBUG (&quot;use fast AYUV -&gt; RGB matrix&quot;);
1362       data-&gt;matrix_func = video_converter_matrix8_AYUV_ARGB;
1363     } else if (is_no_clip_matrix (data)) {
1364       GST_DEBUG (&quot;use 8bit table&quot;);
1365       data-&gt;matrix_func = video_converter_matrix8_table;
1366       videoconvert_convert_init_tables (data);
1367     } else {
1368       gint a03, a13, a23;
1369 
1370       GST_DEBUG (&quot;use 8bit matrix&quot;);
1371       data-&gt;matrix_func = video_converter_matrix8;
1372 
1373       data-&gt;orc_p1 = (((guint64) (guint16) data-&gt;im[2][0]) &lt;&lt; 48) |
1374           (((guint64) (guint16) data-&gt;im[1][0]) &lt;&lt; 32) |
1375           (((guint64) (guint16) data-&gt;im[0][0]) &lt;&lt; 16);
1376       data-&gt;orc_p2 = (((guint64) (guint16) data-&gt;im[2][1]) &lt;&lt; 48) |
1377           (((guint64) (guint16) data-&gt;im[1][1]) &lt;&lt; 32) |
1378           (((guint64) (guint16) data-&gt;im[0][1]) &lt;&lt; 16);
1379       data-&gt;orc_p3 = (((guint64) (guint16) data-&gt;im[2][2]) &lt;&lt; 48) |
1380           (((guint64) (guint16) data-&gt;im[1][2]) &lt;&lt; 32) |
1381           (((guint64) (guint16) data-&gt;im[0][2]) &lt;&lt; 16);
1382 
1383       a03 = data-&gt;im[0][3] &gt;&gt; SCALE;
1384       a13 = data-&gt;im[1][3] &gt;&gt; SCALE;
1385       a23 = data-&gt;im[2][3] &gt;&gt; SCALE;
1386 
1387       data-&gt;orc_p4 = (((guint64) (guint16) a23) &lt;&lt; 48) |
1388           (((guint64) (guint16) a13) &lt;&lt; 32) | (((guint64) (guint16) a03) &lt;&lt; 16);
1389     }
1390   } else {
1391     GST_DEBUG (&quot;use 16bit matrix&quot;);
1392     data-&gt;matrix_func = video_converter_matrix16;
1393   }
1394 }
1395 
1396 static void
1397 compute_matrix_to_RGB (GstVideoConverter * convert, MatrixData * data)
1398 {
1399   GstVideoInfo *info;
1400   gdouble Kr = 0, Kb = 0;
1401 
1402   info = &amp;convert-&gt;in_info;
1403 
1404   {
1405     const GstVideoFormatInfo *uinfo;
1406     gint offset[4], scale[4];
1407 
1408     uinfo = gst_video_format_get_info (convert-&gt;unpack_format);
1409 
1410     /* bring color components to [0..1.0] range */
1411     gst_video_color_range_offsets (info-&gt;colorimetry.range, uinfo, offset,
1412         scale);
1413 
1414     color_matrix_offset_components (data, -offset[0], -offset[1], -offset[2]);
1415     color_matrix_scale_components (data, 1 / ((float) scale[0]),
1416         1 / ((float) scale[1]), 1 / ((float) scale[2]));
1417   }
1418 
1419   if (!convert-&gt;unpack_rgb &amp;&amp; !CHECK_MATRIX_NONE (convert)) {
1420     if (CHECK_MATRIX_OUTPUT (convert))
1421       info = &amp;convert-&gt;out_info;
1422 
1423     /* bring components to R&#39;G&#39;B&#39; space */
1424     if (gst_video_color_matrix_get_Kr_Kb (info-&gt;colorimetry.matrix, &amp;Kr, &amp;Kb))
1425       color_matrix_YCbCr_to_RGB (data, Kr, Kb);
1426   }
1427   color_matrix_debug (data);
1428 }
1429 
1430 static void
1431 compute_matrix_to_YUV (GstVideoConverter * convert, MatrixData * data,
1432     gboolean force)
1433 {
1434   GstVideoInfo *info;
1435   gdouble Kr = 0, Kb = 0;
1436 
1437   if (force || (!convert-&gt;pack_rgb &amp;&amp; !CHECK_MATRIX_NONE (convert))) {
1438     if (CHECK_MATRIX_INPUT (convert))
1439       info = &amp;convert-&gt;in_info;
1440     else
1441       info = &amp;convert-&gt;out_info;
1442 
1443     /* bring components to YCbCr space */
1444     if (gst_video_color_matrix_get_Kr_Kb (info-&gt;colorimetry.matrix, &amp;Kr, &amp;Kb))
1445       color_matrix_RGB_to_YCbCr (data, Kr, Kb);
1446   }
1447 
1448   info = &amp;convert-&gt;out_info;
1449 
1450   {
1451     const GstVideoFormatInfo *uinfo;
1452     gint offset[4], scale[4];
1453 
1454     uinfo = gst_video_format_get_info (convert-&gt;pack_format);
1455 
1456     /* bring color components to nominal range */
1457     gst_video_color_range_offsets (info-&gt;colorimetry.range, uinfo, offset,
1458         scale);
1459 
1460     color_matrix_scale_components (data, (float) scale[0], (float) scale[1],
1461         (float) scale[2]);
1462     color_matrix_offset_components (data, offset[0], offset[1], offset[2]);
1463   }
1464 
1465   color_matrix_debug (data);
1466 }
1467 
1468 
1469 static void
1470 gamma_convert_u8_u16 (GammaData * data, gpointer dest, gpointer src)
1471 {
1472   gint i;
1473   guint8 *s = src;
1474   guint16 *d = dest;
1475   guint16 *table = data-&gt;gamma_table;
1476   gint width = data-&gt;width * 4;
1477 
1478   for (i = 0; i &lt; width; i += 4) {
1479     d[i + 0] = (s[i] &lt;&lt; 8) | s[i];
1480     d[i + 1] = table[s[i + 1]];
1481     d[i + 2] = table[s[i + 2]];
1482     d[i + 3] = table[s[i + 3]];
1483   }
1484 }
1485 
1486 static void
1487 gamma_convert_u16_u8 (GammaData * data, gpointer dest, gpointer src)
1488 {
1489   gint i;
1490   guint16 *s = src;
1491   guint8 *d = dest;
1492   guint8 *table = data-&gt;gamma_table;
1493   gint width = data-&gt;width * 4;
1494 
1495   for (i = 0; i &lt; width; i += 4) {
1496     d[i + 0] = s[i] &gt;&gt; 8;
1497     d[i + 1] = table[s[i + 1]];
1498     d[i + 2] = table[s[i + 2]];
1499     d[i + 3] = table[s[i + 3]];
1500   }
1501 }
1502 
1503 static void
1504 gamma_convert_u16_u16 (GammaData * data, gpointer dest, gpointer src)
1505 {
1506   gint i;
1507   guint16 *s = src;
1508   guint16 *d = dest;
1509   guint16 *table = data-&gt;gamma_table;
1510   gint width = data-&gt;width * 4;
1511 
1512   for (i = 0; i &lt; width; i += 4) {
1513     d[i + 0] = s[i];
1514     d[i + 1] = table[s[i + 1]];
1515     d[i + 2] = table[s[i + 2]];
1516     d[i + 3] = table[s[i + 3]];
1517   }
1518 }
1519 
1520 static void
1521 setup_gamma_decode (GstVideoConverter * convert)
1522 {
1523   GstVideoTransferFunction func;
1524   guint16 *t;
1525   gint i;
1526 
1527   func = convert-&gt;in_info.colorimetry.transfer;
1528 
1529   convert-&gt;gamma_dec.width = convert-&gt;current_width;
1530   if (convert-&gt;current_bits == 8) {
1531     GST_DEBUG (&quot;gamma decode 8-&gt;16: %d&quot;, func);
1532     convert-&gt;gamma_dec.gamma_func = gamma_convert_u8_u16;
1533     t = convert-&gt;gamma_dec.gamma_table = g_malloc (sizeof (guint16) * 256);
1534 
1535     for (i = 0; i &lt; 256; i++)
1536       t[i] = rint (gst_video_color_transfer_decode (func, i / 255.0) * 65535.0);
1537   } else {
1538     GST_DEBUG (&quot;gamma decode 16-&gt;16: %d&quot;, func);
1539     convert-&gt;gamma_dec.gamma_func = gamma_convert_u16_u16;
1540     t = convert-&gt;gamma_dec.gamma_table = g_malloc (sizeof (guint16) * 65536);
1541 
1542     for (i = 0; i &lt; 65536; i++)
1543       t[i] =
1544           rint (gst_video_color_transfer_decode (func, i / 65535.0) * 65535.0);
1545   }
1546   convert-&gt;current_bits = 16;
1547   convert-&gt;current_pstride = 8;
1548   convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB64;
1549 }
1550 
1551 static void
1552 setup_gamma_encode (GstVideoConverter * convert, gint target_bits)
1553 {
1554   GstVideoTransferFunction func;
1555   gint i;
1556 
1557   func = convert-&gt;out_info.colorimetry.transfer;
1558 
1559   convert-&gt;gamma_enc.width = convert-&gt;current_width;
1560   if (target_bits == 8) {
1561     guint8 *t;
1562 
1563     GST_DEBUG (&quot;gamma encode 16-&gt;8: %d&quot;, func);
1564     convert-&gt;gamma_enc.gamma_func = gamma_convert_u16_u8;
1565     t = convert-&gt;gamma_enc.gamma_table = g_malloc (sizeof (guint8) * 65536);
1566 
1567     for (i = 0; i &lt; 65536; i++)
1568       t[i] = rint (gst_video_color_transfer_encode (func, i / 65535.0) * 255.0);
1569   } else {
1570     guint16 *t;
1571 
1572     GST_DEBUG (&quot;gamma encode 16-&gt;16: %d&quot;, func);
1573     convert-&gt;gamma_enc.gamma_func = gamma_convert_u16_u16;
1574     t = convert-&gt;gamma_enc.gamma_table = g_malloc (sizeof (guint16) * 65536);
1575 
1576     for (i = 0; i &lt; 65536; i++)
1577       t[i] =
1578           rint (gst_video_color_transfer_encode (func, i / 65535.0) * 65535.0);
1579   }
1580 }
1581 
1582 static GstLineCache *
1583 chain_convert_to_RGB (GstVideoConverter * convert, GstLineCache * prev,
1584     gint idx)
1585 {
1586   gboolean do_gamma;
1587 
1588   do_gamma = CHECK_GAMMA_REMAP (convert);
1589 
1590   if (do_gamma) {
1591     gint scale;
1592 
1593     if (!convert-&gt;unpack_rgb) {
1594       color_matrix_set_identity (&amp;convert-&gt;to_RGB_matrix);
1595       compute_matrix_to_RGB (convert, &amp;convert-&gt;to_RGB_matrix);
1596 
1597       /* matrix is in 0..1 range, scale to current bits */
1598       GST_DEBUG (&quot;chain RGB convert&quot;);
1599       scale = 1 &lt;&lt; convert-&gt;current_bits;
1600       color_matrix_scale_components (&amp;convert-&gt;to_RGB_matrix,
1601           (float) scale, (float) scale, (float) scale);
1602 
1603       prepare_matrix (convert, &amp;convert-&gt;to_RGB_matrix);
1604 
1605       if (convert-&gt;current_bits == 8)
1606         convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB;
1607       else
1608         convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB64;
1609     }
1610 
1611     prev = convert-&gt;to_RGB_lines[idx] = gst_line_cache_new (prev);
1612     prev-&gt;write_input = TRUE;
1613     prev-&gt;pass_alloc = FALSE;
1614     prev-&gt;n_lines = 1;
1615     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1616     gst_line_cache_set_need_line_func (prev,
1617         do_convert_to_RGB_lines, idx, convert, NULL);
1618 
1619     GST_DEBUG (&quot;chain gamma decode&quot;);
1620     setup_gamma_decode (convert);
1621   }
1622   return prev;
1623 }
1624 
1625 static GstLineCache *
1626 chain_hscale (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1627 {
1628   gint method;
1629   guint taps;
1630 
1631   method = GET_OPT_RESAMPLER_METHOD (convert);
1632   taps = GET_OPT_RESAMPLER_TAPS (convert);
1633 
1634   convert-&gt;h_scaler[idx] =
1635       gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
1636       convert-&gt;in_width, convert-&gt;out_width, convert-&gt;config);
1637 
1638   gst_video_scaler_get_coeff (convert-&gt;h_scaler[idx], 0, NULL, &amp;taps);
1639 
1640   GST_DEBUG (&quot;chain hscale %d-&gt;%d, taps %d, method %d&quot;,
1641       convert-&gt;in_width, convert-&gt;out_width, taps, method);
1642 
1643   convert-&gt;current_width = convert-&gt;out_width;
1644   convert-&gt;h_scale_format = convert-&gt;current_format;
1645 
1646   prev = convert-&gt;hscale_lines[idx] = gst_line_cache_new (prev);
1647   prev-&gt;write_input = FALSE;
1648   prev-&gt;pass_alloc = FALSE;
1649   prev-&gt;n_lines = 1;
1650   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1651   gst_line_cache_set_need_line_func (prev, do_hscale_lines, idx, convert, NULL);
1652 
1653   return prev;
1654 }
1655 
1656 static GstLineCache *
1657 chain_vscale (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1658 {
1659   gint method;
1660   guint taps, taps_i = 0;
1661   gint backlog = 0;
1662 
1663   method = GET_OPT_RESAMPLER_METHOD (convert);
1664   taps = GET_OPT_RESAMPLER_TAPS (convert);
1665 
1666   if (GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;in_info)) {
1667     convert-&gt;v_scaler_i[idx] =
1668         gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_INTERLACED,
1669         taps, convert-&gt;in_height, convert-&gt;out_height, convert-&gt;config);
1670 
1671     gst_video_scaler_get_coeff (convert-&gt;v_scaler_i[idx], 0, NULL, &amp;taps_i);
1672     backlog = taps_i;
1673   }
1674   convert-&gt;v_scaler_p[idx] =
1675       gst_video_scaler_new (method, 0, taps, convert-&gt;in_height,
1676       convert-&gt;out_height, convert-&gt;config);
1677   convert-&gt;v_scale_width = convert-&gt;current_width;
1678   convert-&gt;v_scale_format = convert-&gt;current_format;
1679   convert-&gt;current_height = convert-&gt;out_height;
1680 
1681   gst_video_scaler_get_coeff (convert-&gt;v_scaler_p[idx], 0, NULL, &amp;taps);
1682 
1683   GST_DEBUG (&quot;chain vscale %d-&gt;%d, taps %d, method %d, backlog %d&quot;,
1684       convert-&gt;in_height, convert-&gt;out_height, taps, method, backlog);
1685 
1686   prev-&gt;backlog = backlog;
1687   prev = convert-&gt;vscale_lines[idx] = gst_line_cache_new (prev);
1688   prev-&gt;pass_alloc = (taps == 1);
1689   prev-&gt;write_input = FALSE;
1690   prev-&gt;n_lines = MAX (taps_i, taps);
1691   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1692   gst_line_cache_set_need_line_func (prev, do_vscale_lines, idx, convert, NULL);
1693 
1694   return prev;
1695 }
1696 
1697 static GstLineCache *
1698 chain_scale (GstVideoConverter * convert, GstLineCache * prev, gboolean force,
1699     gint idx)
1700 {
1701   gint s0, s1, s2, s3;
1702 
1703   s0 = convert-&gt;current_width * convert-&gt;current_height;
1704   s3 = convert-&gt;out_width * convert-&gt;out_height;
1705 
1706   GST_DEBUG (&quot;in pixels %d &lt;&gt; out pixels %d&quot;, s0, s3);
1707 
1708   if (s3 &lt;= s0 || force) {
1709     /* we are making the image smaller or are forced to resample */
1710     s1 = convert-&gt;out_width * convert-&gt;current_height;
1711     s2 = convert-&gt;current_width * convert-&gt;out_height;
1712 
1713     GST_DEBUG (&quot;%d &lt;&gt; %d&quot;, s1, s2);
1714 
1715     if (s1 &lt;= s2) {
1716       /* h scaling first produces less pixels */
1717       if (convert-&gt;current_width != convert-&gt;out_width)
1718         prev = chain_hscale (convert, prev, idx);
1719       if (convert-&gt;current_height != convert-&gt;out_height)
1720         prev = chain_vscale (convert, prev, idx);
1721     } else {
1722       /* v scaling first produces less pixels */
1723       if (convert-&gt;current_height != convert-&gt;out_height)
1724         prev = chain_vscale (convert, prev, idx);
1725       if (convert-&gt;current_width != convert-&gt;out_width)
1726         prev = chain_hscale (convert, prev, idx);
1727     }
1728   }
1729   return prev;
1730 }
1731 
1732 static GstLineCache *
1733 chain_convert (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1734 {
1735   gboolean do_gamma, do_conversion, pass_alloc = FALSE;
1736   gboolean same_matrix, same_primaries, same_bits;
1737   MatrixData p1, p2;
1738 
1739   same_bits = convert-&gt;unpack_bits == convert-&gt;pack_bits;
1740   if (CHECK_MATRIX_NONE (convert)) {
1741     same_matrix = TRUE;
1742   } else {
1743     same_matrix =
1744         convert-&gt;in_info.colorimetry.matrix ==
1745         convert-&gt;out_info.colorimetry.matrix;
1746   }
1747 
1748   if (CHECK_PRIMARIES_NONE (convert)) {
1749     same_primaries = TRUE;
1750   } else {
1751     same_primaries =
1752         convert-&gt;in_info.colorimetry.primaries ==
1753         convert-&gt;out_info.colorimetry.primaries;
1754   }
1755 
1756   GST_DEBUG (&quot;matrix %d -&gt; %d (%d)&quot;, convert-&gt;in_info.colorimetry.matrix,
1757       convert-&gt;out_info.colorimetry.matrix, same_matrix);
1758   GST_DEBUG (&quot;bits %d -&gt; %d (%d)&quot;, convert-&gt;unpack_bits, convert-&gt;pack_bits,
1759       same_bits);
1760   GST_DEBUG (&quot;primaries %d -&gt; %d (%d)&quot;, convert-&gt;in_info.colorimetry.primaries,
1761       convert-&gt;out_info.colorimetry.primaries, same_primaries);
1762 
1763   color_matrix_set_identity (&amp;convert-&gt;convert_matrix);
1764 
1765   if (!same_primaries) {
1766     const GstVideoColorPrimariesInfo *pi;
1767 
1768     pi = gst_video_color_primaries_get_info (convert-&gt;in_info.colorimetry.
1769         primaries);
1770     color_matrix_RGB_to_XYZ (&amp;p1, pi-&gt;Rx, pi-&gt;Ry, pi-&gt;Gx, pi-&gt;Gy, pi-&gt;Bx,
1771         pi-&gt;By, pi-&gt;Wx, pi-&gt;Wy);
1772     GST_DEBUG (&quot;to XYZ matrix&quot;);
1773     color_matrix_debug (&amp;p1);
1774     GST_DEBUG (&quot;current matrix&quot;);
1775     color_matrix_multiply (&amp;convert-&gt;convert_matrix, &amp;convert-&gt;convert_matrix,
1776         &amp;p1);
1777     color_matrix_debug (&amp;convert-&gt;convert_matrix);
1778 
1779     pi = gst_video_color_primaries_get_info (convert-&gt;out_info.colorimetry.
1780         primaries);
1781     color_matrix_RGB_to_XYZ (&amp;p2, pi-&gt;Rx, pi-&gt;Ry, pi-&gt;Gx, pi-&gt;Gy, pi-&gt;Bx,
1782         pi-&gt;By, pi-&gt;Wx, pi-&gt;Wy);
1783     color_matrix_invert (&amp;p2, &amp;p2);
1784     GST_DEBUG (&quot;to RGB matrix&quot;);
1785     color_matrix_debug (&amp;p2);
1786     color_matrix_multiply (&amp;convert-&gt;convert_matrix, &amp;convert-&gt;convert_matrix,
1787         &amp;p2);
1788     GST_DEBUG (&quot;current matrix&quot;);
1789     color_matrix_debug (&amp;convert-&gt;convert_matrix);
1790   }
1791 
1792   do_gamma = CHECK_GAMMA_REMAP (convert);
1793   if (!do_gamma) {
1794 
1795     convert-&gt;in_bits = convert-&gt;unpack_bits;
1796     convert-&gt;out_bits = convert-&gt;pack_bits;
1797 
1798     if (!same_bits || !same_matrix || !same_primaries) {
1799       /* no gamma, combine all conversions into 1 */
1800       if (convert-&gt;in_bits &lt; convert-&gt;out_bits) {
1801         gint scale = 1 &lt;&lt; (convert-&gt;out_bits - convert-&gt;in_bits);
1802         color_matrix_scale_components (&amp;convert-&gt;convert_matrix,
1803             1 / (float) scale, 1 / (float) scale, 1 / (float) scale);
1804       }
1805       GST_DEBUG (&quot;to RGB matrix&quot;);
1806       compute_matrix_to_RGB (convert, &amp;convert-&gt;convert_matrix);
1807       GST_DEBUG (&quot;current matrix&quot;);
1808       color_matrix_debug (&amp;convert-&gt;convert_matrix);
1809 
1810       GST_DEBUG (&quot;to YUV matrix&quot;);
1811       compute_matrix_to_YUV (convert, &amp;convert-&gt;convert_matrix, FALSE);
1812       GST_DEBUG (&quot;current matrix&quot;);
1813       color_matrix_debug (&amp;convert-&gt;convert_matrix);
1814       if (convert-&gt;in_bits &gt; convert-&gt;out_bits) {
1815         gint scale = 1 &lt;&lt; (convert-&gt;in_bits - convert-&gt;out_bits);
1816         color_matrix_scale_components (&amp;convert-&gt;convert_matrix,
1817             (float) scale, (float) scale, (float) scale);
1818       }
1819       convert-&gt;current_bits = MAX (convert-&gt;in_bits, convert-&gt;out_bits);
1820 
1821       do_conversion = TRUE;
1822       if (!same_matrix || !same_primaries)
1823         prepare_matrix (convert, &amp;convert-&gt;convert_matrix);
1824       if (convert-&gt;in_bits == convert-&gt;out_bits)
1825         pass_alloc = TRUE;
1826     } else
1827       do_conversion = FALSE;
1828 
1829     convert-&gt;current_bits = convert-&gt;pack_bits;
1830     convert-&gt;current_format = convert-&gt;pack_format;
1831     convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
1832   } else {
1833     /* we did gamma, just do colorspace conversion if needed */
1834     if (same_primaries) {
1835       do_conversion = FALSE;
1836     } else {
1837       prepare_matrix (convert, &amp;convert-&gt;convert_matrix);
1838       convert-&gt;in_bits = convert-&gt;out_bits = 16;
1839       pass_alloc = TRUE;
1840       do_conversion = TRUE;
1841     }
1842   }
1843 
1844   if (do_conversion) {
1845     GST_DEBUG (&quot;chain conversion&quot;);
1846     prev = convert-&gt;convert_lines[idx] = gst_line_cache_new (prev);
1847     prev-&gt;write_input = TRUE;
1848     prev-&gt;pass_alloc = pass_alloc;
1849     prev-&gt;n_lines = 1;
1850     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1851     gst_line_cache_set_need_line_func (prev,
1852         do_convert_lines, idx, convert, NULL);
1853   }
1854   return prev;
1855 }
1856 
1857 static void
1858 convert_set_alpha_u8 (GstVideoConverter * convert, gpointer pixels, gint width)
1859 {
1860   guint8 *p = pixels;
1861   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
1862   int i;
1863 
1864   for (i = 0; i &lt; width; i++)
1865     p[i * 4] = alpha;
1866 }
1867 
1868 static void
1869 convert_set_alpha_u16 (GstVideoConverter * convert, gpointer pixels, gint width)
1870 {
1871   guint16 *p = pixels;
1872   guint16 alpha;
1873   int i;
1874 
1875   alpha = MIN (convert-&gt;alpha_value, 255);
1876   alpha |= alpha &lt;&lt; 8;
1877 
1878   for (i = 0; i &lt; width; i++)
1879     p[i * 4] = alpha;
1880 }
1881 
1882 static void
1883 convert_mult_alpha_u8 (GstVideoConverter * convert, gpointer pixels, gint width)
1884 {
1885   guint8 *p = pixels;
1886   guint alpha = convert-&gt;alpha_value;
1887   int i;
1888 
1889   for (i = 0; i &lt; width; i++) {
1890     gint a = (p[i * 4] * alpha) / 255;
1891     p[i * 4] = CLAMP (a, 0, 255);
1892   }
1893 }
1894 
1895 static void
1896 convert_mult_alpha_u16 (GstVideoConverter * convert, gpointer pixels,
1897     gint width)
1898 {
1899   guint16 *p = pixels;
1900   guint alpha = convert-&gt;alpha_value;
1901   int i;
1902 
1903   for (i = 0; i &lt; width; i++) {
1904     gint a = (p[i * 4] * alpha) / 255;
1905     p[i * 4] = CLAMP (a, 0, 65535);
1906   }
1907 }
1908 
1909 static GstLineCache *
1910 chain_alpha (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1911 {
1912   switch (convert-&gt;alpha_mode) {
1913     case ALPHA_MODE_NONE:
1914     case ALPHA_MODE_COPY:
1915       return prev;
1916 
1917     case ALPHA_MODE_SET:
1918       if (convert-&gt;current_bits == 8)
1919         convert-&gt;alpha_func = convert_set_alpha_u8;
1920       else
1921         convert-&gt;alpha_func = convert_set_alpha_u16;
1922       break;
1923     case ALPHA_MODE_MULT:
1924       if (convert-&gt;current_bits == 8)
1925         convert-&gt;alpha_func = convert_mult_alpha_u8;
1926       else
1927         convert-&gt;alpha_func = convert_mult_alpha_u16;
1928       break;
1929   }
1930 
1931   GST_DEBUG (&quot;chain alpha mode %d&quot;, convert-&gt;alpha_mode);
1932   prev = convert-&gt;alpha_lines[idx] = gst_line_cache_new (prev);
1933   prev-&gt;write_input = TRUE;
1934   prev-&gt;pass_alloc = TRUE;
1935   prev-&gt;n_lines = 1;
1936   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1937   gst_line_cache_set_need_line_func (prev, do_alpha_lines, idx, convert, NULL);
1938 
1939   return prev;
1940 }
1941 
1942 static GstLineCache *
1943 chain_convert_to_YUV (GstVideoConverter * convert, GstLineCache * prev,
1944     gint idx)
1945 {
1946   gboolean do_gamma;
1947 
1948   do_gamma = CHECK_GAMMA_REMAP (convert);
1949 
1950   if (do_gamma) {
1951     gint scale;
1952 
1953     GST_DEBUG (&quot;chain gamma encode&quot;);
1954     setup_gamma_encode (convert, convert-&gt;pack_bits);
1955 
1956     convert-&gt;current_bits = convert-&gt;pack_bits;
1957     convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
1958 
1959     if (!convert-&gt;pack_rgb) {
1960       color_matrix_set_identity (&amp;convert-&gt;to_YUV_matrix);
1961       compute_matrix_to_YUV (convert, &amp;convert-&gt;to_YUV_matrix, FALSE);
1962 
1963       /* matrix is in 0..255 range, scale to pack bits */
1964       GST_DEBUG (&quot;chain YUV convert&quot;);
1965       scale = 1 &lt;&lt; convert-&gt;pack_bits;
1966       color_matrix_scale_components (&amp;convert-&gt;to_YUV_matrix,
1967           1 / (float) scale, 1 / (float) scale, 1 / (float) scale);
1968       prepare_matrix (convert, &amp;convert-&gt;to_YUV_matrix);
1969     }
1970     convert-&gt;current_format = convert-&gt;pack_format;
1971 
1972     prev = convert-&gt;to_YUV_lines[idx] = gst_line_cache_new (prev);
1973     prev-&gt;write_input = FALSE;
1974     prev-&gt;pass_alloc = FALSE;
1975     prev-&gt;n_lines = 1;
1976     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1977     gst_line_cache_set_need_line_func (prev,
1978         do_convert_to_YUV_lines, idx, convert, NULL);
1979   }
1980 
1981   return prev;
1982 }
1983 
1984 static GstLineCache *
1985 chain_downsample (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1986 {
1987   if (convert-&gt;downsample_p[idx] || convert-&gt;downsample_i[idx]) {
1988     GST_DEBUG (&quot;chain downsample&quot;);
1989     prev = convert-&gt;downsample_lines[idx] = gst_line_cache_new (prev);
1990     prev-&gt;write_input = TRUE;
1991     prev-&gt;pass_alloc = TRUE;
1992     prev-&gt;n_lines = 4;
1993     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1994     gst_line_cache_set_need_line_func (prev,
1995         do_downsample_lines, idx, convert, NULL);
1996   }
1997   return prev;
1998 }
1999 
2000 static GstLineCache *
2001 chain_dither (GstVideoConverter * convert, GstLineCache * prev, gint idx)
2002 {
2003   gint i;
2004   gboolean do_dither = FALSE;
2005   GstVideoDitherFlags flags = 0;
2006   GstVideoDitherMethod method;
2007   guint quant[4], target_quant;
2008 
2009   method = GET_OPT_DITHER_METHOD (convert);
2010   if (method == GST_VIDEO_DITHER_NONE)
2011     return prev;
2012 
2013   target_quant = GET_OPT_DITHER_QUANTIZATION (convert);
2014   GST_DEBUG (&quot;method %d, target-quantization %d&quot;, method, target_quant);
2015 
2016   if (convert-&gt;pack_pal) {
2017     quant[0] = 47;
2018     quant[1] = 47;
2019     quant[2] = 47;
2020     quant[3] = 1;
2021     do_dither = TRUE;
2022   } else {
2023     for (i = 0; i &lt; GST_VIDEO_MAX_COMPONENTS; i++) {
2024       gint depth;
2025 
2026       depth = convert-&gt;out_info.finfo-&gt;depth[i];
2027 
2028       if (depth == 0) {
2029         quant[i] = 0;
2030         continue;
2031       }
2032 
2033       if (convert-&gt;current_bits &gt;= depth) {
2034         quant[i] = 1 &lt;&lt; (convert-&gt;current_bits - depth);
2035         if (target_quant &gt; quant[i]) {
2036           flags |= GST_VIDEO_DITHER_FLAG_QUANTIZE;
2037           quant[i] = target_quant;
2038         }
2039       } else {
2040         quant[i] = 0;
2041       }
2042       if (quant[i] &gt; 1)
2043         do_dither = TRUE;
2044     }
2045   }
2046 
2047   if (do_dither) {
2048     GST_DEBUG (&quot;chain dither&quot;);
2049 
2050     convert-&gt;dither[idx] = gst_video_dither_new (method,
2051         flags, convert-&gt;pack_format, quant, convert-&gt;current_width);
2052 
2053     prev = convert-&gt;dither_lines[idx] = gst_line_cache_new (prev);
2054     prev-&gt;write_input = TRUE;
2055     prev-&gt;pass_alloc = TRUE;
2056     prev-&gt;n_lines = 1;
2057     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
2058     gst_line_cache_set_need_line_func (prev, do_dither_lines, idx, convert,
2059         NULL);
2060   }
2061   return prev;
2062 }
2063 
2064 static GstLineCache *
2065 chain_pack (GstVideoConverter * convert, GstLineCache * prev, gint idx)
2066 {
2067   convert-&gt;pack_nlines = convert-&gt;out_info.finfo-&gt;pack_lines;
2068   convert-&gt;pack_pstride = convert-&gt;current_pstride;
2069   convert-&gt;identity_pack =
2070       (convert-&gt;out_info.finfo-&gt;format ==
2071       convert-&gt;out_info.finfo-&gt;unpack_format);
2072   GST_DEBUG (&quot;chain pack line format %s, pstride %d, identity_pack %d (%d %d)&quot;,
2073       gst_video_format_to_string (convert-&gt;current_format),
2074       convert-&gt;current_pstride, convert-&gt;identity_pack,
2075       convert-&gt;out_info.finfo-&gt;format, convert-&gt;out_info.finfo-&gt;unpack_format);
2076 
2077   return prev;
2078 }
2079 
2080 static void
2081 setup_allocators (GstVideoConverter * convert)
2082 {
<a name="1" id="anc1"></a><span class="line-modified">2083   GstLineCache *cache;</span>
2084   GstLineCacheAllocLineFunc alloc_line;
2085   gboolean alloc_writable;
2086   gpointer user_data;
2087   GDestroyNotify notify;
<a name="2" id="anc2"></a><span class="line-modified">2088   gint width, n_lines;</span>
2089   gint i;
2090 
2091   width = MAX (convert-&gt;in_maxwidth, convert-&gt;out_maxwidth);
2092   width += convert-&gt;out_x;
2093 
2094   for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++) {
<a name="3" id="anc3"></a><span class="line-removed">2095     n_lines = 1;</span>
<span class="line-removed">2096 </span>
2097     /* start with using dest lines if we can directly write into it */
2098     if (convert-&gt;identity_pack) {
2099       alloc_line = get_dest_line;
2100       alloc_writable = TRUE;
2101       user_data = convert;
2102       notify = NULL;
2103     } else {
2104       user_data =
2105           converter_alloc_new (sizeof (guint16) * width * 4, 4 + BACKLOG,
2106           convert, NULL);
2107       setup_border_alloc (convert, user_data);
2108       notify = (GDestroyNotify) converter_alloc_free;
2109       alloc_line = get_border_temp_line;
2110       /* when we add a border, we need to write */
2111       alloc_writable = convert-&gt;borderline != NULL;
2112     }
2113 
<a name="4" id="anc4"></a>












2114     /* now walk backwards, we try to write into the dest lines directly
2115      * and keep track if the source needs to be writable */
2116     for (cache = convert-&gt;pack_lines[i]; cache; cache = cache-&gt;prev) {
2117       gst_line_cache_set_alloc_line_func (cache, alloc_line, user_data, notify);
2118       cache-&gt;alloc_writable = alloc_writable;
<a name="5" id="anc5"></a><span class="line-removed">2119       n_lines = MAX (n_lines, cache-&gt;n_lines);</span>
2120 
2121       /* make sure only one cache frees the allocator */
2122       notify = NULL;
2123 
2124       if (!cache-&gt;pass_alloc) {
2125         /* can&#39;t pass allocator, make new temp line allocator */
2126         user_data =
2127             converter_alloc_new (sizeof (guint16) * width * 4,
<a name="6" id="anc6"></a><span class="line-modified">2128             n_lines + cache-&gt;backlog, convert, NULL);</span>
2129         notify = (GDestroyNotify) converter_alloc_free;
2130         alloc_line = get_temp_line;
2131         alloc_writable = FALSE;
<a name="7" id="anc7"></a><span class="line-removed">2132         n_lines = cache-&gt;n_lines;</span>
2133       }
2134       /* if someone writes to the input, we need a writable line from the
2135        * previous cache */
2136       if (cache-&gt;write_input)
2137         alloc_writable = TRUE;
2138     }
2139     /* free leftover allocator */
2140     if (notify)
2141       notify (user_data);
2142   }
2143 }
2144 
2145 static void
2146 setup_borderline (GstVideoConverter * convert)
2147 {
2148   gint width;
2149 
2150   width = MAX (convert-&gt;in_maxwidth, convert-&gt;out_maxwidth);
2151   width += convert-&gt;out_x;
2152 
2153   if (convert-&gt;fill_border &amp;&amp; (convert-&gt;out_height &lt; convert-&gt;out_maxheight ||
2154           convert-&gt;out_width &lt; convert-&gt;out_maxwidth)) {
2155     guint32 border_val;
2156     gint i, w_sub;
2157     const GstVideoFormatInfo *out_finfo;
2158     gpointer planes[GST_VIDEO_MAX_PLANES];
2159     gint strides[GST_VIDEO_MAX_PLANES];
2160 
2161     convert-&gt;borderline = g_malloc0 (sizeof (guint16) * width * 4);
2162 
2163     out_finfo = convert-&gt;out_info.finfo;
2164 
2165     if (GST_VIDEO_INFO_IS_YUV (&amp;convert-&gt;out_info)) {
2166       MatrixData cm;
2167       gint a, r, g, b;
2168       gint y, u, v;
2169 
2170       /* Get Color matrix. */
2171       color_matrix_set_identity (&amp;cm);
2172       compute_matrix_to_YUV (convert, &amp;cm, TRUE);
2173       color_matrix_convert (&amp;cm);
2174 
2175       border_val = GINT32_FROM_BE (convert-&gt;border_argb);
2176 
2177       b = (0xFF000000 &amp; border_val) &gt;&gt; 24;
2178       g = (0x00FF0000 &amp; border_val) &gt;&gt; 16;
2179       r = (0x0000FF00 &amp; border_val) &gt;&gt; 8;
2180       a = (0x000000FF &amp; border_val);
2181 
2182       y = 16 + ((r * cm.im[0][0] + g * cm.im[0][1] + b * cm.im[0][2]) &gt;&gt; 8);
2183       u = 128 + ((r * cm.im[1][0] + g * cm.im[1][1] + b * cm.im[1][2]) &gt;&gt; 8);
2184       v = 128 + ((r * cm.im[2][0] + g * cm.im[2][1] + b * cm.im[2][2]) &gt;&gt; 8);
2185 
2186       a = CLAMP (a, 0, 255);
2187       y = CLAMP (y, 0, 255);
2188       u = CLAMP (u, 0, 255);
2189       v = CLAMP (v, 0, 255);
2190 
2191       border_val = a | (y &lt;&lt; 8) | (u &lt;&lt; 16) | ((guint32) v &lt;&lt; 24);
2192     } else {
2193       border_val = GINT32_FROM_BE (convert-&gt;border_argb);
2194     }
2195     if (convert-&gt;pack_bits == 8)
2196       video_orc_splat_u32 (convert-&gt;borderline, border_val, width);
2197     else
2198       video_orc_splat2_u64 (convert-&gt;borderline, border_val, width);
2199 
2200     /* convert pixels */
2201     for (i = 0; i &lt; out_finfo-&gt;n_planes; i++) {
2202       planes[i] = &amp;convert-&gt;borders[i];
2203       strides[i] = sizeof (guint64);
2204     }
2205     w_sub = 0;
2206     if (out_finfo-&gt;n_planes == 1) {
2207       /* for packed formats, convert based on subsampling so that we
2208        * get a complete group of pixels */
2209       for (i = 0; i &lt; out_finfo-&gt;n_components; i++) {
2210         w_sub = MAX (w_sub, out_finfo-&gt;w_sub[i]);
2211       }
2212     }
2213     out_finfo-&gt;pack_func (out_finfo, GST_VIDEO_PACK_FLAG_NONE,
2214         convert-&gt;borderline, 0, planes, strides,
2215         GST_VIDEO_CHROMA_SITE_UNKNOWN, 0, 1 &lt;&lt; w_sub);
2216   } else {
2217     convert-&gt;borderline = NULL;
2218   }
2219 }
2220 
2221 static AlphaMode
2222 convert_get_alpha_mode (GstVideoConverter * convert)
2223 {
2224   gboolean in_alpha, out_alpha;
2225 
2226   in_alpha = GST_VIDEO_INFO_HAS_ALPHA (&amp;convert-&gt;in_info);
2227   out_alpha = GST_VIDEO_INFO_HAS_ALPHA (&amp;convert-&gt;out_info);
2228 
2229   /* no output alpha, do nothing */
2230   if (!out_alpha)
2231     return ALPHA_MODE_NONE;
2232 
2233   if (in_alpha) {
2234     /* in and out */
2235     if (CHECK_ALPHA_COPY (convert))
2236       return ALPHA_MODE_COPY;
2237 
2238     if (CHECK_ALPHA_MULT (convert)) {
2239       if (GET_OPT_ALPHA_VALUE (convert) == 1.0)
2240         return ALPHA_MODE_COPY;
2241       else
2242         return ALPHA_MODE_MULT;
2243     }
2244   }
2245   /* nothing special, this is what unpack etc does automatically */
2246   if (GET_OPT_ALPHA_VALUE (convert) == 1.0)
2247     return ALPHA_MODE_NONE;
2248 
2249   /* everything else becomes SET */
2250   return ALPHA_MODE_SET;
2251 }
2252 
2253 /**
2254  * gst_video_converter_new: (skip)
2255  * @in_info: a #GstVideoInfo
2256  * @out_info: a #GstVideoInfo
2257  * @config: (transfer full): a #GstStructure with configuration options
2258  *
2259  * Create a new converter object to convert between @in_info and @out_info
2260  * with @config.
2261  *
2262  * Returns: a #GstVideoConverter or %NULL if conversion is not possible.
2263  *
2264  * Since: 1.6
2265  */
2266 GstVideoConverter *
2267 gst_video_converter_new (GstVideoInfo * in_info, GstVideoInfo * out_info,
2268     GstStructure * config)
2269 {
2270   GstVideoConverter *convert;
2271   GstLineCache *prev;
2272   const GstVideoFormatInfo *fin, *fout, *finfo;
2273   gdouble alpha_value;
2274   gint n_threads, i;
2275 
2276   g_return_val_if_fail (in_info != NULL, NULL);
2277   g_return_val_if_fail (out_info != NULL, NULL);
2278   /* we won&#39;t ever do framerate conversion */
2279   g_return_val_if_fail (in_info-&gt;fps_n == out_info-&gt;fps_n, NULL);
2280   g_return_val_if_fail (in_info-&gt;fps_d == out_info-&gt;fps_d, NULL);
2281   /* we won&#39;t ever do deinterlace */
2282   g_return_val_if_fail (in_info-&gt;interlace_mode == out_info-&gt;interlace_mode,
2283       NULL);
2284 
2285   convert = g_slice_new0 (GstVideoConverter);
2286 
2287   fin = in_info-&gt;finfo;
2288   fout = out_info-&gt;finfo;
2289 
2290   convert-&gt;in_info = *in_info;
2291   convert-&gt;out_info = *out_info;
2292 
2293   /* default config */
2294   convert-&gt;config = gst_structure_new_empty (&quot;GstVideoConverter&quot;);
2295   if (config)
2296     gst_video_converter_set_config (convert, config);
2297 
2298   convert-&gt;in_maxwidth = GST_VIDEO_INFO_WIDTH (in_info);
2299   convert-&gt;in_maxheight = GST_VIDEO_INFO_HEIGHT (in_info);
2300   convert-&gt;out_maxwidth = GST_VIDEO_INFO_WIDTH (out_info);
2301   convert-&gt;out_maxheight = GST_VIDEO_INFO_HEIGHT (out_info);
2302 
2303   convert-&gt;in_x = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_SRC_X, 0);
2304   convert-&gt;in_y = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_SRC_Y, 0);
2305   convert-&gt;in_x &amp;= ~((1 &lt;&lt; fin-&gt;w_sub[1]) - 1);
2306   convert-&gt;in_y &amp;= ~((1 &lt;&lt; fin-&gt;h_sub[1]) - 1);
2307 
2308   convert-&gt;in_width = get_opt_int (convert,
2309       GST_VIDEO_CONVERTER_OPT_SRC_WIDTH, convert-&gt;in_maxwidth - convert-&gt;in_x);
2310   convert-&gt;in_height = get_opt_int (convert,
2311       GST_VIDEO_CONVERTER_OPT_SRC_HEIGHT,
2312       convert-&gt;in_maxheight - convert-&gt;in_y);
2313 
2314   convert-&gt;in_width =
2315       MIN (convert-&gt;in_width, convert-&gt;in_maxwidth - convert-&gt;in_x);
2316   convert-&gt;in_height =
2317       MIN (convert-&gt;in_height, convert-&gt;in_maxheight - convert-&gt;in_y);
2318 
2319   convert-&gt;out_x = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_X, 0);
2320   convert-&gt;out_y = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_Y, 0);
2321   convert-&gt;out_x &amp;= ~((1 &lt;&lt; fout-&gt;w_sub[1]) - 1);
2322   convert-&gt;out_y &amp;= ~((1 &lt;&lt; fout-&gt;h_sub[1]) - 1);
2323 
2324   convert-&gt;out_width = get_opt_int (convert,
2325       GST_VIDEO_CONVERTER_OPT_DEST_WIDTH,
2326       convert-&gt;out_maxwidth - convert-&gt;out_x);
2327   convert-&gt;out_height =
2328       get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_HEIGHT,
2329       convert-&gt;out_maxheight - convert-&gt;out_y);
2330 
2331   convert-&gt;out_width =
2332       MIN (convert-&gt;out_width, convert-&gt;out_maxwidth - convert-&gt;out_x);
2333   convert-&gt;out_height =
2334       MIN (convert-&gt;out_height, convert-&gt;out_maxheight - convert-&gt;out_y);
2335 
2336   convert-&gt;fill_border = GET_OPT_FILL_BORDER (convert);
2337   convert-&gt;border_argb = get_opt_uint (convert,
2338       GST_VIDEO_CONVERTER_OPT_BORDER_ARGB, DEFAULT_OPT_BORDER_ARGB);
2339 
2340   alpha_value = GET_OPT_ALPHA_VALUE (convert);
2341   convert-&gt;alpha_value = 255 * alpha_value;
2342   convert-&gt;alpha_mode = convert_get_alpha_mode (convert);
2343 
2344   convert-&gt;unpack_format = in_info-&gt;finfo-&gt;unpack_format;
2345   finfo = gst_video_format_get_info (convert-&gt;unpack_format);
2346   convert-&gt;unpack_bits = GST_VIDEO_FORMAT_INFO_DEPTH (finfo, 0);
2347   convert-&gt;unpack_rgb = GST_VIDEO_FORMAT_INFO_IS_RGB (finfo);
2348   if (convert-&gt;unpack_rgb
2349       &amp;&amp; in_info-&gt;colorimetry.matrix != GST_VIDEO_COLOR_MATRIX_RGB) {
2350     /* force identity matrix for RGB input */
2351     GST_WARNING (&quot;invalid matrix %d for input RGB format, using RGB&quot;,
2352         in_info-&gt;colorimetry.matrix);
2353     convert-&gt;in_info.colorimetry.matrix = GST_VIDEO_COLOR_MATRIX_RGB;
2354   }
2355 
2356   convert-&gt;pack_format = out_info-&gt;finfo-&gt;unpack_format;
2357   finfo = gst_video_format_get_info (convert-&gt;pack_format);
2358   convert-&gt;pack_bits = GST_VIDEO_FORMAT_INFO_DEPTH (finfo, 0);
2359   convert-&gt;pack_rgb = GST_VIDEO_FORMAT_INFO_IS_RGB (finfo);
2360   convert-&gt;pack_pal =
2361       gst_video_format_get_palette (GST_VIDEO_INFO_FORMAT (out_info),
2362       &amp;convert-&gt;pack_palsize);
2363   if (convert-&gt;pack_rgb
2364       &amp;&amp; out_info-&gt;colorimetry.matrix != GST_VIDEO_COLOR_MATRIX_RGB) {
2365     /* force identity matrix for RGB output */
2366     GST_WARNING (&quot;invalid matrix %d for output RGB format, using RGB&quot;,
2367         out_info-&gt;colorimetry.matrix);
2368     convert-&gt;out_info.colorimetry.matrix = GST_VIDEO_COLOR_MATRIX_RGB;
2369   }
2370 
2371   n_threads = get_opt_uint (convert, GST_VIDEO_CONVERTER_OPT_THREADS, 1);
2372   if (n_threads == 0 || n_threads &gt; g_get_num_processors ())
2373     n_threads = g_get_num_processors ();
2374   /* Magic number of 200 lines */
2375   if (MAX (convert-&gt;out_height, convert-&gt;in_height) / n_threads &lt; 200)
2376     n_threads = (MAX (convert-&gt;out_height, convert-&gt;in_height) + 199) / 200;
2377   convert-&gt;conversion_runner = gst_parallelized_task_runner_new (n_threads);
2378 
2379   if (video_converter_lookup_fastpath (convert))
2380     goto done;
2381 
2382   if (in_info-&gt;finfo-&gt;unpack_func == NULL)
2383     goto no_unpack_func;
2384 
2385   if (out_info-&gt;finfo-&gt;pack_func == NULL)
2386     goto no_pack_func;
2387 
2388   convert-&gt;convert = video_converter_generic;
2389 
2390   convert-&gt;upsample_p = g_new0 (GstVideoChromaResample *, n_threads);
2391   convert-&gt;upsample_i = g_new0 (GstVideoChromaResample *, n_threads);
2392   convert-&gt;downsample_p = g_new0 (GstVideoChromaResample *, n_threads);
2393   convert-&gt;downsample_i = g_new0 (GstVideoChromaResample *, n_threads);
2394   convert-&gt;v_scaler_p = g_new0 (GstVideoScaler *, n_threads);
2395   convert-&gt;v_scaler_i = g_new0 (GstVideoScaler *, n_threads);
2396   convert-&gt;h_scaler = g_new0 (GstVideoScaler *, n_threads);
2397   convert-&gt;unpack_lines = g_new0 (GstLineCache *, n_threads);
2398   convert-&gt;pack_lines = g_new0 (GstLineCache *, n_threads);
2399   convert-&gt;upsample_lines = g_new0 (GstLineCache *, n_threads);
2400   convert-&gt;to_RGB_lines = g_new0 (GstLineCache *, n_threads);
2401   convert-&gt;hscale_lines = g_new0 (GstLineCache *, n_threads);
2402   convert-&gt;vscale_lines = g_new0 (GstLineCache *, n_threads);
2403   convert-&gt;convert_lines = g_new0 (GstLineCache *, n_threads);
2404   convert-&gt;alpha_lines = g_new0 (GstLineCache *, n_threads);
2405   convert-&gt;to_YUV_lines = g_new0 (GstLineCache *, n_threads);
2406   convert-&gt;downsample_lines = g_new0 (GstLineCache *, n_threads);
2407   convert-&gt;dither_lines = g_new0 (GstLineCache *, n_threads);
2408   convert-&gt;dither = g_new0 (GstVideoDither *, n_threads);
2409 
2410   for (i = 0; i &lt; n_threads; i++) {
2411     convert-&gt;current_format = GST_VIDEO_INFO_FORMAT (in_info);
2412     convert-&gt;current_width = convert-&gt;in_width;
2413     convert-&gt;current_height = convert-&gt;in_height;
2414 
2415     /* unpack */
2416     prev = chain_unpack_line (convert, i);
2417     /* upsample chroma */
2418     prev = chain_upsample (convert, prev, i);
2419     /* convert to gamma decoded RGB */
2420     prev = chain_convert_to_RGB (convert, prev, i);
2421     /* do all downscaling */
2422     prev = chain_scale (convert, prev, FALSE, i);
2423     /* do conversion between color spaces */
2424     prev = chain_convert (convert, prev, i);
2425     /* do alpha channels */
2426     prev = chain_alpha (convert, prev, i);
2427     /* do all remaining (up)scaling */
2428     prev = chain_scale (convert, prev, TRUE, i);
2429     /* convert to gamma encoded Y&#39;Cb&#39;Cr&#39; */
2430     prev = chain_convert_to_YUV (convert, prev, i);
2431     /* downsample chroma */
2432     prev = chain_downsample (convert, prev, i);
2433     /* dither */
2434     prev = chain_dither (convert, prev, i);
2435     /* pack into final format */
2436     convert-&gt;pack_lines[i] = chain_pack (convert, prev, i);
2437   }
2438 
2439   setup_borderline (convert);
2440   /* now figure out allocators */
2441   setup_allocators (convert);
2442 
2443 done:
2444   return convert;
2445 
2446   /* ERRORS */
2447 no_unpack_func:
2448   {
2449     GST_ERROR (&quot;no unpack_func for format %s&quot;,
2450         gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (in_info)));
2451     gst_video_converter_free (convert);
2452     return NULL;
2453   }
2454 no_pack_func:
2455   {
2456     GST_ERROR (&quot;no pack_func for format %s&quot;,
2457         gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (out_info)));
2458     gst_video_converter_free (convert);
2459     return NULL;
2460   }
2461 }
2462 
2463 static void
2464 clear_matrix_data (MatrixData * data)
2465 {
2466   g_free (data-&gt;t_r);
2467   g_free (data-&gt;t_g);
2468   g_free (data-&gt;t_b);
2469 }
2470 
2471 /**
2472  * gst_video_converter_free:
2473  * @convert: a #GstVideoConverter
2474  *
2475  * Free @convert
2476  *
2477  * Since: 1.6
2478  */
2479 void
2480 gst_video_converter_free (GstVideoConverter * convert)
2481 {
2482   guint i, j;
2483 
2484   g_return_if_fail (convert != NULL);
2485 
2486   for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++) {
2487     if (convert-&gt;upsample_p &amp;&amp; convert-&gt;upsample_p[i])
2488       gst_video_chroma_resample_free (convert-&gt;upsample_p[i]);
2489     if (convert-&gt;upsample_i &amp;&amp; convert-&gt;upsample_i[i])
2490       gst_video_chroma_resample_free (convert-&gt;upsample_i[i]);
2491     if (convert-&gt;downsample_p &amp;&amp; convert-&gt;downsample_p[i])
2492       gst_video_chroma_resample_free (convert-&gt;downsample_p[i]);
2493     if (convert-&gt;downsample_i &amp;&amp; convert-&gt;downsample_i[i])
2494       gst_video_chroma_resample_free (convert-&gt;downsample_i[i]);
2495     if (convert-&gt;v_scaler_p &amp;&amp; convert-&gt;v_scaler_p[i])
2496       gst_video_scaler_free (convert-&gt;v_scaler_p[i]);
2497     if (convert-&gt;v_scaler_i &amp;&amp; convert-&gt;v_scaler_i[i])
2498       gst_video_scaler_free (convert-&gt;v_scaler_i[i]);
2499     if (convert-&gt;h_scaler &amp;&amp; convert-&gt;h_scaler[i])
2500       gst_video_scaler_free (convert-&gt;h_scaler[i]);
2501     if (convert-&gt;unpack_lines &amp;&amp; convert-&gt;unpack_lines[i])
2502       gst_line_cache_free (convert-&gt;unpack_lines[i]);
2503     if (convert-&gt;upsample_lines &amp;&amp; convert-&gt;upsample_lines[i])
2504       gst_line_cache_free (convert-&gt;upsample_lines[i]);
2505     if (convert-&gt;to_RGB_lines &amp;&amp; convert-&gt;to_RGB_lines[i])
2506       gst_line_cache_free (convert-&gt;to_RGB_lines[i]);
2507     if (convert-&gt;hscale_lines &amp;&amp; convert-&gt;hscale_lines[i])
2508       gst_line_cache_free (convert-&gt;hscale_lines[i]);
2509     if (convert-&gt;vscale_lines &amp;&amp; convert-&gt;vscale_lines[i])
2510       gst_line_cache_free (convert-&gt;vscale_lines[i]);
2511     if (convert-&gt;convert_lines &amp;&amp; convert-&gt;convert_lines[i])
2512       gst_line_cache_free (convert-&gt;convert_lines[i]);
2513     if (convert-&gt;alpha_lines &amp;&amp; convert-&gt;alpha_lines[i])
2514       gst_line_cache_free (convert-&gt;alpha_lines[i]);
2515     if (convert-&gt;to_YUV_lines &amp;&amp; convert-&gt;to_YUV_lines[i])
2516       gst_line_cache_free (convert-&gt;to_YUV_lines[i]);
2517     if (convert-&gt;downsample_lines &amp;&amp; convert-&gt;downsample_lines[i])
2518       gst_line_cache_free (convert-&gt;downsample_lines[i]);
2519     if (convert-&gt;dither_lines &amp;&amp; convert-&gt;dither_lines[i])
2520       gst_line_cache_free (convert-&gt;dither_lines[i]);
2521     if (convert-&gt;dither &amp;&amp; convert-&gt;dither[i])
2522       gst_video_dither_free (convert-&gt;dither[i]);
2523   }
2524   g_free (convert-&gt;upsample_p);
2525   g_free (convert-&gt;upsample_i);
2526   g_free (convert-&gt;downsample_p);
2527   g_free (convert-&gt;downsample_i);
2528   g_free (convert-&gt;v_scaler_p);
2529   g_free (convert-&gt;v_scaler_i);
2530   g_free (convert-&gt;h_scaler);
2531   g_free (convert-&gt;unpack_lines);
2532   g_free (convert-&gt;pack_lines);
2533   g_free (convert-&gt;upsample_lines);
2534   g_free (convert-&gt;to_RGB_lines);
2535   g_free (convert-&gt;hscale_lines);
2536   g_free (convert-&gt;vscale_lines);
2537   g_free (convert-&gt;convert_lines);
2538   g_free (convert-&gt;alpha_lines);
2539   g_free (convert-&gt;to_YUV_lines);
2540   g_free (convert-&gt;downsample_lines);
2541   g_free (convert-&gt;dither_lines);
2542   g_free (convert-&gt;dither);
2543 
2544   g_free (convert-&gt;gamma_dec.gamma_table);
2545   g_free (convert-&gt;gamma_enc.gamma_table);
2546 
2547   if (convert-&gt;tmpline) {
2548     for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++)
2549       g_free (convert-&gt;tmpline[i]);
2550     g_free (convert-&gt;tmpline);
2551   }
2552 
2553   g_free (convert-&gt;borderline);
2554 
2555   if (convert-&gt;config)
2556     gst_structure_free (convert-&gt;config);
2557 
2558   for (i = 0; i &lt; 4; i++) {
2559     for (j = 0; j &lt; convert-&gt;conversion_runner-&gt;n_threads; j++) {
2560       if (convert-&gt;fv_scaler[i].scaler)
2561         gst_video_scaler_free (convert-&gt;fv_scaler[i].scaler[j]);
2562       if (convert-&gt;fh_scaler[i].scaler)
2563         gst_video_scaler_free (convert-&gt;fh_scaler[i].scaler[j]);
2564     }
2565     g_free (convert-&gt;fv_scaler[i].scaler);
2566     g_free (convert-&gt;fh_scaler[i].scaler);
2567   }
2568 
2569   if (convert-&gt;conversion_runner)
2570     gst_parallelized_task_runner_free (convert-&gt;conversion_runner);
2571 
2572   clear_matrix_data (&amp;convert-&gt;to_RGB_matrix);
2573   clear_matrix_data (&amp;convert-&gt;convert_matrix);
2574   clear_matrix_data (&amp;convert-&gt;to_YUV_matrix);
2575 
2576   g_slice_free (GstVideoConverter, convert);
2577 }
2578 
2579 static gboolean
2580 copy_config (GQuark field_id, const GValue * value, gpointer user_data)
2581 {
2582   GstVideoConverter *convert = user_data;
2583 
2584   gst_structure_id_set_value (convert-&gt;config, field_id, value);
2585 
2586   return TRUE;
2587 }
2588 
2589 /**
2590  * gst_video_converter_set_config:
2591  * @convert: a #GstVideoConverter
2592  * @config: (transfer full): a #GstStructure
2593  *
2594  * Set @config as extra configuraion for @convert.
2595  *
2596  * If the parameters in @config can not be set exactly, this function returns
2597  * %FALSE and will try to update as much state as possible. The new state can
2598  * then be retrieved and refined with gst_video_converter_get_config().
2599  *
2600  * Look at the #GST_VIDEO_CONVERTER_OPT_* fields to check valid configuration
2601  * option and values.
2602  *
2603  * Returns: %TRUE when @config could be set.
2604  *
2605  * Since: 1.6
2606  */
2607 gboolean
2608 gst_video_converter_set_config (GstVideoConverter * convert,
2609     GstStructure * config)
2610 {
2611   g_return_val_if_fail (convert != NULL, FALSE);
2612   g_return_val_if_fail (config != NULL, FALSE);
2613 
2614   gst_structure_foreach (config, copy_config, convert);
2615   gst_structure_free (config);
2616 
2617   return TRUE;
2618 }
2619 
2620 /**
2621  * gst_video_converter_get_config:
2622  * @convert: a #GstVideoConverter
2623  *
2624  * Get the current configuration of @convert.
2625  *
2626  * Returns: a #GstStructure that remains valid for as long as @convert is valid
2627  *   or until gst_video_converter_set_config() is called.
2628  */
2629 const GstStructure *
2630 gst_video_converter_get_config (GstVideoConverter * convert)
2631 {
2632   g_return_val_if_fail (convert != NULL, NULL);
2633 
2634   return convert-&gt;config;
2635 }
2636 
2637 /**
2638  * gst_video_converter_frame:
2639  * @convert: a #GstVideoConverter
2640  * @dest: a #GstVideoFrame
2641  * @src: a #GstVideoFrame
2642  *
2643  * Convert the pixels of @src into @dest using @convert.
2644  *
2645  * Since: 1.6
2646  */
2647 void
2648 gst_video_converter_frame (GstVideoConverter * convert,
2649     const GstVideoFrame * src, GstVideoFrame * dest)
2650 {
2651   g_return_if_fail (convert != NULL);
2652   g_return_if_fail (src != NULL);
2653   g_return_if_fail (dest != NULL);
2654 
2655   convert-&gt;convert (convert, src, dest);
2656 }
2657 
2658 static void
2659 video_converter_compute_matrix (GstVideoConverter * convert)
2660 {
2661   MatrixData *dst = &amp;convert-&gt;convert_matrix;
2662 
2663   color_matrix_set_identity (dst);
2664   compute_matrix_to_RGB (convert, dst);
2665   compute_matrix_to_YUV (convert, dst, FALSE);
2666 
2667   convert-&gt;current_bits = 8;
2668   prepare_matrix (convert, dst);
2669 }
2670 
2671 static void
2672 video_converter_compute_resample (GstVideoConverter * convert, gint idx)
2673 {
2674   GstVideoInfo *in_info, *out_info;
2675   const GstVideoFormatInfo *sfinfo, *dfinfo;
2676 
2677   if (CHECK_CHROMA_NONE (convert))
2678     return;
2679 
2680   in_info = &amp;convert-&gt;in_info;
2681   out_info = &amp;convert-&gt;out_info;
2682 
2683   sfinfo = in_info-&gt;finfo;
2684   dfinfo = out_info-&gt;finfo;
2685 
2686   GST_DEBUG (&quot;site: %d-&gt;%d, w_sub: %d-&gt;%d, h_sub: %d-&gt;%d&quot;, in_info-&gt;chroma_site,
2687       out_info-&gt;chroma_site, sfinfo-&gt;w_sub[2], dfinfo-&gt;w_sub[2],
2688       sfinfo-&gt;h_sub[2], dfinfo-&gt;h_sub[2]);
2689 
2690   if (sfinfo-&gt;w_sub[2] != dfinfo-&gt;w_sub[2] ||
2691       sfinfo-&gt;h_sub[2] != dfinfo-&gt;h_sub[2] ||
2692       in_info-&gt;chroma_site != out_info-&gt;chroma_site ||
2693       in_info-&gt;width != out_info-&gt;width ||
2694       in_info-&gt;height != out_info-&gt;height) {
2695     if (GST_VIDEO_INFO_IS_INTERLACED (in_info)) {
2696       if (!CHECK_CHROMA_DOWNSAMPLE (convert))
2697         convert-&gt;upsample_i[idx] = gst_video_chroma_resample_new (0,
2698             in_info-&gt;chroma_site, GST_VIDEO_CHROMA_FLAG_INTERLACED,
2699             sfinfo-&gt;unpack_format, sfinfo-&gt;w_sub[2], sfinfo-&gt;h_sub[2]);
2700       if (!CHECK_CHROMA_UPSAMPLE (convert))
2701         convert-&gt;downsample_i[idx] =
2702             gst_video_chroma_resample_new (0, out_info-&gt;chroma_site,
2703             GST_VIDEO_CHROMA_FLAG_INTERLACED, dfinfo-&gt;unpack_format,
2704             -dfinfo-&gt;w_sub[2], -dfinfo-&gt;h_sub[2]);
2705     }
2706     if (!CHECK_CHROMA_DOWNSAMPLE (convert))
2707       convert-&gt;upsample_p[idx] = gst_video_chroma_resample_new (0,
2708           in_info-&gt;chroma_site, 0, sfinfo-&gt;unpack_format, sfinfo-&gt;w_sub[2],
2709           sfinfo-&gt;h_sub[2]);
2710     if (!CHECK_CHROMA_UPSAMPLE (convert))
2711       convert-&gt;downsample_p[idx] = gst_video_chroma_resample_new (0,
2712           out_info-&gt;chroma_site, 0, dfinfo-&gt;unpack_format, -dfinfo-&gt;w_sub[2],
2713           -dfinfo-&gt;h_sub[2]);
2714   }
2715 }
2716 
2717 #define FRAME_GET_PLANE_STRIDE(frame, plane) \
2718   GST_VIDEO_FRAME_PLANE_STRIDE (frame, plane)
2719 #define FRAME_GET_PLANE_LINE(frame, plane, line) \
2720   (gpointer)(((guint8*)(GST_VIDEO_FRAME_PLANE_DATA (frame, plane))) + \
2721       FRAME_GET_PLANE_STRIDE (frame, plane) * (line))
2722 
2723 #define FRAME_GET_COMP_STRIDE(frame, comp) \
2724   GST_VIDEO_FRAME_COMP_STRIDE (frame, comp)
2725 #define FRAME_GET_COMP_LINE(frame, comp, line) \
2726   (gpointer)(((guint8*)(GST_VIDEO_FRAME_COMP_DATA (frame, comp))) + \
2727       FRAME_GET_COMP_STRIDE (frame, comp) * (line))
2728 
2729 #define FRAME_GET_STRIDE(frame)      FRAME_GET_PLANE_STRIDE (frame, 0)
2730 #define FRAME_GET_LINE(frame,line)   FRAME_GET_PLANE_LINE (frame, 0, line)
2731 
2732 #define FRAME_GET_Y_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_Y, line)
2733 #define FRAME_GET_U_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_U, line)
2734 #define FRAME_GET_V_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_V, line)
2735 #define FRAME_GET_A_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_A, line)
2736 
2737 #define FRAME_GET_Y_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_Y)
2738 #define FRAME_GET_U_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_U)
2739 #define FRAME_GET_V_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_V)
2740 #define FRAME_GET_A_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_A)
2741 
2742 
2743 #define UNPACK_FRAME(frame,dest,line,x,width)        \
2744   frame-&gt;info.finfo-&gt;unpack_func (frame-&gt;info.finfo, \
2745       (GST_VIDEO_FRAME_IS_INTERLACED (frame) ?       \
2746         GST_VIDEO_PACK_FLAG_INTERLACED :             \
2747         GST_VIDEO_PACK_FLAG_NONE),                   \
2748       dest, frame-&gt;data, frame-&gt;info.stride, x,      \
2749       line, width)
2750 #define PACK_FRAME(frame,src,line,width)             \
2751   frame-&gt;info.finfo-&gt;pack_func (frame-&gt;info.finfo,   \
2752       (GST_VIDEO_FRAME_IS_INTERLACED (frame) ?       \
2753         GST_VIDEO_PACK_FLAG_INTERLACED :             \
2754         GST_VIDEO_PACK_FLAG_NONE),                   \
2755       src, 0, frame-&gt;data, frame-&gt;info.stride,       \
2756       frame-&gt;info.chroma_site, line, width);
2757 
2758 static gpointer
2759 get_dest_line (GstLineCache * cache, gint idx, gpointer user_data)
2760 {
2761   GstVideoConverter *convert = user_data;
2762   guint8 *line;
2763   gint pstride = convert-&gt;pack_pstride;
2764   gint out_x = convert-&gt;out_x;
2765   guint cline;
2766 
2767   cline = CLAMP (idx, 0, convert-&gt;out_maxheight - 1);
2768 
2769   line = FRAME_GET_LINE (convert-&gt;dest, cline);
2770   GST_DEBUG (&quot;get dest line %d %p&quot;, cline, line);
2771 
2772   if (convert-&gt;borderline) {
2773     gint r_border = (out_x + convert-&gt;out_width) * pstride;
2774     gint rb_width = convert-&gt;out_maxwidth * pstride - r_border;
2775     gint lb_width = out_x * pstride;
2776 
2777     memcpy (line, convert-&gt;borderline, lb_width);
2778     memcpy (line + r_border, convert-&gt;borderline, rb_width);
2779   }
2780   line += out_x * pstride;
2781 
2782   return line;
2783 }
2784 
2785 static gboolean
2786 do_unpack_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2787     gpointer user_data)
2788 {
2789   GstVideoConverter *convert = user_data;
2790   gpointer tmpline;
2791   guint cline;
2792 
2793   cline = CLAMP (in_line + convert-&gt;in_y, 0, convert-&gt;in_maxheight - 1);
2794 
2795   if (cache-&gt;alloc_writable || !convert-&gt;identity_unpack) {
2796     tmpline = gst_line_cache_alloc_line (cache, out_line);
2797     GST_DEBUG (&quot;unpack line %d (%u) %p&quot;, in_line, cline, tmpline);
2798     UNPACK_FRAME (convert-&gt;src, tmpline, cline, convert-&gt;in_x,
2799         convert-&gt;in_width);
2800   } else {
2801     tmpline = ((guint8 *) FRAME_GET_LINE (convert-&gt;src, cline)) +
2802         convert-&gt;in_x * convert-&gt;unpack_pstride;
2803     GST_DEBUG (&quot;get src line %d (%u) %p&quot;, in_line, cline, tmpline);
2804   }
2805   gst_line_cache_add_line (cache, in_line, tmpline);
2806 
2807   return TRUE;
2808 }
2809 
2810 static gboolean
2811 do_upsample_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2812     gpointer user_data)
2813 {
2814   GstVideoConverter *convert = user_data;
2815   gpointer *lines;
2816   gint i, start_line, n_lines;
2817 
2818   n_lines = convert-&gt;up_n_lines;
2819   start_line = in_line;
2820   if (start_line &lt; n_lines + convert-&gt;up_offset) {
2821     start_line += convert-&gt;up_offset;
2822     out_line += convert-&gt;up_offset;
2823   }
2824 
2825   /* get the lines needed for chroma upsample */
2826   lines =
2827       gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, start_line,
2828       n_lines);
2829 
2830   if (convert-&gt;upsample) {
2831     GST_DEBUG (&quot;doing upsample %d-%d %p&quot;, start_line, start_line + n_lines - 1,
2832         lines[0]);
2833     gst_video_chroma_resample (convert-&gt;upsample[idx], lines,
2834         convert-&gt;in_width);
2835   }
2836 
2837   for (i = 0; i &lt; n_lines; i++)
2838     gst_line_cache_add_line (cache, start_line + i, lines[i]);
2839 
2840   return TRUE;
2841 }
2842 
2843 static gboolean
2844 do_convert_to_RGB_lines (GstLineCache * cache, gint idx, gint out_line,
2845     gint in_line, gpointer user_data)
2846 {
2847   GstVideoConverter *convert = user_data;
2848   MatrixData *data = &amp;convert-&gt;to_RGB_matrix;
2849   gpointer *lines, destline;
2850 
2851   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2852   destline = lines[0];
2853 
2854   if (data-&gt;matrix_func) {
2855     GST_DEBUG (&quot;to RGB line %d %p&quot;, in_line, destline);
2856     data-&gt;matrix_func (data, destline);
2857   }
2858   if (convert-&gt;gamma_dec.gamma_func) {
2859     destline = gst_line_cache_alloc_line (cache, out_line);
2860 
2861     GST_DEBUG (&quot;gamma decode line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
2862     convert-&gt;gamma_dec.gamma_func (&amp;convert-&gt;gamma_dec, destline, lines[0]);
2863   }
2864   gst_line_cache_add_line (cache, in_line, destline);
2865 
2866   return TRUE;
2867 }
2868 
2869 static gboolean
2870 do_hscale_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2871     gpointer user_data)
2872 {
2873   GstVideoConverter *convert = user_data;
2874   gpointer *lines, destline;
2875 
2876   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2877 
2878   destline = gst_line_cache_alloc_line (cache, out_line);
2879 
2880   GST_DEBUG (&quot;hresample line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
2881   gst_video_scaler_horizontal (convert-&gt;h_scaler[idx], convert-&gt;h_scale_format,
2882       lines[0], destline, 0, convert-&gt;out_width);
2883 
2884   gst_line_cache_add_line (cache, in_line, destline);
2885 
2886   return TRUE;
2887 }
2888 
2889 static gboolean
2890 do_vscale_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2891     gpointer user_data)
2892 {
2893   GstVideoConverter *convert = user_data;
2894   gpointer *lines, destline;
2895   guint sline, n_lines;
2896   guint cline;
2897 
2898   cline = CLAMP (in_line, 0, convert-&gt;out_height - 1);
2899 
2900   gst_video_scaler_get_coeff (convert-&gt;v_scaler[idx], cline, &amp;sline, &amp;n_lines);
2901   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, sline, n_lines);
2902 
2903   destline = gst_line_cache_alloc_line (cache, out_line);
2904 
2905   GST_DEBUG (&quot;vresample line %d %d-%d %p-&gt;%p&quot;, in_line, sline,
2906       sline + n_lines - 1, lines[0], destline);
2907   gst_video_scaler_vertical (convert-&gt;v_scaler[idx], convert-&gt;v_scale_format,
2908       lines, destline, cline, convert-&gt;v_scale_width);
2909 
2910   gst_line_cache_add_line (cache, in_line, destline);
2911 
2912   return TRUE;
2913 }
2914 
2915 static gboolean
2916 do_convert_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2917     gpointer user_data)
2918 {
2919   GstVideoConverter *convert = user_data;
2920   MatrixData *data = &amp;convert-&gt;convert_matrix;
2921   gpointer *lines, destline;
2922   guint in_bits, out_bits;
2923   gint width;
2924 
2925   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2926 
2927   destline = lines[0];
2928 
2929   in_bits = convert-&gt;in_bits;
2930   out_bits = convert-&gt;out_bits;
2931 
2932   width = MIN (convert-&gt;in_width, convert-&gt;out_width);
2933 
2934   if (out_bits == 16 || in_bits == 16) {
2935     gpointer srcline = lines[0];
2936 
2937     if (out_bits != in_bits)
2938       destline = gst_line_cache_alloc_line (cache, out_line);
2939 
2940     /* FIXME, we can scale in the conversion matrix */
2941     if (in_bits == 8) {
2942       GST_DEBUG (&quot;8-&gt;16 line %d %p-&gt;%p&quot;, in_line, srcline, destline);
2943       video_orc_convert_u8_to_u16 (destline, srcline, width * 4);
2944       srcline = destline;
2945     }
2946 
2947     if (data-&gt;matrix_func) {
2948       GST_DEBUG (&quot;matrix line %d %p&quot;, in_line, srcline);
2949       data-&gt;matrix_func (data, srcline);
2950     }
2951 
2952     /* FIXME, dither here */
2953     if (out_bits == 8) {
2954       GST_DEBUG (&quot;16-&gt;8 line %d %p-&gt;%p&quot;, in_line, srcline, destline);
2955       video_orc_convert_u16_to_u8 (destline, srcline, width * 4);
2956     }
2957   } else {
2958     if (data-&gt;matrix_func) {
2959       GST_DEBUG (&quot;matrix line %d %p&quot;, in_line, destline);
2960       data-&gt;matrix_func (data, destline);
2961     }
2962   }
2963   gst_line_cache_add_line (cache, in_line, destline);
2964 
2965   return TRUE;
2966 }
2967 
2968 static gboolean
2969 do_alpha_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2970     gpointer user_data)
2971 {
2972   gpointer *lines, destline;
2973   GstVideoConverter *convert = user_data;
2974   gint width = MIN (convert-&gt;in_width, convert-&gt;out_width);
2975 
2976   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2977   destline = lines[0];
2978 
2979   GST_DEBUG (&quot;alpha line %d %p&quot;, in_line, destline);
2980   convert-&gt;alpha_func (convert, destline, width);
2981 
2982   gst_line_cache_add_line (cache, in_line, destline);
2983 
2984   return TRUE;
2985 }
2986 
2987 static gboolean
2988 do_convert_to_YUV_lines (GstLineCache * cache, gint idx, gint out_line,
2989     gint in_line, gpointer user_data)
2990 {
2991   GstVideoConverter *convert = user_data;
2992   MatrixData *data = &amp;convert-&gt;to_YUV_matrix;
2993   gpointer *lines, destline;
2994 
2995   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2996   destline = lines[0];
2997 
2998   if (convert-&gt;gamma_enc.gamma_func) {
2999     destline = gst_line_cache_alloc_line (cache, out_line);
3000 
3001     GST_DEBUG (&quot;gamma encode line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
3002     convert-&gt;gamma_enc.gamma_func (&amp;convert-&gt;gamma_enc, destline, lines[0]);
3003   }
3004   if (data-&gt;matrix_func) {
3005     GST_DEBUG (&quot;to YUV line %d %p&quot;, in_line, destline);
3006     data-&gt;matrix_func (data, destline);
3007   }
3008   gst_line_cache_add_line (cache, in_line, destline);
3009 
3010   return TRUE;
3011 }
3012 
3013 static gboolean
3014 do_downsample_lines (GstLineCache * cache, gint idx, gint out_line,
3015     gint in_line, gpointer user_data)
3016 {
3017   GstVideoConverter *convert = user_data;
3018   gpointer *lines;
3019   gint i, start_line, n_lines;
3020 
3021   n_lines = convert-&gt;down_n_lines;
3022   start_line = in_line;
3023   if (start_line &lt; n_lines + convert-&gt;down_offset)
3024     start_line += convert-&gt;down_offset;
3025 
3026   /* get the lines needed for chroma downsample */
3027   lines =
3028       gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, start_line,
3029       n_lines);
3030 
3031   if (convert-&gt;downsample) {
3032     GST_DEBUG (&quot;downsample line %d %d-%d %p&quot;, in_line, start_line,
3033         start_line + n_lines - 1, lines[0]);
3034     gst_video_chroma_resample (convert-&gt;downsample[idx], lines,
3035         convert-&gt;out_width);
3036   }
3037 
3038   for (i = 0; i &lt; n_lines; i++)
3039     gst_line_cache_add_line (cache, start_line + i, lines[i]);
3040 
3041   return TRUE;
3042 }
3043 
3044 static gboolean
3045 do_dither_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
3046     gpointer user_data)
3047 {
3048   GstVideoConverter *convert = user_data;
3049   gpointer *lines, destline;
3050 
3051   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
3052   destline = lines[0];
3053 
3054   if (convert-&gt;dither) {
3055     GST_DEBUG (&quot;Dither line %d %p&quot;, in_line, destline);
3056     gst_video_dither_line (convert-&gt;dither[idx], destline, 0, out_line,
3057         convert-&gt;out_width);
3058   }
3059   gst_line_cache_add_line (cache, in_line, destline);
3060 
3061   return TRUE;
3062 }
3063 
3064 typedef struct
3065 {
3066   GstLineCache *pack_lines;
3067   gint idx;
3068   gint h_0, h_1;
3069   gint pack_lines_count;
3070   gint out_y;
3071   gboolean identity_pack;
3072   gint lb_width, out_maxwidth;
3073   GstVideoFrame *dest;
3074 } ConvertTask;
3075 
3076 static void
3077 convert_generic_task (ConvertTask * task)
3078 {
3079   gint i;
3080 
3081   for (i = task-&gt;h_0; i &lt; task-&gt;h_1; i += task-&gt;pack_lines_count) {
3082     gpointer *lines;
3083 
3084     /* load the lines needed to pack */
3085     lines =
3086         gst_line_cache_get_lines (task-&gt;pack_lines, task-&gt;idx, i + task-&gt;out_y,
3087         i, task-&gt;pack_lines_count);
3088 
3089     if (!task-&gt;identity_pack) {
3090       /* take away the border */
3091       guint8 *l = ((guint8 *) lines[0]) - task-&gt;lb_width;
3092       /* and pack into destination */
3093       GST_DEBUG (&quot;pack line %d %p (%p)&quot;, i + task-&gt;out_y, lines[0], l);
3094       PACK_FRAME (task-&gt;dest, l, i + task-&gt;out_y, task-&gt;out_maxwidth);
3095     }
3096   }
3097 }
3098 
3099 static void
3100 video_converter_generic (GstVideoConverter * convert, const GstVideoFrame * src,
3101     GstVideoFrame * dest)
3102 {
3103   gint i;
3104   gint out_maxwidth, out_maxheight;
3105   gint out_x, out_y, out_height;
3106   gint pack_lines, pstride;
3107   gint lb_width;
3108   ConvertTask *tasks;
3109   ConvertTask **tasks_p;
3110   gint n_threads;
3111   gint lines_per_thread;
3112 
3113   out_height = convert-&gt;out_height;
3114   out_maxwidth = convert-&gt;out_maxwidth;
3115   out_maxheight = convert-&gt;out_maxheight;
3116 
3117   out_x = convert-&gt;out_x;
3118   out_y = convert-&gt;out_y;
3119 
3120   convert-&gt;src = src;
3121   convert-&gt;dest = dest;
3122 
3123   if (GST_VIDEO_FRAME_IS_INTERLACED (src)) {
3124     GST_DEBUG (&quot;setup interlaced frame&quot;);
3125     convert-&gt;upsample = convert-&gt;upsample_i;
3126     convert-&gt;downsample = convert-&gt;downsample_i;
3127     convert-&gt;v_scaler = convert-&gt;v_scaler_i;
3128   } else {
3129     GST_DEBUG (&quot;setup progressive frame&quot;);
3130     convert-&gt;upsample = convert-&gt;upsample_p;
3131     convert-&gt;downsample = convert-&gt;downsample_p;
3132     convert-&gt;v_scaler = convert-&gt;v_scaler_p;
3133   }
3134   if (convert-&gt;upsample[0]) {
3135     gst_video_chroma_resample_get_info (convert-&gt;upsample[0],
3136         &amp;convert-&gt;up_n_lines, &amp;convert-&gt;up_offset);
3137   } else {
3138     convert-&gt;up_n_lines = 1;
3139     convert-&gt;up_offset = 0;
3140   }
3141   if (convert-&gt;downsample[0]) {
3142     gst_video_chroma_resample_get_info (convert-&gt;downsample[0],
3143         &amp;convert-&gt;down_n_lines, &amp;convert-&gt;down_offset);
3144   } else {
3145     convert-&gt;down_n_lines = 1;
3146     convert-&gt;down_offset = 0;
3147   }
3148 
3149   pack_lines = convert-&gt;pack_nlines;    /* only 1 for now */
3150   pstride = convert-&gt;pack_pstride;
3151 
3152   lb_width = out_x * pstride;
3153 
3154   if (convert-&gt;borderline) {
3155     /* FIXME we should try to avoid PACK_FRAME */
3156     for (i = 0; i &lt; out_y; i++)
3157       PACK_FRAME (dest, convert-&gt;borderline, i, out_maxwidth);
3158   }
3159 
3160   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3161   tasks = g_newa (ConvertTask, n_threads);
3162   tasks_p = g_newa (ConvertTask *, n_threads);
3163 
3164   lines_per_thread =
3165       GST_ROUND_UP_N ((out_height + n_threads - 1) / n_threads, pack_lines);
3166 
3167   for (i = 0; i &lt; n_threads; i++) {
3168     tasks[i].dest = dest;
3169     tasks[i].pack_lines = convert-&gt;pack_lines[i];
3170     tasks[i].idx = i;
3171     tasks[i].pack_lines_count = pack_lines;
3172     tasks[i].out_y = out_y;
3173     tasks[i].identity_pack = convert-&gt;identity_pack;
3174     tasks[i].lb_width = lb_width;
3175     tasks[i].out_maxwidth = out_maxwidth;
3176 
3177     tasks[i].h_0 = i * lines_per_thread;
3178     tasks[i].h_1 = MIN ((i + 1) * lines_per_thread, out_height);
3179 
3180     tasks_p[i] = &amp;tasks[i];
3181   }
3182 
3183   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3184       (GstParallelizedTaskFunc) convert_generic_task, (gpointer) tasks_p);
3185 
3186   if (convert-&gt;borderline) {
3187     for (i = out_y + out_height; i &lt; out_maxheight; i++)
3188       PACK_FRAME (dest, convert-&gt;borderline, i, out_maxwidth);
3189   }
3190   if (convert-&gt;pack_pal) {
3191     memcpy (GST_VIDEO_FRAME_PLANE_DATA (dest, 1), convert-&gt;pack_pal,
3192         convert-&gt;pack_palsize);
3193   }
3194 }
3195 
3196 static void convert_fill_border (GstVideoConverter * convert,
3197     GstVideoFrame * dest);
3198 
3199 /* Fast paths */
3200 
3201 #define GET_LINE_OFFSETS(interlaced,line,l1,l2) \
3202     if (interlaced) {                           \
3203       l1 = (line &amp; 2 ? line - 1 : line);        \
3204       l2 = l1 + 2;                              \
3205     } else {                                    \
3206       l1 = line;                                \
3207       l2 = l1 + 1;                              \
3208     }
3209 
3210 typedef struct
3211 {
3212   const GstVideoFrame *src;
3213   GstVideoFrame *dest;
3214   gint height_0, height_1;
3215 
3216   /* parameters */
3217   gboolean interlaced;
3218   gint width;
3219   gint alpha;
3220   MatrixData *data;
3221   gint in_x, in_y;
3222   gint out_x, out_y;
3223   gpointer tmpline;
3224 } FConvertTask;
3225 
3226 static void
3227 convert_I420_YUY2_task (FConvertTask * task)
3228 {
3229   gint i;
3230   gint l1, l2;
3231 
3232   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3233     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3234 
3235     video_orc_convert_I420_YUY2 (FRAME_GET_LINE (task-&gt;dest, l1),
3236         FRAME_GET_LINE (task-&gt;dest, l2),
3237         FRAME_GET_Y_LINE (task-&gt;src, l1),
3238         FRAME_GET_Y_LINE (task-&gt;src, l2),
3239         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1),
3240         FRAME_GET_V_LINE (task-&gt;src, i &gt;&gt; 1), (task-&gt;width + 1) / 2);
3241   }
3242 }
3243 
3244 static void
3245 convert_I420_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
3246     GstVideoFrame * dest)
3247 {
3248   int i;
3249   gint width = convert-&gt;in_width;
3250   gint height = convert-&gt;in_height;
3251   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3252   gint h2;
3253   FConvertTask *tasks;
3254   FConvertTask **tasks_p;
3255   gint n_threads;
3256   gint lines_per_thread;
3257 
3258   /* I420 has half as many chroma lines, as such we have to
3259    * always merge two into one. For non-interlaced these are
3260    * the two next to each other, for interlaced one is skipped
3261    * in between. */
3262   if (interlaced)
3263     h2 = GST_ROUND_DOWN_4 (height);
3264   else
3265     h2 = GST_ROUND_DOWN_2 (height);
3266 
3267   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3268   tasks = g_newa (FConvertTask, n_threads);
3269   tasks_p = g_newa (FConvertTask *, n_threads);
3270 
3271   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3272 
3273   for (i = 0; i &lt; n_threads; i++) {
3274     tasks[i].src = src;
3275     tasks[i].dest = dest;
3276 
3277     tasks[i].interlaced = interlaced;
3278     tasks[i].width = width;
3279 
3280     tasks[i].height_0 = i * lines_per_thread;
3281     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3282     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3283 
3284     tasks_p[i] = &amp;tasks[i];
3285   }
3286 
3287   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3288       (GstParallelizedTaskFunc) convert_I420_YUY2_task, (gpointer) tasks_p);
3289 
3290   /* now handle last lines. For interlaced these are up to 3 */
3291   if (h2 != height) {
3292     for (i = h2; i &lt; height; i++) {
3293       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3294       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3295     }
3296   }
3297 }
3298 
3299 static void
3300 convert_I420_UYVY_task (FConvertTask * task)
3301 {
3302   gint i;
3303   gint l1, l2;
3304 
3305   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3306     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3307 
3308     video_orc_convert_I420_UYVY (FRAME_GET_LINE (task-&gt;dest, l1),
3309         FRAME_GET_LINE (task-&gt;dest, l2),
3310         FRAME_GET_Y_LINE (task-&gt;src, l1),
3311         FRAME_GET_Y_LINE (task-&gt;src, l2),
3312         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1),
3313         FRAME_GET_V_LINE (task-&gt;src, i &gt;&gt; 1), (task-&gt;width + 1) / 2);
3314   }
3315 }
3316 
3317 static void
3318 convert_I420_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
3319     GstVideoFrame * dest)
3320 {
3321   int i;
3322   gint width = convert-&gt;in_width;
3323   gint height = convert-&gt;in_height;
3324   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3325   gint h2;
3326   FConvertTask *tasks;
3327   FConvertTask **tasks_p;
3328   gint n_threads;
3329   gint lines_per_thread;
3330 
3331   /* I420 has half as many chroma lines, as such we have to
3332    * always merge two into one. For non-interlaced these are
3333    * the two next to each other, for interlaced one is skipped
3334    * in between. */
3335   if (interlaced)
3336     h2 = GST_ROUND_DOWN_4 (height);
3337   else
3338     h2 = GST_ROUND_DOWN_2 (height);
3339 
3340   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3341   tasks = g_newa (FConvertTask, n_threads);
3342   tasks_p = g_newa (FConvertTask *, n_threads);
3343 
3344   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3345 
3346   for (i = 0; i &lt; n_threads; i++) {
3347     tasks[i].src = src;
3348     tasks[i].dest = dest;
3349 
3350     tasks[i].interlaced = interlaced;
3351     tasks[i].width = width;
3352 
3353     tasks[i].height_0 = i * lines_per_thread;
3354     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3355     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3356 
3357     tasks_p[i] = &amp;tasks[i];
3358   }
3359 
3360   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3361       (GstParallelizedTaskFunc) convert_I420_UYVY_task, (gpointer) tasks_p);
3362 
3363   /* now handle last lines. For interlaced these are up to 3 */
3364   if (h2 != height) {
3365     for (i = h2; i &lt; height; i++) {
3366       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3367       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3368     }
3369   }
3370 }
3371 
3372 static void
3373 convert_I420_AYUV_task (FConvertTask * task)
3374 {
3375   gint i;
3376   gint l1, l2;
3377 
3378   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3379     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3380 
3381     video_orc_convert_I420_AYUV (FRAME_GET_LINE (task-&gt;dest, l1),
3382         FRAME_GET_LINE (task-&gt;dest, l2),
3383         FRAME_GET_Y_LINE (task-&gt;src, l1),
3384         FRAME_GET_Y_LINE (task-&gt;src, l2),
3385         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1), FRAME_GET_V_LINE (task-&gt;src,
3386             i &gt;&gt; 1), task-&gt;alpha, task-&gt;width);
3387   }
3388 }
3389 
3390 static void
3391 convert_I420_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3392     GstVideoFrame * dest)
3393 {
3394   int i;
3395   gint width = convert-&gt;in_width;
3396   gint height = convert-&gt;in_height;
3397   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3398   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3399   gint h2;
3400   FConvertTask *tasks;
3401   FConvertTask **tasks_p;
3402   gint n_threads;
3403   gint lines_per_thread;
3404 
3405   /* I420 has half as many chroma lines, as such we have to
3406    * always merge two into one. For non-interlaced these are
3407    * the two next to each other, for interlaced one is skipped
3408    * in between. */
3409   if (interlaced)
3410     h2 = GST_ROUND_DOWN_4 (height);
3411   else
3412     h2 = GST_ROUND_DOWN_2 (height);
3413 
3414 
3415   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3416   tasks = g_newa (FConvertTask, n_threads);
3417   tasks_p = g_newa (FConvertTask *, n_threads);
3418 
3419   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3420 
3421   for (i = 0; i &lt; n_threads; i++) {
3422     tasks[i].src = src;
3423     tasks[i].dest = dest;
3424 
3425     tasks[i].interlaced = interlaced;
3426     tasks[i].width = width;
3427     tasks[i].alpha = alpha;
3428 
3429     tasks[i].height_0 = i * lines_per_thread;
3430     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3431     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3432 
3433     tasks_p[i] = &amp;tasks[i];
3434   }
3435 
3436   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3437       (GstParallelizedTaskFunc) convert_I420_AYUV_task, (gpointer) tasks_p);
3438 
3439   /* now handle last lines. For interlaced these are up to 3 */
3440   if (h2 != height) {
3441     for (i = h2; i &lt; height; i++) {
3442       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3443       if (alpha != 0xff)
3444         convert_set_alpha_u8 (convert, convert-&gt;tmpline[0], width);
3445       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3446     }
3447   }
3448 }
3449 
3450 static void
3451 convert_YUY2_I420_task (FConvertTask * task)
3452 {
3453   gint i;
3454   gint l1, l2;
3455 
3456   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3457     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3458 
3459     video_orc_convert_YUY2_I420 (FRAME_GET_Y_LINE (task-&gt;dest, l1),
3460         FRAME_GET_Y_LINE (task-&gt;dest, l2),
3461         FRAME_GET_U_LINE (task-&gt;dest, i &gt;&gt; 1),
3462         FRAME_GET_V_LINE (task-&gt;dest, i &gt;&gt; 1),
3463         FRAME_GET_LINE (task-&gt;src, l1), FRAME_GET_LINE (task-&gt;src, l2),
3464         (task-&gt;width + 1) / 2);
3465   }
3466 }
3467 
3468 static void
3469 convert_YUY2_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
3470     GstVideoFrame * dest)
3471 {
3472   int i;
3473   gint width = convert-&gt;in_width;
3474   gint height = convert-&gt;in_height;
3475   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3476   gint h2;
3477   FConvertTask *tasks;
3478   FConvertTask **tasks_p;
3479   gint n_threads;
3480   gint lines_per_thread;
3481 
3482   /* I420 has half as many chroma lines, as such we have to
3483    * always merge two into one. For non-interlaced these are
3484    * the two next to each other, for interlaced one is skipped
3485    * in between. */
3486   if (interlaced)
3487     h2 = GST_ROUND_DOWN_4 (height);
3488   else
3489     h2 = GST_ROUND_DOWN_2 (height);
3490 
3491   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3492   tasks = g_newa (FConvertTask, n_threads);
3493   tasks_p = g_newa (FConvertTask *, n_threads);
3494 
3495   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3496 
3497   for (i = 0; i &lt; n_threads; i++) {
3498     tasks[i].src = src;
3499     tasks[i].dest = dest;
3500 
3501     tasks[i].interlaced = interlaced;
3502     tasks[i].width = width;
3503 
3504     tasks[i].height_0 = i * lines_per_thread;
3505     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3506     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3507 
3508     tasks_p[i] = &amp;tasks[i];
3509   }
3510 
3511   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3512       (GstParallelizedTaskFunc) convert_YUY2_I420_task, (gpointer) tasks_p);
3513 
3514   /* now handle last lines. For interlaced these are up to 3 */
3515   if (h2 != height) {
3516     for (i = h2; i &lt; height; i++) {
3517       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3518       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3519     }
3520   }
3521 }
3522 
3523 typedef struct
3524 {
3525   const guint8 *s, *s2, *su, *sv;
3526   guint8 *d, *d2, *du, *dv;
3527   gint sstride, sustride, svstride;
3528   gint dstride, dustride, dvstride;
3529   gint width, height;
3530   gint alpha;
3531   MatrixData *data;
3532 } FConvertPlaneTask;
3533 
3534 static void
3535 convert_YUY2_AYUV_task (FConvertPlaneTask * task)
3536 {
3537   video_orc_convert_YUY2_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
3538       task-&gt;sstride, task-&gt;alpha, (task-&gt;width + 1) / 2, task-&gt;height);
3539 }
3540 
3541 static void
3542 convert_YUY2_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3543     GstVideoFrame * dest)
3544 {
3545   gint width = convert-&gt;in_width;
3546   gint height = convert-&gt;in_height;
3547   guint8 *s, *d;
3548   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3549   FConvertPlaneTask *tasks;
3550   FConvertPlaneTask **tasks_p;
3551   gint n_threads;
3552   gint lines_per_thread;
3553   gint i;
3554 
3555   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3556   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3557   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3558   d += (convert-&gt;out_x * 4);
3559 
3560   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3561   tasks = g_newa (FConvertPlaneTask, n_threads);
3562   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3563 
3564   lines_per_thread = (height + n_threads - 1) / n_threads;
3565 
3566   for (i = 0; i &lt; n_threads; i++) {
3567     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3568     tasks[i].sstride = FRAME_GET_STRIDE (src);
3569     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3570     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3571 
3572     tasks[i].width = width;
3573     tasks[i].height = (i + 1) * lines_per_thread;
3574     tasks[i].height = MIN (tasks[i].height, height);
3575     tasks[i].height -= i * lines_per_thread;
3576     tasks[i].alpha = alpha;
3577 
3578     tasks_p[i] = &amp;tasks[i];
3579   }
3580 
3581   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3582       (GstParallelizedTaskFunc) convert_YUY2_AYUV_task, (gpointer) tasks_p);
3583 
3584   convert_fill_border (convert, dest);
3585 }
3586 
3587 static void
3588 convert_YUY2_Y42B_task (FConvertPlaneTask * task)
3589 {
3590   video_orc_convert_YUY2_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
3591       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
3592       task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3593 }
3594 
3595 static void
3596 convert_YUY2_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
3597     GstVideoFrame * dest)
3598 {
3599   gint width = convert-&gt;in_width;
3600   gint height = convert-&gt;in_height;
3601   guint8 *s, *dy, *du, *dv;
3602   FConvertPlaneTask *tasks;
3603   FConvertPlaneTask **tasks_p;
3604   gint n_threads;
3605   gint lines_per_thread;
3606   gint i;
3607 
3608   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3609   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3610 
3611   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3612   dy += convert-&gt;out_x;
3613   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3614   du += convert-&gt;out_x &gt;&gt; 1;
3615   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3616   dv += convert-&gt;out_x &gt;&gt; 1;
3617 
3618   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3619   tasks = g_newa (FConvertPlaneTask, n_threads);
3620   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3621 
3622   lines_per_thread = (height + n_threads - 1) / n_threads;
3623 
3624   for (i = 0; i &lt; n_threads; i++) {
3625     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3626     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3627     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3628     tasks[i].sstride = FRAME_GET_STRIDE (src);
3629     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3630     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3631     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3632     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3633 
3634     tasks[i].width = width;
3635     tasks[i].height = (i + 1) * lines_per_thread;
3636     tasks[i].height = MIN (tasks[i].height, height);
3637     tasks[i].height -= i * lines_per_thread;
3638 
3639     tasks_p[i] = &amp;tasks[i];
3640   }
3641 
3642   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3643       (GstParallelizedTaskFunc) convert_YUY2_Y42B_task, (gpointer) tasks_p);
3644 
3645   convert_fill_border (convert, dest);
3646 }
3647 
3648 static void
3649 convert_YUY2_Y444_task (FConvertPlaneTask * task)
3650 {
3651   video_orc_convert_YUY2_Y444 (task-&gt;d,
3652       task-&gt;dstride, task-&gt;du,
3653       task-&gt;dustride, task-&gt;dv,
3654       task-&gt;dvstride, task-&gt;s,
3655       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3656 }
3657 
3658 static void
3659 convert_YUY2_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
3660     GstVideoFrame * dest)
3661 {
3662   gint width = convert-&gt;in_width;
3663   gint height = convert-&gt;in_height;
3664   guint8 *s, *dy, *du, *dv;
3665   FConvertPlaneTask *tasks;
3666   FConvertPlaneTask **tasks_p;
3667   gint n_threads;
3668   gint lines_per_thread;
3669   gint i;
3670 
3671   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3672   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3673 
3674   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3675   dy += convert-&gt;out_x;
3676   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3677   du += convert-&gt;out_x;
3678   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3679   dv += convert-&gt;out_x;
3680 
3681   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3682   tasks = g_newa (FConvertPlaneTask, n_threads);
3683   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3684 
3685   lines_per_thread = (height + n_threads - 1) / n_threads;
3686 
3687   for (i = 0; i &lt; n_threads; i++) {
3688     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3689     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3690     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3691     tasks[i].sstride = FRAME_GET_STRIDE (src);
3692     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3693     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3694     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3695     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3696 
3697     tasks[i].width = width;
3698     tasks[i].height = (i + 1) * lines_per_thread;
3699     tasks[i].height = MIN (tasks[i].height, height);
3700     tasks[i].height -= i * lines_per_thread;
3701 
3702     tasks_p[i] = &amp;tasks[i];
3703   }
3704 
3705   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3706       (GstParallelizedTaskFunc) convert_YUY2_Y444_task, (gpointer) tasks_p);
3707 
3708   convert_fill_border (convert, dest);
3709 }
3710 
3711 static void
3712 convert_UYVY_I420_task (FConvertTask * task)
3713 {
3714   gint i;
3715   gint l1, l2;
3716 
3717   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3718     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3719 
3720     video_orc_convert_UYVY_I420 (FRAME_GET_COMP_LINE (task-&gt;dest, 0, l1),
3721         FRAME_GET_COMP_LINE (task-&gt;dest, 0, l2),
3722         FRAME_GET_COMP_LINE (task-&gt;dest, 1, i &gt;&gt; 1),
3723         FRAME_GET_COMP_LINE (task-&gt;dest, 2, i &gt;&gt; 1),
3724         FRAME_GET_LINE (task-&gt;src, l1), FRAME_GET_LINE (task-&gt;src, l2),
3725         (task-&gt;width + 1) / 2);
3726   }
3727 }
3728 
3729 static void
3730 convert_UYVY_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
3731     GstVideoFrame * dest)
3732 {
3733   int i;
3734   gint width = convert-&gt;in_width;
3735   gint height = convert-&gt;in_height;
3736   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3737   gint h2;
3738   FConvertTask *tasks;
3739   FConvertTask **tasks_p;
3740   gint n_threads;
3741   gint lines_per_thread;
3742 
3743   /* I420 has half as many chroma lines, as such we have to
3744    * always merge two into one. For non-interlaced these are
3745    * the two next to each other, for interlaced one is skipped
3746    * in between. */
3747   if (interlaced)
3748     h2 = GST_ROUND_DOWN_4 (height);
3749   else
3750     h2 = GST_ROUND_DOWN_2 (height);
3751 
3752   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3753   tasks = g_newa (FConvertTask, n_threads);
3754   tasks_p = g_newa (FConvertTask *, n_threads);
3755 
3756   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3757 
3758   for (i = 0; i &lt; n_threads; i++) {
3759     tasks[i].src = src;
3760     tasks[i].dest = dest;
3761 
3762     tasks[i].interlaced = interlaced;
3763     tasks[i].width = width;
3764 
3765     tasks[i].height_0 = i * lines_per_thread;
3766     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3767     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3768 
3769     tasks_p[i] = &amp;tasks[i];
3770   }
3771 
3772   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3773       (GstParallelizedTaskFunc) convert_UYVY_I420_task, (gpointer) tasks_p);
3774 
3775   /* now handle last lines. For interlaced these are up to 3 */
3776   if (h2 != height) {
3777     for (i = h2; i &lt; height; i++) {
3778       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3779       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3780     }
3781   }
3782 }
3783 
3784 static void
3785 convert_UYVY_AYUV_task (FConvertPlaneTask * task)
3786 {
3787   video_orc_convert_UYVY_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
3788       task-&gt;sstride, task-&gt;alpha, (task-&gt;width + 1) / 2, task-&gt;height);
3789 }
3790 
3791 static void
3792 convert_UYVY_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3793     GstVideoFrame * dest)
3794 {
3795   gint width = convert-&gt;in_width;
3796   gint height = convert-&gt;in_height;
3797   guint8 *s, *d;
3798   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3799   FConvertPlaneTask *tasks;
3800   FConvertPlaneTask **tasks_p;
3801   gint n_threads;
3802   gint lines_per_thread;
3803   gint i;
3804 
3805   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3806   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3807   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3808   d += (convert-&gt;out_x * 4);
3809 
3810   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3811   tasks = g_newa (FConvertPlaneTask, n_threads);
3812   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3813 
3814   lines_per_thread = (height + n_threads - 1) / n_threads;
3815 
3816   for (i = 0; i &lt; n_threads; i++) {
3817     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3818     tasks[i].sstride = FRAME_GET_STRIDE (src);
3819     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3820     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3821 
3822     tasks[i].width = width;
3823     tasks[i].height = (i + 1) * lines_per_thread;
3824     tasks[i].height = MIN (tasks[i].height, height);
3825     tasks[i].height -= i * lines_per_thread;
3826     tasks[i].alpha = alpha;
3827 
3828     tasks_p[i] = &amp;tasks[i];
3829   }
3830 
3831   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3832       (GstParallelizedTaskFunc) convert_UYVY_AYUV_task, (gpointer) tasks_p);
3833 
3834   convert_fill_border (convert, dest);
3835 }
3836 
3837 static void
3838 convert_UYVY_YUY2_task (FConvertPlaneTask * task)
3839 {
3840   video_orc_convert_UYVY_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
3841       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3842 }
3843 
3844 static void
3845 convert_UYVY_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
3846     GstVideoFrame * dest)
3847 {
3848   gint width = convert-&gt;in_width;
3849   gint height = convert-&gt;in_height;
3850   guint8 *s, *d;
3851   FConvertPlaneTask *tasks;
3852   FConvertPlaneTask **tasks_p;
3853   gint n_threads;
3854   gint lines_per_thread;
3855   gint i;
3856 
3857   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3858   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3859   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3860   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
3861 
3862   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3863   tasks = g_newa (FConvertPlaneTask, n_threads);
3864   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3865 
3866   lines_per_thread = (height + n_threads - 1) / n_threads;
3867 
3868   for (i = 0; i &lt; n_threads; i++) {
3869     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3870     tasks[i].sstride = FRAME_GET_STRIDE (src);
3871     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3872     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3873 
3874     tasks[i].width = width;
3875     tasks[i].height = (i + 1) * lines_per_thread;
3876     tasks[i].height = MIN (tasks[i].height, height);
3877     tasks[i].height -= i * lines_per_thread;
3878 
3879     tasks_p[i] = &amp;tasks[i];
3880   }
3881 
3882   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3883       (GstParallelizedTaskFunc) convert_UYVY_YUY2_task, (gpointer) tasks_p);
3884 
3885   convert_fill_border (convert, dest);
3886 }
3887 
3888 static void
3889 convert_UYVY_Y42B_task (FConvertPlaneTask * task)
3890 {
3891   video_orc_convert_UYVY_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
3892       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
3893       task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3894 }
3895 
3896 static void
3897 convert_UYVY_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
3898     GstVideoFrame * dest)
3899 {
3900   gint width = convert-&gt;in_width;
3901   gint height = convert-&gt;in_height;
3902   guint8 *s, *dy, *du, *dv;
3903   FConvertPlaneTask *tasks;
3904   FConvertPlaneTask **tasks_p;
3905   gint n_threads;
3906   gint lines_per_thread;
3907   gint i;
3908 
3909   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3910   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3911 
3912   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3913   dy += convert-&gt;out_x;
3914   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3915   du += convert-&gt;out_x &gt;&gt; 1;
3916   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3917   dv += convert-&gt;out_x &gt;&gt; 1;
3918 
3919   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3920   tasks = g_newa (FConvertPlaneTask, n_threads);
3921   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3922 
3923   lines_per_thread = (height + n_threads - 1) / n_threads;
3924 
3925   for (i = 0; i &lt; n_threads; i++) {
3926     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3927     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3928     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3929     tasks[i].sstride = FRAME_GET_STRIDE (src);
3930     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3931     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3932     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3933     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3934 
3935     tasks[i].width = width;
3936     tasks[i].height = (i + 1) * lines_per_thread;
3937     tasks[i].height = MIN (tasks[i].height, height);
3938     tasks[i].height -= i * lines_per_thread;
3939 
3940     tasks_p[i] = &amp;tasks[i];
3941   }
3942 
3943   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3944       (GstParallelizedTaskFunc) convert_UYVY_Y42B_task, (gpointer) tasks_p);
3945 
3946   convert_fill_border (convert, dest);
3947 }
3948 
3949 static void
3950 convert_UYVY_Y444_task (FConvertPlaneTask * task)
3951 {
3952   video_orc_convert_UYVY_Y444 (task-&gt;d,
3953       task-&gt;dstride, task-&gt;du,
3954       task-&gt;dustride, task-&gt;dv,
3955       task-&gt;dvstride, task-&gt;s,
3956       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3957 }
3958 
3959 static void
3960 convert_UYVY_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
3961     GstVideoFrame * dest)
3962 {
3963   gint width = convert-&gt;in_width;
3964   gint height = convert-&gt;in_height;
3965   guint8 *s, *dy, *du, *dv;
3966   FConvertPlaneTask *tasks;
3967   FConvertPlaneTask **tasks_p;
3968   gint n_threads;
3969   gint lines_per_thread;
3970   gint i;
3971 
3972   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3973   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3974 
3975   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3976   dy += convert-&gt;out_x;
3977   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3978   du += convert-&gt;out_x;
3979   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3980   dv += convert-&gt;out_x;
3981 
3982   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3983   tasks = g_newa (FConvertPlaneTask, n_threads);
3984   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3985 
3986   lines_per_thread = (height + n_threads - 1) / n_threads;
3987 
3988   for (i = 0; i &lt; n_threads; i++) {
3989     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3990     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3991     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3992     tasks[i].sstride = FRAME_GET_STRIDE (src);
3993     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3994     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3995     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3996     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3997 
3998     tasks[i].width = width;
3999     tasks[i].height = (i + 1) * lines_per_thread;
4000     tasks[i].height = MIN (tasks[i].height, height);
4001     tasks[i].height -= i * lines_per_thread;
4002 
4003     tasks_p[i] = &amp;tasks[i];
4004   }
4005 
4006   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4007       (GstParallelizedTaskFunc) convert_UYVY_Y444_task, (gpointer) tasks_p);
4008 
4009   convert_fill_border (convert, dest);
4010 }
4011 
4012 static void
4013 convert_UYVY_GRAY8_task (FConvertPlaneTask * task)
4014 {
4015   video_orc_convert_UYVY_GRAY8 (task-&gt;d, task-&gt;dstride, (guint16 *) task-&gt;s,
4016       task-&gt;sstride, task-&gt;width, task-&gt;height);
4017 }
4018 
4019 static void
4020 convert_UYVY_GRAY8 (GstVideoConverter * convert, const GstVideoFrame * src,
4021     GstVideoFrame * dest)
4022 {
4023   gint width = convert-&gt;in_width;
4024   gint height = convert-&gt;in_height;
4025   guint8 *s;
4026   guint8 *d;
4027   FConvertPlaneTask *tasks;
4028   FConvertPlaneTask **tasks_p;
4029   gint n_threads;
4030   gint lines_per_thread;
4031   gint i;
4032 
4033   s = GST_VIDEO_FRAME_PLANE_DATA (src, 0);
4034   d = GST_VIDEO_FRAME_PLANE_DATA (dest, 0);
4035 
4036   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4037   tasks = g_newa (FConvertPlaneTask, n_threads);
4038   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4039 
4040   lines_per_thread = (height + n_threads - 1) / n_threads;
4041 
4042   for (i = 0; i &lt; n_threads; i++) {
4043     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4044     tasks[i].sstride = FRAME_GET_STRIDE (src);
4045     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4046     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4047 
4048     tasks[i].width = width;
4049     tasks[i].height = (i + 1) * lines_per_thread;
4050     tasks[i].height = MIN (tasks[i].height, height);
4051     tasks[i].height -= i * lines_per_thread;
4052 
4053     tasks_p[i] = &amp;tasks[i];
4054   }
4055 
4056   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4057       (GstParallelizedTaskFunc) convert_UYVY_GRAY8_task, (gpointer) tasks_p);
4058 
4059   convert_fill_border (convert, dest);
4060 }
4061 
4062 static void
4063 convert_AYUV_I420_task (FConvertPlaneTask * task)
4064 {
4065   video_orc_convert_AYUV_I420 (task-&gt;d,
4066       2 * task-&gt;dstride, task-&gt;d2,
4067       2 * task-&gt;dstride, task-&gt;du,
4068       task-&gt;dustride, task-&gt;dv,
4069       task-&gt;dvstride, task-&gt;s,
4070       2 * task-&gt;sstride, task-&gt;s2,
4071       2 * task-&gt;sstride, task-&gt;width / 2, task-&gt;height / 2);
4072 }
4073 
4074 static void
4075 convert_AYUV_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
4076     GstVideoFrame * dest)
4077 {
4078   gint width = convert-&gt;in_width;
4079   gint height = convert-&gt;in_height;
4080   guint8 *s1, *s2, *dy1, *dy2, *du, *dv;
4081   FConvertPlaneTask *tasks;
4082   FConvertPlaneTask **tasks_p;
4083   gint n_threads;
4084   gint lines_per_thread;
4085   gint i;
4086 
4087   s1 = FRAME_GET_LINE (src, convert-&gt;in_y + 0);
4088   s1 += convert-&gt;in_x * 4;
4089   s2 = FRAME_GET_LINE (src, convert-&gt;in_y + 1);
4090   s2 += convert-&gt;in_x * 4;
4091 
4092   dy1 = FRAME_GET_Y_LINE (dest, convert-&gt;out_y + 0);
4093   dy1 += convert-&gt;out_x;
4094   dy2 = FRAME_GET_Y_LINE (dest, convert-&gt;out_y + 1);
4095   dy2 += convert-&gt;out_x;
4096   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y &gt;&gt; 1);
4097   du += convert-&gt;out_x &gt;&gt; 1;
4098   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y &gt;&gt; 1);
4099   dv += convert-&gt;out_x &gt;&gt; 1;
4100 
4101   /* only for even width/height */
4102 
4103   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4104   tasks = g_newa (FConvertPlaneTask, n_threads);
4105   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4106 
4107   lines_per_thread = GST_ROUND_UP_2 ((height + n_threads - 1) / n_threads);
4108 
4109   for (i = 0; i &lt; n_threads; i++) {
4110     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4111     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4112     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4113     tasks[i].sstride = FRAME_GET_STRIDE (src);
4114     tasks[i].d = dy1 + i * lines_per_thread * tasks[i].dstride;
4115     tasks[i].d2 = dy2 + i * lines_per_thread * tasks[i].dstride;
4116     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride / 2;
4117     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride / 2;
4118     tasks[i].s = s1 + i * lines_per_thread * tasks[i].sstride;
4119     tasks[i].s2 = s2 + i * lines_per_thread * tasks[i].sstride;
4120 
4121     tasks[i].width = width;
4122     tasks[i].height = (i + 1) * lines_per_thread;
4123     tasks[i].height = MIN (tasks[i].height, height);
4124     tasks[i].height -= i * lines_per_thread;
4125 
4126     tasks_p[i] = &amp;tasks[i];
4127   }
4128 
4129   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4130       (GstParallelizedTaskFunc) convert_AYUV_I420_task, (gpointer) tasks_p);
4131 
4132   convert_fill_border (convert, dest);
4133 }
4134 
4135 static void
4136 convert_AYUV_YUY2_task (FConvertPlaneTask * task)
4137 {
4138   video_orc_convert_AYUV_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
4139       task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4140 }
4141 
4142 static void
4143 convert_AYUV_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4144     GstVideoFrame * dest)
4145 {
4146   gint width = convert-&gt;in_width;
4147   gint height = convert-&gt;in_height;
4148   guint8 *s, *d;
4149   FConvertPlaneTask *tasks;
4150   FConvertPlaneTask **tasks_p;
4151   gint n_threads;
4152   gint lines_per_thread;
4153   gint i;
4154 
4155   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4156   s += convert-&gt;in_x * 4;
4157   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4158   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4159 
4160   /* only for even width */
4161   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4162   tasks = g_newa (FConvertPlaneTask, n_threads);
4163   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4164 
4165   lines_per_thread = (height + n_threads - 1) / n_threads;
4166 
4167   for (i = 0; i &lt; n_threads; i++) {
4168     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4169     tasks[i].sstride = FRAME_GET_STRIDE (src);
4170     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4171     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4172 
4173     tasks[i].width = width;
4174     tasks[i].height = (i + 1) * lines_per_thread;
4175     tasks[i].height = MIN (tasks[i].height, height);
4176     tasks[i].height -= i * lines_per_thread;
4177 
4178     tasks_p[i] = &amp;tasks[i];
4179   }
4180 
4181   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4182       (GstParallelizedTaskFunc) convert_AYUV_YUY2_task, (gpointer) tasks_p);
4183 
4184   convert_fill_border (convert, dest);
4185 }
4186 
4187 static void
4188 convert_AYUV_UYVY_task (FConvertPlaneTask * task)
4189 {
4190   video_orc_convert_AYUV_UYVY (task-&gt;d, task-&gt;dstride, task-&gt;s,
4191       task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4192 }
4193 
4194 static void
4195 convert_AYUV_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4196     GstVideoFrame * dest)
4197 {
4198   gint width = convert-&gt;in_width;
4199   gint height = convert-&gt;in_height;
4200   guint8 *s, *d;
4201   FConvertPlaneTask *tasks;
4202   FConvertPlaneTask **tasks_p;
4203   gint n_threads;
4204   gint lines_per_thread;
4205   gint i;
4206 
4207   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4208   s += convert-&gt;in_x * 4;
4209   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4210   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4211 
4212   /* only for even width */
4213   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4214   tasks = g_newa (FConvertPlaneTask, n_threads);
4215   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4216 
4217   lines_per_thread = (height + n_threads - 1) / n_threads;
4218 
4219   for (i = 0; i &lt; n_threads; i++) {
4220     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4221     tasks[i].sstride = FRAME_GET_STRIDE (src);
4222     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4223     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4224 
4225     tasks[i].width = width;
4226     tasks[i].height = (i + 1) * lines_per_thread;
4227     tasks[i].height = MIN (tasks[i].height, height);
4228     tasks[i].height -= i * lines_per_thread;
4229 
4230     tasks_p[i] = &amp;tasks[i];
4231   }
4232 
4233   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4234       (GstParallelizedTaskFunc) convert_AYUV_UYVY_task, (gpointer) tasks_p);
4235 
4236   convert_fill_border (convert, dest);
4237 }
4238 
4239 static void
4240 convert_AYUV_Y42B_task (FConvertPlaneTask * task)
4241 {
4242   video_orc_convert_AYUV_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
4243       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
4244       task-&gt;s, task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4245 }
4246 
4247 static void
4248 convert_AYUV_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
4249     GstVideoFrame * dest)
4250 {
4251   gint width = convert-&gt;in_width;
4252   gint height = convert-&gt;in_height;
4253   guint8 *s, *dy, *du, *dv;
4254   FConvertPlaneTask *tasks;
4255   FConvertPlaneTask **tasks_p;
4256   gint n_threads;
4257   gint lines_per_thread;
4258   gint i;
4259 
4260   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4261   s += convert-&gt;in_x * 4;
4262 
4263   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
4264   dy += convert-&gt;out_x;
4265   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
4266   du += convert-&gt;out_x &gt;&gt; 1;
4267   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
4268   dv += convert-&gt;out_x &gt;&gt; 1;
4269 
4270   /* only works for even width */
4271   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4272   tasks = g_newa (FConvertPlaneTask, n_threads);
4273   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4274 
4275   lines_per_thread = (height + n_threads - 1) / n_threads;
4276 
4277   for (i = 0; i &lt; n_threads; i++) {
4278     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4279     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4280     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4281     tasks[i].sstride = FRAME_GET_STRIDE (src);
4282     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
4283     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
4284     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
4285     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4286 
4287     tasks[i].width = width;
4288     tasks[i].height = (i + 1) * lines_per_thread;
4289     tasks[i].height = MIN (tasks[i].height, height);
4290     tasks[i].height -= i * lines_per_thread;
4291 
4292     tasks_p[i] = &amp;tasks[i];
4293   }
4294 
4295   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4296       (GstParallelizedTaskFunc) convert_AYUV_Y42B_task, (gpointer) tasks_p);
4297 
4298   convert_fill_border (convert, dest);
4299 }
4300 
4301 static void
4302 convert_AYUV_Y444_task (FConvertPlaneTask * task)
4303 {
4304   video_orc_convert_AYUV_Y444 (task-&gt;d, task-&gt;dstride, task-&gt;du,
4305       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
4306       task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height);
4307 }
4308 
4309 static void
4310 convert_AYUV_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
4311     GstVideoFrame * dest)
4312 {
4313   gint width = convert-&gt;in_width;
4314   gint height = convert-&gt;in_height;
4315   guint8 *s, *dy, *du, *dv;
4316   FConvertPlaneTask *tasks;
4317   FConvertPlaneTask **tasks_p;
4318   gint n_threads;
4319   gint lines_per_thread;
4320   gint i;
4321 
4322   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4323   s += convert-&gt;in_x * 4;
4324 
4325   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
4326   dy += convert-&gt;out_x;
4327   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
4328   du += convert-&gt;out_x;
4329   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
4330   dv += convert-&gt;out_x;
4331 
4332   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4333   tasks = g_newa (FConvertPlaneTask, n_threads);
4334   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4335 
4336   lines_per_thread = (height + n_threads - 1) / n_threads;
4337 
4338   for (i = 0; i &lt; n_threads; i++) {
4339     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4340     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4341     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4342     tasks[i].sstride = FRAME_GET_STRIDE (src);
4343     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
4344     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
4345     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
4346     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4347 
4348     tasks[i].width = width;
4349     tasks[i].height = (i + 1) * lines_per_thread;
4350     tasks[i].height = MIN (tasks[i].height, height);
4351     tasks[i].height -= i * lines_per_thread;
4352 
4353     tasks_p[i] = &amp;tasks[i];
4354   }
4355 
4356   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4357       (GstParallelizedTaskFunc) convert_AYUV_Y444_task, (gpointer) tasks_p);
4358   convert_fill_border (convert, dest);
4359 }
4360 
4361 static void
4362 convert_Y42B_YUY2_task (FConvertPlaneTask * task)
4363 {
4364   video_orc_convert_Y42B_YUY2 (task-&gt;d, task-&gt;dstride,
4365       task-&gt;s, task-&gt;sstride,
4366       task-&gt;su, task-&gt;sustride,
4367       task-&gt;sv, task-&gt;svstride, (task-&gt;width + 1) / 2, task-&gt;height);
4368 }
4369 
4370 static void
4371 convert_Y42B_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4372     GstVideoFrame * dest)
4373 {
4374   gint width = convert-&gt;in_width;
4375   gint height = convert-&gt;in_height;
4376   guint8 *sy, *su, *sv, *d;
4377   FConvertPlaneTask *tasks;
4378   FConvertPlaneTask **tasks_p;
4379   gint n_threads;
4380   gint lines_per_thread;
4381   gint i;
4382 
4383   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4384   sy += convert-&gt;in_x;
4385   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4386   su += convert-&gt;in_x &gt;&gt; 1;
4387   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4388   sv += convert-&gt;in_x &gt;&gt; 1;
4389 
4390   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4391   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4392 
4393   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4394   tasks = g_newa (FConvertPlaneTask, n_threads);
4395   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4396 
4397   lines_per_thread = (height + n_threads - 1) / n_threads;
4398 
4399   for (i = 0; i &lt; n_threads; i++) {
4400     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4401     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4402     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4403     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4404     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4405     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4406     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4407     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4408 
4409     tasks[i].width = width;
4410     tasks[i].height = (i + 1) * lines_per_thread;
4411     tasks[i].height = MIN (tasks[i].height, height);
4412     tasks[i].height -= i * lines_per_thread;
4413 
4414     tasks_p[i] = &amp;tasks[i];
4415   }
4416 
4417   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4418       (GstParallelizedTaskFunc) convert_Y42B_YUY2_task, (gpointer) tasks_p);
4419 
4420   convert_fill_border (convert, dest);
4421 }
4422 
4423 static void
4424 convert_Y42B_UYVY_task (FConvertPlaneTask * task)
4425 {
4426   video_orc_convert_Y42B_UYVY (task-&gt;d, task-&gt;dstride,
4427       task-&gt;s, task-&gt;sstride,
4428       task-&gt;su, task-&gt;sustride,
4429       task-&gt;sv, task-&gt;svstride, (task-&gt;width + 1) / 2, task-&gt;height);
4430 }
4431 
4432 static void
4433 convert_Y42B_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4434     GstVideoFrame * dest)
4435 {
4436   gint width = convert-&gt;in_width;
4437   gint height = convert-&gt;in_height;
4438   guint8 *sy, *su, *sv, *d;
4439   FConvertPlaneTask *tasks;
4440   FConvertPlaneTask **tasks_p;
4441   gint n_threads;
4442   gint lines_per_thread;
4443   gint i;
4444 
4445   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4446   sy += convert-&gt;in_x;
4447   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4448   su += convert-&gt;in_x &gt;&gt; 1;
4449   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4450   sv += convert-&gt;in_x &gt;&gt; 1;
4451 
4452   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4453   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4454 
4455   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4456   tasks = g_newa (FConvertPlaneTask, n_threads);
4457   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4458 
4459   lines_per_thread = (height + n_threads - 1) / n_threads;
4460 
4461   for (i = 0; i &lt; n_threads; i++) {
4462     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4463     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4464     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4465     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4466     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4467     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4468     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4469     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4470 
4471     tasks[i].width = width;
4472     tasks[i].height = (i + 1) * lines_per_thread;
4473     tasks[i].height = MIN (tasks[i].height, height);
4474     tasks[i].height -= i * lines_per_thread;
4475 
4476     tasks_p[i] = &amp;tasks[i];
4477   }
4478 
4479   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4480       (GstParallelizedTaskFunc) convert_Y42B_UYVY_task, (gpointer) tasks_p);
4481 
4482   convert_fill_border (convert, dest);
4483 }
4484 
4485 static void
4486 convert_Y42B_AYUV_task (FConvertPlaneTask * task)
4487 {
4488   video_orc_convert_Y42B_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
4489       task-&gt;sstride,
4490       task-&gt;su,
4491       task-&gt;sustride,
4492       task-&gt;sv, task-&gt;svstride, task-&gt;alpha, task-&gt;width / 2, task-&gt;height);
4493 }
4494 
4495 static void
4496 convert_Y42B_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
4497     GstVideoFrame * dest)
4498 {
4499   gint width = convert-&gt;in_width;
4500   gint height = convert-&gt;in_height;
4501   guint8 *sy, *su, *sv, *d;
4502   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
4503   FConvertPlaneTask *tasks;
4504   FConvertPlaneTask **tasks_p;
4505   gint n_threads;
4506   gint lines_per_thread;
4507   gint i;
4508 
4509   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4510   sy += convert-&gt;in_x;
4511   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4512   su += convert-&gt;in_x &gt;&gt; 1;
4513   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4514   sv += convert-&gt;in_x &gt;&gt; 1;
4515 
4516   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4517   d += convert-&gt;out_x * 4;
4518 
4519   /* only for even width */
4520   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4521   tasks = g_newa (FConvertPlaneTask, n_threads);
4522   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4523 
4524   lines_per_thread = (height + n_threads - 1) / n_threads;
4525 
4526   for (i = 0; i &lt; n_threads; i++) {
4527     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4528     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4529     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4530     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4531     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4532     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4533     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4534     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4535 
4536     tasks[i].width = width;
4537     tasks[i].height = (i + 1) * lines_per_thread;
4538     tasks[i].height = MIN (tasks[i].height, height);
4539     tasks[i].height -= i * lines_per_thread;
4540     tasks[i].alpha = alpha;
4541 
4542     tasks_p[i] = &amp;tasks[i];
4543   }
4544 
4545   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4546       (GstParallelizedTaskFunc) convert_Y42B_AYUV_task, (gpointer) tasks_p);
4547 
4548   convert_fill_border (convert, dest);
4549 }
4550 
4551 static void
4552 convert_Y444_YUY2_task (FConvertPlaneTask * task)
4553 {
4554   video_orc_convert_Y444_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
4555       task-&gt;sstride,
4556       task-&gt;su,
4557       task-&gt;sustride, task-&gt;sv, task-&gt;svstride, task-&gt;width / 2, task-&gt;height);
4558 }
4559 
4560 static void
4561 convert_Y444_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4562     GstVideoFrame * dest)
4563 {
4564   gint width = convert-&gt;in_width;
4565   gint height = convert-&gt;in_height;
4566   guint8 *sy, *su, *sv, *d;
4567   FConvertPlaneTask *tasks;
4568   FConvertPlaneTask **tasks_p;
4569   gint n_threads;
4570   gint lines_per_thread;
4571   gint i;
4572 
4573   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4574   sy += convert-&gt;in_x;
4575   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4576   su += convert-&gt;in_x;
4577   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4578   sv += convert-&gt;in_x;
4579 
4580   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4581   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4582 
4583   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4584   tasks = g_newa (FConvertPlaneTask, n_threads);
4585   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4586 
4587   lines_per_thread = (height + n_threads - 1) / n_threads;
4588 
4589   for (i = 0; i &lt; n_threads; i++) {
4590     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4591     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4592     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4593     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4594     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4595     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4596     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4597     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4598 
4599     tasks[i].width = width;
4600     tasks[i].height = (i + 1) * lines_per_thread;
4601     tasks[i].height = MIN (tasks[i].height, height);
4602     tasks[i].height -= i * lines_per_thread;
4603 
4604     tasks_p[i] = &amp;tasks[i];
4605   }
4606 
4607   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4608       (GstParallelizedTaskFunc) convert_Y444_YUY2_task, (gpointer) tasks_p);
4609 
4610   convert_fill_border (convert, dest);
4611 }
4612 
4613 static void
4614 convert_Y444_UYVY_task (FConvertPlaneTask * task)
4615 {
4616   video_orc_convert_Y444_UYVY (task-&gt;d, task-&gt;dstride, task-&gt;s,
4617       task-&gt;sstride,
4618       task-&gt;su,
4619       task-&gt;sustride, task-&gt;sv, task-&gt;svstride, task-&gt;width / 2, task-&gt;height);
4620 }
4621 
4622 static void
4623 convert_Y444_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4624     GstVideoFrame * dest)
4625 {
4626   gint width = convert-&gt;in_width;
4627   gint height = convert-&gt;in_height;
4628   guint8 *sy, *su, *sv, *d;
4629   FConvertPlaneTask *tasks;
4630   FConvertPlaneTask **tasks_p;
4631   gint n_threads;
4632   gint lines_per_thread;
4633   gint i;
4634 
4635   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4636   sy += convert-&gt;in_x;
4637   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4638   su += convert-&gt;in_x;
4639   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4640   sv += convert-&gt;in_x;
4641 
4642   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4643   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4644 
4645   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4646   tasks = g_newa (FConvertPlaneTask, n_threads);
4647   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4648 
4649   lines_per_thread = (height + n_threads - 1) / n_threads;
4650 
4651   for (i = 0; i &lt; n_threads; i++) {
4652     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4653     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4654     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4655     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4656     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4657     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4658     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4659     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4660 
4661     tasks[i].width = width;
4662     tasks[i].height = (i + 1) * lines_per_thread;
4663     tasks[i].height = MIN (tasks[i].height, height);
4664     tasks[i].height -= i * lines_per_thread;
4665 
4666     tasks_p[i] = &amp;tasks[i];
4667   }
4668 
4669   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4670       (GstParallelizedTaskFunc) convert_Y444_UYVY_task, (gpointer) tasks_p);
4671 
4672   convert_fill_border (convert, dest);
4673 }
4674 
4675 static void
4676 convert_Y444_AYUV_task (FConvertPlaneTask * task)
4677 {
4678   video_orc_convert_Y444_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
4679       task-&gt;sstride,
4680       task-&gt;su,
4681       task-&gt;sustride,
4682       task-&gt;sv, task-&gt;svstride, task-&gt;alpha, task-&gt;width, task-&gt;height);
4683 }
4684 
4685 static void
4686 convert_Y444_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
4687     GstVideoFrame * dest)
4688 {
4689   gint width = convert-&gt;in_width;
4690   gint height = convert-&gt;in_height;
4691   guint8 *sy, *su, *sv, *d;
4692   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
4693   FConvertPlaneTask *tasks;
4694   FConvertPlaneTask **tasks_p;
4695   gint n_threads;
4696   gint lines_per_thread;
4697   gint i;
4698 
4699   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4700   sy += convert-&gt;in_x;
4701   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4702   su += convert-&gt;in_x;
4703   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4704   sv += convert-&gt;in_x;
4705 
4706   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4707   d += convert-&gt;out_x * 4;
4708 
4709   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4710   tasks = g_newa (FConvertPlaneTask, n_threads);
4711   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4712 
4713   lines_per_thread = (height + n_threads - 1) / n_threads;
4714 
4715   for (i = 0; i &lt; n_threads; i++) {
4716     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4717     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4718     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4719     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4720     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4721     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4722     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4723     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4724 
4725     tasks[i].width = width;
4726     tasks[i].height = (i + 1) * lines_per_thread;
4727     tasks[i].height = MIN (tasks[i].height, height);
4728     tasks[i].height -= i * lines_per_thread;
4729     tasks[i].alpha = alpha;
4730 
4731     tasks_p[i] = &amp;tasks[i];
4732   }
4733 
4734   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4735       (GstParallelizedTaskFunc) convert_Y444_AYUV_task, (gpointer) tasks_p);
4736 
4737   convert_fill_border (convert, dest);
4738 }
4739 
4740 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
4741 static void
4742 convert_AYUV_ARGB_task (FConvertPlaneTask * task)
4743 {
4744   video_orc_convert_AYUV_ARGB (task-&gt;d, task-&gt;dstride, task-&gt;s,
4745       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4746       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4747       task-&gt;width, task-&gt;height);
4748 }
4749 
4750 static void
4751 convert_AYUV_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
4752     GstVideoFrame * dest)
4753 {
4754   gint width = convert-&gt;in_width;
4755   gint height = convert-&gt;in_height;
4756   MatrixData *data = &amp;convert-&gt;convert_matrix;
4757   guint8 *s, *d;
4758   FConvertPlaneTask *tasks;
4759   FConvertPlaneTask **tasks_p;
4760   gint n_threads;
4761   gint lines_per_thread;
4762   gint i;
4763 
4764   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4765   s += (convert-&gt;in_x * 4);
4766   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4767   d += (convert-&gt;out_x * 4);
4768 
4769   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4770   tasks = g_newa (FConvertPlaneTask, n_threads);
4771   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4772 
4773   lines_per_thread = (height + n_threads - 1) / n_threads;
4774 
4775   for (i = 0; i &lt; n_threads; i++) {
4776     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4777     tasks[i].sstride = FRAME_GET_STRIDE (src);
4778     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4779     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4780 
4781     tasks[i].width = width;
4782     tasks[i].height = (i + 1) * lines_per_thread;
4783     tasks[i].height = MIN (tasks[i].height, height);
4784     tasks[i].height -= i * lines_per_thread;
4785     tasks[i].data = data;
4786 
4787     tasks_p[i] = &amp;tasks[i];
4788   }
4789 
4790   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4791       (GstParallelizedTaskFunc) convert_AYUV_ARGB_task, (gpointer) tasks_p);
4792 
4793   convert_fill_border (convert, dest);
4794 }
4795 
4796 static void
4797 convert_AYUV_BGRA_task (FConvertPlaneTask * task)
4798 {
4799   video_orc_convert_AYUV_BGRA (task-&gt;d, task-&gt;dstride, task-&gt;s,
4800       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4801       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4802       task-&gt;width, task-&gt;height);
4803 }
4804 
4805 static void
4806 convert_AYUV_BGRA (GstVideoConverter * convert, const GstVideoFrame * src,
4807     GstVideoFrame * dest)
4808 {
4809   gint width = convert-&gt;in_width;
4810   gint height = convert-&gt;in_height;
4811   MatrixData *data = &amp;convert-&gt;convert_matrix;
4812   guint8 *s, *d;
4813   FConvertPlaneTask *tasks;
4814   FConvertPlaneTask **tasks_p;
4815   gint n_threads;
4816   gint lines_per_thread;
4817   gint i;
4818 
4819   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4820   s += (convert-&gt;in_x * 4);
4821   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4822   d += (convert-&gt;out_x * 4);
4823 
4824   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4825   tasks = g_newa (FConvertPlaneTask, n_threads);
4826   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4827 
4828   lines_per_thread = (height + n_threads - 1) / n_threads;
4829 
4830   for (i = 0; i &lt; n_threads; i++) {
4831     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4832     tasks[i].sstride = FRAME_GET_STRIDE (src);
4833     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4834     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4835 
4836     tasks[i].width = width;
4837     tasks[i].height = (i + 1) * lines_per_thread;
4838     tasks[i].height = MIN (tasks[i].height, height);
4839     tasks[i].height -= i * lines_per_thread;
4840     tasks[i].data = data;
4841 
4842     tasks_p[i] = &amp;tasks[i];
4843   }
4844 
4845   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4846       (GstParallelizedTaskFunc) convert_AYUV_BGRA_task, (gpointer) tasks_p);
4847 
4848   convert_fill_border (convert, dest);
4849 }
4850 
4851 static void
4852 convert_AYUV_ABGR_task (FConvertPlaneTask * task)
4853 {
4854   video_orc_convert_AYUV_ABGR (task-&gt;d, task-&gt;dstride, task-&gt;s,
4855       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4856       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4857       task-&gt;width, task-&gt;height);
4858 }
4859 
4860 static void
4861 convert_AYUV_ABGR (GstVideoConverter * convert, const GstVideoFrame * src,
4862     GstVideoFrame * dest)
4863 {
4864   gint width = convert-&gt;in_width;
4865   gint height = convert-&gt;in_height;
4866   MatrixData *data = &amp;convert-&gt;convert_matrix;
4867   guint8 *s, *d;
4868   FConvertPlaneTask *tasks;
4869   FConvertPlaneTask **tasks_p;
4870   gint n_threads;
4871   gint lines_per_thread;
4872   gint i;
4873 
4874   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4875   s += (convert-&gt;in_x * 4);
4876   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4877   d += (convert-&gt;out_x * 4);
4878 
4879   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4880   tasks = g_newa (FConvertPlaneTask, n_threads);
4881   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4882 
4883   lines_per_thread = (height + n_threads - 1) / n_threads;
4884 
4885   for (i = 0; i &lt; n_threads; i++) {
4886     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4887     tasks[i].sstride = FRAME_GET_STRIDE (src);
4888     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4889     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4890 
4891     tasks[i].width = width;
4892     tasks[i].height = (i + 1) * lines_per_thread;
4893     tasks[i].height = MIN (tasks[i].height, height);
4894     tasks[i].height -= i * lines_per_thread;
4895     tasks[i].data = data;
4896 
4897     tasks_p[i] = &amp;tasks[i];
4898   }
4899 
4900   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4901       (GstParallelizedTaskFunc) convert_AYUV_ABGR_task, (gpointer) tasks_p);
4902 
4903   convert_fill_border (convert, dest);
4904 }
4905 
4906 static void
4907 convert_AYUV_RGBA_task (FConvertPlaneTask * task)
4908 {
4909   video_orc_convert_AYUV_RGBA (task-&gt;d, task-&gt;dstride, task-&gt;s,
4910       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4911       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4912       task-&gt;width, task-&gt;height);
4913 }
4914 
4915 static void
4916 convert_AYUV_RGBA (GstVideoConverter * convert, const GstVideoFrame * src,
4917     GstVideoFrame * dest)
4918 {
4919   gint width = convert-&gt;in_width;
4920   gint height = convert-&gt;in_height;
4921   MatrixData *data = &amp;convert-&gt;convert_matrix;
4922   guint8 *s, *d;
4923   FConvertPlaneTask *tasks;
4924   FConvertPlaneTask **tasks_p;
4925   gint n_threads;
4926   gint lines_per_thread;
4927   gint i;
4928 
4929   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4930   s += (convert-&gt;in_x * 4);
4931   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4932   d += (convert-&gt;out_x * 4);
4933 
4934   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4935   tasks = g_newa (FConvertPlaneTask, n_threads);
4936   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4937 
4938   lines_per_thread = (height + n_threads - 1) / n_threads;
4939 
4940   for (i = 0; i &lt; n_threads; i++) {
4941     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4942     tasks[i].sstride = FRAME_GET_STRIDE (src);
4943     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4944     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4945 
4946     tasks[i].width = width;
4947     tasks[i].height = (i + 1) * lines_per_thread;
4948     tasks[i].height = MIN (tasks[i].height, height);
4949     tasks[i].height -= i * lines_per_thread;
4950     tasks[i].data = data;
4951 
4952     tasks_p[i] = &amp;tasks[i];
4953   }
4954 
4955   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4956       (GstParallelizedTaskFunc) convert_AYUV_RGBA_task, (gpointer) tasks_p);
4957 
4958   convert_fill_border (convert, dest);
4959 }
4960 #endif
4961 
4962 static void
4963 convert_I420_BGRA_task (FConvertTask * task)
4964 {
4965   gint i;
4966 
4967   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
4968     guint8 *sy, *su, *sv, *d;
4969 
4970     d = FRAME_GET_LINE (task-&gt;dest, i + task-&gt;out_y);
4971     d += (task-&gt;out_x * 4);
4972     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
4973     sy += task-&gt;in_x;
4974     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
4975     su += (task-&gt;in_x &gt;&gt; 1);
4976     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
4977     sv += (task-&gt;in_x &gt;&gt; 1);
4978 
4979 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
4980     video_orc_convert_I420_BGRA (d, sy, su, sv,
4981         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4982         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4983         task-&gt;width);
4984 #else
4985     video_orc_convert_I420_ARGB (d, sy, su, sv,
4986         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4987         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4988         task-&gt;width);
4989 #endif
4990   }
4991 }
4992 
4993 static void
4994 convert_I420_BGRA (GstVideoConverter * convert, const GstVideoFrame * src,
4995     GstVideoFrame * dest)
4996 {
4997   int i;
4998   gint width = convert-&gt;in_width;
4999   gint height = convert-&gt;in_height;
5000   MatrixData *data = &amp;convert-&gt;convert_matrix;
5001   FConvertTask *tasks;
5002   FConvertTask **tasks_p;
5003   gint n_threads;
5004   gint lines_per_thread;
5005 
5006   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5007   tasks = g_newa (FConvertTask, n_threads);
5008   tasks_p = g_newa (FConvertTask *, n_threads);
5009 
5010   lines_per_thread = (height + n_threads - 1) / n_threads;
5011 
5012   for (i = 0; i &lt; n_threads; i++) {
5013     tasks[i].src = src;
5014     tasks[i].dest = dest;
5015 
5016     tasks[i].width = width;
5017     tasks[i].data = data;
5018     tasks[i].in_x = convert-&gt;in_x;
5019     tasks[i].in_y = convert-&gt;in_y;
5020     tasks[i].out_x = convert-&gt;out_x;
5021     tasks[i].out_y = convert-&gt;out_y;
5022 
5023     tasks[i].height_0 = i * lines_per_thread;
5024     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5025     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5026 
5027     tasks_p[i] = &amp;tasks[i];
5028   }
5029 
5030   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5031       (GstParallelizedTaskFunc) convert_I420_BGRA_task, (gpointer) tasks_p);
5032 
5033   convert_fill_border (convert, dest);
5034 }
5035 
5036 static void
5037 convert_I420_ARGB_task (FConvertTask * task)
5038 {
5039   gint i;
5040 
5041   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
5042     guint8 *sy, *su, *sv, *d;
5043 
5044     d = FRAME_GET_LINE (task-&gt;dest, i + task-&gt;out_y);
5045     d += (task-&gt;out_x * 4);
5046     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
5047     sy += task-&gt;in_x;
5048     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5049     su += (task-&gt;in_x &gt;&gt; 1);
5050     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5051     sv += (task-&gt;in_x &gt;&gt; 1);
5052 
5053 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5054     video_orc_convert_I420_ARGB (d, sy, su, sv,
5055         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5056         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5057         task-&gt;width);
5058 #else
5059     video_orc_convert_I420_BGRA (d, sy, su, sv,
5060         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5061         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5062         task-&gt;width);
5063 #endif
5064   }
5065 }
5066 
5067 static void
5068 convert_I420_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
5069     GstVideoFrame * dest)
5070 {
5071   int i;
5072   gint width = convert-&gt;in_width;
5073   gint height = convert-&gt;in_height;
5074   MatrixData *data = &amp;convert-&gt;convert_matrix;
5075   FConvertTask *tasks;
5076   FConvertTask **tasks_p;
5077   gint n_threads;
5078   gint lines_per_thread;
5079 
5080   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5081   tasks = g_newa (FConvertTask, n_threads);
5082   tasks_p = g_newa (FConvertTask *, n_threads);
5083 
5084   lines_per_thread = (height + n_threads - 1) / n_threads;
5085 
5086   for (i = 0; i &lt; n_threads; i++) {
5087     tasks[i].src = src;
5088     tasks[i].dest = dest;
5089 
5090     tasks[i].width = width;
5091     tasks[i].data = data;
5092     tasks[i].in_x = convert-&gt;in_x;
5093     tasks[i].in_y = convert-&gt;in_y;
5094     tasks[i].out_x = convert-&gt;out_x;
5095     tasks[i].out_y = convert-&gt;out_y;
5096 
5097     tasks[i].height_0 = i * lines_per_thread;
5098     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5099     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5100 
5101     tasks_p[i] = &amp;tasks[i];
5102   }
5103 
5104   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5105       (GstParallelizedTaskFunc) convert_I420_ARGB_task, (gpointer) tasks_p);
5106 
5107   convert_fill_border (convert, dest);
5108 }
5109 
5110 static void
5111 convert_I420_pack_ARGB_task (FConvertTask * task)
5112 {
5113   gint i;
5114   gpointer d[GST_VIDEO_MAX_PLANES];
5115 
5116   d[0] = FRAME_GET_LINE (task-&gt;dest, 0);
5117   d[0] =
5118       (guint8 *) d[0] +
5119       task-&gt;out_x * GST_VIDEO_FORMAT_INFO_PSTRIDE (task-&gt;dest-&gt;info.finfo, 0);
5120 
5121   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
5122     guint8 *sy, *su, *sv;
5123 
5124     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
5125     sy += task-&gt;in_x;
5126     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5127     su += (task-&gt;in_x &gt;&gt; 1);
5128     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5129     sv += (task-&gt;in_x &gt;&gt; 1);
5130 
5131 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5132     video_orc_convert_I420_ARGB (task-&gt;tmpline, sy, su, sv,
5133         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5134         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5135         task-&gt;width);
5136 #else
5137     video_orc_convert_I420_BGRA (task-&gt;tmpline, sy, su, sv,
5138         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5139         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5140         task-&gt;width);
5141 #endif
5142     task-&gt;dest-&gt;info.finfo-&gt;pack_func (task-&gt;dest-&gt;info.finfo,
5143         (GST_VIDEO_FRAME_IS_INTERLACED (task-&gt;dest) ?
5144             GST_VIDEO_PACK_FLAG_INTERLACED :
5145             GST_VIDEO_PACK_FLAG_NONE),
5146         task-&gt;tmpline, 0, d, task-&gt;dest-&gt;info.stride,
5147         task-&gt;dest-&gt;info.chroma_site, i + task-&gt;out_y, task-&gt;width);
5148   }
5149 }
5150 
5151 static void
5152 convert_I420_pack_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
5153     GstVideoFrame * dest)
5154 {
5155   int i;
5156   gint width = convert-&gt;in_width;
5157   gint height = convert-&gt;in_height;
5158   MatrixData *data = &amp;convert-&gt;convert_matrix;
5159   FConvertTask *tasks;
5160   FConvertTask **tasks_p;
5161   gint n_threads;
5162   gint lines_per_thread;
5163 
5164   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5165   tasks = g_newa (FConvertTask, n_threads);
5166   tasks_p = g_newa (FConvertTask *, n_threads);
5167 
5168   lines_per_thread = (height + n_threads - 1) / n_threads;
5169 
5170   for (i = 0; i &lt; n_threads; i++) {
5171     tasks[i].src = src;
5172     tasks[i].dest = dest;
5173 
5174     tasks[i].width = width;
5175     tasks[i].data = data;
5176     tasks[i].in_x = convert-&gt;in_x;
5177     tasks[i].in_y = convert-&gt;in_y;
5178     tasks[i].out_x = convert-&gt;out_x;
5179     tasks[i].out_y = convert-&gt;out_y;
5180     tasks[i].tmpline = convert-&gt;tmpline[i];
5181 
5182     tasks[i].height_0 = i * lines_per_thread;
5183     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5184     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5185 
5186     tasks_p[i] = &amp;tasks[i];
5187   }
5188 
5189   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5190       (GstParallelizedTaskFunc) convert_I420_pack_ARGB_task,
5191       (gpointer) tasks_p);
5192 
5193   convert_fill_border (convert, dest);
5194 }
5195 
5196 static void
5197 memset_u24 (guint8 * data, guint8 col[3], unsigned int n)
5198 {
5199   unsigned int i;
5200 
5201   for (i = 0; i &lt; n; i++) {
5202     data[0] = col[0];
5203     data[1] = col[1];
5204     data[2] = col[2];
5205     data += 3;
5206   }
5207 }
5208 
5209 static void
5210 memset_u32_16 (guint8 * data, guint8 col[4], unsigned int n)
5211 {
5212   unsigned int i;
5213 
5214   for (i = 0; i &lt; n; i += 2) {
5215     data[0] = col[0];
5216     data[1] = col[1];
5217     if (i + 1 &lt; n) {
5218       data[2] = col[2];
5219       data[3] = col[3];
5220     }
5221     data += 4;
5222   }
5223 }
5224 
5225 #define MAKE_BORDER_FUNC(func)                                                  \
5226         for (i = 0; i &lt; out_y; i++)                                             \
5227           func (FRAME_GET_PLANE_LINE (dest, k, i), col, out_maxwidth);          \
5228         if (rb_width || lb_width) {                                             \
5229           for (i = 0; i &lt; out_height; i++) {                                    \
5230             guint8 *d = FRAME_GET_PLANE_LINE (dest, k, i + out_y);              \
5231             if (lb_width)                                                       \
5232               func (d, col, lb_width);                                          \
5233             if (rb_width)                                                       \
5234               func (d + (pstride * r_border), col, rb_width);                   \
5235           }                                                                     \
5236         }                                                                       \
5237         for (i = out_y + out_height; i &lt; out_maxheight; i++)                    \
5238           func (FRAME_GET_PLANE_LINE (dest, k, i), col, out_maxwidth);          \
5239 
5240 static void
5241 convert_fill_border (GstVideoConverter * convert, GstVideoFrame * dest)
5242 {
5243   int k, n_planes;
5244   const GstVideoFormatInfo *out_finfo;
5245 
5246   if (!convert-&gt;fill_border || !convert-&gt;borderline)
5247     return;
5248 
5249   out_finfo = convert-&gt;out_info.finfo;
5250 
5251   n_planes = GST_VIDEO_FRAME_N_PLANES (dest);
5252 
5253   for (k = 0; k &lt; n_planes; k++) {
5254     gint i, out_x, out_y, out_width, out_height, pstride, pgroup;
5255     gint r_border, lb_width, rb_width;
5256     gint out_maxwidth, out_maxheight;
5257     gpointer borders;
5258 
5259     out_x = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_x);
5260     out_y = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k, convert-&gt;out_y);
5261     out_width =
5262         GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_width);
5263     out_height =
5264         GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k, convert-&gt;out_height);
5265     out_maxwidth =
5266         GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_maxwidth);
5267     out_maxheight =
5268         GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k,
5269         convert-&gt;out_maxheight);
5270 
5271     pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, k);
5272 
5273     switch (GST_VIDEO_FORMAT_INFO_FORMAT (out_finfo)) {
5274       case GST_VIDEO_FORMAT_YUY2:
5275       case GST_VIDEO_FORMAT_YVYU:
5276       case GST_VIDEO_FORMAT_UYVY:
5277         pgroup = 42;
5278         out_maxwidth = GST_ROUND_UP_2 (out_maxwidth);
5279         break;
5280       default:
5281         pgroup = pstride;
5282         break;
5283     }
5284 
5285     r_border = out_x + out_width;
5286     rb_width = out_maxwidth - r_border;
5287     lb_width = out_x;
5288 
5289     borders = &amp;convert-&gt;borders[k];
5290 
5291     switch (pgroup) {
5292       case 1:
5293       {
5294         guint8 col = ((guint8 *) borders)[0];
5295         MAKE_BORDER_FUNC (memset);
5296         break;
5297       }
5298       case 2:
5299       {
5300         guint16 col = ((guint16 *) borders)[0];
5301         MAKE_BORDER_FUNC (video_orc_splat_u16);
5302         break;
5303       }
5304       case 3:
5305       {
5306         guint8 col[3];
5307         col[0] = ((guint8 *) borders)[0];
5308         col[1] = ((guint8 *) borders)[1];
5309         col[2] = ((guint8 *) borders)[2];
5310         MAKE_BORDER_FUNC (memset_u24);
5311         break;
5312       }
5313       case 4:
5314       {
5315         guint32 col = ((guint32 *) borders)[0];
5316         MAKE_BORDER_FUNC (video_orc_splat_u32);
5317         break;
5318       }
5319       case 8:
5320       {
5321         guint64 col = ((guint64 *) borders)[0];
5322         MAKE_BORDER_FUNC (video_orc_splat_u64);
5323         break;
5324       }
5325       case 42:
5326       {
5327         guint8 col[4];
5328         col[0] = ((guint8 *) borders)[0];
5329         col[2] = ((guint8 *) borders)[2];
5330         col[1] = ((guint8 *) borders)[r_border &amp; 1 ? 3 : 1];
5331         col[3] = ((guint8 *) borders)[r_border &amp; 1 ? 1 : 3];
5332         MAKE_BORDER_FUNC (memset_u32_16);
5333         break;
5334       }
5335       default:
5336         break;
5337     }
5338   }
5339 }
5340 
5341 typedef struct
5342 {
5343   const guint8 *s, *s2;
5344   guint8 *d, *d2;
5345   gint sstride, dstride;
5346   gint width, height;
5347   gint fill;
5348 } FSimpleScaleTask;
5349 
5350 static void
5351 convert_plane_fill_task (FSimpleScaleTask * task)
5352 {
5353   video_orc_memset_2d (task-&gt;d, task-&gt;dstride,
5354       task-&gt;fill, task-&gt;width, task-&gt;height);
5355 }
5356 
5357 static void
5358 convert_plane_fill (GstVideoConverter * convert,
5359     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5360 {
5361   guint8 *d;
5362   FSimpleScaleTask *tasks;
5363   FSimpleScaleTask **tasks_p;
5364   gint n_threads;
5365   gint lines_per_thread;
5366   gint i;
5367 
5368   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5369   d += convert-&gt;fout_x[plane];
5370 
5371   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5372   tasks = g_newa (FSimpleScaleTask, n_threads);
5373   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5374   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5375 
5376   for (i = 0; i &lt; n_threads; i++) {
5377     tasks[i].d = d + i * lines_per_thread * convert-&gt;fout_width[plane];
5378 
5379     tasks[i].fill = convert-&gt;ffill[plane];
5380     tasks[i].width = convert-&gt;fout_width[plane];
5381     tasks[i].height = (i + 1) * lines_per_thread;
5382     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5383     tasks[i].height -= i * lines_per_thread;
5384     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5385 
5386     tasks_p[i] = &amp;tasks[i];
5387   }
5388 
5389   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5390       (GstParallelizedTaskFunc) convert_plane_fill_task, (gpointer) tasks_p);
5391 }
5392 
5393 static void
5394 convert_plane_h_double_task (FSimpleScaleTask * task)
5395 {
5396   video_orc_planar_chroma_422_444 (task-&gt;d,
5397       task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
5398 }
5399 
5400 static void
5401 convert_plane_h_double (GstVideoConverter * convert,
5402     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5403 {
5404   guint8 *s, *d;
5405   gint splane = convert-&gt;fsplane[plane];
5406   FSimpleScaleTask *tasks;
5407   FSimpleScaleTask **tasks_p;
5408   gint n_threads;
5409   gint lines_per_thread;
5410   gint i;
5411 
5412   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5413   s += convert-&gt;fin_x[splane];
5414   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5415   d += convert-&gt;fout_x[plane];
5416 
5417   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5418   tasks = g_newa (FSimpleScaleTask, n_threads);
5419   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5420   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5421 
5422   for (i = 0; i &lt; n_threads; i++) {
5423     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5424     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5425 
5426     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
5427     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
5428 
5429     tasks[i].width = convert-&gt;fout_width[plane];
5430     tasks[i].height = (i + 1) * lines_per_thread;
5431     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5432     tasks[i].height -= i * lines_per_thread;
5433 
5434     tasks_p[i] = &amp;tasks[i];
5435   }
5436 
5437   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5438       (GstParallelizedTaskFunc) convert_plane_h_double_task,
5439       (gpointer) tasks_p);
5440 }
5441 
5442 static void
5443 convert_plane_h_halve_task (FSimpleScaleTask * task)
5444 {
5445   video_orc_planar_chroma_444_422 (task-&gt;d,
5446       task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height);
5447 }
5448 
5449 static void
5450 convert_plane_h_halve (GstVideoConverter * convert,
5451     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5452 {
5453   guint8 *s, *d;
5454   gint splane = convert-&gt;fsplane[plane];
5455   FSimpleScaleTask *tasks;
5456   FSimpleScaleTask **tasks_p;
5457   gint n_threads;
5458   gint lines_per_thread;
5459   gint i;
5460 
5461   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5462   s += convert-&gt;fin_x[splane];
5463   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5464   d += convert-&gt;fout_x[plane];
5465 
5466   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5467   tasks = g_newa (FSimpleScaleTask, n_threads);
5468   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5469   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5470 
5471   for (i = 0; i &lt; n_threads; i++) {
5472     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5473     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5474 
5475     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
5476     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
5477 
5478     tasks[i].width = convert-&gt;fout_width[plane];
5479     tasks[i].height = (i + 1) * lines_per_thread;
5480     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5481     tasks[i].height -= i * lines_per_thread;
5482 
5483     tasks_p[i] = &amp;tasks[i];
5484   }
5485 
5486   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5487       (GstParallelizedTaskFunc) convert_plane_h_halve_task, (gpointer) tasks_p);
5488 }
5489 
5490 static void
5491 convert_plane_v_double_task (FSimpleScaleTask * task)
5492 {
5493   video_orc_planar_chroma_420_422 (task-&gt;d, 2 * task-&gt;dstride, task-&gt;d2,
5494       2 * task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height / 2);
5495 }
5496 
5497 static void
5498 convert_plane_v_double (GstVideoConverter * convert,
5499     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5500 {
5501   guint8 *s, *d1, *d2;
5502   gint ds, splane = convert-&gt;fsplane[plane];
5503   FSimpleScaleTask *tasks;
5504   FSimpleScaleTask **tasks_p;
5505   gint n_threads;
5506   gint lines_per_thread;
5507   gint i;
5508 
5509   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5510   s += convert-&gt;fin_x[splane];
5511   d1 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5512   d1 += convert-&gt;fout_x[plane];
5513   d2 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane] + 1);
5514   d2 += convert-&gt;fout_x[plane];
5515   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5516 
5517   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5518   tasks = g_newa (FSimpleScaleTask, n_threads);
5519   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5520   lines_per_thread =
5521       GST_ROUND_UP_2 ((convert-&gt;fout_height[plane] + n_threads -
5522           1) / n_threads);
5523 
5524   for (i = 0; i &lt; n_threads; i++) {
5525     tasks[i].d = d1 + i * lines_per_thread * ds;
5526     tasks[i].d2 = d2 + i * lines_per_thread * ds;
5527     tasks[i].dstride = ds;
5528     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5529     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride / 2;
5530 
5531     tasks[i].width = convert-&gt;fout_width[plane];
5532     tasks[i].height = (i + 1) * lines_per_thread;
5533     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5534     tasks[i].height -= i * lines_per_thread;
5535 
5536     tasks_p[i] = &amp;tasks[i];
5537   }
5538 
5539   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5540       (GstParallelizedTaskFunc) convert_plane_v_double_task,
5541       (gpointer) tasks_p);
5542 }
5543 
5544 static void
5545 convert_plane_v_halve_task (FSimpleScaleTask * task)
5546 {
5547   video_orc_planar_chroma_422_420 (task-&gt;d, task-&gt;dstride, task-&gt;s,
5548       2 * task-&gt;sstride, task-&gt;s2, 2 * task-&gt;sstride, task-&gt;width,
5549       task-&gt;height);
5550 }
5551 
5552 static void
5553 convert_plane_v_halve (GstVideoConverter * convert,
5554     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5555 {
5556   guint8 *s1, *s2, *d;
5557   gint ss, ds, splane = convert-&gt;fsplane[plane];
5558   FSimpleScaleTask *tasks;
5559   FSimpleScaleTask **tasks_p;
5560   gint n_threads;
5561   gint lines_per_thread;
5562   gint i;
5563 
5564   s1 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5565   s1 += convert-&gt;fin_x[splane];
5566   s2 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane] + 1);
5567   s2 += convert-&gt;fin_x[splane];
5568   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5569   d += convert-&gt;fout_x[plane];
5570 
5571   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5572   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5573 
5574   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5575   tasks = g_newa (FSimpleScaleTask, n_threads);
5576   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5577   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5578 
5579   for (i = 0; i &lt; n_threads; i++) {
5580     tasks[i].d = d + i * lines_per_thread * ds;
5581     tasks[i].dstride = ds;
5582     tasks[i].s = s1 + i * lines_per_thread * ss * 2;
5583     tasks[i].s2 = s2 + i * lines_per_thread * ss * 2;
5584     tasks[i].sstride = ss;
5585 
5586     tasks[i].width = convert-&gt;fout_width[plane];
5587     tasks[i].height = (i + 1) * lines_per_thread;
5588     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5589     tasks[i].height -= i * lines_per_thread;
5590 
5591     tasks_p[i] = &amp;tasks[i];
5592   }
5593 
5594   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5595       (GstParallelizedTaskFunc) convert_plane_v_halve_task, (gpointer) tasks_p);
5596 }
5597 
5598 static void
5599 convert_plane_hv_double_task (FSimpleScaleTask * task)
5600 {
5601   video_orc_planar_chroma_420_444 (task-&gt;d, 2 * task-&gt;dstride, task-&gt;d2,
5602       2 * task-&gt;dstride, task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2,
5603       task-&gt;height / 2);
5604 }
5605 
5606 static void
5607 convert_plane_hv_double (GstVideoConverter * convert,
5608     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5609 {
5610   guint8 *s, *d1, *d2;
5611   gint ss, ds, splane = convert-&gt;fsplane[plane];
5612   FSimpleScaleTask *tasks;
5613   FSimpleScaleTask **tasks_p;
5614   gint n_threads;
5615   gint lines_per_thread;
5616   gint i;
5617 
5618   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5619   s += convert-&gt;fin_x[splane];
5620   d1 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5621   d1 += convert-&gt;fout_x[plane];
5622   d2 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane] + 1);
5623   d2 += convert-&gt;fout_x[plane];
5624   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5625   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5626 
5627   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5628   tasks = g_newa (FSimpleScaleTask, n_threads);
5629   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5630   lines_per_thread =
5631       GST_ROUND_UP_2 ((convert-&gt;fout_height[plane] + n_threads -
5632           1) / n_threads);
5633 
5634   for (i = 0; i &lt; n_threads; i++) {
5635     tasks[i].d = d1 + i * lines_per_thread * ds;
5636     tasks[i].d2 = d2 + i * lines_per_thread * ds;
5637     tasks[i].dstride = ds;
5638     tasks[i].sstride = ss;
5639     tasks[i].s = s + i * lines_per_thread * ss / 2;
5640 
5641     tasks[i].width = convert-&gt;fout_width[plane];
5642     tasks[i].height = (i + 1) * lines_per_thread;
5643     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5644     tasks[i].height -= i * lines_per_thread;
5645 
5646     tasks_p[i] = &amp;tasks[i];
5647   }
5648 
5649   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5650       (GstParallelizedTaskFunc) convert_plane_hv_double_task,
5651       (gpointer) tasks_p);
5652 }
5653 
5654 static void
5655 convert_plane_hv_halve_task (FSimpleScaleTask * task)
5656 {
5657   video_orc_planar_chroma_444_420 (task-&gt;d, task-&gt;dstride, task-&gt;s,
5658       2 * task-&gt;sstride, task-&gt;s2, 2 * task-&gt;sstride, task-&gt;width,
5659       task-&gt;height);
5660 }
5661 
5662 static void
5663 convert_plane_hv_halve (GstVideoConverter * convert,
5664     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5665 {
5666   guint8 *s1, *s2, *d;
5667   gint ss, ds, splane = convert-&gt;fsplane[plane];
5668   FSimpleScaleTask *tasks;
5669   FSimpleScaleTask **tasks_p;
5670   gint n_threads;
5671   gint lines_per_thread;
5672   gint i;
5673 
5674   s1 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5675   s1 += convert-&gt;fin_x[splane];
5676   s2 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane] + 1);
5677   s2 += convert-&gt;fin_x[splane];
5678   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5679   d += convert-&gt;fout_x[plane];
5680   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5681   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5682 
5683   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5684   tasks = g_newa (FSimpleScaleTask, n_threads);
5685   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5686   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5687 
5688   for (i = 0; i &lt; n_threads; i++) {
5689     tasks[i].d = d + i * lines_per_thread * ds;
5690     tasks[i].dstride = ds;
5691     tasks[i].s = s1 + i * lines_per_thread * ss * 2;
5692     tasks[i].s2 = s2 + i * lines_per_thread * ss * 2;
5693     tasks[i].sstride = ss;
5694 
5695     tasks[i].width = convert-&gt;fout_width[plane];
5696     tasks[i].height = (i + 1) * lines_per_thread;
5697     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5698     tasks[i].height -= i * lines_per_thread;
5699 
5700     tasks_p[i] = &amp;tasks[i];
5701   }
5702 
5703   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5704       (GstParallelizedTaskFunc) convert_plane_hv_halve_task,
5705       (gpointer) tasks_p);
5706 }
5707 
5708 typedef struct
5709 {
5710   GstVideoScaler *h_scaler, *v_scaler;
5711   GstVideoFormat format;
5712   const guint8 *s;
5713   guint8 *d;
5714   gint sstride, dstride;
5715   guint x, y, w, h;
5716 } FScaleTask;
5717 
5718 static void
5719 convert_plane_hv_task (FScaleTask * task)
5720 {
5721   gst_video_scaler_2d (task-&gt;h_scaler, task-&gt;v_scaler, task-&gt;format,
5722       (guint8 *) task-&gt;s, task-&gt;sstride,
5723       task-&gt;d, task-&gt;dstride, task-&gt;x, task-&gt;y, task-&gt;w, task-&gt;h);
5724 }
5725 
5726 static void
5727 convert_plane_hv (GstVideoConverter * convert,
5728     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5729 {
5730   gint in_x, in_y, out_x, out_y, out_width, out_height;
5731   GstVideoFormat format;
5732   gint splane = convert-&gt;fsplane[plane];
5733   guint8 *s, *d;
5734   gint sstride, dstride;
5735   FScaleTask *tasks;
5736   FScaleTask **tasks_p;
5737   gint i, n_threads, lines_per_thread;
5738 
5739   in_x = convert-&gt;fin_x[splane];
5740   in_y = convert-&gt;fin_y[splane];
5741   out_x = convert-&gt;fout_x[plane];
5742   out_y = convert-&gt;fout_y[plane];
5743   out_width = convert-&gt;fout_width[plane];
5744   out_height = convert-&gt;fout_height[plane];
5745   format = convert-&gt;fformat[plane];
5746 
5747   s = FRAME_GET_PLANE_LINE (src, splane, in_y);
5748   s += in_x;
5749   d = FRAME_GET_PLANE_LINE (dest, plane, out_y);
5750   d += out_x;
5751 
5752   sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5753   dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5754 
5755   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5756   tasks = g_newa (FScaleTask, n_threads);
5757   tasks_p = g_newa (FScaleTask *, n_threads);
5758 
5759   lines_per_thread = (out_height + n_threads - 1) / n_threads;
5760 
5761   for (i = 0; i &lt; n_threads; i++) {
5762     tasks[i].h_scaler =
5763         convert-&gt;fh_scaler[plane].scaler ? convert-&gt;
5764         fh_scaler[plane].scaler[i] : NULL;
5765     tasks[i].v_scaler =
5766         convert-&gt;fv_scaler[plane].scaler ? convert-&gt;
5767         fv_scaler[plane].scaler[i] : NULL;
5768     tasks[i].format = format;
5769     tasks[i].s = s;
5770     tasks[i].d = d;
5771     tasks[i].sstride = sstride;
5772     tasks[i].dstride = dstride;
5773 
5774     tasks[i].x = 0;
5775     tasks[i].w = out_width;
5776 
5777     tasks[i].y = i * lines_per_thread;
5778     tasks[i].h = tasks[i].y + lines_per_thread;
5779     tasks[i].h = MIN (out_height, tasks[i].h);
5780 
5781     tasks_p[i] = &amp;tasks[i];
5782   }
5783 
5784   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5785       (GstParallelizedTaskFunc) convert_plane_hv_task, (gpointer) tasks_p);
5786 }
5787 
5788 static void
5789 convert_scale_planes (GstVideoConverter * convert,
5790     const GstVideoFrame * src, GstVideoFrame * dest)
5791 {
5792   int i, n_planes;
5793 
5794   n_planes = GST_VIDEO_FRAME_N_PLANES (dest);
5795   for (i = 0; i &lt; n_planes; i++) {
5796     if (convert-&gt;fconvert[i])
5797       convert-&gt;fconvert[i] (convert, src, dest, i);
5798   }
5799   convert_fill_border (convert, dest);
5800 }
5801 
5802 static GstVideoFormat
5803 get_scale_format (GstVideoFormat format, gint plane)
5804 {
5805   GstVideoFormat res = GST_VIDEO_FORMAT_UNKNOWN;
5806 
5807   switch (format) {
5808     case GST_VIDEO_FORMAT_I420:
5809     case GST_VIDEO_FORMAT_YV12:
5810     case GST_VIDEO_FORMAT_Y41B:
5811     case GST_VIDEO_FORMAT_Y42B:
5812     case GST_VIDEO_FORMAT_Y444:
5813     case GST_VIDEO_FORMAT_GRAY8:
5814     case GST_VIDEO_FORMAT_A420:
5815     case GST_VIDEO_FORMAT_YUV9:
5816     case GST_VIDEO_FORMAT_YVU9:
5817     case GST_VIDEO_FORMAT_GBR:
5818     case GST_VIDEO_FORMAT_GBRA:
5819       res = GST_VIDEO_FORMAT_GRAY8;
5820       break;
5821     case GST_VIDEO_FORMAT_GRAY16_BE:
5822     case GST_VIDEO_FORMAT_GRAY16_LE:
5823       res = GST_VIDEO_FORMAT_GRAY16_BE;
5824       break;
5825     case GST_VIDEO_FORMAT_YUY2:
5826     case GST_VIDEO_FORMAT_UYVY:
5827     case GST_VIDEO_FORMAT_VYUY:
5828     case GST_VIDEO_FORMAT_YVYU:
5829     case GST_VIDEO_FORMAT_AYUV:
<a name="8" id="anc8"></a>
5830     case GST_VIDEO_FORMAT_RGBx:
5831     case GST_VIDEO_FORMAT_BGRx:
5832     case GST_VIDEO_FORMAT_xRGB:
5833     case GST_VIDEO_FORMAT_xBGR:
5834     case GST_VIDEO_FORMAT_RGBA:
5835     case GST_VIDEO_FORMAT_BGRA:
5836     case GST_VIDEO_FORMAT_ARGB:
5837     case GST_VIDEO_FORMAT_ABGR:
5838     case GST_VIDEO_FORMAT_RGB:
5839     case GST_VIDEO_FORMAT_BGR:
5840     case GST_VIDEO_FORMAT_v308:
5841     case GST_VIDEO_FORMAT_IYU2:
5842     case GST_VIDEO_FORMAT_ARGB64:
5843     case GST_VIDEO_FORMAT_AYUV64:
5844       res = format;
5845       break;
5846     case GST_VIDEO_FORMAT_RGB15:
5847     case GST_VIDEO_FORMAT_BGR15:
5848     case GST_VIDEO_FORMAT_RGB16:
5849     case GST_VIDEO_FORMAT_BGR16:
5850       res = GST_VIDEO_FORMAT_NV12;
5851       break;
5852     case GST_VIDEO_FORMAT_NV12:
5853     case GST_VIDEO_FORMAT_NV21:
5854     case GST_VIDEO_FORMAT_NV16:
5855     case GST_VIDEO_FORMAT_NV61:
5856     case GST_VIDEO_FORMAT_NV24:
5857       res = plane == 0 ? GST_VIDEO_FORMAT_GRAY8 : GST_VIDEO_FORMAT_NV12;
5858       break;
5859     case GST_VIDEO_FORMAT_UNKNOWN:
5860     case GST_VIDEO_FORMAT_ENCODED:
5861     case GST_VIDEO_FORMAT_v210:
5862     case GST_VIDEO_FORMAT_v216:
<a name="9" id="anc9"></a>

5863     case GST_VIDEO_FORMAT_UYVP:
5864     case GST_VIDEO_FORMAT_RGB8P:
5865     case GST_VIDEO_FORMAT_IYU1:
5866     case GST_VIDEO_FORMAT_r210:
5867     case GST_VIDEO_FORMAT_I420_10BE:
5868     case GST_VIDEO_FORMAT_I420_10LE:
5869     case GST_VIDEO_FORMAT_I422_10BE:
5870     case GST_VIDEO_FORMAT_I422_10LE:
5871     case GST_VIDEO_FORMAT_Y444_10BE:
5872     case GST_VIDEO_FORMAT_Y444_10LE:
5873     case GST_VIDEO_FORMAT_I420_12BE:
5874     case GST_VIDEO_FORMAT_I420_12LE:
5875     case GST_VIDEO_FORMAT_I422_12BE:
5876     case GST_VIDEO_FORMAT_I422_12LE:
5877     case GST_VIDEO_FORMAT_Y444_12BE:
5878     case GST_VIDEO_FORMAT_Y444_12LE:
5879     case GST_VIDEO_FORMAT_GBR_10BE:
5880     case GST_VIDEO_FORMAT_GBR_10LE:
5881     case GST_VIDEO_FORMAT_GBRA_10BE:
5882     case GST_VIDEO_FORMAT_GBRA_10LE:
5883     case GST_VIDEO_FORMAT_GBR_12BE:
5884     case GST_VIDEO_FORMAT_GBR_12LE:
5885     case GST_VIDEO_FORMAT_GBRA_12BE:
5886     case GST_VIDEO_FORMAT_GBRA_12LE:
5887     case GST_VIDEO_FORMAT_NV12_64Z32:
5888     case GST_VIDEO_FORMAT_A420_10BE:
5889     case GST_VIDEO_FORMAT_A420_10LE:
5890     case GST_VIDEO_FORMAT_A422_10BE:
5891     case GST_VIDEO_FORMAT_A422_10LE:
5892     case GST_VIDEO_FORMAT_A444_10BE:
5893     case GST_VIDEO_FORMAT_A444_10LE:
5894     case GST_VIDEO_FORMAT_P010_10BE:
5895     case GST_VIDEO_FORMAT_P010_10LE:
5896     case GST_VIDEO_FORMAT_GRAY10_LE32:
5897     case GST_VIDEO_FORMAT_NV12_10LE32:
5898     case GST_VIDEO_FORMAT_NV16_10LE32:
<a name="10" id="anc10"></a>

5899       res = format;
5900       g_assert_not_reached ();
5901       break;
5902   }
5903   return res;
5904 }
5905 
5906 static gboolean
5907 is_merge_yuv (GstVideoInfo * info)
5908 {
5909   switch (GST_VIDEO_INFO_FORMAT (info)) {
5910     case GST_VIDEO_FORMAT_YUY2:
5911     case GST_VIDEO_FORMAT_YVYU:
5912     case GST_VIDEO_FORMAT_UYVY:
5913     case GST_VIDEO_FORMAT_VYUY:
5914       return TRUE;
5915     default:
5916       return FALSE;
5917   }
5918 }
5919 
5920 static gboolean
5921 setup_scale (GstVideoConverter * convert)
5922 {
5923   int i, n_planes;
<a name="11" id="anc11"></a><span class="line-modified">5924   gint method, cr_method, stride, in_width, in_height, out_width, out_height;</span>
5925   guint taps;
5926   GstVideoInfo *in_info, *out_info;
5927   const GstVideoFormatInfo *in_finfo, *out_finfo;
5928   GstVideoFormat in_format, out_format;
5929   guint n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5930 
5931   in_info = &amp;convert-&gt;in_info;
5932   out_info = &amp;convert-&gt;out_info;
5933 
5934   in_finfo = in_info-&gt;finfo;
5935   out_finfo = out_info-&gt;finfo;
5936 
5937   n_planes = GST_VIDEO_INFO_N_PLANES (out_info);
5938 
5939   method = GET_OPT_RESAMPLER_METHOD (convert);
5940   if (method == GST_VIDEO_RESAMPLER_METHOD_NEAREST)
5941     cr_method = method;
5942   else
5943     cr_method = GET_OPT_CHROMA_RESAMPLER_METHOD (convert);
5944   taps = GET_OPT_RESAMPLER_TAPS (convert);
5945 
5946   in_format = GST_VIDEO_INFO_FORMAT (in_info);
5947   out_format = GST_VIDEO_INFO_FORMAT (out_info);
5948 
5949   switch (in_format) {
5950     case GST_VIDEO_FORMAT_RGB15:
5951     case GST_VIDEO_FORMAT_RGB16:
5952     case GST_VIDEO_FORMAT_BGR15:
5953     case GST_VIDEO_FORMAT_BGR16:
5954 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5955     case GST_VIDEO_FORMAT_GRAY16_BE:
5956 #else
5957     case GST_VIDEO_FORMAT_GRAY16_LE:
5958 #endif
5959       if (method != GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
5960         GST_DEBUG (&quot;%s only with nearest resampling&quot;,
5961             gst_video_format_to_string (in_format));
5962         return FALSE;
5963       }
5964       break;
5965     default:
5966       break;
5967   }
5968 
5969   in_width = convert-&gt;in_width;
5970   in_height = convert-&gt;in_height;
5971   out_width = convert-&gt;out_width;
5972   out_height = convert-&gt;out_height;
5973 
<a name="12" id="anc12"></a><span class="line-removed">5974   stride = 0;</span>
<span class="line-removed">5975 </span>
5976   if (n_planes == 1 &amp;&amp; !GST_VIDEO_FORMAT_INFO_IS_GRAY (out_finfo)) {
5977     gint pstride;
5978     guint j;
5979 
5980     if (is_merge_yuv (in_info)) {
5981       GstVideoScaler *y_scaler, *uv_scaler;
5982 
5983       if (in_width != out_width) {
5984         convert-&gt;fh_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
5985         for (j = 0; j &lt; n_threads; j++) {
5986           y_scaler =
5987               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
5988               GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, GST_VIDEO_COMP_Y,
5989                   in_width), GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo,
5990                   GST_VIDEO_COMP_Y, out_width), convert-&gt;config);
5991           uv_scaler =
5992               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE,
5993               gst_video_scaler_get_max_taps (y_scaler),
5994               GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, GST_VIDEO_COMP_U,
5995                   in_width), GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo,
5996                   GST_VIDEO_COMP_U, out_width), convert-&gt;config);
5997 
5998           convert-&gt;fh_scaler[0].scaler[j] =
5999               gst_video_scaler_combine_packed_YUV (y_scaler, uv_scaler,
6000               in_format, out_format);
6001 
6002           gst_video_scaler_free (y_scaler);
6003           gst_video_scaler_free (uv_scaler);
6004         }
6005       } else {
6006         convert-&gt;fh_scaler[0].scaler = NULL;
6007       }
6008 
6009       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, GST_VIDEO_COMP_Y);
6010       convert-&gt;fin_x[0] = GST_ROUND_UP_2 (convert-&gt;in_x) * pstride;
6011       convert-&gt;fout_x[0] = GST_ROUND_UP_2 (convert-&gt;out_x) * pstride;
6012 
6013     } else {
6014       if (in_width != out_width &amp;&amp; in_width != 0 &amp;&amp; out_width != 0) {
6015         convert-&gt;fh_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
6016         for (j = 0; j &lt; n_threads; j++) {
6017           convert-&gt;fh_scaler[0].scaler[j] =
6018               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
6019               in_width, out_width, convert-&gt;config);
6020         }
6021       } else {
6022         convert-&gt;fh_scaler[0].scaler = NULL;
6023       }
6024 
6025       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, GST_VIDEO_COMP_R);
6026       convert-&gt;fin_x[0] = convert-&gt;in_x * pstride;
6027       convert-&gt;fout_x[0] = convert-&gt;out_x * pstride;
6028     }
6029 
<a name="13" id="anc13"></a><span class="line-removed">6030     stride = MAX (stride, GST_VIDEO_INFO_PLANE_STRIDE (in_info, 0));</span>
<span class="line-removed">6031     stride = MAX (stride, GST_VIDEO_INFO_PLANE_STRIDE (out_info, 0));</span>
<span class="line-removed">6032 </span>
6033     if (in_height != out_height &amp;&amp; in_height != 0 &amp;&amp; out_height != 0) {
6034       convert-&gt;fv_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
6035 
6036       for (j = 0; j &lt; n_threads; j++) {
6037         convert-&gt;fv_scaler[0].scaler[j] =
6038             gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
6039             in_height, out_height, convert-&gt;config);
6040       }
6041     } else {
6042       convert-&gt;fv_scaler[0].scaler = NULL;
6043     }
6044 
6045     convert-&gt;fin_y[0] = convert-&gt;in_y;
6046     convert-&gt;fout_y[0] = convert-&gt;out_y;
6047     convert-&gt;fout_width[0] = out_width;
6048     convert-&gt;fout_height[0] = out_height;
6049     convert-&gt;fconvert[0] = convert_plane_hv;
6050     convert-&gt;fformat[0] = get_scale_format (in_format, 0);
6051     convert-&gt;fsplane[0] = 0;
6052   } else {
6053     for (i = 0; i &lt; n_planes; i++) {
6054       gint comp, n_comp, j, iw, ih, ow, oh, pstride;
6055       gboolean need_v_scaler, need_h_scaler;
6056       GstStructure *config;
6057       gint resample_method;
6058 
6059       n_comp = GST_VIDEO_FORMAT_INFO_N_COMPONENTS (in_finfo);
6060 
6061       /* find the component in this plane and map it to the plane of
6062        * the source */
6063       comp = -1;
6064       for (j = 0; j &lt; n_comp; j++) {
6065         if (GST_VIDEO_FORMAT_INFO_PLANE (out_finfo, j) == i) {
6066           comp = j;
6067           break;
6068         }
6069       }
6070 
<a name="14" id="anc14"></a><span class="line-removed">6071       stride = MAX (stride, GST_VIDEO_INFO_COMP_STRIDE (in_info, i));</span>
<span class="line-removed">6072       stride = MAX (stride, GST_VIDEO_INFO_COMP_STRIDE (out_info, i));</span>
<span class="line-removed">6073 </span>
6074       iw = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, i, in_width);
6075       ih = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (in_finfo, i, in_height);
6076       ow = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, i, out_width);
6077       oh = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, i, out_height);
6078 
6079       GST_DEBUG (&quot;plane %d: %dx%d -&gt; %dx%d&quot;, i, iw, ih, ow, oh);
6080 
6081       convert-&gt;fout_width[i] = ow;
6082       convert-&gt;fout_height[i] = oh;
6083 
6084       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, i);
6085       convert-&gt;fin_x[i] =
6086           GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, i, convert-&gt;in_x);
6087       convert-&gt;fin_x[i] *= pstride;
6088       convert-&gt;fin_y[i] =
6089           GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (in_finfo, i, convert-&gt;in_y);
6090       convert-&gt;fout_x[i] =
6091           GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, i, convert-&gt;out_x);
6092       convert-&gt;fout_x[i] *= pstride;
6093       convert-&gt;fout_y[i] =
6094           GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, i, convert-&gt;out_y);
6095 
6096       GST_DEBUG (&quot;plane %d: pstride %d&quot;, i, pstride);
6097       GST_DEBUG (&quot;plane %d: in_x %d, in_y %d&quot;, i, convert-&gt;fin_x[i],
6098           convert-&gt;fin_y[i]);
6099       GST_DEBUG (&quot;plane %d: out_x %d, out_y %d&quot;, i, convert-&gt;fout_x[i],
6100           convert-&gt;fout_y[i]);
6101 
6102       if (comp == -1) {
6103         convert-&gt;fconvert[i] = convert_plane_fill;
6104         if (GST_VIDEO_INFO_IS_YUV (out_info)) {
6105           if (i == 3)
6106             convert-&gt;ffill[i] = convert-&gt;alpha_value;
6107           if (i == 0)
6108             convert-&gt;ffill[i] = 0x00;
6109           else
6110             convert-&gt;ffill[i] = 0x80;
6111         } else {
6112           if (i == 3)
6113             convert-&gt;ffill[i] = convert-&gt;alpha_value;
6114           else
6115             convert-&gt;ffill[i] = 0x00;
6116         }
6117         GST_DEBUG (&quot;plane %d fill %02x&quot;, i, convert-&gt;ffill[i]);
6118         continue;
6119       } else {
6120         convert-&gt;fsplane[i] = GST_VIDEO_FORMAT_INFO_PLANE (in_finfo, comp);
6121         GST_DEBUG (&quot;plane %d -&gt; %d (comp %d)&quot;, i, convert-&gt;fsplane[i], comp);
6122       }
6123 
6124       config = gst_structure_copy (convert-&gt;config);
6125 
6126       resample_method = (i == 0 ? method : cr_method);
6127 
6128       need_v_scaler = FALSE;
6129       need_h_scaler = FALSE;
6130       if (iw == ow) {
6131         if (ih == oh) {
6132           convert-&gt;fconvert[i] = convert_plane_hv;
6133           GST_DEBUG (&quot;plane %d: copy&quot;, i);
6134         } else if (ih == 2 * oh &amp;&amp; pstride == 1
6135             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6136           convert-&gt;fconvert[i] = convert_plane_v_halve;
6137           GST_DEBUG (&quot;plane %d: vertical halve&quot;, i);
6138         } else if (2 * ih == oh &amp;&amp; pstride == 1
6139             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6140           convert-&gt;fconvert[i] = convert_plane_v_double;
6141           GST_DEBUG (&quot;plane %d: vertical double&quot;, i);
6142         } else {
6143           convert-&gt;fconvert[i] = convert_plane_hv;
6144           GST_DEBUG (&quot;plane %d: vertical scale&quot;, i);
6145           need_v_scaler = TRUE;
6146         }
6147       } else if (ih == oh) {
6148         if (iw == 2 * ow &amp;&amp; pstride == 1
6149             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6150           convert-&gt;fconvert[i] = convert_plane_h_halve;
6151           GST_DEBUG (&quot;plane %d: horizontal halve&quot;, i);
6152         } else if (2 * iw == ow &amp;&amp; pstride == 1
6153             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6154           convert-&gt;fconvert[i] = convert_plane_h_double;
6155           GST_DEBUG (&quot;plane %d: horizontal double&quot;, i);
6156         } else {
6157           convert-&gt;fconvert[i] = convert_plane_hv;
6158           GST_DEBUG (&quot;plane %d: horizontal scale&quot;, i);
6159           need_h_scaler = TRUE;
6160         }
6161       } else {
6162         if (iw == 2 * ow &amp;&amp; ih == 2 * oh &amp;&amp; pstride == 1
6163             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6164           convert-&gt;fconvert[i] = convert_plane_hv_halve;
6165           GST_DEBUG (&quot;plane %d: horizontal/vertical halve&quot;, i);
6166         } else if (2 * iw == ow &amp;&amp; 2 * ih == oh &amp;&amp; pstride == 1
6167             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6168           convert-&gt;fconvert[i] = convert_plane_hv_double;
6169           GST_DEBUG (&quot;plane %d: horizontal/vertical double&quot;, i);
6170         } else {
6171           convert-&gt;fconvert[i] = convert_plane_hv;
6172           GST_DEBUG (&quot;plane %d: horizontal/vertical scale&quot;, i);
6173           need_v_scaler = TRUE;
6174           need_h_scaler = TRUE;
6175         }
6176       }
6177 
6178       if (need_h_scaler &amp;&amp; iw != 0 &amp;&amp; ow != 0) {
6179         convert-&gt;fh_scaler[i].scaler = g_new (GstVideoScaler *, n_threads);
6180 
6181         for (j = 0; j &lt; n_threads; j++) {
6182           convert-&gt;fh_scaler[i].scaler[j] =
6183               gst_video_scaler_new (resample_method, GST_VIDEO_SCALER_FLAG_NONE,
6184               taps, iw, ow, config);
6185         }
6186       } else {
6187         convert-&gt;fh_scaler[i].scaler = NULL;
6188       }
6189 
6190       if (need_v_scaler &amp;&amp; ih != 0 &amp;&amp; oh != 0) {
6191         convert-&gt;fv_scaler[i].scaler = g_new (GstVideoScaler *, n_threads);
6192 
6193         for (j = 0; j &lt; n_threads; j++) {
6194           convert-&gt;fv_scaler[i].scaler[j] =
6195               gst_video_scaler_new (resample_method, GST_VIDEO_SCALER_FLAG_NONE,
6196               taps, ih, oh, config);
6197         }
6198       } else {
6199         convert-&gt;fv_scaler[i].scaler = NULL;
6200       }
6201 
6202       gst_structure_free (config);
6203       convert-&gt;fformat[i] = get_scale_format (in_format, i);
6204     }
6205   }
6206 
6207   return TRUE;
6208 }
6209 
6210 /* Fast paths */
6211 
6212 typedef struct
6213 {
6214   GstVideoFormat in_format;
6215   GstVideoFormat out_format;
6216   gboolean keeps_interlaced;
6217   gboolean needs_color_matrix;
6218   gboolean keeps_size;
6219   gboolean do_crop;
6220   gboolean do_border;
6221   gboolean alpha_copy;
6222   gboolean alpha_set;
6223   gboolean alpha_mult;
6224   gint width_align, height_align;
6225   void (*convert) (GstVideoConverter * convert, const GstVideoFrame * src,
6226       GstVideoFrame * dest);
6227 } VideoTransform;
6228 
6229 static const VideoTransform transforms[] = {
6230   /* planar -&gt; packed */
6231   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, FALSE,
6232       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_YUY2},
6233   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, FALSE,
6234       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_UYVY},
6235   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, FALSE,
6236       FALSE, FALSE, TRUE, FALSE, 0, 0, convert_I420_AYUV},
6237 
6238   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, FALSE,
6239       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_YUY2},
6240   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, FALSE,
6241       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_UYVY},
6242   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, FALSE,
6243       FALSE, FALSE, TRUE, FALSE, 0, 0, convert_I420_AYUV},
6244 
6245   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6246       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_Y42B_YUY2},
6247   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6248       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_Y42B_UYVY},
6249   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6250       TRUE, FALSE, TRUE, FALSE, 1, 0, convert_Y42B_AYUV},
6251 
6252   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6253       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_Y444_YUY2},
6254   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6255       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_Y444_UYVY},
6256   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6257       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_Y444_AYUV},
6258 
6259   /* packed -&gt; packed */
6260   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, FALSE, TRUE,
6261       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6262   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6263       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_YUY2},      /* alias */
6264   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6265       TRUE, FALSE, TRUE, FALSE, 1, 0, convert_YUY2_AYUV},
6266 
6267   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, FALSE, TRUE,
6268       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6269   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6270       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_YUY2},
6271   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6272       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_UYVY_AYUV},
6273 
6274   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, FALSE, TRUE, TRUE,
6275       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6276   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6277       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_YUY2},
6278   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6279       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_UYVY},
6280 
6281   /* packed -&gt; planar */
6282   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_I420, TRUE, FALSE, TRUE, FALSE,
6283       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_I420},
6284   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_YV12, TRUE, FALSE, TRUE, FALSE,
6285       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_I420},
6286   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6287       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_Y42B},
6288   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6289       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_Y444},
6290   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_GRAY8, TRUE, TRUE, TRUE, TRUE,
6291       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_GRAY8},
6292 
6293   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_I420, TRUE, FALSE, TRUE, FALSE,
6294       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_I420},
6295   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_YV12, TRUE, FALSE, TRUE, FALSE,
6296       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_I420},
6297   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6298       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_Y42B},
6299   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6300       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_Y444},
6301 
6302   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_I420, FALSE, FALSE, TRUE, TRUE,
6303       TRUE, FALSE, FALSE, FALSE, 1, 1, convert_AYUV_I420},
6304   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, TRUE, TRUE,
6305       TRUE, FALSE, FALSE, FALSE, 1, 1, convert_AYUV_I420},
6306   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6307       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_Y42B},
6308   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6309       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_AYUV_Y444},
6310 
6311   /* planar -&gt; planar */
6312   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6313       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6314   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6315       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6316   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6317       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6318   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6319       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6320   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6321       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6322   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6323       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6324   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6325       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6326   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6327       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6328   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6329       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6330 
6331   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6332       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6333   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6334       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6335   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6336       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6337   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6338       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6339   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6340       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6341   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6342       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6343   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6344       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6345   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6346       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6347   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6348       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6349 
6350   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6351       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6352   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6353       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6354   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6355       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6356   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6357       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6358   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6359       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6360   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6361       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6362   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6363       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6364   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6365       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6366   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6367       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6368 
6369   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6370       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6371   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6372       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6373   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6374       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6375   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6376       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6377   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6378       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6379   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6380       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6381   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6382       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6383   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6384       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6385   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6386       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6387 
6388   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6389       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6390   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6391       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6392   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6393       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6394   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6395       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6396   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6397       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6398   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6399       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6400   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6401       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6402   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6403       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6404   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6405       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6406 
6407   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6408       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6409   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6410       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6411   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6412       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6413   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6414       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6415   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6416       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6417   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6418       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6419   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6420       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6421   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6422       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6423   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6424       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6425 
6426   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6427       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6428   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6429       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6430   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6431       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6432   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6433       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6434   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6435       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6436   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6437       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6438   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6439       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6440   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6441       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6442   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6443       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6444 
6445   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6446       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6447   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6448       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6449   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6450       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6451   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6452       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6453   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6454       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6455   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6456       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6457   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6458       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6459   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6460       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6461   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6462       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6463 
6464   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6465       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6466   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6467       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6468   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6469       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6470   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6471       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6472   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6473       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6474   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6475       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6476   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6477       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6478   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6479       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6480   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6481       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6482 
6483   /* sempiplanar -&gt; semiplanar */
6484   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6485       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6486   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6487       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6488   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6489       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6490 
6491   {GST_VIDEO_FORMAT_NV21, GST_VIDEO_FORMAT_NV21, TRUE, FALSE, FALSE, TRUE,
6492       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6493 
6494   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6495       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6496   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6497       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6498   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6499       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6500 
6501   {GST_VIDEO_FORMAT_NV61, GST_VIDEO_FORMAT_NV61, TRUE, FALSE, FALSE, TRUE,
6502       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6503 
6504   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6505       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6506   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6507       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6508   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6509       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6510 
6511 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
6512   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_ARGB, TRUE, TRUE, TRUE, TRUE, TRUE,
6513       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_ARGB},
6514   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_BGRA, TRUE, TRUE, TRUE, TRUE, TRUE,
6515       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_BGRA},
6516   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_xRGB, TRUE, TRUE, TRUE, TRUE, TRUE,
6517       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_ARGB},    /* alias */
6518   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_BGRx, TRUE, TRUE, TRUE, TRUE, TRUE,
6519       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_BGRA},    /* alias */
6520   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_ABGR, TRUE, TRUE, TRUE, TRUE, TRUE,
6521       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_ABGR},
6522   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_RGBA, TRUE, TRUE, TRUE, TRUE, TRUE,
6523       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_RGBA},
6524   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_xBGR, TRUE, TRUE, TRUE, TRUE, TRUE,
6525       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_ABGR},    /* alias */
6526   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_RGBx, TRUE, TRUE, TRUE, TRUE, TRUE,
6527       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_RGBA},    /* alias */
6528 #endif
6529 
6530   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGRA, FALSE, TRUE, TRUE, TRUE,
6531       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6532   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGRx, FALSE, TRUE, TRUE, TRUE,
6533       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6534   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGRA, FALSE, TRUE, TRUE, TRUE,
6535       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6536   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGRx, FALSE, TRUE, TRUE, TRUE,
6537       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6538 
6539   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_ARGB, FALSE, TRUE, TRUE, TRUE,
6540       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6541   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_xRGB, FALSE, TRUE, TRUE, TRUE,
6542       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6543   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_ARGB, FALSE, TRUE, TRUE, TRUE,
6544       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6545   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_xRGB, FALSE, TRUE, TRUE, TRUE,
6546       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6547 
6548   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_ABGR, FALSE, TRUE, TRUE, TRUE,
6549       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6550   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_xBGR, FALSE, TRUE, TRUE, TRUE,
6551       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6552   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGBA, FALSE, TRUE, TRUE, TRUE,
6553       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6554   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGBx, FALSE, TRUE, TRUE, TRUE,
6555       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6556   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB, FALSE, TRUE, TRUE, TRUE,
6557       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6558   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR, FALSE, TRUE, TRUE, TRUE,
6559       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6560   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB15, FALSE, TRUE, TRUE, TRUE,
6561       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6562   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR15, FALSE, TRUE, TRUE, TRUE,
6563       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6564   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB16, FALSE, TRUE, TRUE, TRUE,
6565       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6566   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR16, FALSE, TRUE, TRUE, TRUE,
6567       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6568 
6569   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_ABGR, FALSE, TRUE, TRUE, TRUE,
6570       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6571   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_xBGR, FALSE, TRUE, TRUE, TRUE,
6572       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6573   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGBA, FALSE, TRUE, TRUE, TRUE,
6574       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6575   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGBx, FALSE, TRUE, TRUE, TRUE,
6576       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6577   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB, FALSE, TRUE, TRUE, TRUE,
6578       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6579   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR, FALSE, TRUE, TRUE, TRUE,
6580       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6581   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB15, FALSE, TRUE, TRUE, TRUE,
6582       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6583   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR15, FALSE, TRUE, TRUE, TRUE,
6584       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6585   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB16, FALSE, TRUE, TRUE, TRUE,
6586       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6587   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR16, FALSE, TRUE, TRUE, TRUE,
6588       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6589 
6590   /* scalers */
6591   {GST_VIDEO_FORMAT_GBR, GST_VIDEO_FORMAT_GBR, TRUE, FALSE, FALSE, TRUE,
6592       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6593 
6594   {GST_VIDEO_FORMAT_YVYU, GST_VIDEO_FORMAT_YVYU, TRUE, FALSE, FALSE, TRUE,
6595       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6596 
6597   {GST_VIDEO_FORMAT_RGB15, GST_VIDEO_FORMAT_RGB15, TRUE, FALSE, FALSE, TRUE,
6598       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6599   {GST_VIDEO_FORMAT_RGB16, GST_VIDEO_FORMAT_RGB16, TRUE, FALSE, FALSE, TRUE,
6600       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6601   {GST_VIDEO_FORMAT_BGR15, GST_VIDEO_FORMAT_BGR15, TRUE, FALSE, FALSE, TRUE,
6602       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6603   {GST_VIDEO_FORMAT_BGR16, GST_VIDEO_FORMAT_BGR16, TRUE, FALSE, FALSE, TRUE,
6604       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6605 
6606   {GST_VIDEO_FORMAT_RGB, GST_VIDEO_FORMAT_RGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6607       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6608   {GST_VIDEO_FORMAT_BGR, GST_VIDEO_FORMAT_BGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6609       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6610   {GST_VIDEO_FORMAT_v308, GST_VIDEO_FORMAT_v308, TRUE, FALSE, FALSE, TRUE, TRUE,
6611       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6612   {GST_VIDEO_FORMAT_IYU2, GST_VIDEO_FORMAT_IYU2, TRUE, FALSE, FALSE, TRUE, TRUE,
6613       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6614 
6615   {GST_VIDEO_FORMAT_ARGB, GST_VIDEO_FORMAT_ARGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6616       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6617   {GST_VIDEO_FORMAT_xRGB, GST_VIDEO_FORMAT_xRGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6618       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6619   {GST_VIDEO_FORMAT_ABGR, GST_VIDEO_FORMAT_ABGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6620       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6621   {GST_VIDEO_FORMAT_xBGR, GST_VIDEO_FORMAT_xBGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6622       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6623   {GST_VIDEO_FORMAT_RGBA, GST_VIDEO_FORMAT_RGBA, TRUE, FALSE, FALSE, TRUE, TRUE,
6624       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6625   {GST_VIDEO_FORMAT_RGBx, GST_VIDEO_FORMAT_RGBx, TRUE, FALSE, FALSE, TRUE, TRUE,
6626       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6627   {GST_VIDEO_FORMAT_BGRA, GST_VIDEO_FORMAT_BGRA, TRUE, FALSE, FALSE, TRUE, TRUE,
6628       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6629   {GST_VIDEO_FORMAT_BGRx, GST_VIDEO_FORMAT_BGRx, TRUE, FALSE, FALSE, TRUE, TRUE,
6630       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6631 
6632   {GST_VIDEO_FORMAT_ARGB64, GST_VIDEO_FORMAT_ARGB64, TRUE, FALSE, FALSE, TRUE,
6633       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6634   {GST_VIDEO_FORMAT_AYUV64, GST_VIDEO_FORMAT_AYUV64, TRUE, FALSE, FALSE, TRUE,
6635       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6636 
6637   {GST_VIDEO_FORMAT_GRAY16_LE, GST_VIDEO_FORMAT_GRAY16_LE, TRUE, FALSE, FALSE,
6638       TRUE, TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6639   {GST_VIDEO_FORMAT_GRAY16_BE, GST_VIDEO_FORMAT_GRAY16_BE, TRUE, FALSE, FALSE,
6640       TRUE, TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6641 };
6642 
6643 static gboolean
6644 video_converter_lookup_fastpath (GstVideoConverter * convert)
6645 {
6646   int i;
6647   GstVideoFormat in_format, out_format;
6648   GstVideoTransferFunction in_transf, out_transf;
6649   gboolean interlaced, same_matrix, same_primaries, same_size, crop, border;
6650   gboolean need_copy, need_set, need_mult;
6651   gint width, height;
6652 
6653   width = GST_VIDEO_INFO_WIDTH (&amp;convert-&gt;in_info);
6654   height = GST_VIDEO_INFO_HEIGHT (&amp;convert-&gt;in_info);
6655 
6656   if (GET_OPT_DITHER_QUANTIZATION (convert) != 1)
6657     return FALSE;
6658 
6659   /* we don&#39;t do gamma conversion in fastpath */
6660   in_transf = convert-&gt;in_info.colorimetry.transfer;
6661   out_transf = convert-&gt;out_info.colorimetry.transfer;
6662 
6663   same_size = (width == convert-&gt;out_width &amp;&amp; height == convert-&gt;out_height);
6664 
6665   /* fastpaths don&#39;t do gamma */
6666   if (CHECK_GAMMA_REMAP (convert) &amp;&amp; (!same_size || in_transf != out_transf))
6667     return FALSE;
6668 
6669   need_copy = (convert-&gt;alpha_mode &amp; ALPHA_MODE_COPY) == ALPHA_MODE_COPY;
6670   need_set = (convert-&gt;alpha_mode &amp; ALPHA_MODE_SET) == ALPHA_MODE_SET;
6671   need_mult = (convert-&gt;alpha_mode &amp; ALPHA_MODE_MULT) == ALPHA_MODE_MULT;
6672   GST_DEBUG (&quot;alpha copy %d, set %d, mult %d&quot;, need_copy, need_set, need_mult);
6673 
6674   in_format = GST_VIDEO_INFO_FORMAT (&amp;convert-&gt;in_info);
6675   out_format = GST_VIDEO_INFO_FORMAT (&amp;convert-&gt;out_info);
6676 
6677   if (CHECK_MATRIX_NONE (convert)) {
6678     same_matrix = TRUE;
6679   } else {
6680     GstVideoColorMatrix in_matrix, out_matrix;
6681 
6682     in_matrix = convert-&gt;in_info.colorimetry.matrix;
6683     out_matrix = convert-&gt;out_info.colorimetry.matrix;
6684     same_matrix = in_matrix == out_matrix;
6685   }
6686 
6687   if (CHECK_PRIMARIES_NONE (convert)) {
6688     same_primaries = TRUE;
6689   } else {
6690     GstVideoColorPrimaries in_primaries, out_primaries;
6691 
6692     in_primaries = convert-&gt;in_info.colorimetry.primaries;
6693     out_primaries = convert-&gt;out_info.colorimetry.primaries;
6694     same_primaries = in_primaries == out_primaries;
6695   }
6696 
6697   interlaced = GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;in_info);
6698   interlaced |= GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;out_info);
6699 
6700   crop = convert-&gt;in_x || convert-&gt;in_y
6701       || convert-&gt;in_width &lt; convert-&gt;in_maxwidth
6702       || convert-&gt;in_height &lt; convert-&gt;in_maxheight;
6703   border = convert-&gt;out_x || convert-&gt;out_y
6704       || convert-&gt;out_width &lt; convert-&gt;out_maxwidth
6705       || convert-&gt;out_height &lt; convert-&gt;out_maxheight;
6706 
6707   for (i = 0; i &lt; sizeof (transforms) / sizeof (transforms[0]); i++) {
6708     if (transforms[i].in_format == in_format &amp;&amp;
6709         transforms[i].out_format == out_format &amp;&amp;
6710         (transforms[i].keeps_interlaced || !interlaced) &amp;&amp;
6711         (transforms[i].needs_color_matrix || (same_matrix &amp;&amp; same_primaries))
6712         &amp;&amp; (!transforms[i].keeps_size || same_size)
6713         &amp;&amp; (transforms[i].width_align &amp; width) == 0
6714         &amp;&amp; (transforms[i].height_align &amp; height) == 0
6715         &amp;&amp; (transforms[i].do_crop || !crop)
6716         &amp;&amp; (transforms[i].do_border || !border)
6717         &amp;&amp; (transforms[i].alpha_copy || !need_copy)
6718         &amp;&amp; (transforms[i].alpha_set || !need_set)
6719         &amp;&amp; (transforms[i].alpha_mult || !need_mult)) {
6720       guint j;
6721 
6722       GST_DEBUG (&quot;using fastpath&quot;);
6723       if (transforms[i].needs_color_matrix)
6724         video_converter_compute_matrix (convert);
6725       convert-&gt;convert = transforms[i].convert;
6726 
6727       convert-&gt;tmpline =
6728           g_new (guint16 *, convert-&gt;conversion_runner-&gt;n_threads);
6729       for (j = 0; j &lt; convert-&gt;conversion_runner-&gt;n_threads; j++)
6730         convert-&gt;tmpline[j] = g_malloc0 (sizeof (guint16) * (width + 8) * 4);
6731 
6732       if (!transforms[i].keeps_size)
6733         if (!setup_scale (convert))
6734           return FALSE;
6735       if (border)
6736         setup_borderline (convert);
6737       return TRUE;
6738     }
6739   }
6740   GST_DEBUG (&quot;no fastpath found&quot;);
6741   return FALSE;
6742 }
6743 #endif // GSTREAMER_LITE
<a name="15" id="anc15"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="15" type="hidden" />
</body>
</html>