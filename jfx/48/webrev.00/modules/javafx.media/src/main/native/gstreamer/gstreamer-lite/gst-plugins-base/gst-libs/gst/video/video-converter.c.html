<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/video-converter.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /* GStreamer
   2  * Copyright (C) 2010 David Schleef &lt;ds@schleef.org&gt;
   3  * Copyright (C) 2010 Sebastian Dr√∂ge &lt;sebastian.droege@collabora.co.uk&gt;
   4  *
   5  * This library is free software; you can redistribute it and/or
   6  * modify it under the terms of the GNU Library General Public
   7  * License as published by the Free Software Foundation; either
   8  * version 2 of the License, or (at your option) any later version.
   9  *
  10  * This library is distributed in the hope that it will be useful,
  11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  13  * Library General Public License for more details.
  14  *
  15  * You should have received a copy of the GNU Library General Public
  16  * License along with this library; if not, write to the
  17  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
  18  * Boston, MA 02110-1301, USA.
  19  */
  20 
  21 #ifdef HAVE_CONFIG_H
  22 #include &quot;config.h&quot;
  23 #endif
  24 
  25 #if 0
  26 #ifdef HAVE_PTHREAD
  27 #define _GNU_SOURCE
  28 #include &lt;pthread.h&gt;
  29 #endif
  30 #endif
  31 
  32 #include &quot;video-converter.h&quot;
  33 
  34 #include &lt;glib.h&gt;
  35 #include &lt;string.h&gt;
  36 #include &lt;math.h&gt;
  37 
  38 #include &quot;video-orc.h&quot;
  39 
  40 /**
  41  * SECTION:videoconverter
  42  * @title: GstVideoConverter
  43  * @short_description: Generic video conversion
  44  *
  45  * This object is used to convert video frames from one format to another.
  46  * The object can perform conversion of:
  47  *
  48  *  * video format
  49  *  * video colorspace
  50  *  * chroma-siting
  51  *  * video size
  52  *
  53  */
  54 
  55 /*
  56  * (a)  unpack
  57  * (b)  chroma upsample
  58  * (c)  (convert Y&#39;CbCr to R&#39;G&#39;B&#39;)
  59  * (d)  gamma decode
  60  * (e)  downscale
  61  * (f)  colorspace convert through XYZ
  62  * (g)  upscale
  63  * (h)  gamma encode
  64  * (i)  (convert R&#39;G&#39;B&#39; to Y&#39;CbCr)
  65  * (j)  chroma downsample
  66  * (k)  pack
  67  *
  68  * quality options
  69  *
  70  *  (a) range truncate, range expand
  71  *  (b) full upsample, 1-1 non-cosited upsample, no upsample
  72  *  (c) 8 bits, 16 bits
  73  *  (d)
  74  *  (e) 8 bits, 16 bits
  75  *  (f) 8 bits, 16 bits
  76  *  (g) 8 bits, 16 bits
  77  *  (h)
  78  *  (i) 8 bits, 16 bits
  79  *  (j) 1-1 cosited downsample, no downsample
  80  *  (k)
  81  *
  82  *
  83  *         1 : a -&gt;   -&gt;   -&gt;   -&gt; e  -&gt; f  -&gt; g  -&gt;   -&gt;   -&gt;   -&gt; k
  84  *         2 : a -&gt;   -&gt;   -&gt;   -&gt; e  -&gt; f* -&gt; g  -&gt;   -&gt;   -&gt;   -&gt; k
  85  *         3 : a -&gt;   -&gt;   -&gt;   -&gt; e* -&gt; f* -&gt; g* -&gt;   -&gt;   -&gt;   -&gt; k
  86  *         4 : a -&gt; b -&gt;   -&gt;   -&gt; e  -&gt; f  -&gt; g  -&gt;   -&gt;   -&gt; j -&gt; k
  87  *         5 : a -&gt; b -&gt;   -&gt;   -&gt; e* -&gt; f* -&gt; g* -&gt;   -&gt;   -&gt; j -&gt; k
  88  *         6 : a -&gt; b -&gt; c -&gt; d -&gt; e  -&gt; f  -&gt; g  -&gt; h -&gt; i -&gt; j -&gt; k
  89  *         7 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  90  *
  91  *         8 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  92  *         9 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  93  *        10 : a -&gt; b -&gt; c -&gt; d -&gt; e* -&gt; f* -&gt; g* -&gt; h -&gt; i -&gt; j -&gt; k
  94  */
  95 
  96 #ifndef GSTREAMER_LITE
  97 
  98 #ifndef GST_DISABLE_GST_DEBUG
  99 #define GST_CAT_DEFAULT ensure_debug_category()
 100 static GstDebugCategory *
 101 ensure_debug_category (void)
 102 {
 103   static gsize cat_gonce = 0;
 104 
 105   if (g_once_init_enter (&amp;cat_gonce)) {
 106     gsize cat_done;
 107 
 108     cat_done = (gsize) _gst_debug_category_new (&quot;video-converter&quot;, 0,
 109         &quot;video-converter object&quot;);
 110 
 111     g_once_init_leave (&amp;cat_gonce, cat_done);
 112   }
 113 
 114   return (GstDebugCategory *) cat_gonce;
 115 }
 116 #else
 117 #define ensure_debug_category() /* NOOP */
 118 #endif /* GST_DISABLE_GST_DEBUG */
 119 
 120 typedef void (*GstParallelizedTaskFunc) (gpointer user_data);
 121 
 122 typedef struct _GstParallelizedTaskRunner GstParallelizedTaskRunner;
 123 typedef struct _GstParallelizedTaskThread GstParallelizedTaskThread;
 124 
 125 struct _GstParallelizedTaskThread
 126 {
 127   GstParallelizedTaskRunner *runner;
 128   guint idx;
 129   GThread *thread;
 130 };
 131 
 132 struct _GstParallelizedTaskRunner
 133 {
 134   guint n_threads;
 135 
 136   GstParallelizedTaskThread *threads;
 137 
 138   GstParallelizedTaskFunc func;
 139   gpointer *task_data;
 140 
 141   GMutex lock;
 142   GCond cond_todo, cond_done;
 143   gint n_todo, n_done;
 144   gboolean quit;
 145 };
 146 
 147 static gpointer
 148 gst_parallelized_task_thread_func (gpointer data)
 149 {
 150   GstParallelizedTaskThread *self = data;
 151 
 152 #if 0
 153 #ifdef HAVE_PTHREAD
 154   {
 155     pthread_t thread = pthread_self ();
 156     cpu_set_t cpuset;
 157     int r;
 158 
 159     CPU_ZERO (&amp;cpuset);
 160     CPU_SET (self-&gt;idx, &amp;cpuset);
 161     if ((r = pthread_setaffinity_np (thread, sizeof (cpuset), &amp;cpuset)) != 0)
 162       GST_ERROR (&quot;Failed to set thread affinity for thread %d: %s&quot;, self-&gt;idx,
 163           g_strerror (r));
 164   }
 165 #endif
 166 #endif
 167 
 168   g_mutex_lock (&amp;self-&gt;runner-&gt;lock);
 169   self-&gt;runner-&gt;n_done++;
 170   if (self-&gt;runner-&gt;n_done == self-&gt;runner-&gt;n_threads - 1)
 171     g_cond_signal (&amp;self-&gt;runner-&gt;cond_done);
 172 
 173   do {
 174     gint idx;
 175 
 176     while (self-&gt;runner-&gt;n_todo == -1 &amp;&amp; !self-&gt;runner-&gt;quit)
 177       g_cond_wait (&amp;self-&gt;runner-&gt;cond_todo, &amp;self-&gt;runner-&gt;lock);
 178 
 179     if (self-&gt;runner-&gt;quit)
 180       break;
 181 
 182     idx = self-&gt;runner-&gt;n_todo--;
 183     g_assert (self-&gt;runner-&gt;n_todo &gt;= -1);
 184     g_mutex_unlock (&amp;self-&gt;runner-&gt;lock);
 185 
 186     g_assert (self-&gt;runner-&gt;func != NULL);
 187 
 188     self-&gt;runner-&gt;func (self-&gt;runner-&gt;task_data[idx]);
 189 
 190     g_mutex_lock (&amp;self-&gt;runner-&gt;lock);
 191     self-&gt;runner-&gt;n_done++;
 192     if (self-&gt;runner-&gt;n_done == self-&gt;runner-&gt;n_threads - 1)
 193       g_cond_signal (&amp;self-&gt;runner-&gt;cond_done);
 194   } while (TRUE);
 195 
 196   g_mutex_unlock (&amp;self-&gt;runner-&gt;lock);
 197 
 198   return NULL;
 199 }
 200 
 201 static void
 202 gst_parallelized_task_runner_free (GstParallelizedTaskRunner * self)
 203 {
 204   guint i;
 205 
 206   g_mutex_lock (&amp;self-&gt;lock);
 207   self-&gt;quit = TRUE;
 208   g_cond_broadcast (&amp;self-&gt;cond_todo);
 209   g_mutex_unlock (&amp;self-&gt;lock);
 210 
 211   for (i = 1; i &lt; self-&gt;n_threads; i++) {
 212     if (!self-&gt;threads[i].thread)
 213       continue;
 214 
 215     g_thread_join (self-&gt;threads[i].thread);
 216   }
 217 
 218   g_mutex_clear (&amp;self-&gt;lock);
 219   g_cond_clear (&amp;self-&gt;cond_todo);
 220   g_cond_clear (&amp;self-&gt;cond_done);
 221   g_free (self-&gt;threads);
 222   g_free (self);
 223 }
 224 
 225 static GstParallelizedTaskRunner *
 226 gst_parallelized_task_runner_new (guint n_threads)
 227 {
 228   GstParallelizedTaskRunner *self;
 229   guint i;
 230   GError *err = NULL;
 231 
 232   if (n_threads == 0)
 233     n_threads = g_get_num_processors ();
 234 
 235   self = g_new0 (GstParallelizedTaskRunner, 1);
 236   self-&gt;n_threads = n_threads;
 237   self-&gt;threads = g_new0 (GstParallelizedTaskThread, n_threads);
 238 
 239   self-&gt;quit = FALSE;
 240   self-&gt;n_todo = -1;
 241   self-&gt;n_done = 0;
 242   g_mutex_init (&amp;self-&gt;lock);
 243   g_cond_init (&amp;self-&gt;cond_todo);
 244   g_cond_init (&amp;self-&gt;cond_done);
 245 
 246   /* Set when scheduling a job */
 247   self-&gt;func = NULL;
 248   self-&gt;task_data = NULL;
 249 
 250   for (i = 0; i &lt; n_threads; i++) {
 251     self-&gt;threads[i].runner = self;
 252     self-&gt;threads[i].idx = i;
 253 
 254     /* First thread is the one calling run() */
 255     if (i &gt; 0) {
 256       self-&gt;threads[i].thread =
 257           g_thread_try_new (&quot;videoconvert&quot;, gst_parallelized_task_thread_func,
 258           &amp;self-&gt;threads[i], &amp;err);
 259       if (!self-&gt;threads[i].thread)
 260         goto error;
 261     }
 262   }
 263 
 264   g_mutex_lock (&amp;self-&gt;lock);
 265   while (self-&gt;n_done &lt; self-&gt;n_threads - 1)
 266     g_cond_wait (&amp;self-&gt;cond_done, &amp;self-&gt;lock);
 267   self-&gt;n_done = 0;
 268   g_mutex_unlock (&amp;self-&gt;lock);
 269 
 270   return self;
 271 
 272 error:
 273   {
 274     GST_ERROR (&quot;Failed to start thread %u: %s&quot;, i, err-&gt;message);
 275     g_clear_error (&amp;err);
 276 
 277     gst_parallelized_task_runner_free (self);
 278     return NULL;
 279   }
 280 }
 281 
 282 static void
 283 gst_parallelized_task_runner_run (GstParallelizedTaskRunner * self,
 284     GstParallelizedTaskFunc func, gpointer * task_data)
 285 {
 286   guint n_threads = self-&gt;n_threads;
 287 
 288   self-&gt;func = func;
 289   self-&gt;task_data = task_data;
 290 
 291   if (n_threads &gt; 1) {
 292     g_mutex_lock (&amp;self-&gt;lock);
 293     self-&gt;n_todo = self-&gt;n_threads - 2;
 294     self-&gt;n_done = 0;
 295     g_cond_broadcast (&amp;self-&gt;cond_todo);
 296     g_mutex_unlock (&amp;self-&gt;lock);
 297   }
 298 
 299   self-&gt;func (self-&gt;task_data[self-&gt;n_threads - 1]);
 300 
 301   if (n_threads &gt; 1) {
 302     g_mutex_lock (&amp;self-&gt;lock);
 303     while (self-&gt;n_done &lt; self-&gt;n_threads - 1)
 304       g_cond_wait (&amp;self-&gt;cond_done, &amp;self-&gt;lock);
 305     self-&gt;n_done = 0;
 306     g_mutex_unlock (&amp;self-&gt;lock);
 307   }
 308 
 309   self-&gt;func = NULL;
 310   self-&gt;task_data = NULL;
 311 }
 312 
 313 typedef struct _GstLineCache GstLineCache;
 314 
 315 #endif // GSTREAMER_LITE
 316 
 317 #define SCALE    (8)
 318 #define SCALE_F  ((float) (1 &lt;&lt; SCALE))
 319 
 320 #ifndef GSTREAMER_LITE
 321 
 322 typedef struct _MatrixData MatrixData;
 323 
 324 struct _MatrixData
 325 {
 326   gdouble dm[4][4];
 327   gint im[4][4];
 328   gint width;
 329   guint64 orc_p1;
 330   guint64 orc_p2;
 331   guint64 orc_p3;
 332   guint64 orc_p4;
 333   gint64 *t_r;
 334   gint64 *t_g;
 335   gint64 *t_b;
 336   gint64 t_c;
 337   void (*matrix_func) (MatrixData * data, gpointer pixels);
 338 };
 339 
 340 typedef struct _GammaData GammaData;
 341 
 342 struct _GammaData
 343 {
 344   gpointer gamma_table;
 345   gint width;
 346   void (*gamma_func) (GammaData * data, gpointer dest, gpointer src);
 347 };
 348 
 349 typedef enum
 350 {
 351   ALPHA_MODE_NONE = 0,
 352   ALPHA_MODE_COPY = (1 &lt;&lt; 0),
 353   ALPHA_MODE_SET = (1 &lt;&lt; 1),
 354   ALPHA_MODE_MULT = (1 &lt;&lt; 2)
 355 } AlphaMode;
 356 
 357 typedef struct
 358 {
 359   guint8 *data;
 360   guint stride;
 361   guint n_lines;
 362   guint idx;
 363   gpointer user_data;
 364   GDestroyNotify notify;
 365 } ConverterAlloc;
 366 
 367 typedef void (*FastConvertFunc) (GstVideoConverter * convert,
 368     const GstVideoFrame * src, GstVideoFrame * dest, gint plane);
 369 
 370 struct _GstVideoConverter
 371 {
 372   gint flags;
 373 
 374   GstVideoInfo in_info;
 375   GstVideoInfo out_info;
 376 
 377   gint in_x;
 378   gint in_y;
 379   gint in_width;
 380   gint in_height;
 381   gint in_maxwidth;
 382   gint in_maxheight;
 383   gint out_x;
 384   gint out_y;
 385   gint out_width;
 386   gint out_height;
 387   gint out_maxwidth;
 388   gint out_maxheight;
 389 
 390   gint current_pstride;
 391   gint current_width;
 392   gint current_height;
 393   GstVideoFormat current_format;
 394   gint current_bits;
 395 
 396   GstStructure *config;
 397 
 398   GstParallelizedTaskRunner *conversion_runner;
 399 
 400   guint16 **tmpline;
 401 
 402   gboolean fill_border;
 403   gpointer borderline;
 404   guint64 borders[4];
 405   guint32 border_argb;
 406   guint32 alpha_value;
 407   AlphaMode alpha_mode;
 408 
 409   void (*convert) (GstVideoConverter * convert, const GstVideoFrame * src,
 410       GstVideoFrame * dest);
 411 
 412   /* data for unpack */
 413   GstLineCache **unpack_lines;
 414   GstVideoFormat unpack_format;
 415   guint unpack_bits;
 416   gboolean unpack_rgb;
 417   gboolean identity_unpack;
 418   gint unpack_pstride;
 419 
 420   /* chroma upsample */
 421   GstLineCache **upsample_lines;
 422   GstVideoChromaResample **upsample;
 423   GstVideoChromaResample **upsample_p;
 424   GstVideoChromaResample **upsample_i;
 425   guint up_n_lines;
 426   gint up_offset;
 427 
 428   /* to R&#39;G&#39;B */
 429   GstLineCache **to_RGB_lines;
 430   MatrixData to_RGB_matrix;
 431   /* gamma decode */
 432   GammaData gamma_dec;
 433 
 434   /* scaling */
 435   GstLineCache **hscale_lines;
 436   GstVideoScaler **h_scaler;
 437   gint h_scale_format;
 438   GstLineCache **vscale_lines;
 439   GstVideoScaler **v_scaler;
 440   GstVideoScaler **v_scaler_p;
 441   GstVideoScaler **v_scaler_i;
 442   gint v_scale_width;
 443   gint v_scale_format;
 444 
 445   /* color space conversion */
 446   GstLineCache **convert_lines;
 447   MatrixData convert_matrix;
 448   gint in_bits;
 449   gint out_bits;
 450 
 451   /* alpha correction */
 452   GstLineCache **alpha_lines;
 453   void (*alpha_func) (GstVideoConverter * convert, gpointer pixels, gint width);
 454 
 455   /* gamma encode */
 456   GammaData gamma_enc;
 457   /* to Y&#39;CbCr */
 458   GstLineCache **to_YUV_lines;
 459   MatrixData to_YUV_matrix;
 460 
 461   /* chroma downsample */
 462   GstLineCache **downsample_lines;
 463   GstVideoChromaResample **downsample;
 464   GstVideoChromaResample **downsample_p;
 465   GstVideoChromaResample **downsample_i;
 466   guint down_n_lines;
 467   gint down_offset;
 468 
 469   /* dither */
 470   GstLineCache **dither_lines;
 471   GstVideoDither **dither;
 472 
 473   /* pack */
 474   GstLineCache **pack_lines;
 475   guint pack_nlines;
 476   GstVideoFormat pack_format;
 477   guint pack_bits;
 478   gboolean pack_rgb;
 479   gboolean identity_pack;
 480   gint pack_pstride;
 481   gconstpointer pack_pal;
 482   gsize pack_palsize;
 483 
 484   const GstVideoFrame *src;
 485   GstVideoFrame *dest;
 486 
 487   /* fastpath */
 488   GstVideoFormat fformat[4];
 489   gint fin_x[4];
 490   gint fin_y[4];
 491   gint fout_x[4];
 492   gint fout_y[4];
 493   gint fout_width[4];
 494   gint fout_height[4];
 495   gint fsplane[4];
 496   gint ffill[4];
 497 
 498   struct
 499   {
 500     GstVideoScaler **scaler;
 501   } fh_scaler[4];
 502   struct
 503   {
 504     GstVideoScaler **scaler;
 505   } fv_scaler[4];
 506   FastConvertFunc fconvert[4];
 507 };
 508 
 509 typedef gpointer (*GstLineCacheAllocLineFunc) (GstLineCache * cache, gint idx,
 510     gpointer user_data);
 511 typedef gboolean (*GstLineCacheNeedLineFunc) (GstLineCache * cache, gint idx,
 512     gint out_line, gint in_line, gpointer user_data);
 513 
 514 struct _GstLineCache
 515 {
 516   gint first;
 517   gint backlog;
 518   GPtrArray *lines;
 519 
 520   GstLineCache *prev;
 521   gboolean write_input;
 522   gboolean pass_alloc;
 523   gboolean alloc_writable;
 524 
 525   GstLineCacheNeedLineFunc need_line;
 526   gint need_line_idx;
 527   gpointer need_line_data;
 528   GDestroyNotify need_line_notify;
 529 
 530   guint n_lines;
 531   guint stride;
 532   GstLineCacheAllocLineFunc alloc_line;
 533   gpointer alloc_line_data;
 534   GDestroyNotify alloc_line_notify;
 535 };
 536 
 537 static GstLineCache *
 538 gst_line_cache_new (GstLineCache * prev)
 539 {
 540   GstLineCache *result;
 541 
 542   result = g_slice_new0 (GstLineCache);
 543   result-&gt;lines = g_ptr_array_new ();
 544   result-&gt;prev = prev;
 545 
 546   return result;
 547 }
 548 
 549 static void
 550 gst_line_cache_clear (GstLineCache * cache)
 551 {
 552   g_return_if_fail (cache != NULL);
 553 
 554   g_ptr_array_set_size (cache-&gt;lines, 0);
 555   cache-&gt;first = 0;
 556 }
 557 
 558 static void
 559 gst_line_cache_free (GstLineCache * cache)
 560 {
 561   if (cache-&gt;need_line_notify)
 562     cache-&gt;need_line_notify (cache-&gt;need_line_data);
 563   if (cache-&gt;alloc_line_notify)
 564     cache-&gt;alloc_line_notify (cache-&gt;alloc_line_data);
 565   gst_line_cache_clear (cache);
 566   g_ptr_array_unref (cache-&gt;lines);
 567   g_slice_free (GstLineCache, cache);
 568 }
 569 
 570 static void
 571 gst_line_cache_set_need_line_func (GstLineCache * cache,
 572     GstLineCacheNeedLineFunc need_line, gint idx, gpointer user_data,
 573     GDestroyNotify notify)
 574 {
 575   cache-&gt;need_line = need_line;
 576   cache-&gt;need_line_idx = idx;
 577   cache-&gt;need_line_data = user_data;
 578   cache-&gt;need_line_notify = notify;
 579 }
 580 
 581 static void
 582 gst_line_cache_set_alloc_line_func (GstLineCache * cache,
 583     GstLineCacheAllocLineFunc alloc_line, gpointer user_data,
 584     GDestroyNotify notify)
 585 {
 586   cache-&gt;alloc_line = alloc_line;
 587   cache-&gt;alloc_line_data = user_data;
 588   cache-&gt;alloc_line_notify = notify;
 589 }
 590 
 591 /* keep this much backlog for interlaced video */
 592 #define BACKLOG 2
 593 
 594 static gpointer *
 595 gst_line_cache_get_lines (GstLineCache * cache, gint idx, gint out_line,
 596     gint in_line, gint n_lines)
 597 {
 598   if (cache-&gt;first + cache-&gt;backlog &lt; in_line) {
 599     gint to_remove =
 600         MIN (in_line - (cache-&gt;first + cache-&gt;backlog), cache-&gt;lines-&gt;len);
 601     if (to_remove &gt; 0) {
 602       g_ptr_array_remove_range (cache-&gt;lines, 0, to_remove);
 603     }
 604     cache-&gt;first += to_remove;
 605   } else if (in_line &lt; cache-&gt;first) {
 606     gst_line_cache_clear (cache);
 607     cache-&gt;first = in_line;
 608   }
 609 
 610   while (TRUE) {
 611     gint oline;
 612 
 613     if (cache-&gt;first &lt;= in_line
 614         &amp;&amp; in_line + n_lines &lt;= cache-&gt;first + (gint) cache-&gt;lines-&gt;len) {
 615       return cache-&gt;lines-&gt;pdata + (in_line - cache-&gt;first);
 616     }
 617 
 618     if (cache-&gt;need_line == NULL)
 619       break;
 620 
 621     oline = out_line + cache-&gt;first + cache-&gt;lines-&gt;len - in_line;
 622 
 623     if (!cache-&gt;need_line (cache, idx, oline, cache-&gt;first + cache-&gt;lines-&gt;len,
 624             cache-&gt;need_line_data))
 625       break;
 626   }
 627   GST_DEBUG (&quot;no lines&quot;);
 628   return NULL;
 629 }
 630 
 631 static void
 632 gst_line_cache_add_line (GstLineCache * cache, gint idx, gpointer line)
 633 {
 634   if (cache-&gt;first + cache-&gt;lines-&gt;len != idx) {
 635     gst_line_cache_clear (cache);
 636     cache-&gt;first = idx;
 637   }
 638   g_ptr_array_add (cache-&gt;lines, line);
 639 }
 640 
 641 static gpointer
 642 gst_line_cache_alloc_line (GstLineCache * cache, gint idx)
 643 {
 644   gpointer res;
 645 
 646   if (cache-&gt;alloc_line)
 647     res = cache-&gt;alloc_line (cache, idx, cache-&gt;alloc_line_data);
 648   else
 649     res = NULL;
 650 
 651   return res;
 652 }
 653 
 654 static void video_converter_generic (GstVideoConverter * convert,
 655     const GstVideoFrame * src, GstVideoFrame * dest);
 656 static gboolean video_converter_lookup_fastpath (GstVideoConverter * convert);
 657 static void video_converter_compute_matrix (GstVideoConverter * convert);
 658 static void video_converter_compute_resample (GstVideoConverter * convert,
 659     gint idx);
 660 
 661 static gpointer get_dest_line (GstLineCache * cache, gint idx,
 662     gpointer user_data);
 663 
 664 static gboolean do_unpack_lines (GstLineCache * cache, gint idx, gint out_line,
 665     gint in_line, gpointer user_data);
 666 static gboolean do_downsample_lines (GstLineCache * cache, gint idx,
 667     gint out_line, gint in_line, gpointer user_data);
 668 static gboolean do_convert_to_RGB_lines (GstLineCache * cache, gint idx,
 669     gint out_line, gint in_line, gpointer user_data);
 670 static gboolean do_convert_lines (GstLineCache * cache, gint idx, gint out_line,
 671     gint in_line, gpointer user_data);
 672 static gboolean do_alpha_lines (GstLineCache * cache, gint idx, gint out_line,
 673     gint in_line, gpointer user_data);
 674 static gboolean do_convert_to_YUV_lines (GstLineCache * cache, gint idx,
 675     gint out_line, gint in_line, gpointer user_data);
 676 static gboolean do_upsample_lines (GstLineCache * cache, gint idx,
 677     gint out_line, gint in_line, gpointer user_data);
 678 static gboolean do_vscale_lines (GstLineCache * cache, gint idx, gint out_line,
 679     gint in_line, gpointer user_data);
 680 static gboolean do_hscale_lines (GstLineCache * cache, gint idx, gint out_line,
 681     gint in_line, gpointer user_data);
 682 static gboolean do_dither_lines (GstLineCache * cache, gint idx, gint out_line,
 683     gint in_line, gpointer user_data);
 684 
 685 static ConverterAlloc *
 686 converter_alloc_new (guint stride, guint n_lines, gpointer user_data,
 687     GDestroyNotify notify)
 688 {
 689   ConverterAlloc *alloc;
 690 
 691   GST_DEBUG (&quot;stride %d, n_lines %d&quot;, stride, n_lines);
 692   alloc = g_slice_new0 (ConverterAlloc);
 693   alloc-&gt;data = g_malloc (stride * n_lines);
 694   alloc-&gt;stride = stride;
 695   alloc-&gt;n_lines = n_lines;
 696   alloc-&gt;idx = 0;
 697   alloc-&gt;user_data = user_data;
 698   alloc-&gt;notify = notify;
 699 
 700   return alloc;
 701 }
 702 
 703 static void
 704 converter_alloc_free (ConverterAlloc * alloc)
 705 {
 706   if (alloc-&gt;notify)
 707     alloc-&gt;notify (alloc-&gt;user_data);
 708   g_free (alloc-&gt;data);
 709   g_slice_free (ConverterAlloc, alloc);
 710 }
 711 
 712 static void
 713 setup_border_alloc (GstVideoConverter * convert, ConverterAlloc * alloc)
 714 {
 715   gint i;
 716 
 717   if (convert-&gt;borderline) {
 718     for (i = 0; i &lt; alloc-&gt;n_lines; i++)
 719       memcpy (&amp;alloc-&gt;data[i * alloc-&gt;stride], convert-&gt;borderline,
 720           alloc-&gt;stride);
 721   }
 722 }
 723 
 724 static gpointer
 725 get_temp_line (GstLineCache * cache, gint idx, gpointer user_data)
 726 {
 727   ConverterAlloc *alloc = user_data;
 728   gpointer tmpline;
 729 
 730   GST_DEBUG (&quot;get temp line %d (%p %d)&quot;, idx, alloc, alloc-&gt;idx);
 731   tmpline = &amp;alloc-&gt;data[alloc-&gt;stride * alloc-&gt;idx];
 732   alloc-&gt;idx = (alloc-&gt;idx + 1) % alloc-&gt;n_lines;
 733 
 734   return tmpline;
 735 }
 736 
 737 static gpointer
 738 get_border_temp_line (GstLineCache * cache, gint idx, gpointer user_data)
 739 {
 740   ConverterAlloc *alloc = user_data;
 741   GstVideoConverter *convert = alloc-&gt;user_data;
 742   gpointer tmpline;
 743 
 744   GST_DEBUG (&quot;get temp line %d (%p %d)&quot;, idx, alloc, alloc-&gt;idx);
 745   tmpline = &amp;alloc-&gt;data[alloc-&gt;stride * alloc-&gt;idx] +
 746       (convert-&gt;out_x * convert-&gt;pack_pstride);
 747   alloc-&gt;idx = (alloc-&gt;idx + 1) % alloc-&gt;n_lines;
 748 
 749   return tmpline;
 750 }
 751 
 752 static gint
 753 get_opt_int (GstVideoConverter * convert, const gchar * opt, gint def)
 754 {
 755   gint res;
 756   if (!gst_structure_get_int (convert-&gt;config, opt, &amp;res))
 757     res = def;
 758   return res;
 759 }
 760 
 761 static guint
 762 get_opt_uint (GstVideoConverter * convert, const gchar * opt, guint def)
 763 {
 764   guint res;
 765   if (!gst_structure_get_uint (convert-&gt;config, opt, &amp;res))
 766     res = def;
 767   return res;
 768 }
 769 
 770 static gdouble
 771 get_opt_double (GstVideoConverter * convert, const gchar * opt, gdouble def)
 772 {
 773   gdouble res;
 774   if (!gst_structure_get_double (convert-&gt;config, opt, &amp;res))
 775     res = def;
 776   return res;
 777 }
 778 
 779 static gboolean
 780 get_opt_bool (GstVideoConverter * convert, const gchar * opt, gboolean def)
 781 {
 782   gboolean res;
 783   if (!gst_structure_get_boolean (convert-&gt;config, opt, &amp;res))
 784     res = def;
 785   return res;
 786 }
 787 
 788 static gint
 789 get_opt_enum (GstVideoConverter * convert, const gchar * opt, GType type,
 790     gint def)
 791 {
 792   gint res;
 793   if (!gst_structure_get_enum (convert-&gt;config, opt, type, &amp;res))
 794     res = def;
 795   return res;
 796 }
 797 
 798 #define DEFAULT_OPT_FILL_BORDER TRUE
 799 #define DEFAULT_OPT_ALPHA_VALUE 1.0
 800 /* options copy, set, mult */
 801 #define DEFAULT_OPT_ALPHA_MODE GST_VIDEO_ALPHA_MODE_COPY
 802 #define DEFAULT_OPT_BORDER_ARGB 0xff000000
 803 /* options full, input-only, output-only, none */
 804 #define DEFAULT_OPT_MATRIX_MODE GST_VIDEO_MATRIX_MODE_FULL
 805 /* none, remap */
 806 #define DEFAULT_OPT_GAMMA_MODE GST_VIDEO_GAMMA_MODE_NONE
 807 /* none, merge-only, fast */
 808 #define DEFAULT_OPT_PRIMARIES_MODE GST_VIDEO_PRIMARIES_MODE_NONE
 809 /* options full, upsample-only, downsample-only, none */
 810 #define DEFAULT_OPT_CHROMA_MODE GST_VIDEO_CHROMA_MODE_FULL
 811 #define DEFAULT_OPT_RESAMPLER_METHOD GST_VIDEO_RESAMPLER_METHOD_CUBIC
 812 #define DEFAULT_OPT_CHROMA_RESAMPLER_METHOD GST_VIDEO_RESAMPLER_METHOD_LINEAR
 813 #define DEFAULT_OPT_RESAMPLER_TAPS 0
 814 #define DEFAULT_OPT_DITHER_METHOD GST_VIDEO_DITHER_BAYER
 815 #define DEFAULT_OPT_DITHER_QUANTIZATION 1
 816 
 817 #define GET_OPT_FILL_BORDER(c) get_opt_bool(c, \
 818     GST_VIDEO_CONVERTER_OPT_FILL_BORDER, DEFAULT_OPT_FILL_BORDER)
 819 #define GET_OPT_ALPHA_VALUE(c) get_opt_double(c, \
 820     GST_VIDEO_CONVERTER_OPT_ALPHA_VALUE, DEFAULT_OPT_ALPHA_VALUE)
 821 #define GET_OPT_ALPHA_MODE(c) get_opt_enum(c, \
 822     GST_VIDEO_CONVERTER_OPT_ALPHA_MODE, GST_TYPE_VIDEO_ALPHA_MODE, DEFAULT_OPT_ALPHA_MODE)
 823 #define GET_OPT_BORDER_ARGB(c) get_opt_uint(c, \
 824     GST_VIDEO_CONVERTER_OPT_BORDER_ARGB, DEFAULT_OPT_BORDER_ARGB)
 825 #define GET_OPT_MATRIX_MODE(c) get_opt_enum(c, \
 826     GST_VIDEO_CONVERTER_OPT_MATRIX_MODE, GST_TYPE_VIDEO_MATRIX_MODE, DEFAULT_OPT_MATRIX_MODE)
 827 #define GET_OPT_GAMMA_MODE(c) get_opt_enum(c, \
 828     GST_VIDEO_CONVERTER_OPT_GAMMA_MODE, GST_TYPE_VIDEO_GAMMA_MODE, DEFAULT_OPT_GAMMA_MODE)
 829 #define GET_OPT_PRIMARIES_MODE(c) get_opt_enum(c, \
 830     GST_VIDEO_CONVERTER_OPT_PRIMARIES_MODE, GST_TYPE_VIDEO_PRIMARIES_MODE, DEFAULT_OPT_PRIMARIES_MODE)
 831 #define GET_OPT_CHROMA_MODE(c) get_opt_enum(c, \
 832     GST_VIDEO_CONVERTER_OPT_CHROMA_MODE, GST_TYPE_VIDEO_CHROMA_MODE, DEFAULT_OPT_CHROMA_MODE)
 833 #define GET_OPT_RESAMPLER_METHOD(c) get_opt_enum(c, \
 834     GST_VIDEO_CONVERTER_OPT_RESAMPLER_METHOD, GST_TYPE_VIDEO_RESAMPLER_METHOD, \
 835     DEFAULT_OPT_RESAMPLER_METHOD)
 836 #define GET_OPT_CHROMA_RESAMPLER_METHOD(c) get_opt_enum(c, \
 837     GST_VIDEO_CONVERTER_OPT_CHROMA_RESAMPLER_METHOD, GST_TYPE_VIDEO_RESAMPLER_METHOD, \
 838     DEFAULT_OPT_CHROMA_RESAMPLER_METHOD)
 839 #define GET_OPT_RESAMPLER_TAPS(c) get_opt_uint(c, \
 840     GST_VIDEO_CONVERTER_OPT_RESAMPLER_TAPS, DEFAULT_OPT_RESAMPLER_TAPS)
 841 #define GET_OPT_DITHER_METHOD(c) get_opt_enum(c, \
 842     GST_VIDEO_CONVERTER_OPT_DITHER_METHOD, GST_TYPE_VIDEO_DITHER_METHOD, \
 843     DEFAULT_OPT_DITHER_METHOD)
 844 #define GET_OPT_DITHER_QUANTIZATION(c) get_opt_uint(c, \
 845     GST_VIDEO_CONVERTER_OPT_DITHER_QUANTIZATION, DEFAULT_OPT_DITHER_QUANTIZATION)
 846 
 847 #define CHECK_ALPHA_COPY(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_COPY)
 848 #define CHECK_ALPHA_SET(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_SET)
 849 #define CHECK_ALPHA_MULT(c) (GET_OPT_ALPHA_MODE(c) == GST_VIDEO_ALPHA_MODE_MULT)
 850 
 851 #define CHECK_MATRIX_FULL(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_FULL)
 852 #define CHECK_MATRIX_INPUT(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_INPUT_ONLY)
 853 #define CHECK_MATRIX_OUTPUT(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_OUTPUT_ONLY)
 854 #define CHECK_MATRIX_NONE(c) (GET_OPT_MATRIX_MODE(c) == GST_VIDEO_MATRIX_MODE_NONE)
 855 
 856 #define CHECK_GAMMA_NONE(c) (GET_OPT_GAMMA_MODE(c) == GST_VIDEO_GAMMA_MODE_NONE)
 857 #define CHECK_GAMMA_REMAP(c) (GET_OPT_GAMMA_MODE(c) == GST_VIDEO_GAMMA_MODE_REMAP)
 858 
 859 #define CHECK_PRIMARIES_NONE(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_NONE)
 860 #define CHECK_PRIMARIES_MERGE(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_MERGE_ONLY)
 861 #define CHECK_PRIMARIES_FAST(c) (GET_OPT_PRIMARIES_MODE(c) == GST_VIDEO_PRIMARIES_MODE_FAST)
 862 
 863 #define CHECK_CHROMA_FULL(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_FULL)
 864 #define CHECK_CHROMA_UPSAMPLE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_UPSAMPLE_ONLY)
 865 #define CHECK_CHROMA_DOWNSAMPLE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_DOWNSAMPLE_ONLY)
 866 #define CHECK_CHROMA_NONE(c) (GET_OPT_CHROMA_MODE(c) == GST_VIDEO_CHROMA_MODE_NONE)
 867 
 868 static GstLineCache *
 869 chain_unpack_line (GstVideoConverter * convert, gint idx)
 870 {
 871   GstLineCache *prev;
 872   GstVideoInfo *info;
 873 
 874   info = &amp;convert-&gt;in_info;
 875 
 876   convert-&gt;current_format = convert-&gt;unpack_format;
 877   convert-&gt;current_bits = convert-&gt;unpack_bits;
 878   convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
 879 
 880   convert-&gt;unpack_pstride = convert-&gt;current_pstride;
 881   convert-&gt;identity_unpack = (convert-&gt;current_format == info-&gt;finfo-&gt;format);
 882 
 883   GST_DEBUG (&quot;chain unpack line format %s, pstride %d, identity_unpack %d&quot;,
 884       gst_video_format_to_string (convert-&gt;current_format),
 885       convert-&gt;current_pstride, convert-&gt;identity_unpack);
 886 
 887   prev = convert-&gt;unpack_lines[idx] = gst_line_cache_new (NULL);
 888   prev-&gt;write_input = FALSE;
 889   prev-&gt;pass_alloc = FALSE;
 890   prev-&gt;n_lines = 1;
 891   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
 892   gst_line_cache_set_need_line_func (prev, do_unpack_lines, idx, convert, NULL);
 893 
 894   return prev;
 895 }
 896 
 897 static GstLineCache *
 898 chain_upsample (GstVideoConverter * convert, GstLineCache * prev, gint idx)
 899 {
 900   video_converter_compute_resample (convert, idx);
 901 
 902   if (convert-&gt;upsample_p[idx] || convert-&gt;upsample_i[idx]) {
 903     GST_DEBUG (&quot;chain upsample&quot;);
 904     prev = convert-&gt;upsample_lines[idx] = gst_line_cache_new (prev);
 905     prev-&gt;write_input = TRUE;
 906     prev-&gt;pass_alloc = TRUE;
 907     prev-&gt;n_lines = 4;
 908     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
 909     gst_line_cache_set_need_line_func (prev,
 910         do_upsample_lines, idx, convert, NULL);
 911   }
 912   return prev;
 913 }
 914 
 915 static void
 916 color_matrix_set_identity (MatrixData * m)
 917 {
 918   int i, j;
 919 
 920   for (i = 0; i &lt; 4; i++) {
 921     for (j = 0; j &lt; 4; j++) {
 922       m-&gt;dm[i][j] = (i == j);
 923     }
 924   }
 925 }
 926 
 927 static void
 928 color_matrix_copy (MatrixData * d, const MatrixData * s)
 929 {
 930   gint i, j;
 931 
 932   for (i = 0; i &lt; 4; i++)
 933     for (j = 0; j &lt; 4; j++)
 934       d-&gt;dm[i][j] = s-&gt;dm[i][j];
 935 }
 936 
 937 /* Perform 4x4 matrix multiplication:
 938  *  - @dst@ = @a@ * @b@
 939  *  - @dst@ may be a pointer to @a@ andor @b@
 940  */
 941 static void
 942 color_matrix_multiply (MatrixData * dst, MatrixData * a, MatrixData * b)
 943 {
 944   MatrixData tmp;
 945   int i, j, k;
 946 
 947   for (i = 0; i &lt; 4; i++) {
 948     for (j = 0; j &lt; 4; j++) {
 949       double x = 0;
 950       for (k = 0; k &lt; 4; k++) {
 951         x += a-&gt;dm[i][k] * b-&gt;dm[k][j];
 952       }
 953       tmp.dm[i][j] = x;
 954     }
 955   }
 956   color_matrix_copy (dst, &amp;tmp);
 957 }
 958 
 959 static void
 960 color_matrix_invert (MatrixData * d, MatrixData * s)
 961 {
 962   MatrixData tmp;
 963   int i, j;
 964   double det;
 965 
 966   color_matrix_set_identity (&amp;tmp);
 967   for (j = 0; j &lt; 3; j++) {
 968     for (i = 0; i &lt; 3; i++) {
 969       tmp.dm[j][i] =
 970           s-&gt;dm[(i + 1) % 3][(j + 1) % 3] * s-&gt;dm[(i + 2) % 3][(j + 2) % 3] -
 971           s-&gt;dm[(i + 1) % 3][(j + 2) % 3] * s-&gt;dm[(i + 2) % 3][(j + 1) % 3];
 972     }
 973   }
 974   det =
 975       tmp.dm[0][0] * s-&gt;dm[0][0] + tmp.dm[0][1] * s-&gt;dm[1][0] +
 976       tmp.dm[0][2] * s-&gt;dm[2][0];
 977   for (j = 0; j &lt; 3; j++) {
 978     for (i = 0; i &lt; 3; i++) {
 979       tmp.dm[i][j] /= det;
 980     }
 981   }
 982   color_matrix_copy (d, &amp;tmp);
 983 }
 984 
 985 static void
 986 color_matrix_offset_components (MatrixData * m, double a1, double a2, double a3)
 987 {
 988   MatrixData a;
 989 
 990   color_matrix_set_identity (&amp;a);
 991   a.dm[0][3] = a1;
 992   a.dm[1][3] = a2;
 993   a.dm[2][3] = a3;
 994   color_matrix_multiply (m, &amp;a, m);
 995 }
 996 
 997 static void
 998 color_matrix_scale_components (MatrixData * m, double a1, double a2, double a3)
 999 {
1000   MatrixData a;
1001 
1002   color_matrix_set_identity (&amp;a);
1003   a.dm[0][0] = a1;
1004   a.dm[1][1] = a2;
1005   a.dm[2][2] = a3;
1006   color_matrix_multiply (m, &amp;a, m);
1007 }
1008 
1009 static void
1010 color_matrix_debug (const MatrixData * s)
1011 {
1012   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[0][0], s-&gt;dm[0][1], s-&gt;dm[0][2],
1013       s-&gt;dm[0][3]);
1014   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[1][0], s-&gt;dm[1][1], s-&gt;dm[1][2],
1015       s-&gt;dm[1][3]);
1016   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[2][0], s-&gt;dm[2][1], s-&gt;dm[2][2],
1017       s-&gt;dm[2][3]);
1018   GST_DEBUG (&quot;[%f %f %f %f]&quot;, s-&gt;dm[3][0], s-&gt;dm[3][1], s-&gt;dm[3][2],
1019       s-&gt;dm[3][3]);
1020 }
1021 
1022 static void
1023 color_matrix_convert (MatrixData * s)
1024 {
1025   gint i, j;
1026 
1027   for (i = 0; i &lt; 4; i++)
1028     for (j = 0; j &lt; 4; j++)
1029       s-&gt;im[i][j] = rint (s-&gt;dm[i][j]);
1030 
1031   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[0][0], s-&gt;im[0][1], s-&gt;im[0][2],
1032       s-&gt;im[0][3]);
1033   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[1][0], s-&gt;im[1][1], s-&gt;im[1][2],
1034       s-&gt;im[1][3]);
1035   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[2][0], s-&gt;im[2][1], s-&gt;im[2][2],
1036       s-&gt;im[2][3]);
1037   GST_DEBUG (&quot;[%6d %6d %6d %6d]&quot;, s-&gt;im[3][0], s-&gt;im[3][1], s-&gt;im[3][2],
1038       s-&gt;im[3][3]);
1039 }
1040 
1041 static void
1042 color_matrix_YCbCr_to_RGB (MatrixData * m, double Kr, double Kb)
1043 {
1044   double Kg = 1.0 - Kr - Kb;
1045   MatrixData k = {
1046     {
1047           {1., 0., 2 * (1 - Kr), 0.},
1048           {1., -2 * Kb * (1 - Kb) / Kg, -2 * Kr * (1 - Kr) / Kg, 0.},
1049           {1., 2 * (1 - Kb), 0., 0.},
1050           {0., 0., 0., 1.},
1051         }
1052   };
1053 
1054   color_matrix_multiply (m, &amp;k, m);
1055 }
1056 
1057 static void
1058 color_matrix_RGB_to_YCbCr (MatrixData * m, double Kr, double Kb)
1059 {
1060   double Kg = 1.0 - Kr - Kb;
1061   MatrixData k;
1062   double x;
1063 
1064   k.dm[0][0] = Kr;
1065   k.dm[0][1] = Kg;
1066   k.dm[0][2] = Kb;
1067   k.dm[0][3] = 0;
1068 
1069   x = 1 / (2 * (1 - Kb));
1070   k.dm[1][0] = -x * Kr;
1071   k.dm[1][1] = -x * Kg;
1072   k.dm[1][2] = x * (1 - Kb);
1073   k.dm[1][3] = 0;
1074 
1075   x = 1 / (2 * (1 - Kr));
1076   k.dm[2][0] = x * (1 - Kr);
1077   k.dm[2][1] = -x * Kg;
1078   k.dm[2][2] = -x * Kb;
1079   k.dm[2][3] = 0;
1080 
1081   k.dm[3][0] = 0;
1082   k.dm[3][1] = 0;
1083   k.dm[3][2] = 0;
1084   k.dm[3][3] = 1;
1085 
1086   color_matrix_multiply (m, &amp;k, m);
1087 }
1088 
1089 static void
1090 color_matrix_RGB_to_XYZ (MatrixData * dst, double Rx, double Ry, double Gx,
1091     double Gy, double Bx, double By, double Wx, double Wy)
1092 {
1093   MatrixData m, im;
1094   double sx, sy, sz;
1095   double wx, wy, wz;
1096 
1097   color_matrix_set_identity (&amp;m);
1098 
1099   m.dm[0][0] = Rx;
1100   m.dm[1][0] = Ry;
1101   m.dm[2][0] = (1.0 - Rx - Ry);
1102   m.dm[0][1] = Gx;
1103   m.dm[1][1] = Gy;
1104   m.dm[2][1] = (1.0 - Gx - Gy);
1105   m.dm[0][2] = Bx;
1106   m.dm[1][2] = By;
1107   m.dm[2][2] = (1.0 - Bx - By);
1108 
1109   color_matrix_invert (&amp;im, &amp;m);
1110 
1111   wx = Wx / Wy;
1112   wy = 1.0;
1113   wz = (1.0 - Wx - Wy) / Wy;
1114 
1115   sx = im.dm[0][0] * wx + im.dm[0][1] * wy + im.dm[0][2] * wz;
1116   sy = im.dm[1][0] * wx + im.dm[1][1] * wy + im.dm[1][2] * wz;
1117   sz = im.dm[2][0] * wx + im.dm[2][1] * wy + im.dm[2][2] * wz;
1118 
1119   m.dm[0][0] *= sx;
1120   m.dm[1][0] *= sx;
1121   m.dm[2][0] *= sx;
1122   m.dm[0][1] *= sy;
1123   m.dm[1][1] *= sy;
1124   m.dm[2][1] *= sy;
1125   m.dm[0][2] *= sz;
1126   m.dm[1][2] *= sz;
1127   m.dm[2][2] *= sz;
1128 
1129   color_matrix_copy (dst, &amp;m);
1130 }
1131 
1132 static void
1133 videoconvert_convert_init_tables (MatrixData * data)
1134 {
1135   gint i, j;
1136 
1137   data-&gt;t_r = g_new (gint64, 256);
1138   data-&gt;t_g = g_new (gint64, 256);
1139   data-&gt;t_b = g_new (gint64, 256);
1140 
1141   for (i = 0; i &lt; 256; i++) {
1142     gint64 r = 0, g = 0, b = 0;
1143 
1144     for (j = 0; j &lt; 3; j++) {
1145       r = (r &lt;&lt; 16) + data-&gt;im[j][0] * i;
1146       g = (g &lt;&lt; 16) + data-&gt;im[j][1] * i;
1147       b = (b &lt;&lt; 16) + data-&gt;im[j][2] * i;
1148     }
1149     data-&gt;t_r[i] = r;
1150     data-&gt;t_g[i] = g;
1151     data-&gt;t_b[i] = b;
1152   }
1153   data-&gt;t_c = ((gint64) data-&gt;im[0][3] &lt;&lt; 32)
1154       + ((gint64) data-&gt;im[1][3] &lt;&lt; 16)
1155       + ((gint64) data-&gt;im[2][3] &lt;&lt; 0);
1156 }
1157 
1158 #endif // GSTREAMER_LITE
1159 
1160 void
1161 _custom_video_orc_matrix8 (guint8 * ORC_RESTRICT d1,
1162     const guint8 * ORC_RESTRICT s1, orc_int64 p1, orc_int64 p2, orc_int64 p3,
1163     orc_int64 p4, int n)
1164 {
1165   gint i;
1166   gint r, g, b;
1167   gint y, u, v;
1168   gint a00, a01, a02, a03;
1169   gint a10, a11, a12, a13;
1170   gint a20, a21, a22, a23;
1171 
1172   a00 = (gint16) (p1 &gt;&gt; 16);
1173   a01 = (gint16) (p2 &gt;&gt; 16);
1174   a02 = (gint16) (p3 &gt;&gt; 16);
1175   a03 = (gint16) (p4 &gt;&gt; 16);
1176   a10 = (gint16) (p1 &gt;&gt; 32);
1177   a11 = (gint16) (p2 &gt;&gt; 32);
1178   a12 = (gint16) (p3 &gt;&gt; 32);
1179   a13 = (gint16) (p4 &gt;&gt; 32);
1180   a20 = (gint16) (p1 &gt;&gt; 48);
1181   a21 = (gint16) (p2 &gt;&gt; 48);
1182   a22 = (gint16) (p3 &gt;&gt; 48);
1183   a23 = (gint16) (p4 &gt;&gt; 48);
1184 
1185   for (i = 0; i &lt; n; i++) {
1186     r = s1[i * 4 + 1];
1187     g = s1[i * 4 + 2];
1188     b = s1[i * 4 + 3];
1189 
1190     y = ((a00 * r + a01 * g + a02 * b) &gt;&gt; SCALE) + a03;
1191     u = ((a10 * r + a11 * g + a12 * b) &gt;&gt; SCALE) + a13;
1192     v = ((a20 * r + a21 * g + a22 * b) &gt;&gt; SCALE) + a23;
1193 
1194     d1[i * 4 + 1] = CLAMP (y, 0, 255);
1195     d1[i * 4 + 2] = CLAMP (u, 0, 255);
1196     d1[i * 4 + 3] = CLAMP (v, 0, 255);
1197   }
1198 }
1199 
1200 #ifndef GSTREAMER_LITE
1201 
1202 static void
1203 video_converter_matrix8 (MatrixData * data, gpointer pixels)
1204 {
1205   gpointer d = pixels;
1206   video_orc_matrix8 (d, pixels, data-&gt;orc_p1, data-&gt;orc_p2,
1207       data-&gt;orc_p3, data-&gt;orc_p4, data-&gt;width);
1208 }
1209 
1210 static void
1211 video_converter_matrix8_table (MatrixData * data, gpointer pixels)
1212 {
1213   gint i, width = data-&gt;width * 4;
1214   guint8 r, g, b;
1215   gint64 c = data-&gt;t_c;
1216   guint8 *p = pixels;
1217   gint64 x;
1218 
1219   for (i = 0; i &lt; width; i += 4) {
1220     r = p[i + 1];
1221     g = p[i + 2];
1222     b = p[i + 3];
1223 
1224     x = data-&gt;t_r[r] + data-&gt;t_g[g] + data-&gt;t_b[b] + c;
1225 
1226     p[i + 1] = x &gt;&gt; (32 + SCALE);
1227     p[i + 2] = x &gt;&gt; (16 + SCALE);
1228     p[i + 3] = x &gt;&gt; (0 + SCALE);
1229   }
1230 }
1231 
1232 static void
1233 video_converter_matrix8_AYUV_ARGB (MatrixData * data, gpointer pixels)
1234 {
1235   gpointer d = pixels;
1236 
1237   video_orc_convert_AYUV_ARGB (d, 0, pixels, 0,
1238       data-&gt;im[0][0], data-&gt;im[0][2],
1239       data-&gt;im[2][1], data-&gt;im[1][1], data-&gt;im[1][2], data-&gt;width, 1);
1240 }
1241 
1242 static gboolean
1243 is_ayuv_to_rgb_matrix (MatrixData * data)
1244 {
1245   if (data-&gt;im[0][0] != data-&gt;im[1][0] || data-&gt;im[1][0] != data-&gt;im[2][0])
1246     return FALSE;
1247 
1248   if (data-&gt;im[0][1] != 0 || data-&gt;im[2][2] != 0)
1249     return FALSE;
1250 
1251   return TRUE;
1252 }
1253 
1254 static gboolean
1255 is_identity_matrix (MatrixData * data)
1256 {
1257   gint i, j;
1258   gint c = data-&gt;im[0][0];
1259 
1260   /* not really checking identity because of rounding errors but given
1261    * the conversions we do we just check for anything that looks like:
1262    *
1263    *  c 0 0 0
1264    *  0 c 0 0
1265    *  0 0 c 0
1266    *  0 0 0 1
1267    */
1268   for (i = 0; i &lt; 4; i++) {
1269     for (j = 0; j &lt; 4; j++) {
1270       if (i == j) {
1271         if (i == 3 &amp;&amp; data-&gt;im[i][j] != 1)
1272           return FALSE;
1273         else if (data-&gt;im[i][j] != c)
1274           return FALSE;
1275       } else if (data-&gt;im[i][j] != 0)
1276         return FALSE;
1277     }
1278   }
1279   return TRUE;
1280 }
1281 
1282 static gboolean
1283 is_no_clip_matrix (MatrixData * data)
1284 {
1285   gint i;
1286   static const guint8 test[8][3] = {
1287     {0, 0, 0},
1288     {0, 0, 255},
1289     {0, 255, 0},
1290     {0, 255, 255},
1291     {255, 0, 0},
1292     {255, 0, 255},
1293     {255, 255, 0},
1294     {255, 255, 255}
1295   };
1296 
1297   for (i = 0; i &lt; 8; i++) {
1298     gint r, g, b;
1299     gint y, u, v;
1300 
1301     r = test[i][0];
1302     g = test[i][1];
1303     b = test[i][2];
1304 
1305     y = (data-&gt;im[0][0] * r + data-&gt;im[0][1] * g +
1306         data-&gt;im[0][2] * b + data-&gt;im[0][3]) &gt;&gt; SCALE;
1307     u = (data-&gt;im[1][0] * r + data-&gt;im[1][1] * g +
1308         data-&gt;im[1][2] * b + data-&gt;im[1][3]) &gt;&gt; SCALE;
1309     v = (data-&gt;im[2][0] * r + data-&gt;im[2][1] * g +
1310         data-&gt;im[2][2] * b + data-&gt;im[2][3]) &gt;&gt; SCALE;
1311 
1312     if (y != CLAMP (y, 0, 255) || u != CLAMP (u, 0, 255)
1313         || v != CLAMP (v, 0, 255))
1314       return FALSE;
1315   }
1316   return TRUE;
1317 }
1318 
1319 static void
1320 video_converter_matrix16 (MatrixData * data, gpointer pixels)
1321 {
1322   int i;
1323   int r, g, b;
1324   int y, u, v;
1325   guint16 *p = pixels;
1326   gint width = data-&gt;width;
1327 
1328   for (i = 0; i &lt; width; i++) {
1329     r = p[i * 4 + 1];
1330     g = p[i * 4 + 2];
1331     b = p[i * 4 + 3];
1332 
1333     y = (data-&gt;im[0][0] * r + data-&gt;im[0][1] * g +
1334         data-&gt;im[0][2] * b + data-&gt;im[0][3]) &gt;&gt; SCALE;
1335     u = (data-&gt;im[1][0] * r + data-&gt;im[1][1] * g +
1336         data-&gt;im[1][2] * b + data-&gt;im[1][3]) &gt;&gt; SCALE;
1337     v = (data-&gt;im[2][0] * r + data-&gt;im[2][1] * g +
1338         data-&gt;im[2][2] * b + data-&gt;im[2][3]) &gt;&gt; SCALE;
1339 
1340     p[i * 4 + 1] = CLAMP (y, 0, 65535);
1341     p[i * 4 + 2] = CLAMP (u, 0, 65535);
1342     p[i * 4 + 3] = CLAMP (v, 0, 65535);
1343   }
1344 }
1345 
1346 
1347 static void
1348 prepare_matrix (GstVideoConverter * convert, MatrixData * data)
1349 {
1350   if (is_identity_matrix (data))
1351     return;
1352 
1353   color_matrix_scale_components (data, SCALE_F, SCALE_F, SCALE_F);
1354   color_matrix_convert (data);
1355 
1356   data-&gt;width = convert-&gt;current_width;
1357 
1358   if (convert-&gt;current_bits == 8) {
1359     if (!convert-&gt;unpack_rgb &amp;&amp; convert-&gt;pack_rgb
1360         &amp;&amp; is_ayuv_to_rgb_matrix (data)) {
1361       GST_DEBUG (&quot;use fast AYUV -&gt; RGB matrix&quot;);
1362       data-&gt;matrix_func = video_converter_matrix8_AYUV_ARGB;
1363     } else if (is_no_clip_matrix (data)) {
1364       GST_DEBUG (&quot;use 8bit table&quot;);
1365       data-&gt;matrix_func = video_converter_matrix8_table;
1366       videoconvert_convert_init_tables (data);
1367     } else {
1368       gint a03, a13, a23;
1369 
1370       GST_DEBUG (&quot;use 8bit matrix&quot;);
1371       data-&gt;matrix_func = video_converter_matrix8;
1372 
1373       data-&gt;orc_p1 = (((guint64) (guint16) data-&gt;im[2][0]) &lt;&lt; 48) |
1374           (((guint64) (guint16) data-&gt;im[1][0]) &lt;&lt; 32) |
1375           (((guint64) (guint16) data-&gt;im[0][0]) &lt;&lt; 16);
1376       data-&gt;orc_p2 = (((guint64) (guint16) data-&gt;im[2][1]) &lt;&lt; 48) |
1377           (((guint64) (guint16) data-&gt;im[1][1]) &lt;&lt; 32) |
1378           (((guint64) (guint16) data-&gt;im[0][1]) &lt;&lt; 16);
1379       data-&gt;orc_p3 = (((guint64) (guint16) data-&gt;im[2][2]) &lt;&lt; 48) |
1380           (((guint64) (guint16) data-&gt;im[1][2]) &lt;&lt; 32) |
1381           (((guint64) (guint16) data-&gt;im[0][2]) &lt;&lt; 16);
1382 
1383       a03 = data-&gt;im[0][3] &gt;&gt; SCALE;
1384       a13 = data-&gt;im[1][3] &gt;&gt; SCALE;
1385       a23 = data-&gt;im[2][3] &gt;&gt; SCALE;
1386 
1387       data-&gt;orc_p4 = (((guint64) (guint16) a23) &lt;&lt; 48) |
1388           (((guint64) (guint16) a13) &lt;&lt; 32) | (((guint64) (guint16) a03) &lt;&lt; 16);
1389     }
1390   } else {
1391     GST_DEBUG (&quot;use 16bit matrix&quot;);
1392     data-&gt;matrix_func = video_converter_matrix16;
1393   }
1394 }
1395 
1396 static void
1397 compute_matrix_to_RGB (GstVideoConverter * convert, MatrixData * data)
1398 {
1399   GstVideoInfo *info;
1400   gdouble Kr = 0, Kb = 0;
1401 
1402   info = &amp;convert-&gt;in_info;
1403 
1404   {
1405     const GstVideoFormatInfo *uinfo;
1406     gint offset[4], scale[4];
1407 
1408     uinfo = gst_video_format_get_info (convert-&gt;unpack_format);
1409 
1410     /* bring color components to [0..1.0] range */
1411     gst_video_color_range_offsets (info-&gt;colorimetry.range, uinfo, offset,
1412         scale);
1413 
1414     color_matrix_offset_components (data, -offset[0], -offset[1], -offset[2]);
1415     color_matrix_scale_components (data, 1 / ((float) scale[0]),
1416         1 / ((float) scale[1]), 1 / ((float) scale[2]));
1417   }
1418 
1419   if (!convert-&gt;unpack_rgb &amp;&amp; !CHECK_MATRIX_NONE (convert)) {
1420     if (CHECK_MATRIX_OUTPUT (convert))
1421       info = &amp;convert-&gt;out_info;
1422 
1423     /* bring components to R&#39;G&#39;B&#39; space */
1424     if (gst_video_color_matrix_get_Kr_Kb (info-&gt;colorimetry.matrix, &amp;Kr, &amp;Kb))
1425       color_matrix_YCbCr_to_RGB (data, Kr, Kb);
1426   }
1427   color_matrix_debug (data);
1428 }
1429 
1430 static void
1431 compute_matrix_to_YUV (GstVideoConverter * convert, MatrixData * data,
1432     gboolean force)
1433 {
1434   GstVideoInfo *info;
1435   gdouble Kr = 0, Kb = 0;
1436 
1437   if (force || (!convert-&gt;pack_rgb &amp;&amp; !CHECK_MATRIX_NONE (convert))) {
1438     if (CHECK_MATRIX_INPUT (convert))
1439       info = &amp;convert-&gt;in_info;
1440     else
1441       info = &amp;convert-&gt;out_info;
1442 
1443     /* bring components to YCbCr space */
1444     if (gst_video_color_matrix_get_Kr_Kb (info-&gt;colorimetry.matrix, &amp;Kr, &amp;Kb))
1445       color_matrix_RGB_to_YCbCr (data, Kr, Kb);
1446   }
1447 
1448   info = &amp;convert-&gt;out_info;
1449 
1450   {
1451     const GstVideoFormatInfo *uinfo;
1452     gint offset[4], scale[4];
1453 
1454     uinfo = gst_video_format_get_info (convert-&gt;pack_format);
1455 
1456     /* bring color components to nominal range */
1457     gst_video_color_range_offsets (info-&gt;colorimetry.range, uinfo, offset,
1458         scale);
1459 
1460     color_matrix_scale_components (data, (float) scale[0], (float) scale[1],
1461         (float) scale[2]);
1462     color_matrix_offset_components (data, offset[0], offset[1], offset[2]);
1463   }
1464 
1465   color_matrix_debug (data);
1466 }
1467 
1468 
1469 static void
1470 gamma_convert_u8_u16 (GammaData * data, gpointer dest, gpointer src)
1471 {
1472   gint i;
1473   guint8 *s = src;
1474   guint16 *d = dest;
1475   guint16 *table = data-&gt;gamma_table;
1476   gint width = data-&gt;width * 4;
1477 
1478   for (i = 0; i &lt; width; i += 4) {
1479     d[i + 0] = (s[i] &lt;&lt; 8) | s[i];
1480     d[i + 1] = table[s[i + 1]];
1481     d[i + 2] = table[s[i + 2]];
1482     d[i + 3] = table[s[i + 3]];
1483   }
1484 }
1485 
1486 static void
1487 gamma_convert_u16_u8 (GammaData * data, gpointer dest, gpointer src)
1488 {
1489   gint i;
1490   guint16 *s = src;
1491   guint8 *d = dest;
1492   guint8 *table = data-&gt;gamma_table;
1493   gint width = data-&gt;width * 4;
1494 
1495   for (i = 0; i &lt; width; i += 4) {
1496     d[i + 0] = s[i] &gt;&gt; 8;
1497     d[i + 1] = table[s[i + 1]];
1498     d[i + 2] = table[s[i + 2]];
1499     d[i + 3] = table[s[i + 3]];
1500   }
1501 }
1502 
1503 static void
1504 gamma_convert_u16_u16 (GammaData * data, gpointer dest, gpointer src)
1505 {
1506   gint i;
1507   guint16 *s = src;
1508   guint16 *d = dest;
1509   guint16 *table = data-&gt;gamma_table;
1510   gint width = data-&gt;width * 4;
1511 
1512   for (i = 0; i &lt; width; i += 4) {
1513     d[i + 0] = s[i];
1514     d[i + 1] = table[s[i + 1]];
1515     d[i + 2] = table[s[i + 2]];
1516     d[i + 3] = table[s[i + 3]];
1517   }
1518 }
1519 
1520 static void
1521 setup_gamma_decode (GstVideoConverter * convert)
1522 {
1523   GstVideoTransferFunction func;
1524   guint16 *t;
1525   gint i;
1526 
1527   func = convert-&gt;in_info.colorimetry.transfer;
1528 
1529   convert-&gt;gamma_dec.width = convert-&gt;current_width;
1530   if (convert-&gt;current_bits == 8) {
1531     GST_DEBUG (&quot;gamma decode 8-&gt;16: %d&quot;, func);
1532     convert-&gt;gamma_dec.gamma_func = gamma_convert_u8_u16;
1533     t = convert-&gt;gamma_dec.gamma_table = g_malloc (sizeof (guint16) * 256);
1534 
1535     for (i = 0; i &lt; 256; i++)
1536       t[i] = rint (gst_video_color_transfer_decode (func, i / 255.0) * 65535.0);
1537   } else {
1538     GST_DEBUG (&quot;gamma decode 16-&gt;16: %d&quot;, func);
1539     convert-&gt;gamma_dec.gamma_func = gamma_convert_u16_u16;
1540     t = convert-&gt;gamma_dec.gamma_table = g_malloc (sizeof (guint16) * 65536);
1541 
1542     for (i = 0; i &lt; 65536; i++)
1543       t[i] =
1544           rint (gst_video_color_transfer_decode (func, i / 65535.0) * 65535.0);
1545   }
1546   convert-&gt;current_bits = 16;
1547   convert-&gt;current_pstride = 8;
1548   convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB64;
1549 }
1550 
1551 static void
1552 setup_gamma_encode (GstVideoConverter * convert, gint target_bits)
1553 {
1554   GstVideoTransferFunction func;
1555   gint i;
1556 
1557   func = convert-&gt;out_info.colorimetry.transfer;
1558 
1559   convert-&gt;gamma_enc.width = convert-&gt;current_width;
1560   if (target_bits == 8) {
1561     guint8 *t;
1562 
1563     GST_DEBUG (&quot;gamma encode 16-&gt;8: %d&quot;, func);
1564     convert-&gt;gamma_enc.gamma_func = gamma_convert_u16_u8;
1565     t = convert-&gt;gamma_enc.gamma_table = g_malloc (sizeof (guint8) * 65536);
1566 
1567     for (i = 0; i &lt; 65536; i++)
1568       t[i] = rint (gst_video_color_transfer_encode (func, i / 65535.0) * 255.0);
1569   } else {
1570     guint16 *t;
1571 
1572     GST_DEBUG (&quot;gamma encode 16-&gt;16: %d&quot;, func);
1573     convert-&gt;gamma_enc.gamma_func = gamma_convert_u16_u16;
1574     t = convert-&gt;gamma_enc.gamma_table = g_malloc (sizeof (guint16) * 65536);
1575 
1576     for (i = 0; i &lt; 65536; i++)
1577       t[i] =
1578           rint (gst_video_color_transfer_encode (func, i / 65535.0) * 65535.0);
1579   }
1580 }
1581 
1582 static GstLineCache *
1583 chain_convert_to_RGB (GstVideoConverter * convert, GstLineCache * prev,
1584     gint idx)
1585 {
1586   gboolean do_gamma;
1587 
1588   do_gamma = CHECK_GAMMA_REMAP (convert);
1589 
1590   if (do_gamma) {
1591     gint scale;
1592 
1593     if (!convert-&gt;unpack_rgb) {
1594       color_matrix_set_identity (&amp;convert-&gt;to_RGB_matrix);
1595       compute_matrix_to_RGB (convert, &amp;convert-&gt;to_RGB_matrix);
1596 
1597       /* matrix is in 0..1 range, scale to current bits */
1598       GST_DEBUG (&quot;chain RGB convert&quot;);
1599       scale = 1 &lt;&lt; convert-&gt;current_bits;
1600       color_matrix_scale_components (&amp;convert-&gt;to_RGB_matrix,
1601           (float) scale, (float) scale, (float) scale);
1602 
1603       prepare_matrix (convert, &amp;convert-&gt;to_RGB_matrix);
1604 
1605       if (convert-&gt;current_bits == 8)
1606         convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB;
1607       else
1608         convert-&gt;current_format = GST_VIDEO_FORMAT_ARGB64;
1609     }
1610 
1611     prev = convert-&gt;to_RGB_lines[idx] = gst_line_cache_new (prev);
1612     prev-&gt;write_input = TRUE;
1613     prev-&gt;pass_alloc = FALSE;
1614     prev-&gt;n_lines = 1;
1615     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1616     gst_line_cache_set_need_line_func (prev,
1617         do_convert_to_RGB_lines, idx, convert, NULL);
1618 
1619     GST_DEBUG (&quot;chain gamma decode&quot;);
1620     setup_gamma_decode (convert);
1621   }
1622   return prev;
1623 }
1624 
1625 static GstLineCache *
1626 chain_hscale (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1627 {
1628   gint method;
1629   guint taps;
1630 
1631   method = GET_OPT_RESAMPLER_METHOD (convert);
1632   taps = GET_OPT_RESAMPLER_TAPS (convert);
1633 
1634   convert-&gt;h_scaler[idx] =
1635       gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
1636       convert-&gt;in_width, convert-&gt;out_width, convert-&gt;config);
1637 
1638   gst_video_scaler_get_coeff (convert-&gt;h_scaler[idx], 0, NULL, &amp;taps);
1639 
1640   GST_DEBUG (&quot;chain hscale %d-&gt;%d, taps %d, method %d&quot;,
1641       convert-&gt;in_width, convert-&gt;out_width, taps, method);
1642 
1643   convert-&gt;current_width = convert-&gt;out_width;
1644   convert-&gt;h_scale_format = convert-&gt;current_format;
1645 
1646   prev = convert-&gt;hscale_lines[idx] = gst_line_cache_new (prev);
1647   prev-&gt;write_input = FALSE;
1648   prev-&gt;pass_alloc = FALSE;
1649   prev-&gt;n_lines = 1;
1650   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1651   gst_line_cache_set_need_line_func (prev, do_hscale_lines, idx, convert, NULL);
1652 
1653   return prev;
1654 }
1655 
1656 static GstLineCache *
1657 chain_vscale (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1658 {
1659   gint method;
1660   guint taps, taps_i = 0;
1661   gint backlog = 0;
1662 
1663   method = GET_OPT_RESAMPLER_METHOD (convert);
1664   taps = GET_OPT_RESAMPLER_TAPS (convert);
1665 
1666   if (GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;in_info)) {
1667     convert-&gt;v_scaler_i[idx] =
1668         gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_INTERLACED,
1669         taps, convert-&gt;in_height, convert-&gt;out_height, convert-&gt;config);
1670 
1671     gst_video_scaler_get_coeff (convert-&gt;v_scaler_i[idx], 0, NULL, &amp;taps_i);
1672     backlog = taps_i;
1673   }
1674   convert-&gt;v_scaler_p[idx] =
1675       gst_video_scaler_new (method, 0, taps, convert-&gt;in_height,
1676       convert-&gt;out_height, convert-&gt;config);
1677   convert-&gt;v_scale_width = convert-&gt;current_width;
1678   convert-&gt;v_scale_format = convert-&gt;current_format;
1679   convert-&gt;current_height = convert-&gt;out_height;
1680 
1681   gst_video_scaler_get_coeff (convert-&gt;v_scaler_p[idx], 0, NULL, &amp;taps);
1682 
1683   GST_DEBUG (&quot;chain vscale %d-&gt;%d, taps %d, method %d, backlog %d&quot;,
1684       convert-&gt;in_height, convert-&gt;out_height, taps, method, backlog);
1685 
1686   prev-&gt;backlog = backlog;
1687   prev = convert-&gt;vscale_lines[idx] = gst_line_cache_new (prev);
1688   prev-&gt;pass_alloc = (taps == 1);
1689   prev-&gt;write_input = FALSE;
1690   prev-&gt;n_lines = MAX (taps_i, taps);
1691   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1692   gst_line_cache_set_need_line_func (prev, do_vscale_lines, idx, convert, NULL);
1693 
1694   return prev;
1695 }
1696 
1697 static GstLineCache *
1698 chain_scale (GstVideoConverter * convert, GstLineCache * prev, gboolean force,
1699     gint idx)
1700 {
1701   gint s0, s1, s2, s3;
1702 
1703   s0 = convert-&gt;current_width * convert-&gt;current_height;
1704   s3 = convert-&gt;out_width * convert-&gt;out_height;
1705 
1706   GST_DEBUG (&quot;in pixels %d &lt;&gt; out pixels %d&quot;, s0, s3);
1707 
1708   if (s3 &lt;= s0 || force) {
1709     /* we are making the image smaller or are forced to resample */
1710     s1 = convert-&gt;out_width * convert-&gt;current_height;
1711     s2 = convert-&gt;current_width * convert-&gt;out_height;
1712 
1713     GST_DEBUG (&quot;%d &lt;&gt; %d&quot;, s1, s2);
1714 
1715     if (s1 &lt;= s2) {
1716       /* h scaling first produces less pixels */
1717       if (convert-&gt;current_width != convert-&gt;out_width)
1718         prev = chain_hscale (convert, prev, idx);
1719       if (convert-&gt;current_height != convert-&gt;out_height)
1720         prev = chain_vscale (convert, prev, idx);
1721     } else {
1722       /* v scaling first produces less pixels */
1723       if (convert-&gt;current_height != convert-&gt;out_height)
1724         prev = chain_vscale (convert, prev, idx);
1725       if (convert-&gt;current_width != convert-&gt;out_width)
1726         prev = chain_hscale (convert, prev, idx);
1727     }
1728   }
1729   return prev;
1730 }
1731 
1732 static GstLineCache *
1733 chain_convert (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1734 {
1735   gboolean do_gamma, do_conversion, pass_alloc = FALSE;
1736   gboolean same_matrix, same_primaries, same_bits;
1737   MatrixData p1, p2;
1738 
1739   same_bits = convert-&gt;unpack_bits == convert-&gt;pack_bits;
1740   if (CHECK_MATRIX_NONE (convert)) {
1741     same_matrix = TRUE;
1742   } else {
1743     same_matrix =
1744         convert-&gt;in_info.colorimetry.matrix ==
1745         convert-&gt;out_info.colorimetry.matrix;
1746   }
1747 
1748   if (CHECK_PRIMARIES_NONE (convert)) {
1749     same_primaries = TRUE;
1750   } else {
1751     same_primaries =
1752         convert-&gt;in_info.colorimetry.primaries ==
1753         convert-&gt;out_info.colorimetry.primaries;
1754   }
1755 
1756   GST_DEBUG (&quot;matrix %d -&gt; %d (%d)&quot;, convert-&gt;in_info.colorimetry.matrix,
1757       convert-&gt;out_info.colorimetry.matrix, same_matrix);
1758   GST_DEBUG (&quot;bits %d -&gt; %d (%d)&quot;, convert-&gt;unpack_bits, convert-&gt;pack_bits,
1759       same_bits);
1760   GST_DEBUG (&quot;primaries %d -&gt; %d (%d)&quot;, convert-&gt;in_info.colorimetry.primaries,
1761       convert-&gt;out_info.colorimetry.primaries, same_primaries);
1762 
1763   color_matrix_set_identity (&amp;convert-&gt;convert_matrix);
1764 
1765   if (!same_primaries) {
1766     const GstVideoColorPrimariesInfo *pi;
1767 
1768     pi = gst_video_color_primaries_get_info (convert-&gt;in_info.colorimetry.
1769         primaries);
1770     color_matrix_RGB_to_XYZ (&amp;p1, pi-&gt;Rx, pi-&gt;Ry, pi-&gt;Gx, pi-&gt;Gy, pi-&gt;Bx,
1771         pi-&gt;By, pi-&gt;Wx, pi-&gt;Wy);
1772     GST_DEBUG (&quot;to XYZ matrix&quot;);
1773     color_matrix_debug (&amp;p1);
1774     GST_DEBUG (&quot;current matrix&quot;);
1775     color_matrix_multiply (&amp;convert-&gt;convert_matrix, &amp;convert-&gt;convert_matrix,
1776         &amp;p1);
1777     color_matrix_debug (&amp;convert-&gt;convert_matrix);
1778 
1779     pi = gst_video_color_primaries_get_info (convert-&gt;out_info.colorimetry.
1780         primaries);
1781     color_matrix_RGB_to_XYZ (&amp;p2, pi-&gt;Rx, pi-&gt;Ry, pi-&gt;Gx, pi-&gt;Gy, pi-&gt;Bx,
1782         pi-&gt;By, pi-&gt;Wx, pi-&gt;Wy);
1783     color_matrix_invert (&amp;p2, &amp;p2);
1784     GST_DEBUG (&quot;to RGB matrix&quot;);
1785     color_matrix_debug (&amp;p2);
1786     color_matrix_multiply (&amp;convert-&gt;convert_matrix, &amp;convert-&gt;convert_matrix,
1787         &amp;p2);
1788     GST_DEBUG (&quot;current matrix&quot;);
1789     color_matrix_debug (&amp;convert-&gt;convert_matrix);
1790   }
1791 
1792   do_gamma = CHECK_GAMMA_REMAP (convert);
1793   if (!do_gamma) {
1794 
1795     convert-&gt;in_bits = convert-&gt;unpack_bits;
1796     convert-&gt;out_bits = convert-&gt;pack_bits;
1797 
1798     if (!same_bits || !same_matrix || !same_primaries) {
1799       /* no gamma, combine all conversions into 1 */
1800       if (convert-&gt;in_bits &lt; convert-&gt;out_bits) {
1801         gint scale = 1 &lt;&lt; (convert-&gt;out_bits - convert-&gt;in_bits);
1802         color_matrix_scale_components (&amp;convert-&gt;convert_matrix,
1803             1 / (float) scale, 1 / (float) scale, 1 / (float) scale);
1804       }
1805       GST_DEBUG (&quot;to RGB matrix&quot;);
1806       compute_matrix_to_RGB (convert, &amp;convert-&gt;convert_matrix);
1807       GST_DEBUG (&quot;current matrix&quot;);
1808       color_matrix_debug (&amp;convert-&gt;convert_matrix);
1809 
1810       GST_DEBUG (&quot;to YUV matrix&quot;);
1811       compute_matrix_to_YUV (convert, &amp;convert-&gt;convert_matrix, FALSE);
1812       GST_DEBUG (&quot;current matrix&quot;);
1813       color_matrix_debug (&amp;convert-&gt;convert_matrix);
1814       if (convert-&gt;in_bits &gt; convert-&gt;out_bits) {
1815         gint scale = 1 &lt;&lt; (convert-&gt;in_bits - convert-&gt;out_bits);
1816         color_matrix_scale_components (&amp;convert-&gt;convert_matrix,
1817             (float) scale, (float) scale, (float) scale);
1818       }
1819       convert-&gt;current_bits = MAX (convert-&gt;in_bits, convert-&gt;out_bits);
1820 
1821       do_conversion = TRUE;
1822       if (!same_matrix || !same_primaries)
1823         prepare_matrix (convert, &amp;convert-&gt;convert_matrix);
1824       if (convert-&gt;in_bits == convert-&gt;out_bits)
1825         pass_alloc = TRUE;
1826     } else
1827       do_conversion = FALSE;
1828 
1829     convert-&gt;current_bits = convert-&gt;pack_bits;
1830     convert-&gt;current_format = convert-&gt;pack_format;
1831     convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
1832   } else {
1833     /* we did gamma, just do colorspace conversion if needed */
1834     if (same_primaries) {
1835       do_conversion = FALSE;
1836     } else {
1837       prepare_matrix (convert, &amp;convert-&gt;convert_matrix);
1838       convert-&gt;in_bits = convert-&gt;out_bits = 16;
1839       pass_alloc = TRUE;
1840       do_conversion = TRUE;
1841     }
1842   }
1843 
1844   if (do_conversion) {
1845     GST_DEBUG (&quot;chain conversion&quot;);
1846     prev = convert-&gt;convert_lines[idx] = gst_line_cache_new (prev);
1847     prev-&gt;write_input = TRUE;
1848     prev-&gt;pass_alloc = pass_alloc;
1849     prev-&gt;n_lines = 1;
1850     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1851     gst_line_cache_set_need_line_func (prev,
1852         do_convert_lines, idx, convert, NULL);
1853   }
1854   return prev;
1855 }
1856 
1857 static void
1858 convert_set_alpha_u8 (GstVideoConverter * convert, gpointer pixels, gint width)
1859 {
1860   guint8 *p = pixels;
1861   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
1862   int i;
1863 
1864   for (i = 0; i &lt; width; i++)
1865     p[i * 4] = alpha;
1866 }
1867 
1868 static void
1869 convert_set_alpha_u16 (GstVideoConverter * convert, gpointer pixels, gint width)
1870 {
1871   guint16 *p = pixels;
1872   guint16 alpha;
1873   int i;
1874 
1875   alpha = MIN (convert-&gt;alpha_value, 255);
1876   alpha |= alpha &lt;&lt; 8;
1877 
1878   for (i = 0; i &lt; width; i++)
1879     p[i * 4] = alpha;
1880 }
1881 
1882 static void
1883 convert_mult_alpha_u8 (GstVideoConverter * convert, gpointer pixels, gint width)
1884 {
1885   guint8 *p = pixels;
1886   guint alpha = convert-&gt;alpha_value;
1887   int i;
1888 
1889   for (i = 0; i &lt; width; i++) {
1890     gint a = (p[i * 4] * alpha) / 255;
1891     p[i * 4] = CLAMP (a, 0, 255);
1892   }
1893 }
1894 
1895 static void
1896 convert_mult_alpha_u16 (GstVideoConverter * convert, gpointer pixels,
1897     gint width)
1898 {
1899   guint16 *p = pixels;
1900   guint alpha = convert-&gt;alpha_value;
1901   int i;
1902 
1903   for (i = 0; i &lt; width; i++) {
1904     gint a = (p[i * 4] * alpha) / 255;
1905     p[i * 4] = CLAMP (a, 0, 65535);
1906   }
1907 }
1908 
1909 static GstLineCache *
1910 chain_alpha (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1911 {
1912   switch (convert-&gt;alpha_mode) {
1913     case ALPHA_MODE_NONE:
1914     case ALPHA_MODE_COPY:
1915       return prev;
1916 
1917     case ALPHA_MODE_SET:
1918       if (convert-&gt;current_bits == 8)
1919         convert-&gt;alpha_func = convert_set_alpha_u8;
1920       else
1921         convert-&gt;alpha_func = convert_set_alpha_u16;
1922       break;
1923     case ALPHA_MODE_MULT:
1924       if (convert-&gt;current_bits == 8)
1925         convert-&gt;alpha_func = convert_mult_alpha_u8;
1926       else
1927         convert-&gt;alpha_func = convert_mult_alpha_u16;
1928       break;
1929   }
1930 
1931   GST_DEBUG (&quot;chain alpha mode %d&quot;, convert-&gt;alpha_mode);
1932   prev = convert-&gt;alpha_lines[idx] = gst_line_cache_new (prev);
1933   prev-&gt;write_input = TRUE;
1934   prev-&gt;pass_alloc = TRUE;
1935   prev-&gt;n_lines = 1;
1936   prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1937   gst_line_cache_set_need_line_func (prev, do_alpha_lines, idx, convert, NULL);
1938 
1939   return prev;
1940 }
1941 
1942 static GstLineCache *
1943 chain_convert_to_YUV (GstVideoConverter * convert, GstLineCache * prev,
1944     gint idx)
1945 {
1946   gboolean do_gamma;
1947 
1948   do_gamma = CHECK_GAMMA_REMAP (convert);
1949 
1950   if (do_gamma) {
1951     gint scale;
1952 
1953     GST_DEBUG (&quot;chain gamma encode&quot;);
1954     setup_gamma_encode (convert, convert-&gt;pack_bits);
1955 
1956     convert-&gt;current_bits = convert-&gt;pack_bits;
1957     convert-&gt;current_pstride = convert-&gt;current_bits &gt;&gt; 1;
1958 
1959     if (!convert-&gt;pack_rgb) {
1960       color_matrix_set_identity (&amp;convert-&gt;to_YUV_matrix);
1961       compute_matrix_to_YUV (convert, &amp;convert-&gt;to_YUV_matrix, FALSE);
1962 
1963       /* matrix is in 0..255 range, scale to pack bits */
1964       GST_DEBUG (&quot;chain YUV convert&quot;);
1965       scale = 1 &lt;&lt; convert-&gt;pack_bits;
1966       color_matrix_scale_components (&amp;convert-&gt;to_YUV_matrix,
1967           1 / (float) scale, 1 / (float) scale, 1 / (float) scale);
1968       prepare_matrix (convert, &amp;convert-&gt;to_YUV_matrix);
1969     }
1970     convert-&gt;current_format = convert-&gt;pack_format;
1971 
1972     prev = convert-&gt;to_YUV_lines[idx] = gst_line_cache_new (prev);
1973     prev-&gt;write_input = FALSE;
1974     prev-&gt;pass_alloc = FALSE;
1975     prev-&gt;n_lines = 1;
1976     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1977     gst_line_cache_set_need_line_func (prev,
1978         do_convert_to_YUV_lines, idx, convert, NULL);
1979   }
1980 
1981   return prev;
1982 }
1983 
1984 static GstLineCache *
1985 chain_downsample (GstVideoConverter * convert, GstLineCache * prev, gint idx)
1986 {
1987   if (convert-&gt;downsample_p[idx] || convert-&gt;downsample_i[idx]) {
1988     GST_DEBUG (&quot;chain downsample&quot;);
1989     prev = convert-&gt;downsample_lines[idx] = gst_line_cache_new (prev);
1990     prev-&gt;write_input = TRUE;
1991     prev-&gt;pass_alloc = TRUE;
1992     prev-&gt;n_lines = 4;
1993     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
1994     gst_line_cache_set_need_line_func (prev,
1995         do_downsample_lines, idx, convert, NULL);
1996   }
1997   return prev;
1998 }
1999 
2000 static GstLineCache *
2001 chain_dither (GstVideoConverter * convert, GstLineCache * prev, gint idx)
2002 {
2003   gint i;
2004   gboolean do_dither = FALSE;
2005   GstVideoDitherFlags flags = 0;
2006   GstVideoDitherMethod method;
2007   guint quant[4], target_quant;
2008 
2009   method = GET_OPT_DITHER_METHOD (convert);
2010   if (method == GST_VIDEO_DITHER_NONE)
2011     return prev;
2012 
2013   target_quant = GET_OPT_DITHER_QUANTIZATION (convert);
2014   GST_DEBUG (&quot;method %d, target-quantization %d&quot;, method, target_quant);
2015 
2016   if (convert-&gt;pack_pal) {
2017     quant[0] = 47;
2018     quant[1] = 47;
2019     quant[2] = 47;
2020     quant[3] = 1;
2021     do_dither = TRUE;
2022   } else {
2023     for (i = 0; i &lt; GST_VIDEO_MAX_COMPONENTS; i++) {
2024       gint depth;
2025 
2026       depth = convert-&gt;out_info.finfo-&gt;depth[i];
2027 
2028       if (depth == 0) {
2029         quant[i] = 0;
2030         continue;
2031       }
2032 
2033       if (convert-&gt;current_bits &gt;= depth) {
2034         quant[i] = 1 &lt;&lt; (convert-&gt;current_bits - depth);
2035         if (target_quant &gt; quant[i]) {
2036           flags |= GST_VIDEO_DITHER_FLAG_QUANTIZE;
2037           quant[i] = target_quant;
2038         }
2039       } else {
2040         quant[i] = 0;
2041       }
2042       if (quant[i] &gt; 1)
2043         do_dither = TRUE;
2044     }
2045   }
2046 
2047   if (do_dither) {
2048     GST_DEBUG (&quot;chain dither&quot;);
2049 
2050     convert-&gt;dither[idx] = gst_video_dither_new (method,
2051         flags, convert-&gt;pack_format, quant, convert-&gt;current_width);
2052 
2053     prev = convert-&gt;dither_lines[idx] = gst_line_cache_new (prev);
2054     prev-&gt;write_input = TRUE;
2055     prev-&gt;pass_alloc = TRUE;
2056     prev-&gt;n_lines = 1;
2057     prev-&gt;stride = convert-&gt;current_pstride * convert-&gt;current_width;
2058     gst_line_cache_set_need_line_func (prev, do_dither_lines, idx, convert,
2059         NULL);
2060   }
2061   return prev;
2062 }
2063 
2064 static GstLineCache *
2065 chain_pack (GstVideoConverter * convert, GstLineCache * prev, gint idx)
2066 {
2067   convert-&gt;pack_nlines = convert-&gt;out_info.finfo-&gt;pack_lines;
2068   convert-&gt;pack_pstride = convert-&gt;current_pstride;
2069   convert-&gt;identity_pack =
2070       (convert-&gt;out_info.finfo-&gt;format ==
2071       convert-&gt;out_info.finfo-&gt;unpack_format);
2072   GST_DEBUG (&quot;chain pack line format %s, pstride %d, identity_pack %d (%d %d)&quot;,
2073       gst_video_format_to_string (convert-&gt;current_format),
2074       convert-&gt;current_pstride, convert-&gt;identity_pack,
2075       convert-&gt;out_info.finfo-&gt;format, convert-&gt;out_info.finfo-&gt;unpack_format);
2076 
2077   return prev;
2078 }
2079 
2080 static void
2081 setup_allocators (GstVideoConverter * convert)
2082 {
2083   GstLineCache *cache, *prev;
2084   GstLineCacheAllocLineFunc alloc_line;
2085   gboolean alloc_writable;
2086   gpointer user_data;
2087   GDestroyNotify notify;
2088   gint width;
2089   gint i;
2090 
2091   width = MAX (convert-&gt;in_maxwidth, convert-&gt;out_maxwidth);
2092   width += convert-&gt;out_x;
2093 
2094   for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++) {
2095     /* start with using dest lines if we can directly write into it */
2096     if (convert-&gt;identity_pack) {
2097       alloc_line = get_dest_line;
2098       alloc_writable = TRUE;
2099       user_data = convert;
2100       notify = NULL;
2101     } else {
2102       user_data =
2103           converter_alloc_new (sizeof (guint16) * width * 4, 4 + BACKLOG,
2104           convert, NULL);
2105       setup_border_alloc (convert, user_data);
2106       notify = (GDestroyNotify) converter_alloc_free;
2107       alloc_line = get_border_temp_line;
2108       /* when we add a border, we need to write */
2109       alloc_writable = convert-&gt;borderline != NULL;
2110     }
2111 
2112     /* First step, try to calculate how many temp lines we need. Go backwards,
2113      * keep track of the maximum number of lines we need for each intermediate
2114      * step.  */
2115     for (prev = cache = convert-&gt;pack_lines[i]; cache; cache = cache-&gt;prev) {
2116       GST_DEBUG (&quot;looking at cache %p, %d lines, %d backlog&quot;, cache,
2117           cache-&gt;n_lines, cache-&gt;backlog);
2118       prev-&gt;n_lines = MAX (prev-&gt;n_lines, cache-&gt;n_lines);
2119       if (!cache-&gt;pass_alloc) {
2120         GST_DEBUG (&quot;cache %p, needs %d lines&quot;, prev, prev-&gt;n_lines);
2121         prev = cache;
2122       }
2123     }
2124 
2125     /* now walk backwards, we try to write into the dest lines directly
2126      * and keep track if the source needs to be writable */
2127     for (cache = convert-&gt;pack_lines[i]; cache; cache = cache-&gt;prev) {
2128       gst_line_cache_set_alloc_line_func (cache, alloc_line, user_data, notify);
2129       cache-&gt;alloc_writable = alloc_writable;
2130 
2131       /* make sure only one cache frees the allocator */
2132       notify = NULL;
2133 
2134       if (!cache-&gt;pass_alloc) {
2135         /* can&#39;t pass allocator, make new temp line allocator */
2136         user_data =
2137             converter_alloc_new (sizeof (guint16) * width * 4,
2138             cache-&gt;n_lines + cache-&gt;backlog, convert, NULL);
2139         notify = (GDestroyNotify) converter_alloc_free;
2140         alloc_line = get_temp_line;
2141         alloc_writable = FALSE;
2142       }
2143       /* if someone writes to the input, we need a writable line from the
2144        * previous cache */
2145       if (cache-&gt;write_input)
2146         alloc_writable = TRUE;
2147     }
2148     /* free leftover allocator */
2149     if (notify)
2150       notify (user_data);
2151   }
2152 }
2153 
2154 static void
2155 setup_borderline (GstVideoConverter * convert)
2156 {
2157   gint width;
2158 
2159   width = MAX (convert-&gt;in_maxwidth, convert-&gt;out_maxwidth);
2160   width += convert-&gt;out_x;
2161 
2162   if (convert-&gt;fill_border &amp;&amp; (convert-&gt;out_height &lt; convert-&gt;out_maxheight ||
2163           convert-&gt;out_width &lt; convert-&gt;out_maxwidth)) {
2164     guint32 border_val;
2165     gint i, w_sub;
2166     const GstVideoFormatInfo *out_finfo;
2167     gpointer planes[GST_VIDEO_MAX_PLANES];
2168     gint strides[GST_VIDEO_MAX_PLANES];
2169 
2170     convert-&gt;borderline = g_malloc0 (sizeof (guint16) * width * 4);
2171 
2172     out_finfo = convert-&gt;out_info.finfo;
2173 
2174     if (GST_VIDEO_INFO_IS_YUV (&amp;convert-&gt;out_info)) {
2175       MatrixData cm;
2176       gint a, r, g, b;
2177       gint y, u, v;
2178 
2179       /* Get Color matrix. */
2180       color_matrix_set_identity (&amp;cm);
2181       compute_matrix_to_YUV (convert, &amp;cm, TRUE);
2182       color_matrix_convert (&amp;cm);
2183 
2184       border_val = GINT32_FROM_BE (convert-&gt;border_argb);
2185 
2186       b = (0xFF000000 &amp; border_val) &gt;&gt; 24;
2187       g = (0x00FF0000 &amp; border_val) &gt;&gt; 16;
2188       r = (0x0000FF00 &amp; border_val) &gt;&gt; 8;
2189       a = (0x000000FF &amp; border_val);
2190 
2191       y = 16 + ((r * cm.im[0][0] + g * cm.im[0][1] + b * cm.im[0][2]) &gt;&gt; 8);
2192       u = 128 + ((r * cm.im[1][0] + g * cm.im[1][1] + b * cm.im[1][2]) &gt;&gt; 8);
2193       v = 128 + ((r * cm.im[2][0] + g * cm.im[2][1] + b * cm.im[2][2]) &gt;&gt; 8);
2194 
2195       a = CLAMP (a, 0, 255);
2196       y = CLAMP (y, 0, 255);
2197       u = CLAMP (u, 0, 255);
2198       v = CLAMP (v, 0, 255);
2199 
2200       border_val = a | (y &lt;&lt; 8) | (u &lt;&lt; 16) | ((guint32) v &lt;&lt; 24);
2201     } else {
2202       border_val = GINT32_FROM_BE (convert-&gt;border_argb);
2203     }
2204     if (convert-&gt;pack_bits == 8)
2205       video_orc_splat_u32 (convert-&gt;borderline, border_val, width);
2206     else
2207       video_orc_splat2_u64 (convert-&gt;borderline, border_val, width);
2208 
2209     /* convert pixels */
2210     for (i = 0; i &lt; out_finfo-&gt;n_planes; i++) {
2211       planes[i] = &amp;convert-&gt;borders[i];
2212       strides[i] = sizeof (guint64);
2213     }
2214     w_sub = 0;
2215     if (out_finfo-&gt;n_planes == 1) {
2216       /* for packed formats, convert based on subsampling so that we
2217        * get a complete group of pixels */
2218       for (i = 0; i &lt; out_finfo-&gt;n_components; i++) {
2219         w_sub = MAX (w_sub, out_finfo-&gt;w_sub[i]);
2220       }
2221     }
2222     out_finfo-&gt;pack_func (out_finfo, GST_VIDEO_PACK_FLAG_NONE,
2223         convert-&gt;borderline, 0, planes, strides,
2224         GST_VIDEO_CHROMA_SITE_UNKNOWN, 0, 1 &lt;&lt; w_sub);
2225   } else {
2226     convert-&gt;borderline = NULL;
2227   }
2228 }
2229 
2230 static AlphaMode
2231 convert_get_alpha_mode (GstVideoConverter * convert)
2232 {
2233   gboolean in_alpha, out_alpha;
2234 
2235   in_alpha = GST_VIDEO_INFO_HAS_ALPHA (&amp;convert-&gt;in_info);
2236   out_alpha = GST_VIDEO_INFO_HAS_ALPHA (&amp;convert-&gt;out_info);
2237 
2238   /* no output alpha, do nothing */
2239   if (!out_alpha)
2240     return ALPHA_MODE_NONE;
2241 
2242   if (in_alpha) {
2243     /* in and out */
2244     if (CHECK_ALPHA_COPY (convert))
2245       return ALPHA_MODE_COPY;
2246 
2247     if (CHECK_ALPHA_MULT (convert)) {
2248       if (GET_OPT_ALPHA_VALUE (convert) == 1.0)
2249         return ALPHA_MODE_COPY;
2250       else
2251         return ALPHA_MODE_MULT;
2252     }
2253   }
2254   /* nothing special, this is what unpack etc does automatically */
2255   if (GET_OPT_ALPHA_VALUE (convert) == 1.0)
2256     return ALPHA_MODE_NONE;
2257 
2258   /* everything else becomes SET */
2259   return ALPHA_MODE_SET;
2260 }
2261 
2262 /**
2263  * gst_video_converter_new: (skip)
2264  * @in_info: a #GstVideoInfo
2265  * @out_info: a #GstVideoInfo
2266  * @config: (transfer full): a #GstStructure with configuration options
2267  *
2268  * Create a new converter object to convert between @in_info and @out_info
2269  * with @config.
2270  *
2271  * Returns: a #GstVideoConverter or %NULL if conversion is not possible.
2272  *
2273  * Since: 1.6
2274  */
2275 GstVideoConverter *
2276 gst_video_converter_new (GstVideoInfo * in_info, GstVideoInfo * out_info,
2277     GstStructure * config)
2278 {
2279   GstVideoConverter *convert;
2280   GstLineCache *prev;
2281   const GstVideoFormatInfo *fin, *fout, *finfo;
2282   gdouble alpha_value;
2283   gint n_threads, i;
2284 
2285   g_return_val_if_fail (in_info != NULL, NULL);
2286   g_return_val_if_fail (out_info != NULL, NULL);
2287   /* we won&#39;t ever do framerate conversion */
2288   g_return_val_if_fail (in_info-&gt;fps_n == out_info-&gt;fps_n, NULL);
2289   g_return_val_if_fail (in_info-&gt;fps_d == out_info-&gt;fps_d, NULL);
2290   /* we won&#39;t ever do deinterlace */
2291   g_return_val_if_fail (in_info-&gt;interlace_mode == out_info-&gt;interlace_mode,
2292       NULL);
2293 
2294   convert = g_slice_new0 (GstVideoConverter);
2295 
2296   fin = in_info-&gt;finfo;
2297   fout = out_info-&gt;finfo;
2298 
2299   convert-&gt;in_info = *in_info;
2300   convert-&gt;out_info = *out_info;
2301 
2302   /* default config */
2303   convert-&gt;config = gst_structure_new_empty (&quot;GstVideoConverter&quot;);
2304   if (config)
2305     gst_video_converter_set_config (convert, config);
2306 
2307   convert-&gt;in_maxwidth = GST_VIDEO_INFO_WIDTH (in_info);
2308   convert-&gt;in_maxheight = GST_VIDEO_INFO_HEIGHT (in_info);
2309   convert-&gt;out_maxwidth = GST_VIDEO_INFO_WIDTH (out_info);
2310   convert-&gt;out_maxheight = GST_VIDEO_INFO_HEIGHT (out_info);
2311 
2312   convert-&gt;in_x = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_SRC_X, 0);
2313   convert-&gt;in_y = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_SRC_Y, 0);
2314   convert-&gt;in_x &amp;= ~((1 &lt;&lt; fin-&gt;w_sub[1]) - 1);
2315   convert-&gt;in_y &amp;= ~((1 &lt;&lt; fin-&gt;h_sub[1]) - 1);
2316 
2317   convert-&gt;in_width = get_opt_int (convert,
2318       GST_VIDEO_CONVERTER_OPT_SRC_WIDTH, convert-&gt;in_maxwidth - convert-&gt;in_x);
2319   convert-&gt;in_height = get_opt_int (convert,
2320       GST_VIDEO_CONVERTER_OPT_SRC_HEIGHT,
2321       convert-&gt;in_maxheight - convert-&gt;in_y);
2322 
2323   convert-&gt;in_width =
2324       MIN (convert-&gt;in_width, convert-&gt;in_maxwidth - convert-&gt;in_x);
2325   convert-&gt;in_height =
2326       MIN (convert-&gt;in_height, convert-&gt;in_maxheight - convert-&gt;in_y);
2327 
2328   convert-&gt;out_x = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_X, 0);
2329   convert-&gt;out_y = get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_Y, 0);
2330   convert-&gt;out_x &amp;= ~((1 &lt;&lt; fout-&gt;w_sub[1]) - 1);
2331   convert-&gt;out_y &amp;= ~((1 &lt;&lt; fout-&gt;h_sub[1]) - 1);
2332 
2333   convert-&gt;out_width = get_opt_int (convert,
2334       GST_VIDEO_CONVERTER_OPT_DEST_WIDTH,
2335       convert-&gt;out_maxwidth - convert-&gt;out_x);
2336   convert-&gt;out_height =
2337       get_opt_int (convert, GST_VIDEO_CONVERTER_OPT_DEST_HEIGHT,
2338       convert-&gt;out_maxheight - convert-&gt;out_y);
2339 
2340   convert-&gt;out_width =
2341       MIN (convert-&gt;out_width, convert-&gt;out_maxwidth - convert-&gt;out_x);
2342   convert-&gt;out_height =
2343       MIN (convert-&gt;out_height, convert-&gt;out_maxheight - convert-&gt;out_y);
2344 
2345   convert-&gt;fill_border = GET_OPT_FILL_BORDER (convert);
2346   convert-&gt;border_argb = get_opt_uint (convert,
2347       GST_VIDEO_CONVERTER_OPT_BORDER_ARGB, DEFAULT_OPT_BORDER_ARGB);
2348 
2349   alpha_value = GET_OPT_ALPHA_VALUE (convert);
2350   convert-&gt;alpha_value = 255 * alpha_value;
2351   convert-&gt;alpha_mode = convert_get_alpha_mode (convert);
2352 
2353   convert-&gt;unpack_format = in_info-&gt;finfo-&gt;unpack_format;
2354   finfo = gst_video_format_get_info (convert-&gt;unpack_format);
2355   convert-&gt;unpack_bits = GST_VIDEO_FORMAT_INFO_DEPTH (finfo, 0);
2356   convert-&gt;unpack_rgb = GST_VIDEO_FORMAT_INFO_IS_RGB (finfo);
2357   if (convert-&gt;unpack_rgb
2358       &amp;&amp; in_info-&gt;colorimetry.matrix != GST_VIDEO_COLOR_MATRIX_RGB) {
2359     /* force identity matrix for RGB input */
2360     GST_WARNING (&quot;invalid matrix %d for input RGB format, using RGB&quot;,
2361         in_info-&gt;colorimetry.matrix);
2362     convert-&gt;in_info.colorimetry.matrix = GST_VIDEO_COLOR_MATRIX_RGB;
2363   }
2364 
2365   convert-&gt;pack_format = out_info-&gt;finfo-&gt;unpack_format;
2366   finfo = gst_video_format_get_info (convert-&gt;pack_format);
2367   convert-&gt;pack_bits = GST_VIDEO_FORMAT_INFO_DEPTH (finfo, 0);
2368   convert-&gt;pack_rgb = GST_VIDEO_FORMAT_INFO_IS_RGB (finfo);
2369   convert-&gt;pack_pal =
2370       gst_video_format_get_palette (GST_VIDEO_INFO_FORMAT (out_info),
2371       &amp;convert-&gt;pack_palsize);
2372   if (convert-&gt;pack_rgb
2373       &amp;&amp; out_info-&gt;colorimetry.matrix != GST_VIDEO_COLOR_MATRIX_RGB) {
2374     /* force identity matrix for RGB output */
2375     GST_WARNING (&quot;invalid matrix %d for output RGB format, using RGB&quot;,
2376         out_info-&gt;colorimetry.matrix);
2377     convert-&gt;out_info.colorimetry.matrix = GST_VIDEO_COLOR_MATRIX_RGB;
2378   }
2379 
2380   n_threads = get_opt_uint (convert, GST_VIDEO_CONVERTER_OPT_THREADS, 1);
2381   if (n_threads == 0 || n_threads &gt; g_get_num_processors ())
2382     n_threads = g_get_num_processors ();
2383   /* Magic number of 200 lines */
2384   if (MAX (convert-&gt;out_height, convert-&gt;in_height) / n_threads &lt; 200)
2385     n_threads = (MAX (convert-&gt;out_height, convert-&gt;in_height) + 199) / 200;
2386   convert-&gt;conversion_runner = gst_parallelized_task_runner_new (n_threads);
2387 
2388   if (video_converter_lookup_fastpath (convert))
2389     goto done;
2390 
2391   if (in_info-&gt;finfo-&gt;unpack_func == NULL)
2392     goto no_unpack_func;
2393 
2394   if (out_info-&gt;finfo-&gt;pack_func == NULL)
2395     goto no_pack_func;
2396 
2397   convert-&gt;convert = video_converter_generic;
2398 
2399   convert-&gt;upsample_p = g_new0 (GstVideoChromaResample *, n_threads);
2400   convert-&gt;upsample_i = g_new0 (GstVideoChromaResample *, n_threads);
2401   convert-&gt;downsample_p = g_new0 (GstVideoChromaResample *, n_threads);
2402   convert-&gt;downsample_i = g_new0 (GstVideoChromaResample *, n_threads);
2403   convert-&gt;v_scaler_p = g_new0 (GstVideoScaler *, n_threads);
2404   convert-&gt;v_scaler_i = g_new0 (GstVideoScaler *, n_threads);
2405   convert-&gt;h_scaler = g_new0 (GstVideoScaler *, n_threads);
2406   convert-&gt;unpack_lines = g_new0 (GstLineCache *, n_threads);
2407   convert-&gt;pack_lines = g_new0 (GstLineCache *, n_threads);
2408   convert-&gt;upsample_lines = g_new0 (GstLineCache *, n_threads);
2409   convert-&gt;to_RGB_lines = g_new0 (GstLineCache *, n_threads);
2410   convert-&gt;hscale_lines = g_new0 (GstLineCache *, n_threads);
2411   convert-&gt;vscale_lines = g_new0 (GstLineCache *, n_threads);
2412   convert-&gt;convert_lines = g_new0 (GstLineCache *, n_threads);
2413   convert-&gt;alpha_lines = g_new0 (GstLineCache *, n_threads);
2414   convert-&gt;to_YUV_lines = g_new0 (GstLineCache *, n_threads);
2415   convert-&gt;downsample_lines = g_new0 (GstLineCache *, n_threads);
2416   convert-&gt;dither_lines = g_new0 (GstLineCache *, n_threads);
2417   convert-&gt;dither = g_new0 (GstVideoDither *, n_threads);
2418 
2419   for (i = 0; i &lt; n_threads; i++) {
2420     convert-&gt;current_format = GST_VIDEO_INFO_FORMAT (in_info);
2421     convert-&gt;current_width = convert-&gt;in_width;
2422     convert-&gt;current_height = convert-&gt;in_height;
2423 
2424     /* unpack */
2425     prev = chain_unpack_line (convert, i);
2426     /* upsample chroma */
2427     prev = chain_upsample (convert, prev, i);
2428     /* convert to gamma decoded RGB */
2429     prev = chain_convert_to_RGB (convert, prev, i);
2430     /* do all downscaling */
2431     prev = chain_scale (convert, prev, FALSE, i);
2432     /* do conversion between color spaces */
2433     prev = chain_convert (convert, prev, i);
2434     /* do alpha channels */
2435     prev = chain_alpha (convert, prev, i);
2436     /* do all remaining (up)scaling */
2437     prev = chain_scale (convert, prev, TRUE, i);
2438     /* convert to gamma encoded Y&#39;Cb&#39;Cr&#39; */
2439     prev = chain_convert_to_YUV (convert, prev, i);
2440     /* downsample chroma */
2441     prev = chain_downsample (convert, prev, i);
2442     /* dither */
2443     prev = chain_dither (convert, prev, i);
2444     /* pack into final format */
2445     convert-&gt;pack_lines[i] = chain_pack (convert, prev, i);
2446   }
2447 
2448   setup_borderline (convert);
2449   /* now figure out allocators */
2450   setup_allocators (convert);
2451 
2452 done:
2453   return convert;
2454 
2455   /* ERRORS */
2456 no_unpack_func:
2457   {
2458     GST_ERROR (&quot;no unpack_func for format %s&quot;,
2459         gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (in_info)));
2460     gst_video_converter_free (convert);
2461     return NULL;
2462   }
2463 no_pack_func:
2464   {
2465     GST_ERROR (&quot;no pack_func for format %s&quot;,
2466         gst_video_format_to_string (GST_VIDEO_INFO_FORMAT (out_info)));
2467     gst_video_converter_free (convert);
2468     return NULL;
2469   }
2470 }
2471 
2472 static void
2473 clear_matrix_data (MatrixData * data)
2474 {
2475   g_free (data-&gt;t_r);
2476   g_free (data-&gt;t_g);
2477   g_free (data-&gt;t_b);
2478 }
2479 
2480 /**
2481  * gst_video_converter_free:
2482  * @convert: a #GstVideoConverter
2483  *
2484  * Free @convert
2485  *
2486  * Since: 1.6
2487  */
2488 void
2489 gst_video_converter_free (GstVideoConverter * convert)
2490 {
2491   guint i, j;
2492 
2493   g_return_if_fail (convert != NULL);
2494 
2495   for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++) {
2496     if (convert-&gt;upsample_p &amp;&amp; convert-&gt;upsample_p[i])
2497       gst_video_chroma_resample_free (convert-&gt;upsample_p[i]);
2498     if (convert-&gt;upsample_i &amp;&amp; convert-&gt;upsample_i[i])
2499       gst_video_chroma_resample_free (convert-&gt;upsample_i[i]);
2500     if (convert-&gt;downsample_p &amp;&amp; convert-&gt;downsample_p[i])
2501       gst_video_chroma_resample_free (convert-&gt;downsample_p[i]);
2502     if (convert-&gt;downsample_i &amp;&amp; convert-&gt;downsample_i[i])
2503       gst_video_chroma_resample_free (convert-&gt;downsample_i[i]);
2504     if (convert-&gt;v_scaler_p &amp;&amp; convert-&gt;v_scaler_p[i])
2505       gst_video_scaler_free (convert-&gt;v_scaler_p[i]);
2506     if (convert-&gt;v_scaler_i &amp;&amp; convert-&gt;v_scaler_i[i])
2507       gst_video_scaler_free (convert-&gt;v_scaler_i[i]);
2508     if (convert-&gt;h_scaler &amp;&amp; convert-&gt;h_scaler[i])
2509       gst_video_scaler_free (convert-&gt;h_scaler[i]);
2510     if (convert-&gt;unpack_lines &amp;&amp; convert-&gt;unpack_lines[i])
2511       gst_line_cache_free (convert-&gt;unpack_lines[i]);
2512     if (convert-&gt;upsample_lines &amp;&amp; convert-&gt;upsample_lines[i])
2513       gst_line_cache_free (convert-&gt;upsample_lines[i]);
2514     if (convert-&gt;to_RGB_lines &amp;&amp; convert-&gt;to_RGB_lines[i])
2515       gst_line_cache_free (convert-&gt;to_RGB_lines[i]);
2516     if (convert-&gt;hscale_lines &amp;&amp; convert-&gt;hscale_lines[i])
2517       gst_line_cache_free (convert-&gt;hscale_lines[i]);
2518     if (convert-&gt;vscale_lines &amp;&amp; convert-&gt;vscale_lines[i])
2519       gst_line_cache_free (convert-&gt;vscale_lines[i]);
2520     if (convert-&gt;convert_lines &amp;&amp; convert-&gt;convert_lines[i])
2521       gst_line_cache_free (convert-&gt;convert_lines[i]);
2522     if (convert-&gt;alpha_lines &amp;&amp; convert-&gt;alpha_lines[i])
2523       gst_line_cache_free (convert-&gt;alpha_lines[i]);
2524     if (convert-&gt;to_YUV_lines &amp;&amp; convert-&gt;to_YUV_lines[i])
2525       gst_line_cache_free (convert-&gt;to_YUV_lines[i]);
2526     if (convert-&gt;downsample_lines &amp;&amp; convert-&gt;downsample_lines[i])
2527       gst_line_cache_free (convert-&gt;downsample_lines[i]);
2528     if (convert-&gt;dither_lines &amp;&amp; convert-&gt;dither_lines[i])
2529       gst_line_cache_free (convert-&gt;dither_lines[i]);
2530     if (convert-&gt;dither &amp;&amp; convert-&gt;dither[i])
2531       gst_video_dither_free (convert-&gt;dither[i]);
2532   }
2533   g_free (convert-&gt;upsample_p);
2534   g_free (convert-&gt;upsample_i);
2535   g_free (convert-&gt;downsample_p);
2536   g_free (convert-&gt;downsample_i);
2537   g_free (convert-&gt;v_scaler_p);
2538   g_free (convert-&gt;v_scaler_i);
2539   g_free (convert-&gt;h_scaler);
2540   g_free (convert-&gt;unpack_lines);
2541   g_free (convert-&gt;pack_lines);
2542   g_free (convert-&gt;upsample_lines);
2543   g_free (convert-&gt;to_RGB_lines);
2544   g_free (convert-&gt;hscale_lines);
2545   g_free (convert-&gt;vscale_lines);
2546   g_free (convert-&gt;convert_lines);
2547   g_free (convert-&gt;alpha_lines);
2548   g_free (convert-&gt;to_YUV_lines);
2549   g_free (convert-&gt;downsample_lines);
2550   g_free (convert-&gt;dither_lines);
2551   g_free (convert-&gt;dither);
2552 
2553   g_free (convert-&gt;gamma_dec.gamma_table);
2554   g_free (convert-&gt;gamma_enc.gamma_table);
2555 
2556   if (convert-&gt;tmpline) {
2557     for (i = 0; i &lt; convert-&gt;conversion_runner-&gt;n_threads; i++)
2558       g_free (convert-&gt;tmpline[i]);
2559     g_free (convert-&gt;tmpline);
2560   }
2561 
2562   g_free (convert-&gt;borderline);
2563 
2564   if (convert-&gt;config)
2565     gst_structure_free (convert-&gt;config);
2566 
2567   for (i = 0; i &lt; 4; i++) {
2568     for (j = 0; j &lt; convert-&gt;conversion_runner-&gt;n_threads; j++) {
2569       if (convert-&gt;fv_scaler[i].scaler)
2570         gst_video_scaler_free (convert-&gt;fv_scaler[i].scaler[j]);
2571       if (convert-&gt;fh_scaler[i].scaler)
2572         gst_video_scaler_free (convert-&gt;fh_scaler[i].scaler[j]);
2573     }
2574     g_free (convert-&gt;fv_scaler[i].scaler);
2575     g_free (convert-&gt;fh_scaler[i].scaler);
2576   }
2577 
2578   if (convert-&gt;conversion_runner)
2579     gst_parallelized_task_runner_free (convert-&gt;conversion_runner);
2580 
2581   clear_matrix_data (&amp;convert-&gt;to_RGB_matrix);
2582   clear_matrix_data (&amp;convert-&gt;convert_matrix);
2583   clear_matrix_data (&amp;convert-&gt;to_YUV_matrix);
2584 
2585   g_slice_free (GstVideoConverter, convert);
2586 }
2587 
2588 static gboolean
2589 copy_config (GQuark field_id, const GValue * value, gpointer user_data)
2590 {
2591   GstVideoConverter *convert = user_data;
2592 
2593   gst_structure_id_set_value (convert-&gt;config, field_id, value);
2594 
2595   return TRUE;
2596 }
2597 
2598 /**
2599  * gst_video_converter_set_config:
2600  * @convert: a #GstVideoConverter
2601  * @config: (transfer full): a #GstStructure
2602  *
2603  * Set @config as extra configuraion for @convert.
2604  *
2605  * If the parameters in @config can not be set exactly, this function returns
2606  * %FALSE and will try to update as much state as possible. The new state can
2607  * then be retrieved and refined with gst_video_converter_get_config().
2608  *
2609  * Look at the #GST_VIDEO_CONVERTER_OPT_* fields to check valid configuration
2610  * option and values.
2611  *
2612  * Returns: %TRUE when @config could be set.
2613  *
2614  * Since: 1.6
2615  */
2616 gboolean
2617 gst_video_converter_set_config (GstVideoConverter * convert,
2618     GstStructure * config)
2619 {
2620   g_return_val_if_fail (convert != NULL, FALSE);
2621   g_return_val_if_fail (config != NULL, FALSE);
2622 
2623   gst_structure_foreach (config, copy_config, convert);
2624   gst_structure_free (config);
2625 
2626   return TRUE;
2627 }
2628 
2629 /**
2630  * gst_video_converter_get_config:
2631  * @convert: a #GstVideoConverter
2632  *
2633  * Get the current configuration of @convert.
2634  *
2635  * Returns: a #GstStructure that remains valid for as long as @convert is valid
2636  *   or until gst_video_converter_set_config() is called.
2637  */
2638 const GstStructure *
2639 gst_video_converter_get_config (GstVideoConverter * convert)
2640 {
2641   g_return_val_if_fail (convert != NULL, NULL);
2642 
2643   return convert-&gt;config;
2644 }
2645 
2646 /**
2647  * gst_video_converter_frame:
2648  * @convert: a #GstVideoConverter
2649  * @dest: a #GstVideoFrame
2650  * @src: a #GstVideoFrame
2651  *
2652  * Convert the pixels of @src into @dest using @convert.
2653  *
2654  * Since: 1.6
2655  */
2656 void
2657 gst_video_converter_frame (GstVideoConverter * convert,
2658     const GstVideoFrame * src, GstVideoFrame * dest)
2659 {
2660   g_return_if_fail (convert != NULL);
2661   g_return_if_fail (src != NULL);
2662   g_return_if_fail (dest != NULL);
2663 
2664   convert-&gt;convert (convert, src, dest);
2665 }
2666 
2667 static void
2668 video_converter_compute_matrix (GstVideoConverter * convert)
2669 {
2670   MatrixData *dst = &amp;convert-&gt;convert_matrix;
2671 
2672   color_matrix_set_identity (dst);
2673   compute_matrix_to_RGB (convert, dst);
2674   compute_matrix_to_YUV (convert, dst, FALSE);
2675 
2676   convert-&gt;current_bits = 8;
2677   prepare_matrix (convert, dst);
2678 }
2679 
2680 static void
2681 video_converter_compute_resample (GstVideoConverter * convert, gint idx)
2682 {
2683   GstVideoInfo *in_info, *out_info;
2684   const GstVideoFormatInfo *sfinfo, *dfinfo;
2685 
2686   if (CHECK_CHROMA_NONE (convert))
2687     return;
2688 
2689   in_info = &amp;convert-&gt;in_info;
2690   out_info = &amp;convert-&gt;out_info;
2691 
2692   sfinfo = in_info-&gt;finfo;
2693   dfinfo = out_info-&gt;finfo;
2694 
2695   GST_DEBUG (&quot;site: %d-&gt;%d, w_sub: %d-&gt;%d, h_sub: %d-&gt;%d&quot;, in_info-&gt;chroma_site,
2696       out_info-&gt;chroma_site, sfinfo-&gt;w_sub[2], dfinfo-&gt;w_sub[2],
2697       sfinfo-&gt;h_sub[2], dfinfo-&gt;h_sub[2]);
2698 
2699   if (sfinfo-&gt;w_sub[2] != dfinfo-&gt;w_sub[2] ||
2700       sfinfo-&gt;h_sub[2] != dfinfo-&gt;h_sub[2] ||
2701       in_info-&gt;chroma_site != out_info-&gt;chroma_site ||
2702       in_info-&gt;width != out_info-&gt;width ||
2703       in_info-&gt;height != out_info-&gt;height) {
2704     if (GST_VIDEO_INFO_IS_INTERLACED (in_info)) {
2705       if (!CHECK_CHROMA_DOWNSAMPLE (convert))
2706         convert-&gt;upsample_i[idx] = gst_video_chroma_resample_new (0,
2707             in_info-&gt;chroma_site, GST_VIDEO_CHROMA_FLAG_INTERLACED,
2708             sfinfo-&gt;unpack_format, sfinfo-&gt;w_sub[2], sfinfo-&gt;h_sub[2]);
2709       if (!CHECK_CHROMA_UPSAMPLE (convert))
2710         convert-&gt;downsample_i[idx] =
2711             gst_video_chroma_resample_new (0, out_info-&gt;chroma_site,
2712             GST_VIDEO_CHROMA_FLAG_INTERLACED, dfinfo-&gt;unpack_format,
2713             -dfinfo-&gt;w_sub[2], -dfinfo-&gt;h_sub[2]);
2714     }
2715     if (!CHECK_CHROMA_DOWNSAMPLE (convert))
2716       convert-&gt;upsample_p[idx] = gst_video_chroma_resample_new (0,
2717           in_info-&gt;chroma_site, 0, sfinfo-&gt;unpack_format, sfinfo-&gt;w_sub[2],
2718           sfinfo-&gt;h_sub[2]);
2719     if (!CHECK_CHROMA_UPSAMPLE (convert))
2720       convert-&gt;downsample_p[idx] = gst_video_chroma_resample_new (0,
2721           out_info-&gt;chroma_site, 0, dfinfo-&gt;unpack_format, -dfinfo-&gt;w_sub[2],
2722           -dfinfo-&gt;h_sub[2]);
2723   }
2724 }
2725 
2726 #define FRAME_GET_PLANE_STRIDE(frame, plane) \
2727   GST_VIDEO_FRAME_PLANE_STRIDE (frame, plane)
2728 #define FRAME_GET_PLANE_LINE(frame, plane, line) \
2729   (gpointer)(((guint8*)(GST_VIDEO_FRAME_PLANE_DATA (frame, plane))) + \
2730       FRAME_GET_PLANE_STRIDE (frame, plane) * (line))
2731 
2732 #define FRAME_GET_COMP_STRIDE(frame, comp) \
2733   GST_VIDEO_FRAME_COMP_STRIDE (frame, comp)
2734 #define FRAME_GET_COMP_LINE(frame, comp, line) \
2735   (gpointer)(((guint8*)(GST_VIDEO_FRAME_COMP_DATA (frame, comp))) + \
2736       FRAME_GET_COMP_STRIDE (frame, comp) * (line))
2737 
2738 #define FRAME_GET_STRIDE(frame)      FRAME_GET_PLANE_STRIDE (frame, 0)
2739 #define FRAME_GET_LINE(frame,line)   FRAME_GET_PLANE_LINE (frame, 0, line)
2740 
2741 #define FRAME_GET_Y_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_Y, line)
2742 #define FRAME_GET_U_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_U, line)
2743 #define FRAME_GET_V_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_V, line)
2744 #define FRAME_GET_A_LINE(frame,line) FRAME_GET_COMP_LINE(frame, GST_VIDEO_COMP_A, line)
2745 
2746 #define FRAME_GET_Y_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_Y)
2747 #define FRAME_GET_U_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_U)
2748 #define FRAME_GET_V_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_V)
2749 #define FRAME_GET_A_STRIDE(frame)    FRAME_GET_COMP_STRIDE(frame, GST_VIDEO_COMP_A)
2750 
2751 
2752 #define UNPACK_FRAME(frame,dest,line,x,width)        \
2753   frame-&gt;info.finfo-&gt;unpack_func (frame-&gt;info.finfo, \
2754       (GST_VIDEO_FRAME_IS_INTERLACED (frame) ?       \
2755         GST_VIDEO_PACK_FLAG_INTERLACED :             \
2756         GST_VIDEO_PACK_FLAG_NONE),                   \
2757       dest, frame-&gt;data, frame-&gt;info.stride, x,      \
2758       line, width)
2759 #define PACK_FRAME(frame,src,line,width)             \
2760   frame-&gt;info.finfo-&gt;pack_func (frame-&gt;info.finfo,   \
2761       (GST_VIDEO_FRAME_IS_INTERLACED (frame) ?       \
2762         GST_VIDEO_PACK_FLAG_INTERLACED :             \
2763         GST_VIDEO_PACK_FLAG_NONE),                   \
2764       src, 0, frame-&gt;data, frame-&gt;info.stride,       \
2765       frame-&gt;info.chroma_site, line, width);
2766 
2767 static gpointer
2768 get_dest_line (GstLineCache * cache, gint idx, gpointer user_data)
2769 {
2770   GstVideoConverter *convert = user_data;
2771   guint8 *line;
2772   gint pstride = convert-&gt;pack_pstride;
2773   gint out_x = convert-&gt;out_x;
2774   guint cline;
2775 
2776   cline = CLAMP (idx, 0, convert-&gt;out_maxheight - 1);
2777 
2778   line = FRAME_GET_LINE (convert-&gt;dest, cline);
2779   GST_DEBUG (&quot;get dest line %d %p&quot;, cline, line);
2780 
2781   if (convert-&gt;borderline) {
2782     gint r_border = (out_x + convert-&gt;out_width) * pstride;
2783     gint rb_width = convert-&gt;out_maxwidth * pstride - r_border;
2784     gint lb_width = out_x * pstride;
2785 
2786     memcpy (line, convert-&gt;borderline, lb_width);
2787     memcpy (line + r_border, convert-&gt;borderline, rb_width);
2788   }
2789   line += out_x * pstride;
2790 
2791   return line;
2792 }
2793 
2794 static gboolean
2795 do_unpack_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2796     gpointer user_data)
2797 {
2798   GstVideoConverter *convert = user_data;
2799   gpointer tmpline;
2800   guint cline;
2801 
2802   cline = CLAMP (in_line + convert-&gt;in_y, 0, convert-&gt;in_maxheight - 1);
2803 
2804   if (cache-&gt;alloc_writable || !convert-&gt;identity_unpack) {
2805     tmpline = gst_line_cache_alloc_line (cache, out_line);
2806     GST_DEBUG (&quot;unpack line %d (%u) %p&quot;, in_line, cline, tmpline);
2807     UNPACK_FRAME (convert-&gt;src, tmpline, cline, convert-&gt;in_x,
2808         convert-&gt;in_width);
2809   } else {
2810     tmpline = ((guint8 *) FRAME_GET_LINE (convert-&gt;src, cline)) +
2811         convert-&gt;in_x * convert-&gt;unpack_pstride;
2812     GST_DEBUG (&quot;get src line %d (%u) %p&quot;, in_line, cline, tmpline);
2813   }
2814   gst_line_cache_add_line (cache, in_line, tmpline);
2815 
2816   return TRUE;
2817 }
2818 
2819 static gboolean
2820 do_upsample_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2821     gpointer user_data)
2822 {
2823   GstVideoConverter *convert = user_data;
2824   gpointer *lines;
2825   gint i, start_line, n_lines;
2826 
2827   n_lines = convert-&gt;up_n_lines;
2828   start_line = in_line;
2829   if (start_line &lt; n_lines + convert-&gt;up_offset) {
2830     start_line += convert-&gt;up_offset;
2831     out_line += convert-&gt;up_offset;
2832   }
2833 
2834   /* get the lines needed for chroma upsample */
2835   lines =
2836       gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, start_line,
2837       n_lines);
2838 
2839   if (convert-&gt;upsample) {
2840     GST_DEBUG (&quot;doing upsample %d-%d %p&quot;, start_line, start_line + n_lines - 1,
2841         lines[0]);
2842     gst_video_chroma_resample (convert-&gt;upsample[idx], lines,
2843         convert-&gt;in_width);
2844   }
2845 
2846   for (i = 0; i &lt; n_lines; i++)
2847     gst_line_cache_add_line (cache, start_line + i, lines[i]);
2848 
2849   return TRUE;
2850 }
2851 
2852 static gboolean
2853 do_convert_to_RGB_lines (GstLineCache * cache, gint idx, gint out_line,
2854     gint in_line, gpointer user_data)
2855 {
2856   GstVideoConverter *convert = user_data;
2857   MatrixData *data = &amp;convert-&gt;to_RGB_matrix;
2858   gpointer *lines, destline;
2859 
2860   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2861   destline = lines[0];
2862 
2863   if (data-&gt;matrix_func) {
2864     GST_DEBUG (&quot;to RGB line %d %p&quot;, in_line, destline);
2865     data-&gt;matrix_func (data, destline);
2866   }
2867   if (convert-&gt;gamma_dec.gamma_func) {
2868     destline = gst_line_cache_alloc_line (cache, out_line);
2869 
2870     GST_DEBUG (&quot;gamma decode line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
2871     convert-&gt;gamma_dec.gamma_func (&amp;convert-&gt;gamma_dec, destline, lines[0]);
2872   }
2873   gst_line_cache_add_line (cache, in_line, destline);
2874 
2875   return TRUE;
2876 }
2877 
2878 static gboolean
2879 do_hscale_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2880     gpointer user_data)
2881 {
2882   GstVideoConverter *convert = user_data;
2883   gpointer *lines, destline;
2884 
2885   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2886 
2887   destline = gst_line_cache_alloc_line (cache, out_line);
2888 
2889   GST_DEBUG (&quot;hresample line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
2890   gst_video_scaler_horizontal (convert-&gt;h_scaler[idx], convert-&gt;h_scale_format,
2891       lines[0], destline, 0, convert-&gt;out_width);
2892 
2893   gst_line_cache_add_line (cache, in_line, destline);
2894 
2895   return TRUE;
2896 }
2897 
2898 static gboolean
2899 do_vscale_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2900     gpointer user_data)
2901 {
2902   GstVideoConverter *convert = user_data;
2903   gpointer *lines, destline;
2904   guint sline, n_lines;
2905   guint cline;
2906 
2907   cline = CLAMP (in_line, 0, convert-&gt;out_height - 1);
2908 
2909   gst_video_scaler_get_coeff (convert-&gt;v_scaler[idx], cline, &amp;sline, &amp;n_lines);
2910   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, sline, n_lines);
2911 
2912   destline = gst_line_cache_alloc_line (cache, out_line);
2913 
2914   GST_DEBUG (&quot;vresample line %d %d-%d %p-&gt;%p&quot;, in_line, sline,
2915       sline + n_lines - 1, lines[0], destline);
2916   gst_video_scaler_vertical (convert-&gt;v_scaler[idx], convert-&gt;v_scale_format,
2917       lines, destline, cline, convert-&gt;v_scale_width);
2918 
2919   gst_line_cache_add_line (cache, in_line, destline);
2920 
2921   return TRUE;
2922 }
2923 
2924 static gboolean
2925 do_convert_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2926     gpointer user_data)
2927 {
2928   GstVideoConverter *convert = user_data;
2929   MatrixData *data = &amp;convert-&gt;convert_matrix;
2930   gpointer *lines, destline;
2931   guint in_bits, out_bits;
2932   gint width;
2933 
2934   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2935 
2936   destline = lines[0];
2937 
2938   in_bits = convert-&gt;in_bits;
2939   out_bits = convert-&gt;out_bits;
2940 
2941   width = MIN (convert-&gt;in_width, convert-&gt;out_width);
2942 
2943   if (out_bits == 16 || in_bits == 16) {
2944     gpointer srcline = lines[0];
2945 
2946     if (out_bits != in_bits)
2947       destline = gst_line_cache_alloc_line (cache, out_line);
2948 
2949     /* FIXME, we can scale in the conversion matrix */
2950     if (in_bits == 8) {
2951       GST_DEBUG (&quot;8-&gt;16 line %d %p-&gt;%p&quot;, in_line, srcline, destline);
2952       video_orc_convert_u8_to_u16 (destline, srcline, width * 4);
2953       srcline = destline;
2954     }
2955 
2956     if (data-&gt;matrix_func) {
2957       GST_DEBUG (&quot;matrix line %d %p&quot;, in_line, srcline);
2958       data-&gt;matrix_func (data, srcline);
2959     }
2960 
2961     /* FIXME, dither here */
2962     if (out_bits == 8) {
2963       GST_DEBUG (&quot;16-&gt;8 line %d %p-&gt;%p&quot;, in_line, srcline, destline);
2964       video_orc_convert_u16_to_u8 (destline, srcline, width * 4);
2965     }
2966   } else {
2967     if (data-&gt;matrix_func) {
2968       GST_DEBUG (&quot;matrix line %d %p&quot;, in_line, destline);
2969       data-&gt;matrix_func (data, destline);
2970     }
2971   }
2972   gst_line_cache_add_line (cache, in_line, destline);
2973 
2974   return TRUE;
2975 }
2976 
2977 static gboolean
2978 do_alpha_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
2979     gpointer user_data)
2980 {
2981   gpointer *lines, destline;
2982   GstVideoConverter *convert = user_data;
2983   gint width = MIN (convert-&gt;in_width, convert-&gt;out_width);
2984 
2985   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
2986   destline = lines[0];
2987 
2988   GST_DEBUG (&quot;alpha line %d %p&quot;, in_line, destline);
2989   convert-&gt;alpha_func (convert, destline, width);
2990 
2991   gst_line_cache_add_line (cache, in_line, destline);
2992 
2993   return TRUE;
2994 }
2995 
2996 static gboolean
2997 do_convert_to_YUV_lines (GstLineCache * cache, gint idx, gint out_line,
2998     gint in_line, gpointer user_data)
2999 {
3000   GstVideoConverter *convert = user_data;
3001   MatrixData *data = &amp;convert-&gt;to_YUV_matrix;
3002   gpointer *lines, destline;
3003 
3004   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
3005   destline = lines[0];
3006 
3007   if (convert-&gt;gamma_enc.gamma_func) {
3008     destline = gst_line_cache_alloc_line (cache, out_line);
3009 
3010     GST_DEBUG (&quot;gamma encode line %d %p-&gt;%p&quot;, in_line, lines[0], destline);
3011     convert-&gt;gamma_enc.gamma_func (&amp;convert-&gt;gamma_enc, destline, lines[0]);
3012   }
3013   if (data-&gt;matrix_func) {
3014     GST_DEBUG (&quot;to YUV line %d %p&quot;, in_line, destline);
3015     data-&gt;matrix_func (data, destline);
3016   }
3017   gst_line_cache_add_line (cache, in_line, destline);
3018 
3019   return TRUE;
3020 }
3021 
3022 static gboolean
3023 do_downsample_lines (GstLineCache * cache, gint idx, gint out_line,
3024     gint in_line, gpointer user_data)
3025 {
3026   GstVideoConverter *convert = user_data;
3027   gpointer *lines;
3028   gint i, start_line, n_lines;
3029 
3030   n_lines = convert-&gt;down_n_lines;
3031   start_line = in_line;
3032   if (start_line &lt; n_lines + convert-&gt;down_offset)
3033     start_line += convert-&gt;down_offset;
3034 
3035   /* get the lines needed for chroma downsample */
3036   lines =
3037       gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, start_line,
3038       n_lines);
3039 
3040   if (convert-&gt;downsample) {
3041     GST_DEBUG (&quot;downsample line %d %d-%d %p&quot;, in_line, start_line,
3042         start_line + n_lines - 1, lines[0]);
3043     gst_video_chroma_resample (convert-&gt;downsample[idx], lines,
3044         convert-&gt;out_width);
3045   }
3046 
3047   for (i = 0; i &lt; n_lines; i++)
3048     gst_line_cache_add_line (cache, start_line + i, lines[i]);
3049 
3050   return TRUE;
3051 }
3052 
3053 static gboolean
3054 do_dither_lines (GstLineCache * cache, gint idx, gint out_line, gint in_line,
3055     gpointer user_data)
3056 {
3057   GstVideoConverter *convert = user_data;
3058   gpointer *lines, destline;
3059 
3060   lines = gst_line_cache_get_lines (cache-&gt;prev, idx, out_line, in_line, 1);
3061   destline = lines[0];
3062 
3063   if (convert-&gt;dither) {
3064     GST_DEBUG (&quot;Dither line %d %p&quot;, in_line, destline);
3065     gst_video_dither_line (convert-&gt;dither[idx], destline, 0, out_line,
3066         convert-&gt;out_width);
3067   }
3068   gst_line_cache_add_line (cache, in_line, destline);
3069 
3070   return TRUE;
3071 }
3072 
3073 typedef struct
3074 {
3075   GstLineCache *pack_lines;
3076   gint idx;
3077   gint h_0, h_1;
3078   gint pack_lines_count;
3079   gint out_y;
3080   gboolean identity_pack;
3081   gint lb_width, out_maxwidth;
3082   GstVideoFrame *dest;
3083 } ConvertTask;
3084 
3085 static void
3086 convert_generic_task (ConvertTask * task)
3087 {
3088   gint i;
3089 
3090   for (i = task-&gt;h_0; i &lt; task-&gt;h_1; i += task-&gt;pack_lines_count) {
3091     gpointer *lines;
3092 
3093     /* load the lines needed to pack */
3094     lines =
3095         gst_line_cache_get_lines (task-&gt;pack_lines, task-&gt;idx, i + task-&gt;out_y,
3096         i, task-&gt;pack_lines_count);
3097 
3098     if (!task-&gt;identity_pack) {
3099       /* take away the border */
3100       guint8 *l = ((guint8 *) lines[0]) - task-&gt;lb_width;
3101       /* and pack into destination */
3102       GST_DEBUG (&quot;pack line %d %p (%p)&quot;, i + task-&gt;out_y, lines[0], l);
3103       PACK_FRAME (task-&gt;dest, l, i + task-&gt;out_y, task-&gt;out_maxwidth);
3104     }
3105   }
3106 }
3107 
3108 static void
3109 video_converter_generic (GstVideoConverter * convert, const GstVideoFrame * src,
3110     GstVideoFrame * dest)
3111 {
3112   gint i;
3113   gint out_maxwidth, out_maxheight;
3114   gint out_x, out_y, out_height;
3115   gint pack_lines, pstride;
3116   gint lb_width;
3117   ConvertTask *tasks;
3118   ConvertTask **tasks_p;
3119   gint n_threads;
3120   gint lines_per_thread;
3121 
3122   out_height = convert-&gt;out_height;
3123   out_maxwidth = convert-&gt;out_maxwidth;
3124   out_maxheight = convert-&gt;out_maxheight;
3125 
3126   out_x = convert-&gt;out_x;
3127   out_y = convert-&gt;out_y;
3128 
3129   convert-&gt;src = src;
3130   convert-&gt;dest = dest;
3131 
3132   if (GST_VIDEO_FRAME_IS_INTERLACED (src)) {
3133     GST_DEBUG (&quot;setup interlaced frame&quot;);
3134     convert-&gt;upsample = convert-&gt;upsample_i;
3135     convert-&gt;downsample = convert-&gt;downsample_i;
3136     convert-&gt;v_scaler = convert-&gt;v_scaler_i;
3137   } else {
3138     GST_DEBUG (&quot;setup progressive frame&quot;);
3139     convert-&gt;upsample = convert-&gt;upsample_p;
3140     convert-&gt;downsample = convert-&gt;downsample_p;
3141     convert-&gt;v_scaler = convert-&gt;v_scaler_p;
3142   }
3143   if (convert-&gt;upsample[0]) {
3144     gst_video_chroma_resample_get_info (convert-&gt;upsample[0],
3145         &amp;convert-&gt;up_n_lines, &amp;convert-&gt;up_offset);
3146   } else {
3147     convert-&gt;up_n_lines = 1;
3148     convert-&gt;up_offset = 0;
3149   }
3150   if (convert-&gt;downsample[0]) {
3151     gst_video_chroma_resample_get_info (convert-&gt;downsample[0],
3152         &amp;convert-&gt;down_n_lines, &amp;convert-&gt;down_offset);
3153   } else {
3154     convert-&gt;down_n_lines = 1;
3155     convert-&gt;down_offset = 0;
3156   }
3157 
3158   pack_lines = convert-&gt;pack_nlines;    /* only 1 for now */
3159   pstride = convert-&gt;pack_pstride;
3160 
3161   lb_width = out_x * pstride;
3162 
3163   if (convert-&gt;borderline) {
3164     /* FIXME we should try to avoid PACK_FRAME */
3165     for (i = 0; i &lt; out_y; i++)
3166       PACK_FRAME (dest, convert-&gt;borderline, i, out_maxwidth);
3167   }
3168 
3169   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3170   tasks = g_newa (ConvertTask, n_threads);
3171   tasks_p = g_newa (ConvertTask *, n_threads);
3172 
3173   lines_per_thread =
3174       GST_ROUND_UP_N ((out_height + n_threads - 1) / n_threads, pack_lines);
3175 
3176   for (i = 0; i &lt; n_threads; i++) {
3177     tasks[i].dest = dest;
3178     tasks[i].pack_lines = convert-&gt;pack_lines[i];
3179     tasks[i].idx = i;
3180     tasks[i].pack_lines_count = pack_lines;
3181     tasks[i].out_y = out_y;
3182     tasks[i].identity_pack = convert-&gt;identity_pack;
3183     tasks[i].lb_width = lb_width;
3184     tasks[i].out_maxwidth = out_maxwidth;
3185 
3186     tasks[i].h_0 = i * lines_per_thread;
3187     tasks[i].h_1 = MIN ((i + 1) * lines_per_thread, out_height);
3188 
3189     tasks_p[i] = &amp;tasks[i];
3190   }
3191 
3192   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3193       (GstParallelizedTaskFunc) convert_generic_task, (gpointer) tasks_p);
3194 
3195   if (convert-&gt;borderline) {
3196     for (i = out_y + out_height; i &lt; out_maxheight; i++)
3197       PACK_FRAME (dest, convert-&gt;borderline, i, out_maxwidth);
3198   }
3199   if (convert-&gt;pack_pal) {
3200     memcpy (GST_VIDEO_FRAME_PLANE_DATA (dest, 1), convert-&gt;pack_pal,
3201         convert-&gt;pack_palsize);
3202   }
3203 }
3204 
3205 static void convert_fill_border (GstVideoConverter * convert,
3206     GstVideoFrame * dest);
3207 
3208 /* Fast paths */
3209 
3210 #define GET_LINE_OFFSETS(interlaced,line,l1,l2) \
3211     if (interlaced) {                           \
3212       l1 = (line &amp; 2 ? line - 1 : line);        \
3213       l2 = l1 + 2;                              \
3214     } else {                                    \
3215       l1 = line;                                \
3216       l2 = l1 + 1;                              \
3217     }
3218 
3219 typedef struct
3220 {
3221   const GstVideoFrame *src;
3222   GstVideoFrame *dest;
3223   gint height_0, height_1;
3224 
3225   /* parameters */
3226   gboolean interlaced;
3227   gint width;
3228   gint alpha;
3229   MatrixData *data;
3230   gint in_x, in_y;
3231   gint out_x, out_y;
3232   gpointer tmpline;
3233 } FConvertTask;
3234 
3235 static void
3236 convert_I420_YUY2_task (FConvertTask * task)
3237 {
3238   gint i;
3239   gint l1, l2;
3240 
3241   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3242     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3243 
3244     video_orc_convert_I420_YUY2 (FRAME_GET_LINE (task-&gt;dest, l1),
3245         FRAME_GET_LINE (task-&gt;dest, l2),
3246         FRAME_GET_Y_LINE (task-&gt;src, l1),
3247         FRAME_GET_Y_LINE (task-&gt;src, l2),
3248         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1),
3249         FRAME_GET_V_LINE (task-&gt;src, i &gt;&gt; 1), (task-&gt;width + 1) / 2);
3250   }
3251 }
3252 
3253 static void
3254 convert_I420_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
3255     GstVideoFrame * dest)
3256 {
3257   int i;
3258   gint width = convert-&gt;in_width;
3259   gint height = convert-&gt;in_height;
3260   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3261   gint h2;
3262   FConvertTask *tasks;
3263   FConvertTask **tasks_p;
3264   gint n_threads;
3265   gint lines_per_thread;
3266 
3267   /* I420 has half as many chroma lines, as such we have to
3268    * always merge two into one. For non-interlaced these are
3269    * the two next to each other, for interlaced one is skipped
3270    * in between. */
3271   if (interlaced)
3272     h2 = GST_ROUND_DOWN_4 (height);
3273   else
3274     h2 = GST_ROUND_DOWN_2 (height);
3275 
3276   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3277   tasks = g_newa (FConvertTask, n_threads);
3278   tasks_p = g_newa (FConvertTask *, n_threads);
3279 
3280   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3281 
3282   for (i = 0; i &lt; n_threads; i++) {
3283     tasks[i].src = src;
3284     tasks[i].dest = dest;
3285 
3286     tasks[i].interlaced = interlaced;
3287     tasks[i].width = width;
3288 
3289     tasks[i].height_0 = i * lines_per_thread;
3290     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3291     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3292 
3293     tasks_p[i] = &amp;tasks[i];
3294   }
3295 
3296   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3297       (GstParallelizedTaskFunc) convert_I420_YUY2_task, (gpointer) tasks_p);
3298 
3299   /* now handle last lines. For interlaced these are up to 3 */
3300   if (h2 != height) {
3301     for (i = h2; i &lt; height; i++) {
3302       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3303       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3304     }
3305   }
3306 }
3307 
3308 static void
3309 convert_I420_UYVY_task (FConvertTask * task)
3310 {
3311   gint i;
3312   gint l1, l2;
3313 
3314   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3315     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3316 
3317     video_orc_convert_I420_UYVY (FRAME_GET_LINE (task-&gt;dest, l1),
3318         FRAME_GET_LINE (task-&gt;dest, l2),
3319         FRAME_GET_Y_LINE (task-&gt;src, l1),
3320         FRAME_GET_Y_LINE (task-&gt;src, l2),
3321         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1),
3322         FRAME_GET_V_LINE (task-&gt;src, i &gt;&gt; 1), (task-&gt;width + 1) / 2);
3323   }
3324 }
3325 
3326 static void
3327 convert_I420_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
3328     GstVideoFrame * dest)
3329 {
3330   int i;
3331   gint width = convert-&gt;in_width;
3332   gint height = convert-&gt;in_height;
3333   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3334   gint h2;
3335   FConvertTask *tasks;
3336   FConvertTask **tasks_p;
3337   gint n_threads;
3338   gint lines_per_thread;
3339 
3340   /* I420 has half as many chroma lines, as such we have to
3341    * always merge two into one. For non-interlaced these are
3342    * the two next to each other, for interlaced one is skipped
3343    * in between. */
3344   if (interlaced)
3345     h2 = GST_ROUND_DOWN_4 (height);
3346   else
3347     h2 = GST_ROUND_DOWN_2 (height);
3348 
3349   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3350   tasks = g_newa (FConvertTask, n_threads);
3351   tasks_p = g_newa (FConvertTask *, n_threads);
3352 
3353   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3354 
3355   for (i = 0; i &lt; n_threads; i++) {
3356     tasks[i].src = src;
3357     tasks[i].dest = dest;
3358 
3359     tasks[i].interlaced = interlaced;
3360     tasks[i].width = width;
3361 
3362     tasks[i].height_0 = i * lines_per_thread;
3363     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3364     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3365 
3366     tasks_p[i] = &amp;tasks[i];
3367   }
3368 
3369   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3370       (GstParallelizedTaskFunc) convert_I420_UYVY_task, (gpointer) tasks_p);
3371 
3372   /* now handle last lines. For interlaced these are up to 3 */
3373   if (h2 != height) {
3374     for (i = h2; i &lt; height; i++) {
3375       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3376       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3377     }
3378   }
3379 }
3380 
3381 static void
3382 convert_I420_AYUV_task (FConvertTask * task)
3383 {
3384   gint i;
3385   gint l1, l2;
3386 
3387   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3388     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3389 
3390     video_orc_convert_I420_AYUV (FRAME_GET_LINE (task-&gt;dest, l1),
3391         FRAME_GET_LINE (task-&gt;dest, l2),
3392         FRAME_GET_Y_LINE (task-&gt;src, l1),
3393         FRAME_GET_Y_LINE (task-&gt;src, l2),
3394         FRAME_GET_U_LINE (task-&gt;src, i &gt;&gt; 1), FRAME_GET_V_LINE (task-&gt;src,
3395             i &gt;&gt; 1), task-&gt;alpha, task-&gt;width);
3396   }
3397 }
3398 
3399 static void
3400 convert_I420_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3401     GstVideoFrame * dest)
3402 {
3403   int i;
3404   gint width = convert-&gt;in_width;
3405   gint height = convert-&gt;in_height;
3406   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3407   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3408   gint h2;
3409   FConvertTask *tasks;
3410   FConvertTask **tasks_p;
3411   gint n_threads;
3412   gint lines_per_thread;
3413 
3414   /* I420 has half as many chroma lines, as such we have to
3415    * always merge two into one. For non-interlaced these are
3416    * the two next to each other, for interlaced one is skipped
3417    * in between. */
3418   if (interlaced)
3419     h2 = GST_ROUND_DOWN_4 (height);
3420   else
3421     h2 = GST_ROUND_DOWN_2 (height);
3422 
3423 
3424   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3425   tasks = g_newa (FConvertTask, n_threads);
3426   tasks_p = g_newa (FConvertTask *, n_threads);
3427 
3428   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3429 
3430   for (i = 0; i &lt; n_threads; i++) {
3431     tasks[i].src = src;
3432     tasks[i].dest = dest;
3433 
3434     tasks[i].interlaced = interlaced;
3435     tasks[i].width = width;
3436     tasks[i].alpha = alpha;
3437 
3438     tasks[i].height_0 = i * lines_per_thread;
3439     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3440     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3441 
3442     tasks_p[i] = &amp;tasks[i];
3443   }
3444 
3445   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3446       (GstParallelizedTaskFunc) convert_I420_AYUV_task, (gpointer) tasks_p);
3447 
3448   /* now handle last lines. For interlaced these are up to 3 */
3449   if (h2 != height) {
3450     for (i = h2; i &lt; height; i++) {
3451       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3452       if (alpha != 0xff)
3453         convert_set_alpha_u8 (convert, convert-&gt;tmpline[0], width);
3454       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3455     }
3456   }
3457 }
3458 
3459 static void
3460 convert_YUY2_I420_task (FConvertTask * task)
3461 {
3462   gint i;
3463   gint l1, l2;
3464 
3465   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3466     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3467 
3468     video_orc_convert_YUY2_I420 (FRAME_GET_Y_LINE (task-&gt;dest, l1),
3469         FRAME_GET_Y_LINE (task-&gt;dest, l2),
3470         FRAME_GET_U_LINE (task-&gt;dest, i &gt;&gt; 1),
3471         FRAME_GET_V_LINE (task-&gt;dest, i &gt;&gt; 1),
3472         FRAME_GET_LINE (task-&gt;src, l1), FRAME_GET_LINE (task-&gt;src, l2),
3473         (task-&gt;width + 1) / 2);
3474   }
3475 }
3476 
3477 static void
3478 convert_YUY2_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
3479     GstVideoFrame * dest)
3480 {
3481   int i;
3482   gint width = convert-&gt;in_width;
3483   gint height = convert-&gt;in_height;
3484   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3485   gint h2;
3486   FConvertTask *tasks;
3487   FConvertTask **tasks_p;
3488   gint n_threads;
3489   gint lines_per_thread;
3490 
3491   /* I420 has half as many chroma lines, as such we have to
3492    * always merge two into one. For non-interlaced these are
3493    * the two next to each other, for interlaced one is skipped
3494    * in between. */
3495   if (interlaced)
3496     h2 = GST_ROUND_DOWN_4 (height);
3497   else
3498     h2 = GST_ROUND_DOWN_2 (height);
3499 
3500   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3501   tasks = g_newa (FConvertTask, n_threads);
3502   tasks_p = g_newa (FConvertTask *, n_threads);
3503 
3504   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3505 
3506   for (i = 0; i &lt; n_threads; i++) {
3507     tasks[i].src = src;
3508     tasks[i].dest = dest;
3509 
3510     tasks[i].interlaced = interlaced;
3511     tasks[i].width = width;
3512 
3513     tasks[i].height_0 = i * lines_per_thread;
3514     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3515     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3516 
3517     tasks_p[i] = &amp;tasks[i];
3518   }
3519 
3520   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3521       (GstParallelizedTaskFunc) convert_YUY2_I420_task, (gpointer) tasks_p);
3522 
3523   /* now handle last lines. For interlaced these are up to 3 */
3524   if (h2 != height) {
3525     for (i = h2; i &lt; height; i++) {
3526       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3527       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3528     }
3529   }
3530 }
3531 
3532 typedef struct
3533 {
3534   const guint8 *s, *s2, *su, *sv;
3535   guint8 *d, *d2, *du, *dv;
3536   gint sstride, sustride, svstride;
3537   gint dstride, dustride, dvstride;
3538   gint width, height;
3539   gint alpha;
3540   MatrixData *data;
3541 } FConvertPlaneTask;
3542 
3543 static void
3544 convert_YUY2_AYUV_task (FConvertPlaneTask * task)
3545 {
3546   video_orc_convert_YUY2_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
3547       task-&gt;sstride, task-&gt;alpha, (task-&gt;width + 1) / 2, task-&gt;height);
3548 }
3549 
3550 static void
3551 convert_YUY2_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3552     GstVideoFrame * dest)
3553 {
3554   gint width = convert-&gt;in_width;
3555   gint height = convert-&gt;in_height;
3556   guint8 *s, *d;
3557   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3558   FConvertPlaneTask *tasks;
3559   FConvertPlaneTask **tasks_p;
3560   gint n_threads;
3561   gint lines_per_thread;
3562   gint i;
3563 
3564   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3565   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3566   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3567   d += (convert-&gt;out_x * 4);
3568 
3569   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3570   tasks = g_newa (FConvertPlaneTask, n_threads);
3571   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3572 
3573   lines_per_thread = (height + n_threads - 1) / n_threads;
3574 
3575   for (i = 0; i &lt; n_threads; i++) {
3576     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3577     tasks[i].sstride = FRAME_GET_STRIDE (src);
3578     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3579     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3580 
3581     tasks[i].width = width;
3582     tasks[i].height = (i + 1) * lines_per_thread;
3583     tasks[i].height = MIN (tasks[i].height, height);
3584     tasks[i].height -= i * lines_per_thread;
3585     tasks[i].alpha = alpha;
3586 
3587     tasks_p[i] = &amp;tasks[i];
3588   }
3589 
3590   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3591       (GstParallelizedTaskFunc) convert_YUY2_AYUV_task, (gpointer) tasks_p);
3592 
3593   convert_fill_border (convert, dest);
3594 }
3595 
3596 static void
3597 convert_YUY2_Y42B_task (FConvertPlaneTask * task)
3598 {
3599   video_orc_convert_YUY2_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
3600       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
3601       task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3602 }
3603 
3604 static void
3605 convert_YUY2_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
3606     GstVideoFrame * dest)
3607 {
3608   gint width = convert-&gt;in_width;
3609   gint height = convert-&gt;in_height;
3610   guint8 *s, *dy, *du, *dv;
3611   FConvertPlaneTask *tasks;
3612   FConvertPlaneTask **tasks_p;
3613   gint n_threads;
3614   gint lines_per_thread;
3615   gint i;
3616 
3617   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3618   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3619 
3620   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3621   dy += convert-&gt;out_x;
3622   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3623   du += convert-&gt;out_x &gt;&gt; 1;
3624   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3625   dv += convert-&gt;out_x &gt;&gt; 1;
3626 
3627   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3628   tasks = g_newa (FConvertPlaneTask, n_threads);
3629   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3630 
3631   lines_per_thread = (height + n_threads - 1) / n_threads;
3632 
3633   for (i = 0; i &lt; n_threads; i++) {
3634     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3635     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3636     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3637     tasks[i].sstride = FRAME_GET_STRIDE (src);
3638     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3639     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3640     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3641     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3642 
3643     tasks[i].width = width;
3644     tasks[i].height = (i + 1) * lines_per_thread;
3645     tasks[i].height = MIN (tasks[i].height, height);
3646     tasks[i].height -= i * lines_per_thread;
3647 
3648     tasks_p[i] = &amp;tasks[i];
3649   }
3650 
3651   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3652       (GstParallelizedTaskFunc) convert_YUY2_Y42B_task, (gpointer) tasks_p);
3653 
3654   convert_fill_border (convert, dest);
3655 }
3656 
3657 static void
3658 convert_YUY2_Y444_task (FConvertPlaneTask * task)
3659 {
3660   video_orc_convert_YUY2_Y444 (task-&gt;d,
3661       task-&gt;dstride, task-&gt;du,
3662       task-&gt;dustride, task-&gt;dv,
3663       task-&gt;dvstride, task-&gt;s,
3664       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3665 }
3666 
3667 static void
3668 convert_YUY2_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
3669     GstVideoFrame * dest)
3670 {
3671   gint width = convert-&gt;in_width;
3672   gint height = convert-&gt;in_height;
3673   guint8 *s, *dy, *du, *dv;
3674   FConvertPlaneTask *tasks;
3675   FConvertPlaneTask **tasks_p;
3676   gint n_threads;
3677   gint lines_per_thread;
3678   gint i;
3679 
3680   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3681   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3682 
3683   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3684   dy += convert-&gt;out_x;
3685   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3686   du += convert-&gt;out_x;
3687   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3688   dv += convert-&gt;out_x;
3689 
3690   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3691   tasks = g_newa (FConvertPlaneTask, n_threads);
3692   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3693 
3694   lines_per_thread = (height + n_threads - 1) / n_threads;
3695 
3696   for (i = 0; i &lt; n_threads; i++) {
3697     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3698     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3699     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3700     tasks[i].sstride = FRAME_GET_STRIDE (src);
3701     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3702     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3703     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3704     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3705 
3706     tasks[i].width = width;
3707     tasks[i].height = (i + 1) * lines_per_thread;
3708     tasks[i].height = MIN (tasks[i].height, height);
3709     tasks[i].height -= i * lines_per_thread;
3710 
3711     tasks_p[i] = &amp;tasks[i];
3712   }
3713 
3714   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3715       (GstParallelizedTaskFunc) convert_YUY2_Y444_task, (gpointer) tasks_p);
3716 
3717   convert_fill_border (convert, dest);
3718 }
3719 
3720 static void
3721 convert_UYVY_I420_task (FConvertTask * task)
3722 {
3723   gint i;
3724   gint l1, l2;
3725 
3726   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i += 2) {
3727     GET_LINE_OFFSETS (task-&gt;interlaced, i, l1, l2);
3728 
3729     video_orc_convert_UYVY_I420 (FRAME_GET_COMP_LINE (task-&gt;dest, 0, l1),
3730         FRAME_GET_COMP_LINE (task-&gt;dest, 0, l2),
3731         FRAME_GET_COMP_LINE (task-&gt;dest, 1, i &gt;&gt; 1),
3732         FRAME_GET_COMP_LINE (task-&gt;dest, 2, i &gt;&gt; 1),
3733         FRAME_GET_LINE (task-&gt;src, l1), FRAME_GET_LINE (task-&gt;src, l2),
3734         (task-&gt;width + 1) / 2);
3735   }
3736 }
3737 
3738 static void
3739 convert_UYVY_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
3740     GstVideoFrame * dest)
3741 {
3742   int i;
3743   gint width = convert-&gt;in_width;
3744   gint height = convert-&gt;in_height;
3745   gboolean interlaced = GST_VIDEO_FRAME_IS_INTERLACED (src);
3746   gint h2;
3747   FConvertTask *tasks;
3748   FConvertTask **tasks_p;
3749   gint n_threads;
3750   gint lines_per_thread;
3751 
3752   /* I420 has half as many chroma lines, as such we have to
3753    * always merge two into one. For non-interlaced these are
3754    * the two next to each other, for interlaced one is skipped
3755    * in between. */
3756   if (interlaced)
3757     h2 = GST_ROUND_DOWN_4 (height);
3758   else
3759     h2 = GST_ROUND_DOWN_2 (height);
3760 
3761   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3762   tasks = g_newa (FConvertTask, n_threads);
3763   tasks_p = g_newa (FConvertTask *, n_threads);
3764 
3765   lines_per_thread = GST_ROUND_UP_2 ((h2 + n_threads - 1) / n_threads);
3766 
3767   for (i = 0; i &lt; n_threads; i++) {
3768     tasks[i].src = src;
3769     tasks[i].dest = dest;
3770 
3771     tasks[i].interlaced = interlaced;
3772     tasks[i].width = width;
3773 
3774     tasks[i].height_0 = i * lines_per_thread;
3775     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
3776     tasks[i].height_1 = MIN (h2, tasks[i].height_1);
3777 
3778     tasks_p[i] = &amp;tasks[i];
3779   }
3780 
3781   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3782       (GstParallelizedTaskFunc) convert_UYVY_I420_task, (gpointer) tasks_p);
3783 
3784   /* now handle last lines. For interlaced these are up to 3 */
3785   if (h2 != height) {
3786     for (i = h2; i &lt; height; i++) {
3787       UNPACK_FRAME (src, convert-&gt;tmpline[0], i, convert-&gt;in_x, width);
3788       PACK_FRAME (dest, convert-&gt;tmpline[0], i, width);
3789     }
3790   }
3791 }
3792 
3793 static void
3794 convert_UYVY_AYUV_task (FConvertPlaneTask * task)
3795 {
3796   video_orc_convert_UYVY_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
3797       task-&gt;sstride, task-&gt;alpha, (task-&gt;width + 1) / 2, task-&gt;height);
3798 }
3799 
3800 static void
3801 convert_UYVY_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
3802     GstVideoFrame * dest)
3803 {
3804   gint width = convert-&gt;in_width;
3805   gint height = convert-&gt;in_height;
3806   guint8 *s, *d;
3807   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
3808   FConvertPlaneTask *tasks;
3809   FConvertPlaneTask **tasks_p;
3810   gint n_threads;
3811   gint lines_per_thread;
3812   gint i;
3813 
3814   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3815   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3816   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3817   d += (convert-&gt;out_x * 4);
3818 
3819   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3820   tasks = g_newa (FConvertPlaneTask, n_threads);
3821   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3822 
3823   lines_per_thread = (height + n_threads - 1) / n_threads;
3824 
3825   for (i = 0; i &lt; n_threads; i++) {
3826     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3827     tasks[i].sstride = FRAME_GET_STRIDE (src);
3828     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3829     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3830 
3831     tasks[i].width = width;
3832     tasks[i].height = (i + 1) * lines_per_thread;
3833     tasks[i].height = MIN (tasks[i].height, height);
3834     tasks[i].height -= i * lines_per_thread;
3835     tasks[i].alpha = alpha;
3836 
3837     tasks_p[i] = &amp;tasks[i];
3838   }
3839 
3840   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3841       (GstParallelizedTaskFunc) convert_UYVY_AYUV_task, (gpointer) tasks_p);
3842 
3843   convert_fill_border (convert, dest);
3844 }
3845 
3846 static void
3847 convert_UYVY_YUY2_task (FConvertPlaneTask * task)
3848 {
3849   video_orc_convert_UYVY_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
3850       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3851 }
3852 
3853 static void
3854 convert_UYVY_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
3855     GstVideoFrame * dest)
3856 {
3857   gint width = convert-&gt;in_width;
3858   gint height = convert-&gt;in_height;
3859   guint8 *s, *d;
3860   FConvertPlaneTask *tasks;
3861   FConvertPlaneTask **tasks_p;
3862   gint n_threads;
3863   gint lines_per_thread;
3864   gint i;
3865 
3866   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3867   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3868   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
3869   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
3870 
3871   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3872   tasks = g_newa (FConvertPlaneTask, n_threads);
3873   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3874 
3875   lines_per_thread = (height + n_threads - 1) / n_threads;
3876 
3877   for (i = 0; i &lt; n_threads; i++) {
3878     tasks[i].dstride = FRAME_GET_STRIDE (dest);
3879     tasks[i].sstride = FRAME_GET_STRIDE (src);
3880     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
3881     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3882 
3883     tasks[i].width = width;
3884     tasks[i].height = (i + 1) * lines_per_thread;
3885     tasks[i].height = MIN (tasks[i].height, height);
3886     tasks[i].height -= i * lines_per_thread;
3887 
3888     tasks_p[i] = &amp;tasks[i];
3889   }
3890 
3891   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3892       (GstParallelizedTaskFunc) convert_UYVY_YUY2_task, (gpointer) tasks_p);
3893 
3894   convert_fill_border (convert, dest);
3895 }
3896 
3897 static void
3898 convert_UYVY_Y42B_task (FConvertPlaneTask * task)
3899 {
3900   video_orc_convert_UYVY_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
3901       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
3902       task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3903 }
3904 
3905 static void
3906 convert_UYVY_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
3907     GstVideoFrame * dest)
3908 {
3909   gint width = convert-&gt;in_width;
3910   gint height = convert-&gt;in_height;
3911   guint8 *s, *dy, *du, *dv;
3912   FConvertPlaneTask *tasks;
3913   FConvertPlaneTask **tasks_p;
3914   gint n_threads;
3915   gint lines_per_thread;
3916   gint i;
3917 
3918   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3919   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3920 
3921   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3922   dy += convert-&gt;out_x;
3923   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3924   du += convert-&gt;out_x &gt;&gt; 1;
3925   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3926   dv += convert-&gt;out_x &gt;&gt; 1;
3927 
3928   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3929   tasks = g_newa (FConvertPlaneTask, n_threads);
3930   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3931 
3932   lines_per_thread = (height + n_threads - 1) / n_threads;
3933 
3934   for (i = 0; i &lt; n_threads; i++) {
3935     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3936     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
3937     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
3938     tasks[i].sstride = FRAME_GET_STRIDE (src);
3939     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
3940     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
3941     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
3942     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
3943 
3944     tasks[i].width = width;
3945     tasks[i].height = (i + 1) * lines_per_thread;
3946     tasks[i].height = MIN (tasks[i].height, height);
3947     tasks[i].height -= i * lines_per_thread;
3948 
3949     tasks_p[i] = &amp;tasks[i];
3950   }
3951 
3952   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
3953       (GstParallelizedTaskFunc) convert_UYVY_Y42B_task, (gpointer) tasks_p);
3954 
3955   convert_fill_border (convert, dest);
3956 }
3957 
3958 static void
3959 convert_UYVY_Y444_task (FConvertPlaneTask * task)
3960 {
3961   video_orc_convert_UYVY_Y444 (task-&gt;d,
3962       task-&gt;dstride, task-&gt;du,
3963       task-&gt;dustride, task-&gt;dv,
3964       task-&gt;dvstride, task-&gt;s,
3965       task-&gt;sstride, (task-&gt;width + 1) / 2, task-&gt;height);
3966 }
3967 
3968 static void
3969 convert_UYVY_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
3970     GstVideoFrame * dest)
3971 {
3972   gint width = convert-&gt;in_width;
3973   gint height = convert-&gt;in_height;
3974   guint8 *s, *dy, *du, *dv;
3975   FConvertPlaneTask *tasks;
3976   FConvertPlaneTask **tasks_p;
3977   gint n_threads;
3978   gint lines_per_thread;
3979   gint i;
3980 
3981   s = FRAME_GET_LINE (src, convert-&gt;in_y);
3982   s += (GST_ROUND_UP_2 (convert-&gt;in_x) * 2);
3983 
3984   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
3985   dy += convert-&gt;out_x;
3986   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
3987   du += convert-&gt;out_x;
3988   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
3989   dv += convert-&gt;out_x;
3990 
3991   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
3992   tasks = g_newa (FConvertPlaneTask, n_threads);
3993   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
3994 
3995   lines_per_thread = (height + n_threads - 1) / n_threads;
3996 
3997   for (i = 0; i &lt; n_threads; i++) {
3998     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
3999     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4000     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4001     tasks[i].sstride = FRAME_GET_STRIDE (src);
4002     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
4003     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
4004     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
4005     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4006 
4007     tasks[i].width = width;
4008     tasks[i].height = (i + 1) * lines_per_thread;
4009     tasks[i].height = MIN (tasks[i].height, height);
4010     tasks[i].height -= i * lines_per_thread;
4011 
4012     tasks_p[i] = &amp;tasks[i];
4013   }
4014 
4015   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4016       (GstParallelizedTaskFunc) convert_UYVY_Y444_task, (gpointer) tasks_p);
4017 
4018   convert_fill_border (convert, dest);
4019 }
4020 
4021 static void
4022 convert_UYVY_GRAY8_task (FConvertPlaneTask * task)
4023 {
4024   video_orc_convert_UYVY_GRAY8 (task-&gt;d, task-&gt;dstride, (guint16 *) task-&gt;s,
4025       task-&gt;sstride, task-&gt;width, task-&gt;height);
4026 }
4027 
4028 static void
4029 convert_UYVY_GRAY8 (GstVideoConverter * convert, const GstVideoFrame * src,
4030     GstVideoFrame * dest)
4031 {
4032   gint width = convert-&gt;in_width;
4033   gint height = convert-&gt;in_height;
4034   guint8 *s;
4035   guint8 *d;
4036   FConvertPlaneTask *tasks;
4037   FConvertPlaneTask **tasks_p;
4038   gint n_threads;
4039   gint lines_per_thread;
4040   gint i;
4041 
4042   s = GST_VIDEO_FRAME_PLANE_DATA (src, 0);
4043   d = GST_VIDEO_FRAME_PLANE_DATA (dest, 0);
4044 
4045   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4046   tasks = g_newa (FConvertPlaneTask, n_threads);
4047   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4048 
4049   lines_per_thread = (height + n_threads - 1) / n_threads;
4050 
4051   for (i = 0; i &lt; n_threads; i++) {
4052     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4053     tasks[i].sstride = FRAME_GET_STRIDE (src);
4054     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4055     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4056 
4057     tasks[i].width = width;
4058     tasks[i].height = (i + 1) * lines_per_thread;
4059     tasks[i].height = MIN (tasks[i].height, height);
4060     tasks[i].height -= i * lines_per_thread;
4061 
4062     tasks_p[i] = &amp;tasks[i];
4063   }
4064 
4065   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4066       (GstParallelizedTaskFunc) convert_UYVY_GRAY8_task, (gpointer) tasks_p);
4067 
4068   convert_fill_border (convert, dest);
4069 }
4070 
4071 static void
4072 convert_AYUV_I420_task (FConvertPlaneTask * task)
4073 {
4074   video_orc_convert_AYUV_I420 (task-&gt;d,
4075       2 * task-&gt;dstride, task-&gt;d2,
4076       2 * task-&gt;dstride, task-&gt;du,
4077       task-&gt;dustride, task-&gt;dv,
4078       task-&gt;dvstride, task-&gt;s,
4079       2 * task-&gt;sstride, task-&gt;s2,
4080       2 * task-&gt;sstride, task-&gt;width / 2, task-&gt;height / 2);
4081 }
4082 
4083 static void
4084 convert_AYUV_I420 (GstVideoConverter * convert, const GstVideoFrame * src,
4085     GstVideoFrame * dest)
4086 {
4087   gint width = convert-&gt;in_width;
4088   gint height = convert-&gt;in_height;
4089   guint8 *s1, *s2, *dy1, *dy2, *du, *dv;
4090   FConvertPlaneTask *tasks;
4091   FConvertPlaneTask **tasks_p;
4092   gint n_threads;
4093   gint lines_per_thread;
4094   gint i;
4095 
4096   s1 = FRAME_GET_LINE (src, convert-&gt;in_y + 0);
4097   s1 += convert-&gt;in_x * 4;
4098   s2 = FRAME_GET_LINE (src, convert-&gt;in_y + 1);
4099   s2 += convert-&gt;in_x * 4;
4100 
4101   dy1 = FRAME_GET_Y_LINE (dest, convert-&gt;out_y + 0);
4102   dy1 += convert-&gt;out_x;
4103   dy2 = FRAME_GET_Y_LINE (dest, convert-&gt;out_y + 1);
4104   dy2 += convert-&gt;out_x;
4105   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y &gt;&gt; 1);
4106   du += convert-&gt;out_x &gt;&gt; 1;
4107   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y &gt;&gt; 1);
4108   dv += convert-&gt;out_x &gt;&gt; 1;
4109 
4110   /* only for even width/height */
4111 
4112   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4113   tasks = g_newa (FConvertPlaneTask, n_threads);
4114   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4115 
4116   lines_per_thread = GST_ROUND_UP_2 ((height + n_threads - 1) / n_threads);
4117 
4118   for (i = 0; i &lt; n_threads; i++) {
4119     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4120     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4121     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4122     tasks[i].sstride = FRAME_GET_STRIDE (src);
4123     tasks[i].d = dy1 + i * lines_per_thread * tasks[i].dstride;
4124     tasks[i].d2 = dy2 + i * lines_per_thread * tasks[i].dstride;
4125     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride / 2;
4126     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride / 2;
4127     tasks[i].s = s1 + i * lines_per_thread * tasks[i].sstride;
4128     tasks[i].s2 = s2 + i * lines_per_thread * tasks[i].sstride;
4129 
4130     tasks[i].width = width;
4131     tasks[i].height = (i + 1) * lines_per_thread;
4132     tasks[i].height = MIN (tasks[i].height, height);
4133     tasks[i].height -= i * lines_per_thread;
4134 
4135     tasks_p[i] = &amp;tasks[i];
4136   }
4137 
4138   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4139       (GstParallelizedTaskFunc) convert_AYUV_I420_task, (gpointer) tasks_p);
4140 
4141   convert_fill_border (convert, dest);
4142 }
4143 
4144 static void
4145 convert_AYUV_YUY2_task (FConvertPlaneTask * task)
4146 {
4147   video_orc_convert_AYUV_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
4148       task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4149 }
4150 
4151 static void
4152 convert_AYUV_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4153     GstVideoFrame * dest)
4154 {
4155   gint width = convert-&gt;in_width;
4156   gint height = convert-&gt;in_height;
4157   guint8 *s, *d;
4158   FConvertPlaneTask *tasks;
4159   FConvertPlaneTask **tasks_p;
4160   gint n_threads;
4161   gint lines_per_thread;
4162   gint i;
4163 
4164   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4165   s += convert-&gt;in_x * 4;
4166   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4167   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4168 
4169   /* only for even width */
4170   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4171   tasks = g_newa (FConvertPlaneTask, n_threads);
4172   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4173 
4174   lines_per_thread = (height + n_threads - 1) / n_threads;
4175 
4176   for (i = 0; i &lt; n_threads; i++) {
4177     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4178     tasks[i].sstride = FRAME_GET_STRIDE (src);
4179     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4180     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4181 
4182     tasks[i].width = width;
4183     tasks[i].height = (i + 1) * lines_per_thread;
4184     tasks[i].height = MIN (tasks[i].height, height);
4185     tasks[i].height -= i * lines_per_thread;
4186 
4187     tasks_p[i] = &amp;tasks[i];
4188   }
4189 
4190   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4191       (GstParallelizedTaskFunc) convert_AYUV_YUY2_task, (gpointer) tasks_p);
4192 
4193   convert_fill_border (convert, dest);
4194 }
4195 
4196 static void
4197 convert_AYUV_UYVY_task (FConvertPlaneTask * task)
4198 {
4199   video_orc_convert_AYUV_UYVY (task-&gt;d, task-&gt;dstride, task-&gt;s,
4200       task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4201 }
4202 
4203 static void
4204 convert_AYUV_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4205     GstVideoFrame * dest)
4206 {
4207   gint width = convert-&gt;in_width;
4208   gint height = convert-&gt;in_height;
4209   guint8 *s, *d;
4210   FConvertPlaneTask *tasks;
4211   FConvertPlaneTask **tasks_p;
4212   gint n_threads;
4213   gint lines_per_thread;
4214   gint i;
4215 
4216   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4217   s += convert-&gt;in_x * 4;
4218   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4219   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4220 
4221   /* only for even width */
4222   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4223   tasks = g_newa (FConvertPlaneTask, n_threads);
4224   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4225 
4226   lines_per_thread = (height + n_threads - 1) / n_threads;
4227 
4228   for (i = 0; i &lt; n_threads; i++) {
4229     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4230     tasks[i].sstride = FRAME_GET_STRIDE (src);
4231     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4232     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4233 
4234     tasks[i].width = width;
4235     tasks[i].height = (i + 1) * lines_per_thread;
4236     tasks[i].height = MIN (tasks[i].height, height);
4237     tasks[i].height -= i * lines_per_thread;
4238 
4239     tasks_p[i] = &amp;tasks[i];
4240   }
4241 
4242   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4243       (GstParallelizedTaskFunc) convert_AYUV_UYVY_task, (gpointer) tasks_p);
4244 
4245   convert_fill_border (convert, dest);
4246 }
4247 
4248 static void
4249 convert_AYUV_Y42B_task (FConvertPlaneTask * task)
4250 {
4251   video_orc_convert_AYUV_Y42B (task-&gt;d, task-&gt;dstride, task-&gt;du,
4252       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
4253       task-&gt;s, task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
4254 }
4255 
4256 static void
4257 convert_AYUV_Y42B (GstVideoConverter * convert, const GstVideoFrame * src,
4258     GstVideoFrame * dest)
4259 {
4260   gint width = convert-&gt;in_width;
4261   gint height = convert-&gt;in_height;
4262   guint8 *s, *dy, *du, *dv;
4263   FConvertPlaneTask *tasks;
4264   FConvertPlaneTask **tasks_p;
4265   gint n_threads;
4266   gint lines_per_thread;
4267   gint i;
4268 
4269   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4270   s += convert-&gt;in_x * 4;
4271 
4272   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
4273   dy += convert-&gt;out_x;
4274   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
4275   du += convert-&gt;out_x &gt;&gt; 1;
4276   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
4277   dv += convert-&gt;out_x &gt;&gt; 1;
4278 
4279   /* only works for even width */
4280   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4281   tasks = g_newa (FConvertPlaneTask, n_threads);
4282   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4283 
4284   lines_per_thread = (height + n_threads - 1) / n_threads;
4285 
4286   for (i = 0; i &lt; n_threads; i++) {
4287     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4288     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4289     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4290     tasks[i].sstride = FRAME_GET_STRIDE (src);
4291     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
4292     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
4293     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
4294     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4295 
4296     tasks[i].width = width;
4297     tasks[i].height = (i + 1) * lines_per_thread;
4298     tasks[i].height = MIN (tasks[i].height, height);
4299     tasks[i].height -= i * lines_per_thread;
4300 
4301     tasks_p[i] = &amp;tasks[i];
4302   }
4303 
4304   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4305       (GstParallelizedTaskFunc) convert_AYUV_Y42B_task, (gpointer) tasks_p);
4306 
4307   convert_fill_border (convert, dest);
4308 }
4309 
4310 static void
4311 convert_AYUV_Y444_task (FConvertPlaneTask * task)
4312 {
4313   video_orc_convert_AYUV_Y444 (task-&gt;d, task-&gt;dstride, task-&gt;du,
4314       task-&gt;dustride, task-&gt;dv, task-&gt;dvstride,
4315       task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height);
4316 }
4317 
4318 static void
4319 convert_AYUV_Y444 (GstVideoConverter * convert, const GstVideoFrame * src,
4320     GstVideoFrame * dest)
4321 {
4322   gint width = convert-&gt;in_width;
4323   gint height = convert-&gt;in_height;
4324   guint8 *s, *dy, *du, *dv;
4325   FConvertPlaneTask *tasks;
4326   FConvertPlaneTask **tasks_p;
4327   gint n_threads;
4328   gint lines_per_thread;
4329   gint i;
4330 
4331   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4332   s += convert-&gt;in_x * 4;
4333 
4334   dy = FRAME_GET_Y_LINE (dest, convert-&gt;out_y);
4335   dy += convert-&gt;out_x;
4336   du = FRAME_GET_U_LINE (dest, convert-&gt;out_y);
4337   du += convert-&gt;out_x;
4338   dv = FRAME_GET_V_LINE (dest, convert-&gt;out_y);
4339   dv += convert-&gt;out_x;
4340 
4341   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4342   tasks = g_newa (FConvertPlaneTask, n_threads);
4343   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4344 
4345   lines_per_thread = (height + n_threads - 1) / n_threads;
4346 
4347   for (i = 0; i &lt; n_threads; i++) {
4348     tasks[i].dstride = FRAME_GET_Y_STRIDE (dest);
4349     tasks[i].dustride = FRAME_GET_U_STRIDE (dest);
4350     tasks[i].dvstride = FRAME_GET_V_STRIDE (dest);
4351     tasks[i].sstride = FRAME_GET_STRIDE (src);
4352     tasks[i].d = dy + i * lines_per_thread * tasks[i].dstride;
4353     tasks[i].du = du + i * lines_per_thread * tasks[i].dustride;
4354     tasks[i].dv = dv + i * lines_per_thread * tasks[i].dvstride;
4355     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4356 
4357     tasks[i].width = width;
4358     tasks[i].height = (i + 1) * lines_per_thread;
4359     tasks[i].height = MIN (tasks[i].height, height);
4360     tasks[i].height -= i * lines_per_thread;
4361 
4362     tasks_p[i] = &amp;tasks[i];
4363   }
4364 
4365   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4366       (GstParallelizedTaskFunc) convert_AYUV_Y444_task, (gpointer) tasks_p);
4367   convert_fill_border (convert, dest);
4368 }
4369 
4370 static void
4371 convert_Y42B_YUY2_task (FConvertPlaneTask * task)
4372 {
4373   video_orc_convert_Y42B_YUY2 (task-&gt;d, task-&gt;dstride,
4374       task-&gt;s, task-&gt;sstride,
4375       task-&gt;su, task-&gt;sustride,
4376       task-&gt;sv, task-&gt;svstride, (task-&gt;width + 1) / 2, task-&gt;height);
4377 }
4378 
4379 static void
4380 convert_Y42B_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4381     GstVideoFrame * dest)
4382 {
4383   gint width = convert-&gt;in_width;
4384   gint height = convert-&gt;in_height;
4385   guint8 *sy, *su, *sv, *d;
4386   FConvertPlaneTask *tasks;
4387   FConvertPlaneTask **tasks_p;
4388   gint n_threads;
4389   gint lines_per_thread;
4390   gint i;
4391 
4392   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4393   sy += convert-&gt;in_x;
4394   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4395   su += convert-&gt;in_x &gt;&gt; 1;
4396   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4397   sv += convert-&gt;in_x &gt;&gt; 1;
4398 
4399   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4400   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4401 
4402   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4403   tasks = g_newa (FConvertPlaneTask, n_threads);
4404   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4405 
4406   lines_per_thread = (height + n_threads - 1) / n_threads;
4407 
4408   for (i = 0; i &lt; n_threads; i++) {
4409     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4410     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4411     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4412     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4413     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4414     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4415     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4416     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4417 
4418     tasks[i].width = width;
4419     tasks[i].height = (i + 1) * lines_per_thread;
4420     tasks[i].height = MIN (tasks[i].height, height);
4421     tasks[i].height -= i * lines_per_thread;
4422 
4423     tasks_p[i] = &amp;tasks[i];
4424   }
4425 
4426   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4427       (GstParallelizedTaskFunc) convert_Y42B_YUY2_task, (gpointer) tasks_p);
4428 
4429   convert_fill_border (convert, dest);
4430 }
4431 
4432 static void
4433 convert_Y42B_UYVY_task (FConvertPlaneTask * task)
4434 {
4435   video_orc_convert_Y42B_UYVY (task-&gt;d, task-&gt;dstride,
4436       task-&gt;s, task-&gt;sstride,
4437       task-&gt;su, task-&gt;sustride,
4438       task-&gt;sv, task-&gt;svstride, (task-&gt;width + 1) / 2, task-&gt;height);
4439 }
4440 
4441 static void
4442 convert_Y42B_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4443     GstVideoFrame * dest)
4444 {
4445   gint width = convert-&gt;in_width;
4446   gint height = convert-&gt;in_height;
4447   guint8 *sy, *su, *sv, *d;
4448   FConvertPlaneTask *tasks;
4449   FConvertPlaneTask **tasks_p;
4450   gint n_threads;
4451   gint lines_per_thread;
4452   gint i;
4453 
4454   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4455   sy += convert-&gt;in_x;
4456   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4457   su += convert-&gt;in_x &gt;&gt; 1;
4458   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4459   sv += convert-&gt;in_x &gt;&gt; 1;
4460 
4461   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4462   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4463 
4464   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4465   tasks = g_newa (FConvertPlaneTask, n_threads);
4466   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4467 
4468   lines_per_thread = (height + n_threads - 1) / n_threads;
4469 
4470   for (i = 0; i &lt; n_threads; i++) {
4471     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4472     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4473     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4474     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4475     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4476     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4477     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4478     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4479 
4480     tasks[i].width = width;
4481     tasks[i].height = (i + 1) * lines_per_thread;
4482     tasks[i].height = MIN (tasks[i].height, height);
4483     tasks[i].height -= i * lines_per_thread;
4484 
4485     tasks_p[i] = &amp;tasks[i];
4486   }
4487 
4488   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4489       (GstParallelizedTaskFunc) convert_Y42B_UYVY_task, (gpointer) tasks_p);
4490 
4491   convert_fill_border (convert, dest);
4492 }
4493 
4494 static void
4495 convert_Y42B_AYUV_task (FConvertPlaneTask * task)
4496 {
4497   video_orc_convert_Y42B_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
4498       task-&gt;sstride,
4499       task-&gt;su,
4500       task-&gt;sustride,
4501       task-&gt;sv, task-&gt;svstride, task-&gt;alpha, task-&gt;width / 2, task-&gt;height);
4502 }
4503 
4504 static void
4505 convert_Y42B_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
4506     GstVideoFrame * dest)
4507 {
4508   gint width = convert-&gt;in_width;
4509   gint height = convert-&gt;in_height;
4510   guint8 *sy, *su, *sv, *d;
4511   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
4512   FConvertPlaneTask *tasks;
4513   FConvertPlaneTask **tasks_p;
4514   gint n_threads;
4515   gint lines_per_thread;
4516   gint i;
4517 
4518   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4519   sy += convert-&gt;in_x;
4520   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4521   su += convert-&gt;in_x &gt;&gt; 1;
4522   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4523   sv += convert-&gt;in_x &gt;&gt; 1;
4524 
4525   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4526   d += convert-&gt;out_x * 4;
4527 
4528   /* only for even width */
4529   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4530   tasks = g_newa (FConvertPlaneTask, n_threads);
4531   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4532 
4533   lines_per_thread = (height + n_threads - 1) / n_threads;
4534 
4535   for (i = 0; i &lt; n_threads; i++) {
4536     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4537     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4538     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4539     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4540     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4541     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4542     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4543     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4544 
4545     tasks[i].width = width;
4546     tasks[i].height = (i + 1) * lines_per_thread;
4547     tasks[i].height = MIN (tasks[i].height, height);
4548     tasks[i].height -= i * lines_per_thread;
4549     tasks[i].alpha = alpha;
4550 
4551     tasks_p[i] = &amp;tasks[i];
4552   }
4553 
4554   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4555       (GstParallelizedTaskFunc) convert_Y42B_AYUV_task, (gpointer) tasks_p);
4556 
4557   convert_fill_border (convert, dest);
4558 }
4559 
4560 static void
4561 convert_Y444_YUY2_task (FConvertPlaneTask * task)
4562 {
4563   video_orc_convert_Y444_YUY2 (task-&gt;d, task-&gt;dstride, task-&gt;s,
4564       task-&gt;sstride,
4565       task-&gt;su,
4566       task-&gt;sustride, task-&gt;sv, task-&gt;svstride, task-&gt;width / 2, task-&gt;height);
4567 }
4568 
4569 static void
4570 convert_Y444_YUY2 (GstVideoConverter * convert, const GstVideoFrame * src,
4571     GstVideoFrame * dest)
4572 {
4573   gint width = convert-&gt;in_width;
4574   gint height = convert-&gt;in_height;
4575   guint8 *sy, *su, *sv, *d;
4576   FConvertPlaneTask *tasks;
4577   FConvertPlaneTask **tasks_p;
4578   gint n_threads;
4579   gint lines_per_thread;
4580   gint i;
4581 
4582   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4583   sy += convert-&gt;in_x;
4584   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4585   su += convert-&gt;in_x;
4586   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4587   sv += convert-&gt;in_x;
4588 
4589   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4590   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4591 
4592   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4593   tasks = g_newa (FConvertPlaneTask, n_threads);
4594   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4595 
4596   lines_per_thread = (height + n_threads - 1) / n_threads;
4597 
4598   for (i = 0; i &lt; n_threads; i++) {
4599     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4600     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4601     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4602     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4603     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4604     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4605     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4606     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4607 
4608     tasks[i].width = width;
4609     tasks[i].height = (i + 1) * lines_per_thread;
4610     tasks[i].height = MIN (tasks[i].height, height);
4611     tasks[i].height -= i * lines_per_thread;
4612 
4613     tasks_p[i] = &amp;tasks[i];
4614   }
4615 
4616   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4617       (GstParallelizedTaskFunc) convert_Y444_YUY2_task, (gpointer) tasks_p);
4618 
4619   convert_fill_border (convert, dest);
4620 }
4621 
4622 static void
4623 convert_Y444_UYVY_task (FConvertPlaneTask * task)
4624 {
4625   video_orc_convert_Y444_UYVY (task-&gt;d, task-&gt;dstride, task-&gt;s,
4626       task-&gt;sstride,
4627       task-&gt;su,
4628       task-&gt;sustride, task-&gt;sv, task-&gt;svstride, task-&gt;width / 2, task-&gt;height);
4629 }
4630 
4631 static void
4632 convert_Y444_UYVY (GstVideoConverter * convert, const GstVideoFrame * src,
4633     GstVideoFrame * dest)
4634 {
4635   gint width = convert-&gt;in_width;
4636   gint height = convert-&gt;in_height;
4637   guint8 *sy, *su, *sv, *d;
4638   FConvertPlaneTask *tasks;
4639   FConvertPlaneTask **tasks_p;
4640   gint n_threads;
4641   gint lines_per_thread;
4642   gint i;
4643 
4644   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4645   sy += convert-&gt;in_x;
4646   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4647   su += convert-&gt;in_x;
4648   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4649   sv += convert-&gt;in_x;
4650 
4651   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4652   d += (GST_ROUND_UP_2 (convert-&gt;out_x) * 2);
4653 
4654   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4655   tasks = g_newa (FConvertPlaneTask, n_threads);
4656   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4657 
4658   lines_per_thread = (height + n_threads - 1) / n_threads;
4659 
4660   for (i = 0; i &lt; n_threads; i++) {
4661     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4662     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4663     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4664     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4665     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4666     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4667     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4668     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4669 
4670     tasks[i].width = width;
4671     tasks[i].height = (i + 1) * lines_per_thread;
4672     tasks[i].height = MIN (tasks[i].height, height);
4673     tasks[i].height -= i * lines_per_thread;
4674 
4675     tasks_p[i] = &amp;tasks[i];
4676   }
4677 
4678   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4679       (GstParallelizedTaskFunc) convert_Y444_UYVY_task, (gpointer) tasks_p);
4680 
4681   convert_fill_border (convert, dest);
4682 }
4683 
4684 static void
4685 convert_Y444_AYUV_task (FConvertPlaneTask * task)
4686 {
4687   video_orc_convert_Y444_AYUV (task-&gt;d, task-&gt;dstride, task-&gt;s,
4688       task-&gt;sstride,
4689       task-&gt;su,
4690       task-&gt;sustride,
4691       task-&gt;sv, task-&gt;svstride, task-&gt;alpha, task-&gt;width, task-&gt;height);
4692 }
4693 
4694 static void
4695 convert_Y444_AYUV (GstVideoConverter * convert, const GstVideoFrame * src,
4696     GstVideoFrame * dest)
4697 {
4698   gint width = convert-&gt;in_width;
4699   gint height = convert-&gt;in_height;
4700   guint8 *sy, *su, *sv, *d;
4701   guint8 alpha = MIN (convert-&gt;alpha_value, 255);
4702   FConvertPlaneTask *tasks;
4703   FConvertPlaneTask **tasks_p;
4704   gint n_threads;
4705   gint lines_per_thread;
4706   gint i;
4707 
4708   sy = FRAME_GET_Y_LINE (src, convert-&gt;in_y);
4709   sy += convert-&gt;in_x;
4710   su = FRAME_GET_U_LINE (src, convert-&gt;in_y);
4711   su += convert-&gt;in_x;
4712   sv = FRAME_GET_V_LINE (src, convert-&gt;in_y);
4713   sv += convert-&gt;in_x;
4714 
4715   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4716   d += convert-&gt;out_x * 4;
4717 
4718   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4719   tasks = g_newa (FConvertPlaneTask, n_threads);
4720   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4721 
4722   lines_per_thread = (height + n_threads - 1) / n_threads;
4723 
4724   for (i = 0; i &lt; n_threads; i++) {
4725     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4726     tasks[i].sstride = FRAME_GET_Y_STRIDE (src);
4727     tasks[i].sustride = FRAME_GET_U_STRIDE (src);
4728     tasks[i].svstride = FRAME_GET_V_STRIDE (src);
4729     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4730     tasks[i].s = sy + i * lines_per_thread * tasks[i].sstride;
4731     tasks[i].su = su + i * lines_per_thread * tasks[i].sustride;
4732     tasks[i].sv = sv + i * lines_per_thread * tasks[i].svstride;
4733 
4734     tasks[i].width = width;
4735     tasks[i].height = (i + 1) * lines_per_thread;
4736     tasks[i].height = MIN (tasks[i].height, height);
4737     tasks[i].height -= i * lines_per_thread;
4738     tasks[i].alpha = alpha;
4739 
4740     tasks_p[i] = &amp;tasks[i];
4741   }
4742 
4743   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4744       (GstParallelizedTaskFunc) convert_Y444_AYUV_task, (gpointer) tasks_p);
4745 
4746   convert_fill_border (convert, dest);
4747 }
4748 
4749 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
4750 static void
4751 convert_AYUV_ARGB_task (FConvertPlaneTask * task)
4752 {
4753   video_orc_convert_AYUV_ARGB (task-&gt;d, task-&gt;dstride, task-&gt;s,
4754       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4755       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4756       task-&gt;width, task-&gt;height);
4757 }
4758 
4759 static void
4760 convert_AYUV_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
4761     GstVideoFrame * dest)
4762 {
4763   gint width = convert-&gt;in_width;
4764   gint height = convert-&gt;in_height;
4765   MatrixData *data = &amp;convert-&gt;convert_matrix;
4766   guint8 *s, *d;
4767   FConvertPlaneTask *tasks;
4768   FConvertPlaneTask **tasks_p;
4769   gint n_threads;
4770   gint lines_per_thread;
4771   gint i;
4772 
4773   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4774   s += (convert-&gt;in_x * 4);
4775   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4776   d += (convert-&gt;out_x * 4);
4777 
4778   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4779   tasks = g_newa (FConvertPlaneTask, n_threads);
4780   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4781 
4782   lines_per_thread = (height + n_threads - 1) / n_threads;
4783 
4784   for (i = 0; i &lt; n_threads; i++) {
4785     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4786     tasks[i].sstride = FRAME_GET_STRIDE (src);
4787     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4788     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4789 
4790     tasks[i].width = width;
4791     tasks[i].height = (i + 1) * lines_per_thread;
4792     tasks[i].height = MIN (tasks[i].height, height);
4793     tasks[i].height -= i * lines_per_thread;
4794     tasks[i].data = data;
4795 
4796     tasks_p[i] = &amp;tasks[i];
4797   }
4798 
4799   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4800       (GstParallelizedTaskFunc) convert_AYUV_ARGB_task, (gpointer) tasks_p);
4801 
4802   convert_fill_border (convert, dest);
4803 }
4804 
4805 static void
4806 convert_AYUV_BGRA_task (FConvertPlaneTask * task)
4807 {
4808   video_orc_convert_AYUV_BGRA (task-&gt;d, task-&gt;dstride, task-&gt;s,
4809       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4810       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4811       task-&gt;width, task-&gt;height);
4812 }
4813 
4814 static void
4815 convert_AYUV_BGRA (GstVideoConverter * convert, const GstVideoFrame * src,
4816     GstVideoFrame * dest)
4817 {
4818   gint width = convert-&gt;in_width;
4819   gint height = convert-&gt;in_height;
4820   MatrixData *data = &amp;convert-&gt;convert_matrix;
4821   guint8 *s, *d;
4822   FConvertPlaneTask *tasks;
4823   FConvertPlaneTask **tasks_p;
4824   gint n_threads;
4825   gint lines_per_thread;
4826   gint i;
4827 
4828   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4829   s += (convert-&gt;in_x * 4);
4830   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4831   d += (convert-&gt;out_x * 4);
4832 
4833   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4834   tasks = g_newa (FConvertPlaneTask, n_threads);
4835   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4836 
4837   lines_per_thread = (height + n_threads - 1) / n_threads;
4838 
4839   for (i = 0; i &lt; n_threads; i++) {
4840     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4841     tasks[i].sstride = FRAME_GET_STRIDE (src);
4842     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4843     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4844 
4845     tasks[i].width = width;
4846     tasks[i].height = (i + 1) * lines_per_thread;
4847     tasks[i].height = MIN (tasks[i].height, height);
4848     tasks[i].height -= i * lines_per_thread;
4849     tasks[i].data = data;
4850 
4851     tasks_p[i] = &amp;tasks[i];
4852   }
4853 
4854   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4855       (GstParallelizedTaskFunc) convert_AYUV_BGRA_task, (gpointer) tasks_p);
4856 
4857   convert_fill_border (convert, dest);
4858 }
4859 
4860 static void
4861 convert_AYUV_ABGR_task (FConvertPlaneTask * task)
4862 {
4863   video_orc_convert_AYUV_ABGR (task-&gt;d, task-&gt;dstride, task-&gt;s,
4864       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4865       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4866       task-&gt;width, task-&gt;height);
4867 }
4868 
4869 static void
4870 convert_AYUV_ABGR (GstVideoConverter * convert, const GstVideoFrame * src,
4871     GstVideoFrame * dest)
4872 {
4873   gint width = convert-&gt;in_width;
4874   gint height = convert-&gt;in_height;
4875   MatrixData *data = &amp;convert-&gt;convert_matrix;
4876   guint8 *s, *d;
4877   FConvertPlaneTask *tasks;
4878   FConvertPlaneTask **tasks_p;
4879   gint n_threads;
4880   gint lines_per_thread;
4881   gint i;
4882 
4883   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4884   s += (convert-&gt;in_x * 4);
4885   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4886   d += (convert-&gt;out_x * 4);
4887 
4888   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4889   tasks = g_newa (FConvertPlaneTask, n_threads);
4890   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4891 
4892   lines_per_thread = (height + n_threads - 1) / n_threads;
4893 
4894   for (i = 0; i &lt; n_threads; i++) {
4895     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4896     tasks[i].sstride = FRAME_GET_STRIDE (src);
4897     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4898     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4899 
4900     tasks[i].width = width;
4901     tasks[i].height = (i + 1) * lines_per_thread;
4902     tasks[i].height = MIN (tasks[i].height, height);
4903     tasks[i].height -= i * lines_per_thread;
4904     tasks[i].data = data;
4905 
4906     tasks_p[i] = &amp;tasks[i];
4907   }
4908 
4909   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4910       (GstParallelizedTaskFunc) convert_AYUV_ABGR_task, (gpointer) tasks_p);
4911 
4912   convert_fill_border (convert, dest);
4913 }
4914 
4915 static void
4916 convert_AYUV_RGBA_task (FConvertPlaneTask * task)
4917 {
4918   video_orc_convert_AYUV_RGBA (task-&gt;d, task-&gt;dstride, task-&gt;s,
4919       task-&gt;sstride, task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4920       task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4921       task-&gt;width, task-&gt;height);
4922 }
4923 
4924 static void
4925 convert_AYUV_RGBA (GstVideoConverter * convert, const GstVideoFrame * src,
4926     GstVideoFrame * dest)
4927 {
4928   gint width = convert-&gt;in_width;
4929   gint height = convert-&gt;in_height;
4930   MatrixData *data = &amp;convert-&gt;convert_matrix;
4931   guint8 *s, *d;
4932   FConvertPlaneTask *tasks;
4933   FConvertPlaneTask **tasks_p;
4934   gint n_threads;
4935   gint lines_per_thread;
4936   gint i;
4937 
4938   s = FRAME_GET_LINE (src, convert-&gt;in_y);
4939   s += (convert-&gt;in_x * 4);
4940   d = FRAME_GET_LINE (dest, convert-&gt;out_y);
4941   d += (convert-&gt;out_x * 4);
4942 
4943   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
4944   tasks = g_newa (FConvertPlaneTask, n_threads);
4945   tasks_p = g_newa (FConvertPlaneTask *, n_threads);
4946 
4947   lines_per_thread = (height + n_threads - 1) / n_threads;
4948 
4949   for (i = 0; i &lt; n_threads; i++) {
4950     tasks[i].dstride = FRAME_GET_STRIDE (dest);
4951     tasks[i].sstride = FRAME_GET_STRIDE (src);
4952     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
4953     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
4954 
4955     tasks[i].width = width;
4956     tasks[i].height = (i + 1) * lines_per_thread;
4957     tasks[i].height = MIN (tasks[i].height, height);
4958     tasks[i].height -= i * lines_per_thread;
4959     tasks[i].data = data;
4960 
4961     tasks_p[i] = &amp;tasks[i];
4962   }
4963 
4964   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
4965       (GstParallelizedTaskFunc) convert_AYUV_RGBA_task, (gpointer) tasks_p);
4966 
4967   convert_fill_border (convert, dest);
4968 }
4969 #endif
4970 
4971 static void
4972 convert_I420_BGRA_task (FConvertTask * task)
4973 {
4974   gint i;
4975 
4976   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
4977     guint8 *sy, *su, *sv, *d;
4978 
4979     d = FRAME_GET_LINE (task-&gt;dest, i + task-&gt;out_y);
4980     d += (task-&gt;out_x * 4);
4981     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
4982     sy += task-&gt;in_x;
4983     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
4984     su += (task-&gt;in_x &gt;&gt; 1);
4985     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
4986     sv += (task-&gt;in_x &gt;&gt; 1);
4987 
4988 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
4989     video_orc_convert_I420_BGRA (d, sy, su, sv,
4990         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4991         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4992         task-&gt;width);
4993 #else
4994     video_orc_convert_I420_ARGB (d, sy, su, sv,
4995         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
4996         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
4997         task-&gt;width);
4998 #endif
4999   }
5000 }
5001 
5002 static void
5003 convert_I420_BGRA (GstVideoConverter * convert, const GstVideoFrame * src,
5004     GstVideoFrame * dest)
5005 {
5006   int i;
5007   gint width = convert-&gt;in_width;
5008   gint height = convert-&gt;in_height;
5009   MatrixData *data = &amp;convert-&gt;convert_matrix;
5010   FConvertTask *tasks;
5011   FConvertTask **tasks_p;
5012   gint n_threads;
5013   gint lines_per_thread;
5014 
5015   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5016   tasks = g_newa (FConvertTask, n_threads);
5017   tasks_p = g_newa (FConvertTask *, n_threads);
5018 
5019   lines_per_thread = (height + n_threads - 1) / n_threads;
5020 
5021   for (i = 0; i &lt; n_threads; i++) {
5022     tasks[i].src = src;
5023     tasks[i].dest = dest;
5024 
5025     tasks[i].width = width;
5026     tasks[i].data = data;
5027     tasks[i].in_x = convert-&gt;in_x;
5028     tasks[i].in_y = convert-&gt;in_y;
5029     tasks[i].out_x = convert-&gt;out_x;
5030     tasks[i].out_y = convert-&gt;out_y;
5031 
5032     tasks[i].height_0 = i * lines_per_thread;
5033     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5034     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5035 
5036     tasks_p[i] = &amp;tasks[i];
5037   }
5038 
5039   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5040       (GstParallelizedTaskFunc) convert_I420_BGRA_task, (gpointer) tasks_p);
5041 
5042   convert_fill_border (convert, dest);
5043 }
5044 
5045 static void
5046 convert_I420_ARGB_task (FConvertTask * task)
5047 {
5048   gint i;
5049 
5050   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
5051     guint8 *sy, *su, *sv, *d;
5052 
5053     d = FRAME_GET_LINE (task-&gt;dest, i + task-&gt;out_y);
5054     d += (task-&gt;out_x * 4);
5055     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
5056     sy += task-&gt;in_x;
5057     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5058     su += (task-&gt;in_x &gt;&gt; 1);
5059     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5060     sv += (task-&gt;in_x &gt;&gt; 1);
5061 
5062 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5063     video_orc_convert_I420_ARGB (d, sy, su, sv,
5064         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5065         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5066         task-&gt;width);
5067 #else
5068     video_orc_convert_I420_BGRA (d, sy, su, sv,
5069         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5070         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5071         task-&gt;width);
5072 #endif
5073   }
5074 }
5075 
5076 static void
5077 convert_I420_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
5078     GstVideoFrame * dest)
5079 {
5080   int i;
5081   gint width = convert-&gt;in_width;
5082   gint height = convert-&gt;in_height;
5083   MatrixData *data = &amp;convert-&gt;convert_matrix;
5084   FConvertTask *tasks;
5085   FConvertTask **tasks_p;
5086   gint n_threads;
5087   gint lines_per_thread;
5088 
5089   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5090   tasks = g_newa (FConvertTask, n_threads);
5091   tasks_p = g_newa (FConvertTask *, n_threads);
5092 
5093   lines_per_thread = (height + n_threads - 1) / n_threads;
5094 
5095   for (i = 0; i &lt; n_threads; i++) {
5096     tasks[i].src = src;
5097     tasks[i].dest = dest;
5098 
5099     tasks[i].width = width;
5100     tasks[i].data = data;
5101     tasks[i].in_x = convert-&gt;in_x;
5102     tasks[i].in_y = convert-&gt;in_y;
5103     tasks[i].out_x = convert-&gt;out_x;
5104     tasks[i].out_y = convert-&gt;out_y;
5105 
5106     tasks[i].height_0 = i * lines_per_thread;
5107     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5108     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5109 
5110     tasks_p[i] = &amp;tasks[i];
5111   }
5112 
5113   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5114       (GstParallelizedTaskFunc) convert_I420_ARGB_task, (gpointer) tasks_p);
5115 
5116   convert_fill_border (convert, dest);
5117 }
5118 
5119 static void
5120 convert_I420_pack_ARGB_task (FConvertTask * task)
5121 {
5122   gint i;
5123   gpointer d[GST_VIDEO_MAX_PLANES];
5124 
5125   d[0] = FRAME_GET_LINE (task-&gt;dest, 0);
5126   d[0] =
5127       (guint8 *) d[0] +
5128       task-&gt;out_x * GST_VIDEO_FORMAT_INFO_PSTRIDE (task-&gt;dest-&gt;info.finfo, 0);
5129 
5130   for (i = task-&gt;height_0; i &lt; task-&gt;height_1; i++) {
5131     guint8 *sy, *su, *sv;
5132 
5133     sy = FRAME_GET_Y_LINE (task-&gt;src, i + task-&gt;in_y);
5134     sy += task-&gt;in_x;
5135     su = FRAME_GET_U_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5136     su += (task-&gt;in_x &gt;&gt; 1);
5137     sv = FRAME_GET_V_LINE (task-&gt;src, (i + task-&gt;in_y) &gt;&gt; 1);
5138     sv += (task-&gt;in_x &gt;&gt; 1);
5139 
5140 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5141     video_orc_convert_I420_ARGB (task-&gt;tmpline, sy, su, sv,
5142         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5143         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5144         task-&gt;width);
5145 #else
5146     video_orc_convert_I420_BGRA (task-&gt;tmpline, sy, su, sv,
5147         task-&gt;data-&gt;im[0][0], task-&gt;data-&gt;im[0][2],
5148         task-&gt;data-&gt;im[2][1], task-&gt;data-&gt;im[1][1], task-&gt;data-&gt;im[1][2],
5149         task-&gt;width);
5150 #endif
5151     task-&gt;dest-&gt;info.finfo-&gt;pack_func (task-&gt;dest-&gt;info.finfo,
5152         (GST_VIDEO_FRAME_IS_INTERLACED (task-&gt;dest) ?
5153             GST_VIDEO_PACK_FLAG_INTERLACED :
5154             GST_VIDEO_PACK_FLAG_NONE),
5155         task-&gt;tmpline, 0, d, task-&gt;dest-&gt;info.stride,
5156         task-&gt;dest-&gt;info.chroma_site, i + task-&gt;out_y, task-&gt;width);
5157   }
5158 }
5159 
5160 static void
5161 convert_I420_pack_ARGB (GstVideoConverter * convert, const GstVideoFrame * src,
5162     GstVideoFrame * dest)
5163 {
5164   int i;
5165   gint width = convert-&gt;in_width;
5166   gint height = convert-&gt;in_height;
5167   MatrixData *data = &amp;convert-&gt;convert_matrix;
5168   FConvertTask *tasks;
5169   FConvertTask **tasks_p;
5170   gint n_threads;
5171   gint lines_per_thread;
5172 
5173   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5174   tasks = g_newa (FConvertTask, n_threads);
5175   tasks_p = g_newa (FConvertTask *, n_threads);
5176 
5177   lines_per_thread = (height + n_threads - 1) / n_threads;
5178 
5179   for (i = 0; i &lt; n_threads; i++) {
5180     tasks[i].src = src;
5181     tasks[i].dest = dest;
5182 
5183     tasks[i].width = width;
5184     tasks[i].data = data;
5185     tasks[i].in_x = convert-&gt;in_x;
5186     tasks[i].in_y = convert-&gt;in_y;
5187     tasks[i].out_x = convert-&gt;out_x;
5188     tasks[i].out_y = convert-&gt;out_y;
5189     tasks[i].tmpline = convert-&gt;tmpline[i];
5190 
5191     tasks[i].height_0 = i * lines_per_thread;
5192     tasks[i].height_1 = tasks[i].height_0 + lines_per_thread;
5193     tasks[i].height_1 = MIN (height, tasks[i].height_1);
5194 
5195     tasks_p[i] = &amp;tasks[i];
5196   }
5197 
5198   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5199       (GstParallelizedTaskFunc) convert_I420_pack_ARGB_task,
5200       (gpointer) tasks_p);
5201 
5202   convert_fill_border (convert, dest);
5203 }
5204 
5205 static void
5206 memset_u24 (guint8 * data, guint8 col[3], unsigned int n)
5207 {
5208   unsigned int i;
5209 
5210   for (i = 0; i &lt; n; i++) {
5211     data[0] = col[0];
5212     data[1] = col[1];
5213     data[2] = col[2];
5214     data += 3;
5215   }
5216 }
5217 
5218 static void
5219 memset_u32_16 (guint8 * data, guint8 col[4], unsigned int n)
5220 {
5221   unsigned int i;
5222 
5223   for (i = 0; i &lt; n; i += 2) {
5224     data[0] = col[0];
5225     data[1] = col[1];
5226     if (i + 1 &lt; n) {
5227       data[2] = col[2];
5228       data[3] = col[3];
5229     }
5230     data += 4;
5231   }
5232 }
5233 
5234 #define MAKE_BORDER_FUNC(func)                                                  \
5235         for (i = 0; i &lt; out_y; i++)                                             \
5236           func (FRAME_GET_PLANE_LINE (dest, k, i), col, out_maxwidth);          \
5237         if (rb_width || lb_width) {                                             \
5238           for (i = 0; i &lt; out_height; i++) {                                    \
5239             guint8 *d = FRAME_GET_PLANE_LINE (dest, k, i + out_y);              \
5240             if (lb_width)                                                       \
5241               func (d, col, lb_width);                                          \
5242             if (rb_width)                                                       \
5243               func (d + (pstride * r_border), col, rb_width);                   \
5244           }                                                                     \
5245         }                                                                       \
5246         for (i = out_y + out_height; i &lt; out_maxheight; i++)                    \
5247           func (FRAME_GET_PLANE_LINE (dest, k, i), col, out_maxwidth);          \
5248 
5249 static void
5250 convert_fill_border (GstVideoConverter * convert, GstVideoFrame * dest)
5251 {
5252   int k, n_planes;
5253   const GstVideoFormatInfo *out_finfo;
5254 
5255   if (!convert-&gt;fill_border || !convert-&gt;borderline)
5256     return;
5257 
5258   out_finfo = convert-&gt;out_info.finfo;
5259 
5260   n_planes = GST_VIDEO_FRAME_N_PLANES (dest);
5261 
5262   for (k = 0; k &lt; n_planes; k++) {
5263     gint i, out_x, out_y, out_width, out_height, pstride, pgroup;
5264     gint r_border, lb_width, rb_width;
5265     gint out_maxwidth, out_maxheight;
5266     gpointer borders;
5267 
5268     out_x = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_x);
5269     out_y = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k, convert-&gt;out_y);
5270     out_width =
5271         GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_width);
5272     out_height =
5273         GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k, convert-&gt;out_height);
5274     out_maxwidth =
5275         GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, k, convert-&gt;out_maxwidth);
5276     out_maxheight =
5277         GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, k,
5278         convert-&gt;out_maxheight);
5279 
5280     pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, k);
5281 
5282     switch (GST_VIDEO_FORMAT_INFO_FORMAT (out_finfo)) {
5283       case GST_VIDEO_FORMAT_YUY2:
5284       case GST_VIDEO_FORMAT_YVYU:
5285       case GST_VIDEO_FORMAT_UYVY:
5286         pgroup = 42;
5287         out_maxwidth = GST_ROUND_UP_2 (out_maxwidth);
5288         break;
5289       default:
5290         pgroup = pstride;
5291         break;
5292     }
5293 
5294     r_border = out_x + out_width;
5295     rb_width = out_maxwidth - r_border;
5296     lb_width = out_x;
5297 
5298     borders = &amp;convert-&gt;borders[k];
5299 
5300     switch (pgroup) {
5301       case 1:
5302       {
5303         guint8 col = ((guint8 *) borders)[0];
5304         MAKE_BORDER_FUNC (memset);
5305         break;
5306       }
5307       case 2:
5308       {
5309         guint16 col = ((guint16 *) borders)[0];
5310         MAKE_BORDER_FUNC (video_orc_splat_u16);
5311         break;
5312       }
5313       case 3:
5314       {
5315         guint8 col[3];
5316         col[0] = ((guint8 *) borders)[0];
5317         col[1] = ((guint8 *) borders)[1];
5318         col[2] = ((guint8 *) borders)[2];
5319         MAKE_BORDER_FUNC (memset_u24);
5320         break;
5321       }
5322       case 4:
5323       {
5324         guint32 col = ((guint32 *) borders)[0];
5325         MAKE_BORDER_FUNC (video_orc_splat_u32);
5326         break;
5327       }
5328       case 8:
5329       {
5330         guint64 col = ((guint64 *) borders)[0];
5331         MAKE_BORDER_FUNC (video_orc_splat_u64);
5332         break;
5333       }
5334       case 42:
5335       {
5336         guint8 col[4];
5337         col[0] = ((guint8 *) borders)[0];
5338         col[2] = ((guint8 *) borders)[2];
5339         col[1] = ((guint8 *) borders)[r_border &amp; 1 ? 3 : 1];
5340         col[3] = ((guint8 *) borders)[r_border &amp; 1 ? 1 : 3];
5341         MAKE_BORDER_FUNC (memset_u32_16);
5342         break;
5343       }
5344       default:
5345         break;
5346     }
5347   }
5348 }
5349 
5350 typedef struct
5351 {
5352   const guint8 *s, *s2;
5353   guint8 *d, *d2;
5354   gint sstride, dstride;
5355   gint width, height;
5356   gint fill;
5357 } FSimpleScaleTask;
5358 
5359 static void
5360 convert_plane_fill_task (FSimpleScaleTask * task)
5361 {
5362   video_orc_memset_2d (task-&gt;d, task-&gt;dstride,
5363       task-&gt;fill, task-&gt;width, task-&gt;height);
5364 }
5365 
5366 static void
5367 convert_plane_fill (GstVideoConverter * convert,
5368     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5369 {
5370   guint8 *d;
5371   FSimpleScaleTask *tasks;
5372   FSimpleScaleTask **tasks_p;
5373   gint n_threads;
5374   gint lines_per_thread;
5375   gint i;
5376 
5377   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5378   d += convert-&gt;fout_x[plane];
5379 
5380   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5381   tasks = g_newa (FSimpleScaleTask, n_threads);
5382   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5383   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5384 
5385   for (i = 0; i &lt; n_threads; i++) {
5386     tasks[i].d = d + i * lines_per_thread * convert-&gt;fout_width[plane];
5387 
5388     tasks[i].fill = convert-&gt;ffill[plane];
5389     tasks[i].width = convert-&gt;fout_width[plane];
5390     tasks[i].height = (i + 1) * lines_per_thread;
5391     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5392     tasks[i].height -= i * lines_per_thread;
5393     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5394 
5395     tasks_p[i] = &amp;tasks[i];
5396   }
5397 
5398   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5399       (GstParallelizedTaskFunc) convert_plane_fill_task, (gpointer) tasks_p);
5400 }
5401 
5402 static void
5403 convert_plane_h_double_task (FSimpleScaleTask * task)
5404 {
5405   video_orc_planar_chroma_422_444 (task-&gt;d,
5406       task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width / 2, task-&gt;height);
5407 }
5408 
5409 static void
5410 convert_plane_h_double (GstVideoConverter * convert,
5411     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5412 {
5413   guint8 *s, *d;
5414   gint splane = convert-&gt;fsplane[plane];
5415   FSimpleScaleTask *tasks;
5416   FSimpleScaleTask **tasks_p;
5417   gint n_threads;
5418   gint lines_per_thread;
5419   gint i;
5420 
5421   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5422   s += convert-&gt;fin_x[splane];
5423   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5424   d += convert-&gt;fout_x[plane];
5425 
5426   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5427   tasks = g_newa (FSimpleScaleTask, n_threads);
5428   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5429   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5430 
5431   for (i = 0; i &lt; n_threads; i++) {
5432     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5433     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5434 
5435     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
5436     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
5437 
5438     tasks[i].width = convert-&gt;fout_width[plane];
5439     tasks[i].height = (i + 1) * lines_per_thread;
5440     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5441     tasks[i].height -= i * lines_per_thread;
5442 
5443     tasks_p[i] = &amp;tasks[i];
5444   }
5445 
5446   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5447       (GstParallelizedTaskFunc) convert_plane_h_double_task,
5448       (gpointer) tasks_p);
5449 }
5450 
5451 static void
5452 convert_plane_h_halve_task (FSimpleScaleTask * task)
5453 {
5454   video_orc_planar_chroma_444_422 (task-&gt;d,
5455       task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height);
5456 }
5457 
5458 static void
5459 convert_plane_h_halve (GstVideoConverter * convert,
5460     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5461 {
5462   guint8 *s, *d;
5463   gint splane = convert-&gt;fsplane[plane];
5464   FSimpleScaleTask *tasks;
5465   FSimpleScaleTask **tasks_p;
5466   gint n_threads;
5467   gint lines_per_thread;
5468   gint i;
5469 
5470   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5471   s += convert-&gt;fin_x[splane];
5472   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5473   d += convert-&gt;fout_x[plane];
5474 
5475   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5476   tasks = g_newa (FSimpleScaleTask, n_threads);
5477   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5478   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5479 
5480   for (i = 0; i &lt; n_threads; i++) {
5481     tasks[i].dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5482     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5483 
5484     tasks[i].d = d + i * lines_per_thread * tasks[i].dstride;
5485     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride;
5486 
5487     tasks[i].width = convert-&gt;fout_width[plane];
5488     tasks[i].height = (i + 1) * lines_per_thread;
5489     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5490     tasks[i].height -= i * lines_per_thread;
5491 
5492     tasks_p[i] = &amp;tasks[i];
5493   }
5494 
5495   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5496       (GstParallelizedTaskFunc) convert_plane_h_halve_task, (gpointer) tasks_p);
5497 }
5498 
5499 static void
5500 convert_plane_v_double_task (FSimpleScaleTask * task)
5501 {
5502   video_orc_planar_chroma_420_422 (task-&gt;d, 2 * task-&gt;dstride, task-&gt;d2,
5503       2 * task-&gt;dstride, task-&gt;s, task-&gt;sstride, task-&gt;width, task-&gt;height / 2);
5504 }
5505 
5506 static void
5507 convert_plane_v_double (GstVideoConverter * convert,
5508     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5509 {
5510   guint8 *s, *d1, *d2;
5511   gint ds, splane = convert-&gt;fsplane[plane];
5512   FSimpleScaleTask *tasks;
5513   FSimpleScaleTask **tasks_p;
5514   gint n_threads;
5515   gint lines_per_thread;
5516   gint i;
5517 
5518   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5519   s += convert-&gt;fin_x[splane];
5520   d1 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5521   d1 += convert-&gt;fout_x[plane];
5522   d2 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane] + 1);
5523   d2 += convert-&gt;fout_x[plane];
5524   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5525 
5526   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5527   tasks = g_newa (FSimpleScaleTask, n_threads);
5528   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5529   lines_per_thread =
5530       GST_ROUND_UP_2 ((convert-&gt;fout_height[plane] + n_threads -
5531           1) / n_threads);
5532 
5533   for (i = 0; i &lt; n_threads; i++) {
5534     tasks[i].d = d1 + i * lines_per_thread * ds;
5535     tasks[i].d2 = d2 + i * lines_per_thread * ds;
5536     tasks[i].dstride = ds;
5537     tasks[i].sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5538     tasks[i].s = s + i * lines_per_thread * tasks[i].sstride / 2;
5539 
5540     tasks[i].width = convert-&gt;fout_width[plane];
5541     tasks[i].height = (i + 1) * lines_per_thread;
5542     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5543     tasks[i].height -= i * lines_per_thread;
5544 
5545     tasks_p[i] = &amp;tasks[i];
5546   }
5547 
5548   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5549       (GstParallelizedTaskFunc) convert_plane_v_double_task,
5550       (gpointer) tasks_p);
5551 }
5552 
5553 static void
5554 convert_plane_v_halve_task (FSimpleScaleTask * task)
5555 {
5556   video_orc_planar_chroma_422_420 (task-&gt;d, task-&gt;dstride, task-&gt;s,
5557       2 * task-&gt;sstride, task-&gt;s2, 2 * task-&gt;sstride, task-&gt;width,
5558       task-&gt;height);
5559 }
5560 
5561 static void
5562 convert_plane_v_halve (GstVideoConverter * convert,
5563     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5564 {
5565   guint8 *s1, *s2, *d;
5566   gint ss, ds, splane = convert-&gt;fsplane[plane];
5567   FSimpleScaleTask *tasks;
5568   FSimpleScaleTask **tasks_p;
5569   gint n_threads;
5570   gint lines_per_thread;
5571   gint i;
5572 
5573   s1 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5574   s1 += convert-&gt;fin_x[splane];
5575   s2 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane] + 1);
5576   s2 += convert-&gt;fin_x[splane];
5577   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5578   d += convert-&gt;fout_x[plane];
5579 
5580   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5581   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5582 
5583   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5584   tasks = g_newa (FSimpleScaleTask, n_threads);
5585   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5586   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5587 
5588   for (i = 0; i &lt; n_threads; i++) {
5589     tasks[i].d = d + i * lines_per_thread * ds;
5590     tasks[i].dstride = ds;
5591     tasks[i].s = s1 + i * lines_per_thread * ss * 2;
5592     tasks[i].s2 = s2 + i * lines_per_thread * ss * 2;
5593     tasks[i].sstride = ss;
5594 
5595     tasks[i].width = convert-&gt;fout_width[plane];
5596     tasks[i].height = (i + 1) * lines_per_thread;
5597     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5598     tasks[i].height -= i * lines_per_thread;
5599 
5600     tasks_p[i] = &amp;tasks[i];
5601   }
5602 
5603   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5604       (GstParallelizedTaskFunc) convert_plane_v_halve_task, (gpointer) tasks_p);
5605 }
5606 
5607 static void
5608 convert_plane_hv_double_task (FSimpleScaleTask * task)
5609 {
5610   video_orc_planar_chroma_420_444 (task-&gt;d, 2 * task-&gt;dstride, task-&gt;d2,
5611       2 * task-&gt;dstride, task-&gt;s, task-&gt;sstride, (task-&gt;width + 1) / 2,
5612       task-&gt;height / 2);
5613 }
5614 
5615 static void
5616 convert_plane_hv_double (GstVideoConverter * convert,
5617     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5618 {
5619   guint8 *s, *d1, *d2;
5620   gint ss, ds, splane = convert-&gt;fsplane[plane];
5621   FSimpleScaleTask *tasks;
5622   FSimpleScaleTask **tasks_p;
5623   gint n_threads;
5624   gint lines_per_thread;
5625   gint i;
5626 
5627   s = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5628   s += convert-&gt;fin_x[splane];
5629   d1 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5630   d1 += convert-&gt;fout_x[plane];
5631   d2 = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane] + 1);
5632   d2 += convert-&gt;fout_x[plane];
5633   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5634   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5635 
5636   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5637   tasks = g_newa (FSimpleScaleTask, n_threads);
5638   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5639   lines_per_thread =
5640       GST_ROUND_UP_2 ((convert-&gt;fout_height[plane] + n_threads -
5641           1) / n_threads);
5642 
5643   for (i = 0; i &lt; n_threads; i++) {
5644     tasks[i].d = d1 + i * lines_per_thread * ds;
5645     tasks[i].d2 = d2 + i * lines_per_thread * ds;
5646     tasks[i].dstride = ds;
5647     tasks[i].sstride = ss;
5648     tasks[i].s = s + i * lines_per_thread * ss / 2;
5649 
5650     tasks[i].width = convert-&gt;fout_width[plane];
5651     tasks[i].height = (i + 1) * lines_per_thread;
5652     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5653     tasks[i].height -= i * lines_per_thread;
5654 
5655     tasks_p[i] = &amp;tasks[i];
5656   }
5657 
5658   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5659       (GstParallelizedTaskFunc) convert_plane_hv_double_task,
5660       (gpointer) tasks_p);
5661 }
5662 
5663 static void
5664 convert_plane_hv_halve_task (FSimpleScaleTask * task)
5665 {
5666   video_orc_planar_chroma_444_420 (task-&gt;d, task-&gt;dstride, task-&gt;s,
5667       2 * task-&gt;sstride, task-&gt;s2, 2 * task-&gt;sstride, task-&gt;width,
5668       task-&gt;height);
5669 }
5670 
5671 static void
5672 convert_plane_hv_halve (GstVideoConverter * convert,
5673     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5674 {
5675   guint8 *s1, *s2, *d;
5676   gint ss, ds, splane = convert-&gt;fsplane[plane];
5677   FSimpleScaleTask *tasks;
5678   FSimpleScaleTask **tasks_p;
5679   gint n_threads;
5680   gint lines_per_thread;
5681   gint i;
5682 
5683   s1 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane]);
5684   s1 += convert-&gt;fin_x[splane];
5685   s2 = FRAME_GET_PLANE_LINE (src, splane, convert-&gt;fin_y[splane] + 1);
5686   s2 += convert-&gt;fin_x[splane];
5687   d = FRAME_GET_PLANE_LINE (dest, plane, convert-&gt;fout_y[plane]);
5688   d += convert-&gt;fout_x[plane];
5689   ss = FRAME_GET_PLANE_STRIDE (src, splane);
5690   ds = FRAME_GET_PLANE_STRIDE (dest, plane);
5691 
5692   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5693   tasks = g_newa (FSimpleScaleTask, n_threads);
5694   tasks_p = g_newa (FSimpleScaleTask *, n_threads);
5695   lines_per_thread = (convert-&gt;fout_height[plane] + n_threads - 1) / n_threads;
5696 
5697   for (i = 0; i &lt; n_threads; i++) {
5698     tasks[i].d = d + i * lines_per_thread * ds;
5699     tasks[i].dstride = ds;
5700     tasks[i].s = s1 + i * lines_per_thread * ss * 2;
5701     tasks[i].s2 = s2 + i * lines_per_thread * ss * 2;
5702     tasks[i].sstride = ss;
5703 
5704     tasks[i].width = convert-&gt;fout_width[plane];
5705     tasks[i].height = (i + 1) * lines_per_thread;
5706     tasks[i].height = MIN (tasks[i].height, convert-&gt;fout_height[plane]);
5707     tasks[i].height -= i * lines_per_thread;
5708 
5709     tasks_p[i] = &amp;tasks[i];
5710   }
5711 
5712   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5713       (GstParallelizedTaskFunc) convert_plane_hv_halve_task,
5714       (gpointer) tasks_p);
5715 }
5716 
5717 typedef struct
5718 {
5719   GstVideoScaler *h_scaler, *v_scaler;
5720   GstVideoFormat format;
5721   const guint8 *s;
5722   guint8 *d;
5723   gint sstride, dstride;
5724   guint x, y, w, h;
5725 } FScaleTask;
5726 
5727 static void
5728 convert_plane_hv_task (FScaleTask * task)
5729 {
5730   gst_video_scaler_2d (task-&gt;h_scaler, task-&gt;v_scaler, task-&gt;format,
5731       (guint8 *) task-&gt;s, task-&gt;sstride,
5732       task-&gt;d, task-&gt;dstride, task-&gt;x, task-&gt;y, task-&gt;w, task-&gt;h);
5733 }
5734 
5735 static void
5736 convert_plane_hv (GstVideoConverter * convert,
5737     const GstVideoFrame * src, GstVideoFrame * dest, gint plane)
5738 {
5739   gint in_x, in_y, out_x, out_y, out_width, out_height;
5740   GstVideoFormat format;
5741   gint splane = convert-&gt;fsplane[plane];
5742   guint8 *s, *d;
5743   gint sstride, dstride;
5744   FScaleTask *tasks;
5745   FScaleTask **tasks_p;
5746   gint i, n_threads, lines_per_thread;
5747 
5748   in_x = convert-&gt;fin_x[splane];
5749   in_y = convert-&gt;fin_y[splane];
5750   out_x = convert-&gt;fout_x[plane];
5751   out_y = convert-&gt;fout_y[plane];
5752   out_width = convert-&gt;fout_width[plane];
5753   out_height = convert-&gt;fout_height[plane];
5754   format = convert-&gt;fformat[plane];
5755 
5756   s = FRAME_GET_PLANE_LINE (src, splane, in_y);
5757   s += in_x;
5758   d = FRAME_GET_PLANE_LINE (dest, plane, out_y);
5759   d += out_x;
5760 
5761   sstride = FRAME_GET_PLANE_STRIDE (src, splane);
5762   dstride = FRAME_GET_PLANE_STRIDE (dest, plane);
5763 
5764   n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5765   tasks = g_newa (FScaleTask, n_threads);
5766   tasks_p = g_newa (FScaleTask *, n_threads);
5767 
5768   lines_per_thread = (out_height + n_threads - 1) / n_threads;
5769 
5770   for (i = 0; i &lt; n_threads; i++) {
5771     tasks[i].h_scaler =
5772         convert-&gt;fh_scaler[plane].scaler ? convert-&gt;
5773         fh_scaler[plane].scaler[i] : NULL;
5774     tasks[i].v_scaler =
5775         convert-&gt;fv_scaler[plane].scaler ? convert-&gt;
5776         fv_scaler[plane].scaler[i] : NULL;
5777     tasks[i].format = format;
5778     tasks[i].s = s;
5779     tasks[i].d = d;
5780     tasks[i].sstride = sstride;
5781     tasks[i].dstride = dstride;
5782 
5783     tasks[i].x = 0;
5784     tasks[i].w = out_width;
5785 
5786     tasks[i].y = i * lines_per_thread;
5787     tasks[i].h = tasks[i].y + lines_per_thread;
5788     tasks[i].h = MIN (out_height, tasks[i].h);
5789 
5790     tasks_p[i] = &amp;tasks[i];
5791   }
5792 
5793   gst_parallelized_task_runner_run (convert-&gt;conversion_runner,
5794       (GstParallelizedTaskFunc) convert_plane_hv_task, (gpointer) tasks_p);
5795 }
5796 
5797 static void
5798 convert_scale_planes (GstVideoConverter * convert,
5799     const GstVideoFrame * src, GstVideoFrame * dest)
5800 {
5801   int i, n_planes;
5802 
5803   n_planes = GST_VIDEO_FRAME_N_PLANES (dest);
5804   for (i = 0; i &lt; n_planes; i++) {
5805     if (convert-&gt;fconvert[i])
5806       convert-&gt;fconvert[i] (convert, src, dest, i);
5807   }
5808   convert_fill_border (convert, dest);
5809 }
5810 
5811 static GstVideoFormat
5812 get_scale_format (GstVideoFormat format, gint plane)
5813 {
5814   GstVideoFormat res = GST_VIDEO_FORMAT_UNKNOWN;
5815 
5816   switch (format) {
5817     case GST_VIDEO_FORMAT_I420:
5818     case GST_VIDEO_FORMAT_YV12:
5819     case GST_VIDEO_FORMAT_Y41B:
5820     case GST_VIDEO_FORMAT_Y42B:
5821     case GST_VIDEO_FORMAT_Y444:
5822     case GST_VIDEO_FORMAT_GRAY8:
5823     case GST_VIDEO_FORMAT_A420:
5824     case GST_VIDEO_FORMAT_YUV9:
5825     case GST_VIDEO_FORMAT_YVU9:
5826     case GST_VIDEO_FORMAT_GBR:
5827     case GST_VIDEO_FORMAT_GBRA:
5828       res = GST_VIDEO_FORMAT_GRAY8;
5829       break;
5830     case GST_VIDEO_FORMAT_GRAY16_BE:
5831     case GST_VIDEO_FORMAT_GRAY16_LE:
5832       res = GST_VIDEO_FORMAT_GRAY16_BE;
5833       break;
5834     case GST_VIDEO_FORMAT_YUY2:
5835     case GST_VIDEO_FORMAT_UYVY:
5836     case GST_VIDEO_FORMAT_VYUY:
5837     case GST_VIDEO_FORMAT_YVYU:
5838     case GST_VIDEO_FORMAT_AYUV:
5839     case GST_VIDEO_FORMAT_VUYA:
5840     case GST_VIDEO_FORMAT_RGBx:
5841     case GST_VIDEO_FORMAT_BGRx:
5842     case GST_VIDEO_FORMAT_xRGB:
5843     case GST_VIDEO_FORMAT_xBGR:
5844     case GST_VIDEO_FORMAT_RGBA:
5845     case GST_VIDEO_FORMAT_BGRA:
5846     case GST_VIDEO_FORMAT_ARGB:
5847     case GST_VIDEO_FORMAT_ABGR:
5848     case GST_VIDEO_FORMAT_RGB:
5849     case GST_VIDEO_FORMAT_BGR:
5850     case GST_VIDEO_FORMAT_v308:
5851     case GST_VIDEO_FORMAT_IYU2:
5852     case GST_VIDEO_FORMAT_ARGB64:
5853     case GST_VIDEO_FORMAT_AYUV64:
5854       res = format;
5855       break;
5856     case GST_VIDEO_FORMAT_RGB15:
5857     case GST_VIDEO_FORMAT_BGR15:
5858     case GST_VIDEO_FORMAT_RGB16:
5859     case GST_VIDEO_FORMAT_BGR16:
5860       res = GST_VIDEO_FORMAT_NV12;
5861       break;
5862     case GST_VIDEO_FORMAT_NV12:
5863     case GST_VIDEO_FORMAT_NV21:
5864     case GST_VIDEO_FORMAT_NV16:
5865     case GST_VIDEO_FORMAT_NV61:
5866     case GST_VIDEO_FORMAT_NV24:
5867       res = plane == 0 ? GST_VIDEO_FORMAT_GRAY8 : GST_VIDEO_FORMAT_NV12;
5868       break;
5869     case GST_VIDEO_FORMAT_UNKNOWN:
5870     case GST_VIDEO_FORMAT_ENCODED:
5871     case GST_VIDEO_FORMAT_v210:
5872     case GST_VIDEO_FORMAT_v216:
5873     case GST_VIDEO_FORMAT_Y210:
5874     case GST_VIDEO_FORMAT_Y410:
5875     case GST_VIDEO_FORMAT_UYVP:
5876     case GST_VIDEO_FORMAT_RGB8P:
5877     case GST_VIDEO_FORMAT_IYU1:
5878     case GST_VIDEO_FORMAT_r210:
5879     case GST_VIDEO_FORMAT_I420_10BE:
5880     case GST_VIDEO_FORMAT_I420_10LE:
5881     case GST_VIDEO_FORMAT_I422_10BE:
5882     case GST_VIDEO_FORMAT_I422_10LE:
5883     case GST_VIDEO_FORMAT_Y444_10BE:
5884     case GST_VIDEO_FORMAT_Y444_10LE:
5885     case GST_VIDEO_FORMAT_I420_12BE:
5886     case GST_VIDEO_FORMAT_I420_12LE:
5887     case GST_VIDEO_FORMAT_I422_12BE:
5888     case GST_VIDEO_FORMAT_I422_12LE:
5889     case GST_VIDEO_FORMAT_Y444_12BE:
5890     case GST_VIDEO_FORMAT_Y444_12LE:
5891     case GST_VIDEO_FORMAT_GBR_10BE:
5892     case GST_VIDEO_FORMAT_GBR_10LE:
5893     case GST_VIDEO_FORMAT_GBRA_10BE:
5894     case GST_VIDEO_FORMAT_GBRA_10LE:
5895     case GST_VIDEO_FORMAT_GBR_12BE:
5896     case GST_VIDEO_FORMAT_GBR_12LE:
5897     case GST_VIDEO_FORMAT_GBRA_12BE:
5898     case GST_VIDEO_FORMAT_GBRA_12LE:
5899     case GST_VIDEO_FORMAT_NV12_64Z32:
5900     case GST_VIDEO_FORMAT_A420_10BE:
5901     case GST_VIDEO_FORMAT_A420_10LE:
5902     case GST_VIDEO_FORMAT_A422_10BE:
5903     case GST_VIDEO_FORMAT_A422_10LE:
5904     case GST_VIDEO_FORMAT_A444_10BE:
5905     case GST_VIDEO_FORMAT_A444_10LE:
5906     case GST_VIDEO_FORMAT_P010_10BE:
5907     case GST_VIDEO_FORMAT_P010_10LE:
5908     case GST_VIDEO_FORMAT_GRAY10_LE32:
5909     case GST_VIDEO_FORMAT_NV12_10LE32:
5910     case GST_VIDEO_FORMAT_NV16_10LE32:
5911     case GST_VIDEO_FORMAT_NV12_10LE40:
5912     case GST_VIDEO_FORMAT_BGR10A2_LE:
5913       res = format;
5914       g_assert_not_reached ();
5915       break;
5916   }
5917   return res;
5918 }
5919 
5920 static gboolean
5921 is_merge_yuv (GstVideoInfo * info)
5922 {
5923   switch (GST_VIDEO_INFO_FORMAT (info)) {
5924     case GST_VIDEO_FORMAT_YUY2:
5925     case GST_VIDEO_FORMAT_YVYU:
5926     case GST_VIDEO_FORMAT_UYVY:
5927     case GST_VIDEO_FORMAT_VYUY:
5928       return TRUE;
5929     default:
5930       return FALSE;
5931   }
5932 }
5933 
5934 static gboolean
5935 setup_scale (GstVideoConverter * convert)
5936 {
5937   int i, n_planes;
5938   gint method, cr_method, in_width, in_height, out_width, out_height;
5939   guint taps;
5940   GstVideoInfo *in_info, *out_info;
5941   const GstVideoFormatInfo *in_finfo, *out_finfo;
5942   GstVideoFormat in_format, out_format;
5943   guint n_threads = convert-&gt;conversion_runner-&gt;n_threads;
5944 
5945   in_info = &amp;convert-&gt;in_info;
5946   out_info = &amp;convert-&gt;out_info;
5947 
5948   in_finfo = in_info-&gt;finfo;
5949   out_finfo = out_info-&gt;finfo;
5950 
5951   n_planes = GST_VIDEO_INFO_N_PLANES (out_info);
5952 
5953   method = GET_OPT_RESAMPLER_METHOD (convert);
5954   if (method == GST_VIDEO_RESAMPLER_METHOD_NEAREST)
5955     cr_method = method;
5956   else
5957     cr_method = GET_OPT_CHROMA_RESAMPLER_METHOD (convert);
5958   taps = GET_OPT_RESAMPLER_TAPS (convert);
5959 
5960   in_format = GST_VIDEO_INFO_FORMAT (in_info);
5961   out_format = GST_VIDEO_INFO_FORMAT (out_info);
5962 
5963   switch (in_format) {
5964     case GST_VIDEO_FORMAT_RGB15:
5965     case GST_VIDEO_FORMAT_RGB16:
5966     case GST_VIDEO_FORMAT_BGR15:
5967     case GST_VIDEO_FORMAT_BGR16:
5968 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
5969     case GST_VIDEO_FORMAT_GRAY16_BE:
5970 #else
5971     case GST_VIDEO_FORMAT_GRAY16_LE:
5972 #endif
5973       if (method != GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
5974         GST_DEBUG (&quot;%s only with nearest resampling&quot;,
5975             gst_video_format_to_string (in_format));
5976         return FALSE;
5977       }
5978       break;
5979     default:
5980       break;
5981   }
5982 
5983   in_width = convert-&gt;in_width;
5984   in_height = convert-&gt;in_height;
5985   out_width = convert-&gt;out_width;
5986   out_height = convert-&gt;out_height;
5987 
5988   if (n_planes == 1 &amp;&amp; !GST_VIDEO_FORMAT_INFO_IS_GRAY (out_finfo)) {
5989     gint pstride;
5990     guint j;
5991 
5992     if (is_merge_yuv (in_info)) {
5993       GstVideoScaler *y_scaler, *uv_scaler;
5994 
5995       if (in_width != out_width) {
5996         convert-&gt;fh_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
5997         for (j = 0; j &lt; n_threads; j++) {
5998           y_scaler =
5999               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
6000               GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, GST_VIDEO_COMP_Y,
6001                   in_width), GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo,
6002                   GST_VIDEO_COMP_Y, out_width), convert-&gt;config);
6003           uv_scaler =
6004               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE,
6005               gst_video_scaler_get_max_taps (y_scaler),
6006               GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, GST_VIDEO_COMP_U,
6007                   in_width), GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo,
6008                   GST_VIDEO_COMP_U, out_width), convert-&gt;config);
6009 
6010           convert-&gt;fh_scaler[0].scaler[j] =
6011               gst_video_scaler_combine_packed_YUV (y_scaler, uv_scaler,
6012               in_format, out_format);
6013 
6014           gst_video_scaler_free (y_scaler);
6015           gst_video_scaler_free (uv_scaler);
6016         }
6017       } else {
6018         convert-&gt;fh_scaler[0].scaler = NULL;
6019       }
6020 
6021       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, GST_VIDEO_COMP_Y);
6022       convert-&gt;fin_x[0] = GST_ROUND_UP_2 (convert-&gt;in_x) * pstride;
6023       convert-&gt;fout_x[0] = GST_ROUND_UP_2 (convert-&gt;out_x) * pstride;
6024 
6025     } else {
6026       if (in_width != out_width &amp;&amp; in_width != 0 &amp;&amp; out_width != 0) {
6027         convert-&gt;fh_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
6028         for (j = 0; j &lt; n_threads; j++) {
6029           convert-&gt;fh_scaler[0].scaler[j] =
6030               gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
6031               in_width, out_width, convert-&gt;config);
6032         }
6033       } else {
6034         convert-&gt;fh_scaler[0].scaler = NULL;
6035       }
6036 
6037       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, GST_VIDEO_COMP_R);
6038       convert-&gt;fin_x[0] = convert-&gt;in_x * pstride;
6039       convert-&gt;fout_x[0] = convert-&gt;out_x * pstride;
6040     }
6041 
6042     if (in_height != out_height &amp;&amp; in_height != 0 &amp;&amp; out_height != 0) {
6043       convert-&gt;fv_scaler[0].scaler = g_new (GstVideoScaler *, n_threads);
6044 
6045       for (j = 0; j &lt; n_threads; j++) {
6046         convert-&gt;fv_scaler[0].scaler[j] =
6047             gst_video_scaler_new (method, GST_VIDEO_SCALER_FLAG_NONE, taps,
6048             in_height, out_height, convert-&gt;config);
6049       }
6050     } else {
6051       convert-&gt;fv_scaler[0].scaler = NULL;
6052     }
6053 
6054     convert-&gt;fin_y[0] = convert-&gt;in_y;
6055     convert-&gt;fout_y[0] = convert-&gt;out_y;
6056     convert-&gt;fout_width[0] = out_width;
6057     convert-&gt;fout_height[0] = out_height;
6058     convert-&gt;fconvert[0] = convert_plane_hv;
6059     convert-&gt;fformat[0] = get_scale_format (in_format, 0);
6060     convert-&gt;fsplane[0] = 0;
6061   } else {
6062     for (i = 0; i &lt; n_planes; i++) {
6063       gint comp, n_comp, j, iw, ih, ow, oh, pstride;
6064       gboolean need_v_scaler, need_h_scaler;
6065       GstStructure *config;
6066       gint resample_method;
6067 
6068       n_comp = GST_VIDEO_FORMAT_INFO_N_COMPONENTS (in_finfo);
6069 
6070       /* find the component in this plane and map it to the plane of
6071        * the source */
6072       comp = -1;
6073       for (j = 0; j &lt; n_comp; j++) {
6074         if (GST_VIDEO_FORMAT_INFO_PLANE (out_finfo, j) == i) {
6075           comp = j;
6076           break;
6077         }
6078       }
6079 
6080       iw = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, i, in_width);
6081       ih = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (in_finfo, i, in_height);
6082       ow = GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, i, out_width);
6083       oh = GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, i, out_height);
6084 
6085       GST_DEBUG (&quot;plane %d: %dx%d -&gt; %dx%d&quot;, i, iw, ih, ow, oh);
6086 
6087       convert-&gt;fout_width[i] = ow;
6088       convert-&gt;fout_height[i] = oh;
6089 
6090       pstride = GST_VIDEO_FORMAT_INFO_PSTRIDE (out_finfo, i);
6091       convert-&gt;fin_x[i] =
6092           GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (in_finfo, i, convert-&gt;in_x);
6093       convert-&gt;fin_x[i] *= pstride;
6094       convert-&gt;fin_y[i] =
6095           GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (in_finfo, i, convert-&gt;in_y);
6096       convert-&gt;fout_x[i] =
6097           GST_VIDEO_FORMAT_INFO_SCALE_WIDTH (out_finfo, i, convert-&gt;out_x);
6098       convert-&gt;fout_x[i] *= pstride;
6099       convert-&gt;fout_y[i] =
6100           GST_VIDEO_FORMAT_INFO_SCALE_HEIGHT (out_finfo, i, convert-&gt;out_y);
6101 
6102       GST_DEBUG (&quot;plane %d: pstride %d&quot;, i, pstride);
6103       GST_DEBUG (&quot;plane %d: in_x %d, in_y %d&quot;, i, convert-&gt;fin_x[i],
6104           convert-&gt;fin_y[i]);
6105       GST_DEBUG (&quot;plane %d: out_x %d, out_y %d&quot;, i, convert-&gt;fout_x[i],
6106           convert-&gt;fout_y[i]);
6107 
6108       if (comp == -1) {
6109         convert-&gt;fconvert[i] = convert_plane_fill;
6110         if (GST_VIDEO_INFO_IS_YUV (out_info)) {
6111           if (i == 3)
6112             convert-&gt;ffill[i] = convert-&gt;alpha_value;
6113           if (i == 0)
6114             convert-&gt;ffill[i] = 0x00;
6115           else
6116             convert-&gt;ffill[i] = 0x80;
6117         } else {
6118           if (i == 3)
6119             convert-&gt;ffill[i] = convert-&gt;alpha_value;
6120           else
6121             convert-&gt;ffill[i] = 0x00;
6122         }
6123         GST_DEBUG (&quot;plane %d fill %02x&quot;, i, convert-&gt;ffill[i]);
6124         continue;
6125       } else {
6126         convert-&gt;fsplane[i] = GST_VIDEO_FORMAT_INFO_PLANE (in_finfo, comp);
6127         GST_DEBUG (&quot;plane %d -&gt; %d (comp %d)&quot;, i, convert-&gt;fsplane[i], comp);
6128       }
6129 
6130       config = gst_structure_copy (convert-&gt;config);
6131 
6132       resample_method = (i == 0 ? method : cr_method);
6133 
6134       need_v_scaler = FALSE;
6135       need_h_scaler = FALSE;
6136       if (iw == ow) {
6137         if (ih == oh) {
6138           convert-&gt;fconvert[i] = convert_plane_hv;
6139           GST_DEBUG (&quot;plane %d: copy&quot;, i);
6140         } else if (ih == 2 * oh &amp;&amp; pstride == 1
6141             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6142           convert-&gt;fconvert[i] = convert_plane_v_halve;
6143           GST_DEBUG (&quot;plane %d: vertical halve&quot;, i);
6144         } else if (2 * ih == oh &amp;&amp; pstride == 1
6145             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6146           convert-&gt;fconvert[i] = convert_plane_v_double;
6147           GST_DEBUG (&quot;plane %d: vertical double&quot;, i);
6148         } else {
6149           convert-&gt;fconvert[i] = convert_plane_hv;
6150           GST_DEBUG (&quot;plane %d: vertical scale&quot;, i);
6151           need_v_scaler = TRUE;
6152         }
6153       } else if (ih == oh) {
6154         if (iw == 2 * ow &amp;&amp; pstride == 1
6155             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6156           convert-&gt;fconvert[i] = convert_plane_h_halve;
6157           GST_DEBUG (&quot;plane %d: horizontal halve&quot;, i);
6158         } else if (2 * iw == ow &amp;&amp; pstride == 1
6159             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6160           convert-&gt;fconvert[i] = convert_plane_h_double;
6161           GST_DEBUG (&quot;plane %d: horizontal double&quot;, i);
6162         } else {
6163           convert-&gt;fconvert[i] = convert_plane_hv;
6164           GST_DEBUG (&quot;plane %d: horizontal scale&quot;, i);
6165           need_h_scaler = TRUE;
6166         }
6167       } else {
6168         if (iw == 2 * ow &amp;&amp; ih == 2 * oh &amp;&amp; pstride == 1
6169             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_LINEAR) {
6170           convert-&gt;fconvert[i] = convert_plane_hv_halve;
6171           GST_DEBUG (&quot;plane %d: horizontal/vertical halve&quot;, i);
6172         } else if (2 * iw == ow &amp;&amp; 2 * ih == oh &amp;&amp; pstride == 1
6173             &amp;&amp; resample_method == GST_VIDEO_RESAMPLER_METHOD_NEAREST) {
6174           convert-&gt;fconvert[i] = convert_plane_hv_double;
6175           GST_DEBUG (&quot;plane %d: horizontal/vertical double&quot;, i);
6176         } else {
6177           convert-&gt;fconvert[i] = convert_plane_hv;
6178           GST_DEBUG (&quot;plane %d: horizontal/vertical scale&quot;, i);
6179           need_v_scaler = TRUE;
6180           need_h_scaler = TRUE;
6181         }
6182       }
6183 
6184       if (need_h_scaler &amp;&amp; iw != 0 &amp;&amp; ow != 0) {
6185         convert-&gt;fh_scaler[i].scaler = g_new (GstVideoScaler *, n_threads);
6186 
6187         for (j = 0; j &lt; n_threads; j++) {
6188           convert-&gt;fh_scaler[i].scaler[j] =
6189               gst_video_scaler_new (resample_method, GST_VIDEO_SCALER_FLAG_NONE,
6190               taps, iw, ow, config);
6191         }
6192       } else {
6193         convert-&gt;fh_scaler[i].scaler = NULL;
6194       }
6195 
6196       if (need_v_scaler &amp;&amp; ih != 0 &amp;&amp; oh != 0) {
6197         convert-&gt;fv_scaler[i].scaler = g_new (GstVideoScaler *, n_threads);
6198 
6199         for (j = 0; j &lt; n_threads; j++) {
6200           convert-&gt;fv_scaler[i].scaler[j] =
6201               gst_video_scaler_new (resample_method, GST_VIDEO_SCALER_FLAG_NONE,
6202               taps, ih, oh, config);
6203         }
6204       } else {
6205         convert-&gt;fv_scaler[i].scaler = NULL;
6206       }
6207 
6208       gst_structure_free (config);
6209       convert-&gt;fformat[i] = get_scale_format (in_format, i);
6210     }
6211   }
6212 
6213   return TRUE;
6214 }
6215 
6216 /* Fast paths */
6217 
6218 typedef struct
6219 {
6220   GstVideoFormat in_format;
6221   GstVideoFormat out_format;
6222   gboolean keeps_interlaced;
6223   gboolean needs_color_matrix;
6224   gboolean keeps_size;
6225   gboolean do_crop;
6226   gboolean do_border;
6227   gboolean alpha_copy;
6228   gboolean alpha_set;
6229   gboolean alpha_mult;
6230   gint width_align, height_align;
6231   void (*convert) (GstVideoConverter * convert, const GstVideoFrame * src,
6232       GstVideoFrame * dest);
6233 } VideoTransform;
6234 
6235 static const VideoTransform transforms[] = {
6236   /* planar -&gt; packed */
6237   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, FALSE,
6238       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_YUY2},
6239   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, FALSE,
6240       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_UYVY},
6241   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, FALSE,
6242       FALSE, FALSE, TRUE, FALSE, 0, 0, convert_I420_AYUV},
6243 
6244   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, FALSE,
6245       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_YUY2},
6246   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, FALSE,
6247       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_I420_UYVY},
6248   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, FALSE,
6249       FALSE, FALSE, TRUE, FALSE, 0, 0, convert_I420_AYUV},
6250 
6251   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6252       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_Y42B_YUY2},
6253   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6254       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_Y42B_UYVY},
6255   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6256       TRUE, FALSE, TRUE, FALSE, 1, 0, convert_Y42B_AYUV},
6257 
6258   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6259       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_Y444_YUY2},
6260   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6261       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_Y444_UYVY},
6262   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6263       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_Y444_AYUV},
6264 
6265   /* packed -&gt; packed */
6266   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, FALSE, TRUE,
6267       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6268   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6269       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_YUY2},      /* alias */
6270   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6271       TRUE, FALSE, TRUE, FALSE, 1, 0, convert_YUY2_AYUV},
6272 
6273   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, FALSE, TRUE,
6274       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6275   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6276       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_YUY2},
6277   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, TRUE, TRUE,
6278       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_UYVY_AYUV},
6279 
6280   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_AYUV, TRUE, FALSE, FALSE, TRUE, TRUE,
6281       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6282   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_YUY2, TRUE, FALSE, TRUE, TRUE,
6283       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_YUY2},
6284   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_UYVY, TRUE, FALSE, TRUE, TRUE,
6285       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_UYVY},
6286 
6287   /* packed -&gt; planar */
6288   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_I420, TRUE, FALSE, TRUE, FALSE,
6289       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_I420},
6290   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_YV12, TRUE, FALSE, TRUE, FALSE,
6291       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_I420},
6292   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6293       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_Y42B},
6294   {GST_VIDEO_FORMAT_YUY2, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6295       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_YUY2_Y444},
6296   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_GRAY8, TRUE, TRUE, TRUE, TRUE,
6297       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_GRAY8},
6298 
6299   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_I420, TRUE, FALSE, TRUE, FALSE,
6300       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_I420},
6301   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_YV12, TRUE, FALSE, TRUE, FALSE,
6302       FALSE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_I420},
6303   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6304       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_Y42B},
6305   {GST_VIDEO_FORMAT_UYVY, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6306       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_UYVY_Y444},
6307 
6308   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_I420, FALSE, FALSE, TRUE, TRUE,
6309       TRUE, FALSE, FALSE, FALSE, 1, 1, convert_AYUV_I420},
6310   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, TRUE, TRUE,
6311       TRUE, FALSE, FALSE, FALSE, 1, 1, convert_AYUV_I420},
6312   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_Y42B, TRUE, FALSE, TRUE, TRUE,
6313       TRUE, FALSE, FALSE, FALSE, 1, 0, convert_AYUV_Y42B},
6314   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_Y444, TRUE, FALSE, TRUE, TRUE,
6315       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_AYUV_Y444},
6316 
6317   /* planar -&gt; planar */
6318   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6319       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6320   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6321       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6322   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6323       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6324   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6325       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6326   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6327       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6328   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6329       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6330   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6331       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6332   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6333       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6334   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6335       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6336 
6337   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6338       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6339   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6340       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6341   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6342       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6343   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6344       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6345   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6346       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6347   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6348       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6349   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6350       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6351   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6352       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6353   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6354       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6355 
6356   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6357       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6358   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6359       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6360   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6361       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6362   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6363       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6364   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6365       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6366   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6367       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6368   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6369       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6370   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6371       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6372   {GST_VIDEO_FORMAT_Y41B, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6373       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6374 
6375   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6376       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6377   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6378       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6379   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6380       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6381   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6382       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6383   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6384       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6385   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6386       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6387   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6388       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6389   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6390       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6391   {GST_VIDEO_FORMAT_Y42B, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6392       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6393 
6394   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6395       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6396   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6397       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6398   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6399       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6400   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6401       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6402   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6403       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6404   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6405       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6406   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6407       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6408   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6409       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6410   {GST_VIDEO_FORMAT_Y444, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6411       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6412 
6413   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6414       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6415   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6416       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6417   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6418       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6419   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6420       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6421   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6422       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6423   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6424       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6425   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6426       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6427   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6428       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6429   {GST_VIDEO_FORMAT_GRAY8, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6430       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6431 
6432   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6433       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6434   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6435       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6436   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6437       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6438   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6439       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6440   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6441       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6442   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6443       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6444   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6445       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6446   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6447       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6448   {GST_VIDEO_FORMAT_A420, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6449       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6450 
6451   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6452       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6453   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6454       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6455   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6456       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6457   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6458       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6459   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6460       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6461   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6462       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6463   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6464       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6465   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6466       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6467   {GST_VIDEO_FORMAT_YUV9, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6468       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6469 
6470   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_I420, FALSE, FALSE, FALSE, TRUE,
6471       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6472   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YV12, FALSE, FALSE, FALSE, TRUE,
6473       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6474   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y41B, FALSE, FALSE, FALSE, TRUE,
6475       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6476   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y42B, FALSE, FALSE, FALSE, TRUE,
6477       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6478   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_Y444, FALSE, FALSE, FALSE, TRUE,
6479       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6480   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_GRAY8, FALSE, FALSE, FALSE, TRUE,
6481       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6482   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_A420, FALSE, FALSE, FALSE, TRUE,
6483       TRUE, FALSE, TRUE, FALSE, 0, 0, convert_scale_planes},
6484   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YUV9, FALSE, FALSE, FALSE, TRUE,
6485       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6486   {GST_VIDEO_FORMAT_YVU9, GST_VIDEO_FORMAT_YVU9, FALSE, FALSE, FALSE, TRUE,
6487       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6488 
6489   /* sempiplanar -&gt; semiplanar */
6490   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6491       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6492   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6493       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6494   {GST_VIDEO_FORMAT_NV12, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6495       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6496 
6497   {GST_VIDEO_FORMAT_NV21, GST_VIDEO_FORMAT_NV21, TRUE, FALSE, FALSE, TRUE,
6498       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6499 
6500   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6501       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6502   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6503       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6504   {GST_VIDEO_FORMAT_NV16, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6505       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6506 
6507   {GST_VIDEO_FORMAT_NV61, GST_VIDEO_FORMAT_NV61, TRUE, FALSE, FALSE, TRUE,
6508       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6509 
6510   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV12, TRUE, FALSE, FALSE, TRUE,
6511       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6512   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV16, TRUE, FALSE, FALSE, TRUE,
6513       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6514   {GST_VIDEO_FORMAT_NV24, GST_VIDEO_FORMAT_NV24, TRUE, FALSE, FALSE, TRUE,
6515       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6516 
6517 #if G_BYTE_ORDER == G_LITTLE_ENDIAN
6518   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_ARGB, TRUE, TRUE, TRUE, TRUE, TRUE,
6519       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_ARGB},
6520   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_BGRA, TRUE, TRUE, TRUE, TRUE, TRUE,
6521       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_BGRA},
6522   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_xRGB, TRUE, TRUE, TRUE, TRUE, TRUE,
6523       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_ARGB},    /* alias */
6524   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_BGRx, TRUE, TRUE, TRUE, TRUE, TRUE,
6525       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_BGRA},    /* alias */
6526   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_ABGR, TRUE, TRUE, TRUE, TRUE, TRUE,
6527       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_ABGR},
6528   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_RGBA, TRUE, TRUE, TRUE, TRUE, TRUE,
6529       TRUE, FALSE, FALSE, 0, 0, convert_AYUV_RGBA},
6530   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_xBGR, TRUE, TRUE, TRUE, TRUE, TRUE,
6531       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_ABGR},    /* alias */
6532   {GST_VIDEO_FORMAT_AYUV, GST_VIDEO_FORMAT_RGBx, TRUE, TRUE, TRUE, TRUE, TRUE,
6533       FALSE, FALSE, FALSE, 0, 0, convert_AYUV_RGBA},    /* alias */
6534 #endif
6535 
6536   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGRA, FALSE, TRUE, TRUE, TRUE,
6537       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6538   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGRx, FALSE, TRUE, TRUE, TRUE,
6539       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6540   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGRA, FALSE, TRUE, TRUE, TRUE,
6541       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6542   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGRx, FALSE, TRUE, TRUE, TRUE,
6543       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_BGRA},
6544 
6545   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_ARGB, FALSE, TRUE, TRUE, TRUE,
6546       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6547   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_xRGB, FALSE, TRUE, TRUE, TRUE,
6548       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6549   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_ARGB, FALSE, TRUE, TRUE, TRUE,
6550       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6551   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_xRGB, FALSE, TRUE, TRUE, TRUE,
6552       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_ARGB},
6553 
6554   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_ABGR, FALSE, TRUE, TRUE, TRUE,
6555       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6556   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_xBGR, FALSE, TRUE, TRUE, TRUE,
6557       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6558   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGBA, FALSE, TRUE, TRUE, TRUE,
6559       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6560   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGBx, FALSE, TRUE, TRUE, TRUE,
6561       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6562   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB, FALSE, TRUE, TRUE, TRUE,
6563       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6564   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR, FALSE, TRUE, TRUE, TRUE,
6565       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6566   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB15, FALSE, TRUE, TRUE, TRUE,
6567       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6568   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR15, FALSE, TRUE, TRUE, TRUE,
6569       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6570   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_RGB16, FALSE, TRUE, TRUE, TRUE,
6571       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6572   {GST_VIDEO_FORMAT_I420, GST_VIDEO_FORMAT_BGR16, FALSE, TRUE, TRUE, TRUE,
6573       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6574 
6575   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_ABGR, FALSE, TRUE, TRUE, TRUE,
6576       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6577   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_xBGR, FALSE, TRUE, TRUE, TRUE,
6578       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6579   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGBA, FALSE, TRUE, TRUE, TRUE,
6580       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6581   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGBx, FALSE, TRUE, TRUE, TRUE,
6582       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6583   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB, FALSE, TRUE, TRUE, TRUE,
6584       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6585   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR, FALSE, TRUE, TRUE, TRUE,
6586       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6587   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB15, FALSE, TRUE, TRUE, TRUE,
6588       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6589   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR15, FALSE, TRUE, TRUE, TRUE,
6590       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6591   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_RGB16, FALSE, TRUE, TRUE, TRUE,
6592       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6593   {GST_VIDEO_FORMAT_YV12, GST_VIDEO_FORMAT_BGR16, FALSE, TRUE, TRUE, TRUE,
6594       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_I420_pack_ARGB},
6595 
6596   /* scalers */
6597   {GST_VIDEO_FORMAT_GBR, GST_VIDEO_FORMAT_GBR, TRUE, FALSE, FALSE, TRUE,
6598       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6599 
6600   {GST_VIDEO_FORMAT_YVYU, GST_VIDEO_FORMAT_YVYU, TRUE, FALSE, FALSE, TRUE,
6601       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6602 
6603   {GST_VIDEO_FORMAT_RGB15, GST_VIDEO_FORMAT_RGB15, TRUE, FALSE, FALSE, TRUE,
6604       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6605   {GST_VIDEO_FORMAT_RGB16, GST_VIDEO_FORMAT_RGB16, TRUE, FALSE, FALSE, TRUE,
6606       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6607   {GST_VIDEO_FORMAT_BGR15, GST_VIDEO_FORMAT_BGR15, TRUE, FALSE, FALSE, TRUE,
6608       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6609   {GST_VIDEO_FORMAT_BGR16, GST_VIDEO_FORMAT_BGR16, TRUE, FALSE, FALSE, TRUE,
6610       TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6611 
6612   {GST_VIDEO_FORMAT_RGB, GST_VIDEO_FORMAT_RGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6613       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6614   {GST_VIDEO_FORMAT_BGR, GST_VIDEO_FORMAT_BGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6615       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6616   {GST_VIDEO_FORMAT_v308, GST_VIDEO_FORMAT_v308, TRUE, FALSE, FALSE, TRUE, TRUE,
6617       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6618   {GST_VIDEO_FORMAT_IYU2, GST_VIDEO_FORMAT_IYU2, TRUE, FALSE, FALSE, TRUE, TRUE,
6619       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6620 
6621   {GST_VIDEO_FORMAT_ARGB, GST_VIDEO_FORMAT_ARGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6622       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6623   {GST_VIDEO_FORMAT_xRGB, GST_VIDEO_FORMAT_xRGB, TRUE, FALSE, FALSE, TRUE, TRUE,
6624       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6625   {GST_VIDEO_FORMAT_ABGR, GST_VIDEO_FORMAT_ABGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6626       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6627   {GST_VIDEO_FORMAT_xBGR, GST_VIDEO_FORMAT_xBGR, TRUE, FALSE, FALSE, TRUE, TRUE,
6628       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6629   {GST_VIDEO_FORMAT_RGBA, GST_VIDEO_FORMAT_RGBA, TRUE, FALSE, FALSE, TRUE, TRUE,
6630       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6631   {GST_VIDEO_FORMAT_RGBx, GST_VIDEO_FORMAT_RGBx, TRUE, FALSE, FALSE, TRUE, TRUE,
6632       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6633   {GST_VIDEO_FORMAT_BGRA, GST_VIDEO_FORMAT_BGRA, TRUE, FALSE, FALSE, TRUE, TRUE,
6634       TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6635   {GST_VIDEO_FORMAT_BGRx, GST_VIDEO_FORMAT_BGRx, TRUE, FALSE, FALSE, TRUE, TRUE,
6636       FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6637 
6638   {GST_VIDEO_FORMAT_ARGB64, GST_VIDEO_FORMAT_ARGB64, TRUE, FALSE, FALSE, TRUE,
6639       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6640   {GST_VIDEO_FORMAT_AYUV64, GST_VIDEO_FORMAT_AYUV64, TRUE, FALSE, FALSE, TRUE,
6641       TRUE, TRUE, FALSE, FALSE, 0, 0, convert_scale_planes},
6642 
6643   {GST_VIDEO_FORMAT_GRAY16_LE, GST_VIDEO_FORMAT_GRAY16_LE, TRUE, FALSE, FALSE,
6644       TRUE, TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6645   {GST_VIDEO_FORMAT_GRAY16_BE, GST_VIDEO_FORMAT_GRAY16_BE, TRUE, FALSE, FALSE,
6646       TRUE, TRUE, FALSE, FALSE, FALSE, 0, 0, convert_scale_planes},
6647 };
6648 
6649 static gboolean
6650 video_converter_lookup_fastpath (GstVideoConverter * convert)
6651 {
6652   int i;
6653   GstVideoFormat in_format, out_format;
6654   GstVideoTransferFunction in_transf, out_transf;
6655   gboolean interlaced, same_matrix, same_primaries, same_size, crop, border;
6656   gboolean need_copy, need_set, need_mult;
6657   gint width, height;
6658 
6659   width = GST_VIDEO_INFO_WIDTH (&amp;convert-&gt;in_info);
6660   height = GST_VIDEO_INFO_HEIGHT (&amp;convert-&gt;in_info);
6661 
6662   if (GET_OPT_DITHER_QUANTIZATION (convert) != 1)
6663     return FALSE;
6664 
6665   /* we don&#39;t do gamma conversion in fastpath */
6666   in_transf = convert-&gt;in_info.colorimetry.transfer;
6667   out_transf = convert-&gt;out_info.colorimetry.transfer;
6668 
6669   same_size = (width == convert-&gt;out_width &amp;&amp; height == convert-&gt;out_height);
6670 
6671   /* fastpaths don&#39;t do gamma */
6672   if (CHECK_GAMMA_REMAP (convert) &amp;&amp; (!same_size || in_transf != out_transf))
6673     return FALSE;
6674 
6675   need_copy = (convert-&gt;alpha_mode &amp; ALPHA_MODE_COPY) == ALPHA_MODE_COPY;
6676   need_set = (convert-&gt;alpha_mode &amp; ALPHA_MODE_SET) == ALPHA_MODE_SET;
6677   need_mult = (convert-&gt;alpha_mode &amp; ALPHA_MODE_MULT) == ALPHA_MODE_MULT;
6678   GST_DEBUG (&quot;alpha copy %d, set %d, mult %d&quot;, need_copy, need_set, need_mult);
6679 
6680   in_format = GST_VIDEO_INFO_FORMAT (&amp;convert-&gt;in_info);
6681   out_format = GST_VIDEO_INFO_FORMAT (&amp;convert-&gt;out_info);
6682 
6683   if (CHECK_MATRIX_NONE (convert)) {
6684     same_matrix = TRUE;
6685   } else {
6686     GstVideoColorMatrix in_matrix, out_matrix;
6687 
6688     in_matrix = convert-&gt;in_info.colorimetry.matrix;
6689     out_matrix = convert-&gt;out_info.colorimetry.matrix;
6690     same_matrix = in_matrix == out_matrix;
6691   }
6692 
6693   if (CHECK_PRIMARIES_NONE (convert)) {
6694     same_primaries = TRUE;
6695   } else {
6696     GstVideoColorPrimaries in_primaries, out_primaries;
6697 
6698     in_primaries = convert-&gt;in_info.colorimetry.primaries;
6699     out_primaries = convert-&gt;out_info.colorimetry.primaries;
6700     same_primaries = in_primaries == out_primaries;
6701   }
6702 
6703   interlaced = GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;in_info);
6704   interlaced |= GST_VIDEO_INFO_IS_INTERLACED (&amp;convert-&gt;out_info);
6705 
6706   crop = convert-&gt;in_x || convert-&gt;in_y
6707       || convert-&gt;in_width &lt; convert-&gt;in_maxwidth
6708       || convert-&gt;in_height &lt; convert-&gt;in_maxheight;
6709   border = convert-&gt;out_x || convert-&gt;out_y
6710       || convert-&gt;out_width &lt; convert-&gt;out_maxwidth
6711       || convert-&gt;out_height &lt; convert-&gt;out_maxheight;
6712 
6713   for (i = 0; i &lt; sizeof (transforms) / sizeof (transforms[0]); i++) {
6714     if (transforms[i].in_format == in_format &amp;&amp;
6715         transforms[i].out_format == out_format &amp;&amp;
6716         (transforms[i].keeps_interlaced || !interlaced) &amp;&amp;
6717         (transforms[i].needs_color_matrix || (same_matrix &amp;&amp; same_primaries))
6718         &amp;&amp; (!transforms[i].keeps_size || same_size)
6719         &amp;&amp; (transforms[i].width_align &amp; width) == 0
6720         &amp;&amp; (transforms[i].height_align &amp; height) == 0
6721         &amp;&amp; (transforms[i].do_crop || !crop)
6722         &amp;&amp; (transforms[i].do_border || !border)
6723         &amp;&amp; (transforms[i].alpha_copy || !need_copy)
6724         &amp;&amp; (transforms[i].alpha_set || !need_set)
6725         &amp;&amp; (transforms[i].alpha_mult || !need_mult)) {
6726       guint j;
6727 
6728       GST_DEBUG (&quot;using fastpath&quot;);
6729       if (transforms[i].needs_color_matrix)
6730         video_converter_compute_matrix (convert);
6731       convert-&gt;convert = transforms[i].convert;
6732 
6733       convert-&gt;tmpline =
6734           g_new (guint16 *, convert-&gt;conversion_runner-&gt;n_threads);
6735       for (j = 0; j &lt; convert-&gt;conversion_runner-&gt;n_threads; j++)
6736         convert-&gt;tmpline[j] = g_malloc0 (sizeof (guint16) * (width + 8) * 4);
6737 
6738       if (!transforms[i].keeps_size)
6739         if (!setup_scale (convert))
6740           return FALSE;
6741       if (border)
6742         setup_borderline (convert);
6743       return TRUE;
6744     }
6745   }
6746   GST_DEBUG (&quot;no fastpath found&quot;);
6747   return FALSE;
6748 }
6749 #endif // GSTREAMER_LITE
    </pre>
  </body>
</html>