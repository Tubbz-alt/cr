<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideoencoder.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /* GStreamer
   2  * Copyright (C) 2008 David Schleef &lt;ds@schleef.org&gt;
   3  * Copyright (C) 2011 Mark Nauwelaerts &lt;mark.nauwelaerts@collabora.co.uk&gt;.
   4  * Copyright (C) 2011 Nokia Corporation. All rights reserved.
   5  *   Contact: Stefan Kost &lt;stefan.kost@nokia.com&gt;
   6  * Copyright (C) 2012 Collabora Ltd.
   7  *  Author : Edward Hervey &lt;edward@collabora.com&gt;
   8  *
   9  * This library is free software; you can redistribute it and/or
  10  * modify it under the terms of the GNU Library General Public
  11  * License as published by the Free Software Foundation; either
  12  * version 2 of the License, or (at your option) any later version.
  13  *
  14  * This library is distributed in the hope that it will be useful,
  15  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  16  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  17  * Library General Public License for more details.
  18  *
  19  * You should have received a copy of the GNU Library General Public
  20  * License along with this library; if not, write to the
  21  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
  22  * Boston, MA 02110-1301, USA.
  23  */
  24 
  25 /**
  26  * SECTION:gstvideoencoder
  27  * @title: GstVideoEncoder
  28  * @short_description: Base class for video encoders
  29  * @see_also:
  30  *
  31  * This base class is for video encoders turning raw video into
  32  * encoded video data.
  33  *
  34  * GstVideoEncoder and subclass should cooperate as follows.
  35  *
  36  * ## Configuration
  37  *
  38  *   * Initially, GstVideoEncoder calls @start when the encoder element
  39  *     is activated, which allows subclass to perform any global setup.
  40  *   * GstVideoEncoder calls @set_format to inform subclass of the format
  41  *     of input video data that it is about to receive.  Subclass should
  42  *     setup for encoding and configure base class as appropriate
  43  *     (e.g. latency). While unlikely, it might be called more than once,
  44  *     if changing input parameters require reconfiguration.  Baseclass
  45  *     will ensure that processing of current configuration is finished.
  46  *   * GstVideoEncoder calls @stop at end of all processing.
  47  *
  48  * ## Data processing
  49  *
  50  *     * Base class collects input data and metadata into a frame and hands
  51  *       this to subclass&#39; @handle_frame.
  52  *
  53  *     * If codec processing results in encoded data, subclass should call
  54  *       @gst_video_encoder_finish_frame to have encoded data pushed
  55  *       downstream.
  56  *
  57  *     * If implemented, baseclass calls subclass @pre_push just prior to
  58  *       pushing to allow subclasses to modify some metadata on the buffer.
  59  *       If it returns GST_FLOW_OK, the buffer is pushed downstream.
  60  *
  61  *     * GstVideoEncoderClass will handle both srcpad and sinkpad events.
  62  *       Sink events will be passed to subclass if @event callback has been
  63  *       provided.
  64  *
  65  * ## Shutdown phase
  66  *
  67  *   * GstVideoEncoder class calls @stop to inform the subclass that data
  68  *     parsing will be stopped.
  69  *
  70  * Subclass is responsible for providing pad template caps for
  71  * source and sink pads. The pads need to be named &quot;sink&quot; and &quot;src&quot;. It should
  72  * also be able to provide fixed src pad caps in @getcaps by the time it calls
  73  * @gst_video_encoder_finish_frame.
  74  *
  75  * Things that subclass need to take care of:
  76  *
  77  *   * Provide pad templates
  78  *   * Provide source pad caps before pushing the first buffer
  79  *   * Accept data in @handle_frame and provide encoded results to
  80  *      @gst_video_encoder_finish_frame.
  81  *
  82  *
  83  * The #GstVideoEncoder:qos property will enable the Quality-of-Service
  84  * features of the encoder which gather statistics about the real-time
  85  * performance of the downstream elements. If enabled, subclasses can
  86  * use gst_video_encoder_get_max_encode_time() to check if input frames
  87  * are already late and drop them right away to give a chance to the
  88  * pipeline to catch up.
  89  */
  90 
  91 #ifdef HAVE_CONFIG_H
  92 #include &quot;config.h&quot;
  93 #endif
  94 
  95 /* TODO
  96  *
  97  * * Calculate actual latency based on input/output timestamp/frame_number
  98  *   and if it exceeds the recorded one, save it and emit a GST_MESSAGE_LATENCY
  99  */
 100 
 101 #include &lt;gst/video/video.h&gt;
 102 #include &quot;gstvideoencoder.h&quot;
 103 #include &quot;gstvideoutils.h&quot;
 104 #include &quot;gstvideoutilsprivate.h&quot;
 105 
 106 #include &lt;gst/video/gstvideometa.h&gt;
 107 #include &lt;gst/video/gstvideopool.h&gt;
 108 
 109 #include &lt;string.h&gt;
 110 
 111 GST_DEBUG_CATEGORY (videoencoder_debug);
 112 #define GST_CAT_DEFAULT videoencoder_debug
 113 
<a name="1" id="anc1"></a>



 114 /* properties */
 115 
 116 #define DEFAULT_QOS                 FALSE
 117 
 118 enum
 119 {
 120   PROP_0,
 121   PROP_QOS,
 122   PROP_LAST
 123 };
 124 
 125 struct _GstVideoEncoderPrivate
 126 {
 127   guint64 presentation_frame_number;
 128   int distance_from_sync;
 129 
 130   /* FIXME : (and introduce a context ?) */
 131   gboolean drained;
 132 
 133   gint64 min_latency;
 134   gint64 max_latency;
 135 
 136   GList *current_frame_events;
 137 
 138   GList *headers;
 139   gboolean new_headers;         /* Whether new headers were just set */
 140 
 141   GList *force_key_unit;        /* List of pending forced keyunits */
 142 
 143   guint32 system_frame_number;
 144 
 145   GList *frames;                /* Protected with OBJECT_LOCK */
 146   GstVideoCodecState *input_state;
 147   GstVideoCodecState *output_state;
 148   gboolean output_state_changed;
 149 
 150   gint64 bytes;
 151   gint64 time;
 152 
 153   GstAllocator *allocator;
 154   GstAllocationParams params;
 155 
 156   /* upstream stream tags (global tags are passed through as-is) */
 157   GstTagList *upstream_tags;
 158 
 159   /* subclass tags */
 160   GstTagList *tags;
 161   GstTagMergeMode tags_merge_mode;
 162 
 163   gboolean tags_changed;
 164 
 165   GstClockTime min_pts;
 166   /* adjustment needed on pts, dts, segment start and stop to accomodate
 167    * min_pts */
 168   GstClockTime time_adjustment;
 169 
 170   /* QoS properties */
 171   gint qos_enabled;             /* ATOMIC */
 172   gdouble proportion;           /* OBJECT_LOCK */
 173   GstClockTime earliest_time;   /* OBJECT_LOCK */
 174   GstClockTime qos_frame_duration;      /* OBJECT_LOCK */
 175   /* qos messages: frames dropped/processed */
 176   guint dropped;
 177   guint processed;
 178 };
 179 
 180 typedef struct _ForcedKeyUnitEvent ForcedKeyUnitEvent;
 181 struct _ForcedKeyUnitEvent
 182 {
 183   GstClockTime running_time;
 184   gboolean pending;             /* TRUE if this was requested already */
 185   gboolean all_headers;
 186   guint count;
 187   guint32 frame_id;
 188 };
 189 
 190 static void
 191 forced_key_unit_event_free (ForcedKeyUnitEvent * evt)
 192 {
 193   g_slice_free (ForcedKeyUnitEvent, evt);
 194 }
 195 
 196 static ForcedKeyUnitEvent *
 197 forced_key_unit_event_new (GstClockTime running_time, gboolean all_headers,
 198     guint count)
 199 {
 200   ForcedKeyUnitEvent *evt = g_slice_new0 (ForcedKeyUnitEvent);
 201 
 202   evt-&gt;running_time = running_time;
 203   evt-&gt;all_headers = all_headers;
 204   evt-&gt;count = count;
 205 
 206   return evt;
 207 }
 208 
 209 static GstElementClass *parent_class = NULL;
<a name="2" id="anc2"></a><span class="line-added"> 210 static gint private_offset = 0;</span>
<span class="line-added"> 211 </span>
 212 static void gst_video_encoder_class_init (GstVideoEncoderClass * klass);
 213 static void gst_video_encoder_init (GstVideoEncoder * enc,
 214     GstVideoEncoderClass * klass);
 215 
 216 static void gst_video_encoder_finalize (GObject * object);
 217 
 218 static gboolean gst_video_encoder_setcaps (GstVideoEncoder * enc,
 219     GstCaps * caps);
 220 static GstCaps *gst_video_encoder_sink_getcaps (GstVideoEncoder * encoder,
 221     GstCaps * filter);
 222 static gboolean gst_video_encoder_src_event (GstPad * pad, GstObject * parent,
 223     GstEvent * event);
 224 static gboolean gst_video_encoder_sink_event (GstPad * pad, GstObject * parent,
 225     GstEvent * event);
 226 static GstFlowReturn gst_video_encoder_chain (GstPad * pad, GstObject * parent,
 227     GstBuffer * buf);
 228 static GstStateChangeReturn gst_video_encoder_change_state (GstElement *
 229     element, GstStateChange transition);
 230 static gboolean gst_video_encoder_sink_query (GstPad * pad, GstObject * parent,
 231     GstQuery * query);
 232 static gboolean gst_video_encoder_src_query (GstPad * pad, GstObject * parent,
 233     GstQuery * query);
 234 static GstVideoCodecFrame *gst_video_encoder_new_frame (GstVideoEncoder *
 235     encoder, GstBuffer * buf, GstClockTime pts, GstClockTime dts,
 236     GstClockTime duration);
 237 
 238 static gboolean gst_video_encoder_sink_event_default (GstVideoEncoder * encoder,
 239     GstEvent * event);
 240 static gboolean gst_video_encoder_src_event_default (GstVideoEncoder * encoder,
 241     GstEvent * event);
 242 static gboolean gst_video_encoder_decide_allocation_default (GstVideoEncoder *
 243     encoder, GstQuery * query);
 244 static gboolean gst_video_encoder_propose_allocation_default (GstVideoEncoder *
 245     encoder, GstQuery * query);
 246 static gboolean gst_video_encoder_negotiate_default (GstVideoEncoder * encoder);
 247 static gboolean gst_video_encoder_negotiate_unlocked (GstVideoEncoder *
 248     encoder);
 249 
 250 static gboolean gst_video_encoder_sink_query_default (GstVideoEncoder * encoder,
 251     GstQuery * query);
 252 static gboolean gst_video_encoder_src_query_default (GstVideoEncoder * encoder,
 253     GstQuery * query);
 254 
 255 static gboolean gst_video_encoder_transform_meta_default (GstVideoEncoder *
 256     encoder, GstVideoCodecFrame * frame, GstMeta * meta);
 257 
 258 /* we can&#39;t use G_DEFINE_ABSTRACT_TYPE because we need the klass in the _init
 259  * method to get to the padtemplates */
 260 GType
 261 gst_video_encoder_get_type (void)
 262 {
 263   static volatile gsize type = 0;
 264 
 265   if (g_once_init_enter (&amp;type)) {
 266     GType _type;
 267     static const GTypeInfo info = {
 268       sizeof (GstVideoEncoderClass),
 269       NULL,
 270       NULL,
 271       (GClassInitFunc) gst_video_encoder_class_init,
 272       NULL,
 273       NULL,
 274       sizeof (GstVideoEncoder),
 275       0,
 276       (GInstanceInitFunc) gst_video_encoder_init,
 277     };
 278 #ifndef GSTREAMER_LITE
 279     const GInterfaceInfo preset_interface_info = {
 280       NULL,                     /* interface_init */
 281       NULL,                     /* interface_finalize */
 282       NULL                      /* interface_data */
 283     };
 284 #endif // GSTREAMER_LITE
 285 
 286     _type = g_type_register_static (GST_TYPE_ELEMENT,
 287         &quot;GstVideoEncoder&quot;, &amp;info, G_TYPE_FLAG_ABSTRACT);
<a name="3" id="anc3"></a><span class="line-added"> 288     private_offset =</span>
<span class="line-added"> 289         g_type_add_instance_private (_type, sizeof (GstVideoEncoderPrivate));</span>
 290 #ifndef GSTREAMER_LITE
 291     g_type_add_interface_static (_type, GST_TYPE_PRESET,
 292         &amp;preset_interface_info);
 293 #endif // GSTREAMER_LITE
 294     g_once_init_leave (&amp;type, _type);
 295   }
 296   return type;
 297 }
 298 
<a name="4" id="anc4"></a><span class="line-added"> 299 static inline GstVideoEncoderPrivate *</span>
<span class="line-added"> 300 gst_video_encoder_get_instance_private (GstVideoEncoder * self)</span>
<span class="line-added"> 301 {</span>
<span class="line-added"> 302   return (G_STRUCT_MEMBER_P (self, private_offset));</span>
<span class="line-added"> 303 }</span>
<span class="line-added"> 304 </span>
 305 static void
 306 gst_video_encoder_set_property (GObject * object, guint prop_id,
 307     const GValue * value, GParamSpec * pspec)
 308 {
 309   GstVideoEncoder *sink = GST_VIDEO_ENCODER (object);
 310 
 311   switch (prop_id) {
 312     case PROP_QOS:
 313       gst_video_encoder_set_qos_enabled (sink, g_value_get_boolean (value));
 314       break;
 315     default:
 316       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
 317       break;
 318   }
 319 }
 320 
 321 static void
 322 gst_video_encoder_get_property (GObject * object, guint prop_id, GValue * value,
 323     GParamSpec * pspec)
 324 {
 325   GstVideoEncoder *sink = GST_VIDEO_ENCODER (object);
 326 
 327   switch (prop_id) {
 328     case PROP_QOS:
 329       g_value_set_boolean (value, gst_video_encoder_is_qos_enabled (sink));
 330       break;
 331     default:
 332       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
 333       break;
 334   }
 335 }
 336 
 337 static void
 338 gst_video_encoder_class_init (GstVideoEncoderClass * klass)
 339 {
 340   GObjectClass *gobject_class;
 341   GstElementClass *gstelement_class;
 342 
 343   gobject_class = G_OBJECT_CLASS (klass);
 344   gstelement_class = GST_ELEMENT_CLASS (klass);
 345 
 346   GST_DEBUG_CATEGORY_INIT (videoencoder_debug, &quot;videoencoder&quot;, 0,
 347       &quot;Base Video Encoder&quot;);
 348 
 349   parent_class = g_type_class_peek_parent (klass);
 350 
<a name="5" id="anc5"></a><span class="line-modified"> 351   if (private_offset != 0)</span>
<span class="line-added"> 352     g_type_class_adjust_private_offset (klass, &amp;private_offset);</span>
 353 
 354   gobject_class-&gt;set_property = gst_video_encoder_set_property;
 355   gobject_class-&gt;get_property = gst_video_encoder_get_property;
 356   gobject_class-&gt;finalize = gst_video_encoder_finalize;
 357 
 358   gstelement_class-&gt;change_state =
 359       GST_DEBUG_FUNCPTR (gst_video_encoder_change_state);
 360 
 361   klass-&gt;sink_event = gst_video_encoder_sink_event_default;
 362   klass-&gt;src_event = gst_video_encoder_src_event_default;
 363   klass-&gt;propose_allocation = gst_video_encoder_propose_allocation_default;
 364   klass-&gt;decide_allocation = gst_video_encoder_decide_allocation_default;
 365   klass-&gt;negotiate = gst_video_encoder_negotiate_default;
 366   klass-&gt;sink_query = gst_video_encoder_sink_query_default;
 367   klass-&gt;src_query = gst_video_encoder_src_query_default;
 368   klass-&gt;transform_meta = gst_video_encoder_transform_meta_default;
 369 
 370   g_object_class_install_property (gobject_class, PROP_QOS,
 371       g_param_spec_boolean (&quot;qos&quot;, &quot;Qos&quot;,
 372           &quot;Handle Quality-of-Service events from downstream&quot;, DEFAULT_QOS,
 373           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 374 }
 375 
 376 static GList *
 377 _flush_events (GstPad * pad, GList * events)
 378 {
 379   GList *tmp;
 380 
 381   for (tmp = events; tmp; tmp = tmp-&gt;next) {
 382     if (GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_EOS &amp;&amp;
 383         GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_SEGMENT &amp;&amp;
 384         GST_EVENT_IS_STICKY (tmp-&gt;data)) {
 385       gst_pad_store_sticky_event (pad, GST_EVENT_CAST (tmp-&gt;data));
 386     }
 387     gst_event_unref (tmp-&gt;data);
 388   }
 389   g_list_free (events);
 390 
 391   return NULL;
 392 }
 393 
 394 static gboolean
 395 gst_video_encoder_reset (GstVideoEncoder * encoder, gboolean hard)
 396 {
 397   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
 398   gboolean ret = TRUE;
 399 
 400   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 401 
 402   priv-&gt;presentation_frame_number = 0;
 403   priv-&gt;distance_from_sync = 0;
 404 
 405   g_list_foreach (priv-&gt;force_key_unit, (GFunc) forced_key_unit_event_free,
 406       NULL);
 407   g_list_free (priv-&gt;force_key_unit);
 408   priv-&gt;force_key_unit = NULL;
 409 
 410   priv-&gt;drained = TRUE;
 411 
 412   GST_OBJECT_LOCK (encoder);
 413   priv-&gt;bytes = 0;
 414   priv-&gt;time = 0;
 415   GST_OBJECT_UNLOCK (encoder);
 416 
 417   priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
 418 
 419   if (hard) {
 420     gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
 421     gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
 422 
 423     if (priv-&gt;input_state)
 424       gst_video_codec_state_unref (priv-&gt;input_state);
 425     priv-&gt;input_state = NULL;
 426     if (priv-&gt;output_state)
 427       gst_video_codec_state_unref (priv-&gt;output_state);
 428     priv-&gt;output_state = NULL;
 429 
 430     if (priv-&gt;upstream_tags) {
 431       gst_tag_list_unref (priv-&gt;upstream_tags);
 432       priv-&gt;upstream_tags = NULL;
 433     }
 434     if (priv-&gt;tags)
 435       gst_tag_list_unref (priv-&gt;tags);
 436     priv-&gt;tags = NULL;
 437     priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
 438     priv-&gt;tags_changed = FALSE;
 439 
 440     g_list_foreach (priv-&gt;headers, (GFunc) gst_event_unref, NULL);
 441     g_list_free (priv-&gt;headers);
 442     priv-&gt;headers = NULL;
 443     priv-&gt;new_headers = FALSE;
 444 
 445     if (priv-&gt;allocator) {
 446       gst_object_unref (priv-&gt;allocator);
 447       priv-&gt;allocator = NULL;
 448     }
 449 
 450     g_list_foreach (priv-&gt;current_frame_events, (GFunc) gst_event_unref, NULL);
 451     g_list_free (priv-&gt;current_frame_events);
 452     priv-&gt;current_frame_events = NULL;
 453 
 454     GST_OBJECT_LOCK (encoder);
 455     priv-&gt;proportion = 0.5;
 456     priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
 457     priv-&gt;qos_frame_duration = 0;
 458     GST_OBJECT_UNLOCK (encoder);
 459 
 460     priv-&gt;dropped = 0;
 461     priv-&gt;processed = 0;
 462   } else {
 463     GList *l;
 464 
 465     for (l = priv-&gt;frames; l; l = l-&gt;next) {
 466       GstVideoCodecFrame *frame = l-&gt;data;
 467 
 468       frame-&gt;events = _flush_events (encoder-&gt;srcpad, frame-&gt;events);
 469     }
 470     priv-&gt;current_frame_events = _flush_events (encoder-&gt;srcpad,
 471         encoder-&gt;priv-&gt;current_frame_events);
 472   }
 473 
 474   g_list_foreach (priv-&gt;frames, (GFunc) gst_video_codec_frame_unref, NULL);
 475   g_list_free (priv-&gt;frames);
 476   priv-&gt;frames = NULL;
 477 
 478   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 479 
 480   return ret;
 481 }
 482 
 483 /* Always call reset() in one way or another after this */
 484 static gboolean
 485 gst_video_encoder_flush (GstVideoEncoder * encoder)
 486 {
 487   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 488   gboolean ret = TRUE;
 489 
 490   if (klass-&gt;flush)
 491     ret = klass-&gt;flush (encoder);
 492 
 493   return ret;
 494 }
 495 
 496 static void
 497 gst_video_encoder_init (GstVideoEncoder * encoder, GstVideoEncoderClass * klass)
 498 {
 499   GstVideoEncoderPrivate *priv;
 500   GstPadTemplate *pad_template;
 501   GstPad *pad;
 502 
 503   GST_DEBUG_OBJECT (encoder, &quot;gst_video_encoder_init&quot;);
 504 
<a name="6" id="anc6"></a><span class="line-modified"> 505   priv = encoder-&gt;priv = gst_video_encoder_get_instance_private (encoder);</span>
 506 
 507   pad_template =
 508       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 509   g_return_if_fail (pad_template != NULL);
 510 
 511   encoder-&gt;sinkpad = pad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 512 
 513   gst_pad_set_chain_function (pad, GST_DEBUG_FUNCPTR (gst_video_encoder_chain));
 514   gst_pad_set_event_function (pad,
 515       GST_DEBUG_FUNCPTR (gst_video_encoder_sink_event));
 516   gst_pad_set_query_function (pad,
 517       GST_DEBUG_FUNCPTR (gst_video_encoder_sink_query));
 518   gst_element_add_pad (GST_ELEMENT (encoder), encoder-&gt;sinkpad);
 519 
 520   pad_template =
 521       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 522   g_return_if_fail (pad_template != NULL);
 523 
 524   encoder-&gt;srcpad = pad = gst_pad_new_from_template (pad_template, &quot;src&quot;);
 525 
 526   gst_pad_set_query_function (pad,
 527       GST_DEBUG_FUNCPTR (gst_video_encoder_src_query));
 528   gst_pad_set_event_function (pad,
 529       GST_DEBUG_FUNCPTR (gst_video_encoder_src_event));
 530   gst_element_add_pad (GST_ELEMENT (encoder), encoder-&gt;srcpad);
 531 
 532   gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
 533   gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
 534 
 535   g_rec_mutex_init (&amp;encoder-&gt;stream_lock);
 536 
 537   priv-&gt;headers = NULL;
 538   priv-&gt;new_headers = FALSE;
 539 
 540   priv-&gt;min_latency = 0;
 541   priv-&gt;max_latency = 0;
 542   priv-&gt;min_pts = GST_CLOCK_TIME_NONE;
 543   priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
 544 
 545   gst_video_encoder_reset (encoder, TRUE);
 546 }
 547 
 548 /**
 549  * gst_video_encoder_set_headers:
 550  * @encoder: a #GstVideoEncoder
 551  * @headers: (transfer full) (element-type GstBuffer): a list of #GstBuffer containing the codec header
 552  *
 553  * Set the codec headers to be sent downstream whenever requested.
 554  */
 555 void
 556 gst_video_encoder_set_headers (GstVideoEncoder * video_encoder, GList * headers)
 557 {
 558   GST_VIDEO_ENCODER_STREAM_LOCK (video_encoder);
 559 
 560   GST_DEBUG_OBJECT (video_encoder, &quot;new headers %p&quot;, headers);
 561   if (video_encoder-&gt;priv-&gt;headers) {
 562     g_list_foreach (video_encoder-&gt;priv-&gt;headers, (GFunc) gst_buffer_unref,
 563         NULL);
 564     g_list_free (video_encoder-&gt;priv-&gt;headers);
 565   }
 566   video_encoder-&gt;priv-&gt;headers = headers;
 567   video_encoder-&gt;priv-&gt;new_headers = TRUE;
 568 
 569   GST_VIDEO_ENCODER_STREAM_UNLOCK (video_encoder);
 570 }
 571 
 572 static GstVideoCodecState *
 573 _new_output_state (GstCaps * caps, GstVideoCodecState * reference)
 574 {
 575   GstVideoCodecState *state;
 576 
 577   state = g_slice_new0 (GstVideoCodecState);
 578   state-&gt;ref_count = 1;
 579   gst_video_info_init (&amp;state-&gt;info);
 580 
 581   if (!gst_video_info_set_format (&amp;state-&gt;info, GST_VIDEO_FORMAT_ENCODED, 0, 0)) {
 582     g_slice_free (GstVideoCodecState, state);
 583     return NULL;
 584   }
 585 
 586   state-&gt;caps = caps;
 587 
 588   if (reference) {
 589     GstVideoInfo *tgt, *ref;
 590 
 591     tgt = &amp;state-&gt;info;
 592     ref = &amp;reference-&gt;info;
 593 
 594     /* Copy over extra fields from reference state */
 595     tgt-&gt;interlace_mode = ref-&gt;interlace_mode;
 596     tgt-&gt;flags = ref-&gt;flags;
 597     tgt-&gt;width = ref-&gt;width;
 598     tgt-&gt;height = ref-&gt;height;
 599     tgt-&gt;chroma_site = ref-&gt;chroma_site;
 600     tgt-&gt;colorimetry = ref-&gt;colorimetry;
 601     tgt-&gt;par_n = ref-&gt;par_n;
 602     tgt-&gt;par_d = ref-&gt;par_d;
 603     tgt-&gt;fps_n = ref-&gt;fps_n;
 604     tgt-&gt;fps_d = ref-&gt;fps_d;
 605 
 606     GST_VIDEO_INFO_FIELD_ORDER (tgt) = GST_VIDEO_INFO_FIELD_ORDER (ref);
 607 
 608     GST_VIDEO_INFO_MULTIVIEW_MODE (tgt) = GST_VIDEO_INFO_MULTIVIEW_MODE (ref);
 609     GST_VIDEO_INFO_MULTIVIEW_FLAGS (tgt) = GST_VIDEO_INFO_MULTIVIEW_FLAGS (ref);
 610   }
 611 
 612   return state;
 613 }
 614 
 615 static GstVideoCodecState *
 616 _new_input_state (GstCaps * caps)
 617 {
 618   GstVideoCodecState *state;
 619 
 620   state = g_slice_new0 (GstVideoCodecState);
 621   state-&gt;ref_count = 1;
 622   gst_video_info_init (&amp;state-&gt;info);
 623   if (G_UNLIKELY (!gst_video_info_from_caps (&amp;state-&gt;info, caps)))
 624     goto parse_fail;
 625   state-&gt;caps = gst_caps_ref (caps);
 626 
 627   return state;
 628 
 629 parse_fail:
 630   {
 631     g_slice_free (GstVideoCodecState, state);
 632     return NULL;
 633   }
 634 }
 635 
 636 static gboolean
 637 gst_video_encoder_setcaps (GstVideoEncoder * encoder, GstCaps * caps)
 638 {
 639   GstVideoEncoderClass *encoder_class;
 640   GstVideoCodecState *state;
 641   gboolean ret;
 642 
 643   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 644 
 645   /* subclass should do something here ... */
 646   g_return_val_if_fail (encoder_class-&gt;set_format != NULL, FALSE);
 647 
 648   GST_DEBUG_OBJECT (encoder, &quot;setcaps %&quot; GST_PTR_FORMAT, caps);
 649 
 650   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 651 
 652   if (encoder-&gt;priv-&gt;input_state) {
 653     GST_DEBUG_OBJECT (encoder,
 654         &quot;Checking if caps changed old %&quot; GST_PTR_FORMAT &quot; new %&quot; GST_PTR_FORMAT,
 655         encoder-&gt;priv-&gt;input_state-&gt;caps, caps);
 656     if (gst_caps_is_equal (encoder-&gt;priv-&gt;input_state-&gt;caps, caps))
 657       goto caps_not_changed;
 658   }
 659 
 660   state = _new_input_state (caps);
 661   if (G_UNLIKELY (!state))
 662     goto parse_fail;
 663 
 664   if (encoder-&gt;priv-&gt;input_state
 665       &amp;&amp; gst_video_info_is_equal (&amp;state-&gt;info,
 666           &amp;encoder-&gt;priv-&gt;input_state-&gt;info)) {
 667     gst_video_codec_state_unref (state);
 668     goto caps_not_changed;
 669   }
 670 
 671   if (encoder_class-&gt;reset) {
 672     GST_FIXME_OBJECT (encoder, &quot;GstVideoEncoder::reset() is deprecated&quot;);
 673     encoder_class-&gt;reset (encoder, TRUE);
 674   }
 675 
 676   /* and subclass should be ready to configure format at any time around */
 677   ret = encoder_class-&gt;set_format (encoder, state);
 678   if (ret) {
 679     if (encoder-&gt;priv-&gt;input_state)
 680       gst_video_codec_state_unref (encoder-&gt;priv-&gt;input_state);
 681     encoder-&gt;priv-&gt;input_state = state;
 682   } else {
 683     gst_video_codec_state_unref (state);
 684   }
 685 
 686   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 687 
 688   if (!ret)
 689     GST_WARNING_OBJECT (encoder, &quot;rejected caps %&quot; GST_PTR_FORMAT, caps);
 690 
 691   return ret;
 692 
 693 caps_not_changed:
 694   {
 695     GST_DEBUG_OBJECT (encoder, &quot;Caps did not change - ignore&quot;);
 696     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 697     return TRUE;
 698   }
 699 
 700   /* ERRORS */
 701 parse_fail:
 702   {
 703     GST_WARNING_OBJECT (encoder, &quot;Failed to parse caps&quot;);
 704     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 705     return FALSE;
 706   }
 707 }
 708 
 709 /**
 710  * gst_video_encoder_proxy_getcaps:
 711  * @enc: a #GstVideoEncoder
 712  * @caps: (allow-none): initial caps
 713  * @filter: (allow-none): filter caps
 714  *
 715  * Returns caps that express @caps (or sink template caps if @caps == NULL)
 716  * restricted to resolution/format/... combinations supported by downstream
 717  * elements (e.g. muxers).
 718  *
 719  * Returns: (transfer full): a #GstCaps owned by caller
 720  */
 721 GstCaps *
 722 gst_video_encoder_proxy_getcaps (GstVideoEncoder * encoder, GstCaps * caps,
 723     GstCaps * filter)
 724 {
 725   return __gst_video_element_proxy_getcaps (GST_ELEMENT_CAST (encoder),
 726       GST_VIDEO_ENCODER_SINK_PAD (encoder),
 727       GST_VIDEO_ENCODER_SRC_PAD (encoder), caps, filter);
 728 }
 729 
 730 static GstCaps *
 731 gst_video_encoder_sink_getcaps (GstVideoEncoder * encoder, GstCaps * filter)
 732 {
 733   GstVideoEncoderClass *klass;
 734   GstCaps *caps;
 735 
 736   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 737 
 738   if (klass-&gt;getcaps)
 739     caps = klass-&gt;getcaps (encoder, filter);
 740   else
 741     caps = gst_video_encoder_proxy_getcaps (encoder, NULL, filter);
 742 
 743   GST_LOG_OBJECT (encoder, &quot;Returning caps %&quot; GST_PTR_FORMAT, caps);
 744 
 745   return caps;
 746 }
 747 
 748 static gboolean
 749 gst_video_encoder_decide_allocation_default (GstVideoEncoder * encoder,
 750     GstQuery * query)
 751 {
 752   GstAllocator *allocator = NULL;
 753   GstAllocationParams params;
 754   gboolean update_allocator;
 755 
 756   /* we got configuration from our peer or the decide_allocation method,
 757    * parse them */
 758   if (gst_query_get_n_allocation_params (query) &gt; 0) {
 759     /* try the allocator */
 760     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 761     update_allocator = TRUE;
 762   } else {
 763     allocator = NULL;
 764     gst_allocation_params_init (&amp;params);
 765     update_allocator = FALSE;
 766   }
 767 
 768   if (update_allocator)
 769     gst_query_set_nth_allocation_param (query, 0, allocator, &amp;params);
 770   else
 771     gst_query_add_allocation_param (query, allocator, &amp;params);
 772   if (allocator)
 773     gst_object_unref (allocator);
 774 
 775   return TRUE;
 776 }
 777 
 778 static gboolean
 779 gst_video_encoder_propose_allocation_default (GstVideoEncoder * encoder,
 780     GstQuery * query)
 781 {
 782   GstCaps *caps;
 783   GstVideoInfo info;
 784   GstBufferPool *pool;
 785   guint size;
 786 
 787   gst_query_parse_allocation (query, &amp;caps, NULL);
 788 
 789   if (caps == NULL)
 790     return FALSE;
 791 
 792   if (!gst_video_info_from_caps (&amp;info, caps))
 793     return FALSE;
 794 
 795   size = GST_VIDEO_INFO_SIZE (&amp;info);
 796 
 797   if (gst_query_get_n_allocation_pools (query) == 0) {
 798     GstStructure *structure;
 799     GstAllocator *allocator = NULL;
 800     GstAllocationParams params = { 0, 15, 0, 0 };
 801 
 802     if (gst_query_get_n_allocation_params (query) &gt; 0)
 803       gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 804     else
 805       gst_query_add_allocation_param (query, allocator, &amp;params);
 806 
 807     pool = gst_video_buffer_pool_new ();
 808 
 809     structure = gst_buffer_pool_get_config (pool);
 810     gst_buffer_pool_config_set_params (structure, caps, size, 0, 0);
 811     gst_buffer_pool_config_set_allocator (structure, allocator, &amp;params);
 812 
 813     if (allocator)
 814       gst_object_unref (allocator);
 815 
 816     if (!gst_buffer_pool_set_config (pool, structure))
 817       goto config_failed;
 818 
 819     gst_query_add_allocation_pool (query, pool, size, 0, 0);
 820     gst_object_unref (pool);
 821     gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
 822   }
 823 
 824   return TRUE;
 825 
 826   /* ERRORS */
 827 config_failed:
 828   {
 829     GST_ERROR_OBJECT (encoder, &quot;failed to set config&quot;);
 830     gst_object_unref (pool);
 831     return FALSE;
 832   }
 833 }
 834 
 835 static gboolean
 836 gst_video_encoder_sink_query_default (GstVideoEncoder * encoder,
 837     GstQuery * query)
 838 {
 839   GstPad *pad = GST_VIDEO_ENCODER_SINK_PAD (encoder);
 840   gboolean res = FALSE;
 841 
 842   switch (GST_QUERY_TYPE (query)) {
 843     case GST_QUERY_CAPS:
 844     {
 845       GstCaps *filter, *caps;
 846 
 847       gst_query_parse_caps (query, &amp;filter);
 848       caps = gst_video_encoder_sink_getcaps (encoder, filter);
 849       gst_query_set_caps_result (query, caps);
 850       gst_caps_unref (caps);
 851       res = TRUE;
 852       break;
 853     }
 854     case GST_QUERY_CONVERT:
 855     {
 856       GstFormat src_fmt, dest_fmt;
 857       gint64 src_val, dest_val;
 858 
 859       GST_DEBUG_OBJECT (encoder, &quot;convert query&quot;);
 860 
 861       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
 862       GST_OBJECT_LOCK (encoder);
 863       if (encoder-&gt;priv-&gt;input_state != NULL)
 864         res = __gst_video_rawvideo_convert (encoder-&gt;priv-&gt;input_state,
 865             src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
 866       else
 867         res = FALSE;
 868       GST_OBJECT_UNLOCK (encoder);
 869       if (!res)
 870         goto error;
 871       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
 872       break;
 873     }
 874     case GST_QUERY_ALLOCATION:
 875     {
 876       GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 877 
 878       if (klass-&gt;propose_allocation)
 879         res = klass-&gt;propose_allocation (encoder, query);
 880       break;
 881     }
 882     default:
 883       res = gst_pad_query_default (pad, GST_OBJECT (encoder), query);
 884       break;
 885   }
 886   return res;
 887 
 888 error:
 889   GST_DEBUG_OBJECT (encoder, &quot;query failed&quot;);
 890   return res;
 891 }
 892 
 893 static gboolean
 894 gst_video_encoder_sink_query (GstPad * pad, GstObject * parent,
 895     GstQuery * query)
 896 {
 897   GstVideoEncoder *encoder;
 898   GstVideoEncoderClass *encoder_class;
 899   gboolean ret = FALSE;
 900 
 901   encoder = GST_VIDEO_ENCODER (parent);
 902   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 903 
 904   GST_DEBUG_OBJECT (encoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
 905       GST_QUERY_TYPE_NAME (query));
 906 
 907   if (encoder_class-&gt;sink_query)
 908     ret = encoder_class-&gt;sink_query (encoder, query);
 909 
 910   return ret;
 911 }
 912 
 913 static void
 914 gst_video_encoder_finalize (GObject * object)
 915 {
 916   GstVideoEncoder *encoder;
 917 
 918   GST_DEBUG_OBJECT (object, &quot;finalize&quot;);
 919 
 920   encoder = GST_VIDEO_ENCODER (object);
 921   g_rec_mutex_clear (&amp;encoder-&gt;stream_lock);
 922 
 923   if (encoder-&gt;priv-&gt;allocator) {
 924     gst_object_unref (encoder-&gt;priv-&gt;allocator);
 925     encoder-&gt;priv-&gt;allocator = NULL;
 926   }
 927 
 928   G_OBJECT_CLASS (parent_class)-&gt;finalize (object);
 929 }
 930 
 931 static gboolean
 932 gst_video_encoder_push_event (GstVideoEncoder * encoder, GstEvent * event)
 933 {
 934   switch (GST_EVENT_TYPE (event)) {
 935     case GST_EVENT_SEGMENT:
 936     {
 937       GstSegment segment;
 938 
 939       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 940 
 941       gst_event_copy_segment (event, &amp;segment);
 942 
 943       GST_DEBUG_OBJECT (encoder, &quot;segment %&quot; GST_SEGMENT_FORMAT, &amp;segment);
 944 
 945       if (segment.format != GST_FORMAT_TIME) {
 946         GST_DEBUG_OBJECT (encoder, &quot;received non TIME segment&quot;);
 947         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 948         break;
 949       }
 950 
 951       if (encoder-&gt;priv-&gt;time_adjustment != GST_CLOCK_TIME_NONE) {
 952         segment.start += encoder-&gt;priv-&gt;time_adjustment;
<a name="7" id="anc7"></a><span class="line-added"> 953         if (GST_CLOCK_TIME_IS_VALID (segment.position)) {</span>
<span class="line-added"> 954           segment.position += encoder-&gt;priv-&gt;time_adjustment;</span>
<span class="line-added"> 955         }</span>
 956         if (GST_CLOCK_TIME_IS_VALID (segment.stop)) {
 957           segment.stop += encoder-&gt;priv-&gt;time_adjustment;
 958         }
 959       }
 960 
 961       encoder-&gt;output_segment = segment;
 962       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 963 
 964       gst_event_unref (event);
 965       event = gst_event_new_segment (&amp;encoder-&gt;output_segment);
 966 
 967       break;
 968     }
 969     default:
 970       break;
 971   }
 972 
 973   return gst_pad_push_event (encoder-&gt;srcpad, event);
 974 }
 975 
 976 static GstEvent *
 977 gst_video_encoder_create_merged_tags_event (GstVideoEncoder * enc)
 978 {
 979   GstTagList *merged_tags;
 980 
 981   GST_LOG_OBJECT (enc, &quot;upstream : %&quot; GST_PTR_FORMAT, enc-&gt;priv-&gt;upstream_tags);
 982   GST_LOG_OBJECT (enc, &quot;encoder  : %&quot; GST_PTR_FORMAT, enc-&gt;priv-&gt;tags);
 983   GST_LOG_OBJECT (enc, &quot;mode     : %d&quot;, enc-&gt;priv-&gt;tags_merge_mode);
 984 
 985   merged_tags =
 986       gst_tag_list_merge (enc-&gt;priv-&gt;upstream_tags, enc-&gt;priv-&gt;tags,
 987       enc-&gt;priv-&gt;tags_merge_mode);
 988 
 989   GST_DEBUG_OBJECT (enc, &quot;merged   : %&quot; GST_PTR_FORMAT, merged_tags);
 990 
 991   if (merged_tags == NULL)
 992     return NULL;
 993 
 994   if (gst_tag_list_is_empty (merged_tags)) {
 995     gst_tag_list_unref (merged_tags);
 996     return NULL;
 997   }
 998 
 999   return gst_event_new_tag (merged_tags);
1000 }
1001 
1002 static inline void
1003 gst_video_encoder_check_and_push_tags (GstVideoEncoder * encoder)
1004 {
1005   if (encoder-&gt;priv-&gt;tags_changed) {
1006     GstEvent *tags_event;
1007 
1008     tags_event = gst_video_encoder_create_merged_tags_event (encoder);
1009 
1010     if (tags_event != NULL)
1011       gst_video_encoder_push_event (encoder, tags_event);
1012 
1013     encoder-&gt;priv-&gt;tags_changed = FALSE;
1014   }
1015 }
1016 
1017 static gboolean
1018 gst_video_encoder_sink_event_default (GstVideoEncoder * encoder,
1019     GstEvent * event)
1020 {
1021   GstVideoEncoderClass *encoder_class;
1022   gboolean ret = FALSE;
1023 
1024   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1025 
1026   switch (GST_EVENT_TYPE (event)) {
1027     case GST_EVENT_CAPS:
1028     {
1029       GstCaps *caps;
1030 
1031       gst_event_parse_caps (event, &amp;caps);
1032       ret = gst_video_encoder_setcaps (encoder, caps);
1033 
1034       gst_event_unref (event);
1035       event = NULL;
1036       break;
1037     }
1038     case GST_EVENT_EOS:
1039     {
1040       GstFlowReturn flow_ret;
1041 
1042       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1043 
1044       if (encoder_class-&gt;finish) {
1045         flow_ret = encoder_class-&gt;finish (encoder);
1046       } else {
1047         flow_ret = GST_FLOW_OK;
1048       }
1049 
1050       if (encoder-&gt;priv-&gt;current_frame_events) {
1051         GList *l;
1052 
1053         for (l = g_list_last (encoder-&gt;priv-&gt;current_frame_events); l;
1054             l = g_list_previous (l)) {
1055           GstEvent *event = GST_EVENT (l-&gt;data);
1056 
1057           gst_video_encoder_push_event (encoder, event);
1058         }
1059       }
1060       g_list_free (encoder-&gt;priv-&gt;current_frame_events);
1061       encoder-&gt;priv-&gt;current_frame_events = NULL;
1062 
1063       gst_video_encoder_check_and_push_tags (encoder);
1064 
1065       ret = (flow_ret == GST_FLOW_OK);
1066       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1067       break;
1068     }
1069     case GST_EVENT_SEGMENT:
1070     {
1071       GstSegment segment;
1072 
1073       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1074 
1075       gst_event_copy_segment (event, &amp;segment);
1076 
1077       GST_DEBUG_OBJECT (encoder, &quot;segment %&quot; GST_SEGMENT_FORMAT, &amp;segment);
1078 
1079       if (segment.format != GST_FORMAT_TIME) {
1080         GST_DEBUG_OBJECT (encoder, &quot;received non TIME newsegment&quot;);
1081         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1082         break;
1083       }
1084 
1085       encoder-&gt;input_segment = segment;
1086       ret = TRUE;
1087       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1088       break;
1089     }
1090     case GST_EVENT_CUSTOM_DOWNSTREAM:
1091     {
1092       if (gst_video_event_is_force_key_unit (event)) {
1093         GstClockTime running_time;
1094         gboolean all_headers;
1095         guint count;
1096 
1097         if (gst_video_event_parse_downstream_force_key_unit (event,
1098                 NULL, NULL, &amp;running_time, &amp;all_headers, &amp;count)) {
1099           ForcedKeyUnitEvent *fevt;
1100 
1101           GST_OBJECT_LOCK (encoder);
1102           fevt = forced_key_unit_event_new (running_time, all_headers, count);
1103           encoder-&gt;priv-&gt;force_key_unit =
1104               g_list_append (encoder-&gt;priv-&gt;force_key_unit, fevt);
1105           GST_OBJECT_UNLOCK (encoder);
1106 
1107           GST_DEBUG_OBJECT (encoder,
1108               &quot;force-key-unit event: running-time %&quot; GST_TIME_FORMAT
1109               &quot;, all_headers %d, count %u&quot;,
1110               GST_TIME_ARGS (running_time), all_headers, count);
1111         }
1112         gst_event_unref (event);
1113         event = NULL;
1114         ret = TRUE;
1115       }
1116       break;
1117     }
1118     case GST_EVENT_STREAM_START:
1119     {
1120       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1121       /* Flush upstream tags after a STREAM_START */
1122       GST_DEBUG_OBJECT (encoder, &quot;STREAM_START, clearing upstream tags&quot;);
1123       if (encoder-&gt;priv-&gt;upstream_tags) {
1124         gst_tag_list_unref (encoder-&gt;priv-&gt;upstream_tags);
1125         encoder-&gt;priv-&gt;upstream_tags = NULL;
1126         encoder-&gt;priv-&gt;tags_changed = TRUE;
1127       }
1128       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1129       break;
1130     }
1131     case GST_EVENT_TAG:
1132     {
1133       GstTagList *tags;
1134 
1135       gst_event_parse_tag (event, &amp;tags);
1136 
1137       if (gst_tag_list_get_scope (tags) == GST_TAG_SCOPE_STREAM) {
1138         GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1139         if (encoder-&gt;priv-&gt;upstream_tags != tags) {
1140           tags = gst_tag_list_copy (tags);
1141 
1142           /* FIXME: make generic based on GST_TAG_FLAG_ENCODED */
1143           gst_tag_list_remove_tag (tags, GST_TAG_CODEC);
1144           gst_tag_list_remove_tag (tags, GST_TAG_AUDIO_CODEC);
1145           gst_tag_list_remove_tag (tags, GST_TAG_VIDEO_CODEC);
1146           gst_tag_list_remove_tag (tags, GST_TAG_SUBTITLE_CODEC);
1147           gst_tag_list_remove_tag (tags, GST_TAG_CONTAINER_FORMAT);
1148           gst_tag_list_remove_tag (tags, GST_TAG_BITRATE);
1149           gst_tag_list_remove_tag (tags, GST_TAG_NOMINAL_BITRATE);
1150           gst_tag_list_remove_tag (tags, GST_TAG_MAXIMUM_BITRATE);
1151           gst_tag_list_remove_tag (tags, GST_TAG_MINIMUM_BITRATE);
1152           gst_tag_list_remove_tag (tags, GST_TAG_ENCODER);
1153           gst_tag_list_remove_tag (tags, GST_TAG_ENCODER_VERSION);
1154 
1155           if (encoder-&gt;priv-&gt;upstream_tags)
1156             gst_tag_list_unref (encoder-&gt;priv-&gt;upstream_tags);
1157           encoder-&gt;priv-&gt;upstream_tags = tags;
1158           GST_INFO_OBJECT (encoder, &quot;upstream tags: %&quot; GST_PTR_FORMAT, tags);
1159         }
1160         gst_event_unref (event);
1161         event = gst_video_encoder_create_merged_tags_event (encoder);
1162         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1163         if (!event)
1164           ret = TRUE;
1165       }
1166       break;
1167     }
1168     case GST_EVENT_FLUSH_STOP:{
1169       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1170       gst_video_encoder_flush (encoder);
1171       gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
1172       gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
1173       gst_video_encoder_reset (encoder, FALSE);
1174       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1175       break;
1176     }
1177     default:
1178       break;
1179   }
1180 
1181   /* Forward non-serialized events and EOS/FLUSH_STOP immediately.
1182    * For EOS this is required because no buffer or serialized event
1183    * will come after EOS and nothing could trigger another
1184    * _finish_frame() call.   *
1185    * If the subclass handles sending of EOS manually it can simply
1186    * not chain up to the parent class&#39; event handler
1187    *
1188    * For FLUSH_STOP this is required because it is expected
1189    * to be forwarded immediately and no buffers are queued anyway.
1190    */
1191   if (event) {
1192     if (!GST_EVENT_IS_SERIALIZED (event)
1193         || GST_EVENT_TYPE (event) == GST_EVENT_EOS
1194         || GST_EVENT_TYPE (event) == GST_EVENT_FLUSH_STOP) {
1195       ret = gst_video_encoder_push_event (encoder, event);
1196     } else {
1197       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1198       encoder-&gt;priv-&gt;current_frame_events =
1199           g_list_prepend (encoder-&gt;priv-&gt;current_frame_events, event);
1200       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1201       ret = TRUE;
1202     }
1203   }
1204 
1205   return ret;
1206 }
1207 
1208 static gboolean
1209 gst_video_encoder_sink_event (GstPad * pad, GstObject * parent,
1210     GstEvent * event)
1211 {
1212   GstVideoEncoder *enc;
1213   GstVideoEncoderClass *klass;
1214   gboolean ret = TRUE;
1215 
1216   enc = GST_VIDEO_ENCODER (parent);
1217   klass = GST_VIDEO_ENCODER_GET_CLASS (enc);
1218 
1219   GST_DEBUG_OBJECT (enc, &quot;received event %d, %s&quot;, GST_EVENT_TYPE (event),
1220       GST_EVENT_TYPE_NAME (event));
1221 
1222   if (klass-&gt;sink_event)
1223     ret = klass-&gt;sink_event (enc, event);
1224 
1225   return ret;
1226 }
1227 
1228 static gboolean
1229 gst_video_encoder_src_event_default (GstVideoEncoder * encoder,
1230     GstEvent * event)
1231 {
1232   gboolean ret = FALSE;
1233   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
1234 
1235   switch (GST_EVENT_TYPE (event)) {
1236     case GST_EVENT_CUSTOM_UPSTREAM:
1237     {
1238       if (gst_video_event_is_force_key_unit (event)) {
1239         GstClockTime running_time;
1240         gboolean all_headers;
1241         guint count;
1242 
1243         if (gst_video_event_parse_upstream_force_key_unit (event,
1244                 &amp;running_time, &amp;all_headers, &amp;count)) {
1245           ForcedKeyUnitEvent *fevt;
1246 
1247           GST_OBJECT_LOCK (encoder);
1248           fevt = forced_key_unit_event_new (running_time, all_headers, count);
1249           encoder-&gt;priv-&gt;force_key_unit =
1250               g_list_append (encoder-&gt;priv-&gt;force_key_unit, fevt);
1251           GST_OBJECT_UNLOCK (encoder);
1252 
1253           GST_DEBUG_OBJECT (encoder,
1254               &quot;force-key-unit event: running-time %&quot; GST_TIME_FORMAT
1255               &quot;, all_headers %d, count %u&quot;,
1256               GST_TIME_ARGS (running_time), all_headers, count);
1257         }
1258         gst_event_unref (event);
1259         event = NULL;
1260         ret = TRUE;
1261       }
1262       break;
1263     }
1264     case GST_EVENT_QOS:
1265     {
1266       GstQOSType type;
1267       gdouble proportion;
1268       GstClockTimeDiff diff;
1269       GstClockTime timestamp;
1270 
1271       if (!g_atomic_int_get (&amp;priv-&gt;qos_enabled))
1272         break;
1273 
1274       gst_event_parse_qos (event, &amp;type, &amp;proportion, &amp;diff, &amp;timestamp);
1275 
1276       GST_OBJECT_LOCK (encoder);
1277       priv-&gt;proportion = proportion;
1278       if (G_LIKELY (GST_CLOCK_TIME_IS_VALID (timestamp))) {
1279         if (G_UNLIKELY (diff &gt; 0)) {
1280           priv-&gt;earliest_time = timestamp + 2 * diff + priv-&gt;qos_frame_duration;
1281         } else {
1282           priv-&gt;earliest_time = timestamp + diff;
1283         }
1284       } else {
1285         priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
1286       }
1287       GST_OBJECT_UNLOCK (encoder);
1288 
1289       GST_DEBUG_OBJECT (encoder,
1290           &quot;got QoS %&quot; GST_TIME_FORMAT &quot;, %&quot; GST_STIME_FORMAT &quot;, %g&quot;,
1291           GST_TIME_ARGS (timestamp), GST_STIME_ARGS (diff), proportion);
1292 
1293       ret = gst_pad_push_event (encoder-&gt;sinkpad, event);
1294       event = NULL;
1295       break;
1296     }
1297     default:
1298       break;
1299   }
1300 
1301   if (event)
1302     ret =
1303         gst_pad_event_default (encoder-&gt;srcpad, GST_OBJECT_CAST (encoder),
1304         event);
1305 
1306   return ret;
1307 }
1308 
1309 static gboolean
1310 gst_video_encoder_src_event (GstPad * pad, GstObject * parent, GstEvent * event)
1311 {
1312   GstVideoEncoder *encoder;
1313   GstVideoEncoderClass *klass;
1314   gboolean ret = FALSE;
1315 
1316   encoder = GST_VIDEO_ENCODER (parent);
1317   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1318 
1319   GST_LOG_OBJECT (encoder, &quot;handling event: %&quot; GST_PTR_FORMAT, event);
1320 
1321   if (klass-&gt;src_event)
1322     ret = klass-&gt;src_event (encoder, event);
1323 
1324   return ret;
1325 }
1326 
1327 static gboolean
1328 gst_video_encoder_src_query_default (GstVideoEncoder * enc, GstQuery * query)
1329 {
1330   GstPad *pad = GST_VIDEO_ENCODER_SRC_PAD (enc);
1331   GstVideoEncoderPrivate *priv;
1332   gboolean res;
1333 
1334   priv = enc-&gt;priv;
1335 
1336   GST_LOG_OBJECT (enc, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
1337 
1338   switch (GST_QUERY_TYPE (query)) {
1339     case GST_QUERY_CONVERT:
1340     {
1341       GstFormat src_fmt, dest_fmt;
1342       gint64 src_val, dest_val;
1343 
1344       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
1345       GST_OBJECT_LOCK (enc);
1346       res =
1347           __gst_video_encoded_video_convert (priv-&gt;bytes, priv-&gt;time, src_fmt,
1348           src_val, &amp;dest_fmt, &amp;dest_val);
1349       GST_OBJECT_UNLOCK (enc);
1350       if (!res)
1351         goto error;
1352       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
1353       break;
1354     }
1355     case GST_QUERY_LATENCY:
1356     {
1357       gboolean live;
1358       GstClockTime min_latency, max_latency;
1359 
1360       res = gst_pad_peer_query (enc-&gt;sinkpad, query);
1361       if (res) {
1362         gst_query_parse_latency (query, &amp;live, &amp;min_latency, &amp;max_latency);
1363         GST_DEBUG_OBJECT (enc, &quot;Peer latency: live %d, min %&quot;
1364             GST_TIME_FORMAT &quot; max %&quot; GST_TIME_FORMAT, live,
1365             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
1366 
1367         GST_OBJECT_LOCK (enc);
1368         min_latency += priv-&gt;min_latency;
1369         if (max_latency == GST_CLOCK_TIME_NONE
1370             || enc-&gt;priv-&gt;max_latency == GST_CLOCK_TIME_NONE)
1371           max_latency = GST_CLOCK_TIME_NONE;
1372         else
1373           max_latency += enc-&gt;priv-&gt;max_latency;
1374         GST_OBJECT_UNLOCK (enc);
1375 
1376         gst_query_set_latency (query, live, min_latency, max_latency);
1377       }
1378     }
1379       break;
1380     default:
1381       res = gst_pad_query_default (pad, GST_OBJECT (enc), query);
1382   }
1383   return res;
1384 
1385 error:
1386   GST_DEBUG_OBJECT (enc, &quot;query failed&quot;);
1387   return res;
1388 }
1389 
1390 static gboolean
1391 gst_video_encoder_src_query (GstPad * pad, GstObject * parent, GstQuery * query)
1392 {
1393   GstVideoEncoder *encoder;
1394   GstVideoEncoderClass *encoder_class;
1395   gboolean ret = FALSE;
1396 
1397   encoder = GST_VIDEO_ENCODER (parent);
1398   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1399 
1400   GST_DEBUG_OBJECT (encoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
1401       GST_QUERY_TYPE_NAME (query));
1402 
1403   if (encoder_class-&gt;src_query)
1404     ret = encoder_class-&gt;src_query (encoder, query);
1405 
1406   return ret;
1407 }
1408 
1409 static GstVideoCodecFrame *
1410 gst_video_encoder_new_frame (GstVideoEncoder * encoder, GstBuffer * buf,
1411     GstClockTime pts, GstClockTime dts, GstClockTime duration)
1412 {
1413   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
1414   GstVideoCodecFrame *frame;
1415 
1416   frame = g_slice_new0 (GstVideoCodecFrame);
1417 
1418   frame-&gt;ref_count = 1;
1419 
1420   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1421   frame-&gt;system_frame_number = priv-&gt;system_frame_number;
1422   priv-&gt;system_frame_number++;
1423 
1424   frame-&gt;presentation_frame_number = priv-&gt;presentation_frame_number;
1425   priv-&gt;presentation_frame_number++;
1426   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1427 
1428   frame-&gt;events = priv-&gt;current_frame_events;
1429   priv-&gt;current_frame_events = NULL;
1430   frame-&gt;input_buffer = buf;
1431   frame-&gt;pts = pts;
1432   frame-&gt;dts = dts;
1433   frame-&gt;duration = duration;
1434   frame-&gt;abidata.ABI.ts = pts;
1435 
1436   return frame;
1437 }
1438 
1439 
1440 static GstFlowReturn
1441 gst_video_encoder_chain (GstPad * pad, GstObject * parent, GstBuffer * buf)
1442 {
1443   GstVideoEncoder *encoder;
1444   GstVideoEncoderPrivate *priv;
1445   GstVideoEncoderClass *klass;
1446   GstVideoCodecFrame *frame;
1447   GstClockTime pts, duration;
1448   GstFlowReturn ret = GST_FLOW_OK;
1449   guint64 start, stop, cstart, cstop;
1450 
1451   encoder = GST_VIDEO_ENCODER (parent);
1452   priv = encoder-&gt;priv;
1453   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1454 
1455   g_return_val_if_fail (klass-&gt;handle_frame != NULL, GST_FLOW_ERROR);
1456 
1457   if (!encoder-&gt;priv-&gt;input_state)
1458     goto not_negotiated;
1459 
1460   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1461 
1462   pts = GST_BUFFER_PTS (buf);
1463   duration = GST_BUFFER_DURATION (buf);
1464 
1465   GST_LOG_OBJECT (encoder,
1466       &quot;received buffer of size %&quot; G_GSIZE_FORMAT &quot; with PTS %&quot; GST_TIME_FORMAT
1467       &quot;, DTS %&quot; GST_TIME_FORMAT &quot;, duration %&quot; GST_TIME_FORMAT,
1468       gst_buffer_get_size (buf), GST_TIME_ARGS (pts),
1469       GST_TIME_ARGS (GST_BUFFER_DTS (buf)), GST_TIME_ARGS (duration));
1470 
1471   start = pts;
1472   if (GST_CLOCK_TIME_IS_VALID (duration))
1473     stop = start + duration;
1474   else
1475     stop = GST_CLOCK_TIME_NONE;
1476 
1477   /* Drop buffers outside of segment */
1478   if (!gst_segment_clip (&amp;encoder-&gt;input_segment,
1479           GST_FORMAT_TIME, start, stop, &amp;cstart, &amp;cstop)) {
1480     GST_DEBUG_OBJECT (encoder, &quot;clipping to segment dropped frame&quot;);
1481     gst_buffer_unref (buf);
1482     goto done;
1483   }
1484 
1485   if (GST_CLOCK_TIME_IS_VALID (cstop))
1486     duration = cstop - cstart;
1487   else
1488     duration = GST_CLOCK_TIME_NONE;
1489 
1490   if (priv-&gt;min_pts != GST_CLOCK_TIME_NONE
1491       &amp;&amp; priv-&gt;time_adjustment == GST_CLOCK_TIME_NONE) {
1492     if (cstart &lt; priv-&gt;min_pts) {
1493       priv-&gt;time_adjustment = priv-&gt;min_pts - cstart;
1494     }
1495   }
1496 
1497   if (priv-&gt;time_adjustment != GST_CLOCK_TIME_NONE) {
1498     cstart += priv-&gt;time_adjustment;
1499   }
1500 
1501   /* incoming DTS is not really relevant and does not make sense anyway,
1502    * so pass along _NONE and maybe come up with something better later on */
1503   frame = gst_video_encoder_new_frame (encoder, buf, cstart,
1504       GST_CLOCK_TIME_NONE, duration);
1505 
1506   GST_OBJECT_LOCK (encoder);
1507   if (priv-&gt;force_key_unit) {
1508     ForcedKeyUnitEvent *fevt = NULL;
1509     GstClockTime running_time;
1510     GList *l;
1511 
1512     running_time =
1513         gst_segment_to_running_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
1514         cstart);
1515 
1516     for (l = priv-&gt;force_key_unit; l; l = l-&gt;next) {
1517       ForcedKeyUnitEvent *tmp = l-&gt;data;
1518 
1519       /* Skip pending keyunits */
1520       if (tmp-&gt;pending)
1521         continue;
1522 
1523       /* Simple case, keyunit ASAP */
1524       if (tmp-&gt;running_time == GST_CLOCK_TIME_NONE) {
1525         fevt = tmp;
1526         break;
1527       }
1528 
1529       /* Event for before this frame */
1530       if (tmp-&gt;running_time &lt;= running_time) {
1531         fevt = tmp;
1532         break;
1533       }
1534     }
1535 
1536     if (fevt) {
1537       fevt-&gt;frame_id = frame-&gt;system_frame_number;
1538       GST_DEBUG_OBJECT (encoder,
1539           &quot;Forcing a key unit at running time %&quot; GST_TIME_FORMAT,
1540           GST_TIME_ARGS (running_time));
1541       GST_VIDEO_CODEC_FRAME_SET_FORCE_KEYFRAME (frame);
1542       if (fevt-&gt;all_headers)
1543         GST_VIDEO_CODEC_FRAME_SET_FORCE_KEYFRAME_HEADERS (frame);
1544       fevt-&gt;pending = TRUE;
1545     }
1546   }
1547   GST_OBJECT_UNLOCK (encoder);
1548 
1549   gst_video_codec_frame_ref (frame);
1550   priv-&gt;frames = g_list_append (priv-&gt;frames, frame);
1551 
1552   /* new data, more finish needed */
1553   priv-&gt;drained = FALSE;
1554 
1555   GST_LOG_OBJECT (encoder, &quot;passing frame pfn %d to subclass&quot;,
1556       frame-&gt;presentation_frame_number);
1557 
1558   frame-&gt;deadline =
1559       gst_segment_to_running_time (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME,
1560       frame-&gt;pts);
1561 
1562   ret = klass-&gt;handle_frame (encoder, frame);
1563 
1564 done:
1565   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1566 
1567   return ret;
1568 
1569   /* ERRORS */
1570 not_negotiated:
1571   {
1572     GST_ELEMENT_ERROR (encoder, CORE, NEGOTIATION, (NULL),
1573         (&quot;encoder not initialized&quot;));
1574     gst_buffer_unref (buf);
1575     return GST_FLOW_NOT_NEGOTIATED;
1576   }
1577 }
1578 
1579 static GstStateChangeReturn
1580 gst_video_encoder_change_state (GstElement * element, GstStateChange transition)
1581 {
1582   GstVideoEncoder *encoder;
1583   GstVideoEncoderClass *encoder_class;
1584   GstStateChangeReturn ret;
1585 
1586   encoder = GST_VIDEO_ENCODER (element);
1587   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (element);
1588 
1589   switch (transition) {
1590     case GST_STATE_CHANGE_NULL_TO_READY:
1591       /* open device/library if needed */
1592       if (encoder_class-&gt;open &amp;&amp; !encoder_class-&gt;open (encoder))
1593         goto open_failed;
1594       break;
1595     case GST_STATE_CHANGE_READY_TO_PAUSED:
1596       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1597       gst_video_encoder_reset (encoder, TRUE);
1598       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1599 
1600       /* Initialize device/library if needed */
1601       if (encoder_class-&gt;start &amp;&amp; !encoder_class-&gt;start (encoder))
1602         goto start_failed;
1603       break;
1604     default:
1605       break;
1606   }
1607 
1608   ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition);
1609 
1610   switch (transition) {
1611     case GST_STATE_CHANGE_PAUSED_TO_READY:{
1612       gboolean stopped = TRUE;
1613 
1614       if (encoder_class-&gt;stop)
1615         stopped = encoder_class-&gt;stop (encoder);
1616 
1617       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1618       gst_video_encoder_reset (encoder, TRUE);
1619       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1620 
1621       if (!stopped)
1622         goto stop_failed;
1623       break;
1624     }
1625     case GST_STATE_CHANGE_READY_TO_NULL:
1626       /* close device/library if needed */
1627       if (encoder_class-&gt;close &amp;&amp; !encoder_class-&gt;close (encoder))
1628         goto close_failed;
1629       break;
1630     default:
1631       break;
1632   }
1633 
1634   return ret;
1635 
1636   /* Errors */
1637 
1638 open_failed:
1639   {
1640     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1641         (&quot;Failed to open encoder&quot;));
1642     return GST_STATE_CHANGE_FAILURE;
1643   }
1644 
1645 start_failed:
1646   {
1647     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1648         (&quot;Failed to start encoder&quot;));
1649     return GST_STATE_CHANGE_FAILURE;
1650   }
1651 
1652 stop_failed:
1653   {
1654     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1655         (&quot;Failed to stop encoder&quot;));
1656     return GST_STATE_CHANGE_FAILURE;
1657   }
1658 
1659 close_failed:
1660   {
1661     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1662         (&quot;Failed to close encoder&quot;));
1663     return GST_STATE_CHANGE_FAILURE;
1664   }
1665 }
1666 
1667 static gboolean
1668 gst_video_encoder_negotiate_default (GstVideoEncoder * encoder)
1669 {
1670   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1671   GstAllocator *allocator;
1672   GstAllocationParams params;
1673   gboolean ret = TRUE;
1674   GstVideoCodecState *state = encoder-&gt;priv-&gt;output_state;
1675   GstVideoInfo *info = &amp;state-&gt;info;
1676   GstQuery *query = NULL;
1677   GstVideoCodecFrame *frame;
1678   GstCaps *prevcaps;
1679   gchar *colorimetry;
1680 
1681   g_return_val_if_fail (state-&gt;caps != NULL, FALSE);
1682 
1683   if (encoder-&gt;priv-&gt;output_state_changed) {
1684     state-&gt;caps = gst_caps_make_writable (state-&gt;caps);
1685 
1686     /* Fill caps */
1687     gst_caps_set_simple (state-&gt;caps, &quot;width&quot;, G_TYPE_INT, info-&gt;width,
1688         &quot;height&quot;, G_TYPE_INT, info-&gt;height,
1689         &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION,
1690         info-&gt;par_n, info-&gt;par_d, NULL);
1691     if (info-&gt;flags &amp; GST_VIDEO_FLAG_VARIABLE_FPS &amp;&amp; info-&gt;fps_n != 0) {
1692       /* variable fps with a max-framerate */
1693       gst_caps_set_simple (state-&gt;caps, &quot;framerate&quot;, GST_TYPE_FRACTION, 0, 1,
1694           &quot;max-framerate&quot;, GST_TYPE_FRACTION, info-&gt;fps_n, info-&gt;fps_d, NULL);
1695     } else {
1696       /* no variable fps or no max-framerate */
1697       gst_caps_set_simple (state-&gt;caps, &quot;framerate&quot;, GST_TYPE_FRACTION,
1698           info-&gt;fps_n, info-&gt;fps_d, NULL);
1699     }
1700     if (state-&gt;codec_data)
1701       gst_caps_set_simple (state-&gt;caps, &quot;codec_data&quot;, GST_TYPE_BUFFER,
1702           state-&gt;codec_data, NULL);
1703 
1704     gst_caps_set_simple (state-&gt;caps, &quot;interlace-mode&quot;, G_TYPE_STRING,
1705         gst_video_interlace_mode_to_string (info-&gt;interlace_mode), NULL);
1706     if (info-&gt;interlace_mode == GST_VIDEO_INTERLACE_MODE_INTERLEAVED &amp;&amp;
1707         GST_VIDEO_INFO_FIELD_ORDER (info) != GST_VIDEO_FIELD_ORDER_UNKNOWN)
1708       gst_caps_set_simple (state-&gt;caps, &quot;field-order&quot;, G_TYPE_STRING,
1709           gst_video_field_order_to_string (GST_VIDEO_INFO_FIELD_ORDER (info)),
1710           NULL);
1711 
1712     colorimetry = gst_video_colorimetry_to_string (&amp;info-&gt;colorimetry);
1713     if (colorimetry)
1714       gst_caps_set_simple (state-&gt;caps, &quot;colorimetry&quot;, G_TYPE_STRING,
1715           colorimetry, NULL);
1716     g_free (colorimetry);
1717 
1718     if (info-&gt;chroma_site != GST_VIDEO_CHROMA_SITE_UNKNOWN)
1719       gst_caps_set_simple (state-&gt;caps, &quot;chroma-site&quot;, G_TYPE_STRING,
1720           gst_video_chroma_to_string (info-&gt;chroma_site), NULL);
1721 
1722     if (GST_VIDEO_INFO_MULTIVIEW_MODE (info) != GST_VIDEO_MULTIVIEW_MODE_NONE) {
1723       const gchar *caps_mview_mode =
1724           gst_video_multiview_mode_to_caps_string (GST_VIDEO_INFO_MULTIVIEW_MODE
1725           (info));
1726 
1727       gst_caps_set_simple (state-&gt;caps, &quot;multiview-mode&quot;, G_TYPE_STRING,
1728           caps_mview_mode, &quot;multiview-flags&quot;, GST_TYPE_VIDEO_MULTIVIEW_FLAGSET,
1729           GST_VIDEO_INFO_MULTIVIEW_FLAGS (info), GST_FLAG_SET_MASK_EXACT, NULL);
1730     }
1731     encoder-&gt;priv-&gt;output_state_changed = FALSE;
1732   }
1733 
1734   if (state-&gt;allocation_caps == NULL)
1735     state-&gt;allocation_caps = gst_caps_ref (state-&gt;caps);
1736 
1737   /* Push all pending pre-caps events of the oldest frame before
1738    * setting caps */
1739   frame = encoder-&gt;priv-&gt;frames ? encoder-&gt;priv-&gt;frames-&gt;data : NULL;
1740   if (frame || encoder-&gt;priv-&gt;current_frame_events) {
1741     GList **events, *l;
1742 
1743     if (frame) {
1744       events = &amp;frame-&gt;events;
1745     } else {
1746       events = &amp;encoder-&gt;priv-&gt;current_frame_events;
1747     }
1748 
1749     for (l = g_list_last (*events); l;) {
1750       GstEvent *event = GST_EVENT (l-&gt;data);
1751       GList *tmp;
1752 
1753       if (GST_EVENT_TYPE (event) &lt; GST_EVENT_CAPS) {
1754         gst_video_encoder_push_event (encoder, event);
1755         tmp = l;
1756         l = l-&gt;prev;
1757         *events = g_list_delete_link (*events, tmp);
1758       } else {
1759         l = l-&gt;prev;
1760       }
1761     }
1762   }
1763 
1764   prevcaps = gst_pad_get_current_caps (encoder-&gt;srcpad);
1765   if (!prevcaps || !gst_caps_is_equal (prevcaps, state-&gt;caps))
1766     ret = gst_pad_set_caps (encoder-&gt;srcpad, state-&gt;caps);
1767   else
1768     ret = TRUE;
1769   if (prevcaps)
1770     gst_caps_unref (prevcaps);
1771 
1772   if (!ret)
1773     goto done;
1774 
1775   query = gst_query_new_allocation (state-&gt;allocation_caps, TRUE);
1776   if (!gst_pad_peer_query (encoder-&gt;srcpad, query)) {
1777     GST_DEBUG_OBJECT (encoder, &quot;didn&#39;t get downstream ALLOCATION hints&quot;);
1778   }
1779 
1780   g_assert (klass-&gt;decide_allocation != NULL);
1781   ret = klass-&gt;decide_allocation (encoder, query);
1782 
1783   GST_DEBUG_OBJECT (encoder, &quot;ALLOCATION (%d) params: %&quot; GST_PTR_FORMAT, ret,
1784       query);
1785 
1786   if (!ret)
1787     goto no_decide_allocation;
1788 
1789   /* we got configuration from our peer or the decide_allocation method,
1790    * parse them */
1791   if (gst_query_get_n_allocation_params (query) &gt; 0) {
1792     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
1793   } else {
1794     allocator = NULL;
1795     gst_allocation_params_init (&amp;params);
1796   }
1797 
1798   if (encoder-&gt;priv-&gt;allocator)
1799     gst_object_unref (encoder-&gt;priv-&gt;allocator);
1800   encoder-&gt;priv-&gt;allocator = allocator;
1801   encoder-&gt;priv-&gt;params = params;
1802 
1803 done:
1804   if (query)
1805     gst_query_unref (query);
1806 
1807   return ret;
1808 
1809   /* Errors */
1810 no_decide_allocation:
1811   {
1812     GST_WARNING_OBJECT (encoder, &quot;Subclass failed to decide allocation&quot;);
1813     goto done;
1814   }
1815 }
1816 
1817 static gboolean
1818 gst_video_encoder_negotiate_unlocked (GstVideoEncoder * encoder)
1819 {
1820   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1821   gboolean ret = TRUE;
1822 
1823   if (G_LIKELY (klass-&gt;negotiate))
1824     ret = klass-&gt;negotiate (encoder);
1825 
1826   return ret;
1827 }
1828 
1829 /**
1830  * gst_video_encoder_negotiate:
1831  * @encoder: a #GstVideoEncoder
1832  *
1833  * Negotiate with downstream elements to currently configured #GstVideoCodecState.
1834  * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
1835  * negotiate fails.
1836  *
1837  * Returns: %TRUE if the negotiation succeeded, else %FALSE.
1838  */
1839 gboolean
1840 gst_video_encoder_negotiate (GstVideoEncoder * encoder)
1841 {
1842   GstVideoEncoderClass *klass;
1843   gboolean ret = TRUE;
1844 
1845   g_return_val_if_fail (GST_IS_VIDEO_ENCODER (encoder), FALSE);
1846   g_return_val_if_fail (encoder-&gt;priv-&gt;output_state, FALSE);
1847 
1848   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1849 
1850   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1851   gst_pad_check_reconfigure (encoder-&gt;srcpad);
1852   if (klass-&gt;negotiate) {
1853     ret = klass-&gt;negotiate (encoder);
1854     if (!ret)
1855       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1856   }
1857   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1858 
1859   return ret;
1860 }
1861 
1862 /**
1863  * gst_video_encoder_allocate_output_buffer:
1864  * @encoder: a #GstVideoEncoder
1865  * @size: size of the buffer
1866  *
1867  * Helper function that allocates a buffer to hold an encoded video frame
1868  * for @encoder&#39;s current #GstVideoCodecState.
1869  *
1870  * Returns: (transfer full): allocated buffer
1871  */
1872 GstBuffer *
1873 gst_video_encoder_allocate_output_buffer (GstVideoEncoder * encoder, gsize size)
1874 {
1875   GstBuffer *buffer;
1876   gboolean needs_reconfigure = FALSE;
1877 
1878   g_return_val_if_fail (size &gt; 0, NULL);
1879 
1880   GST_DEBUG (&quot;alloc src buffer&quot;);
1881 
1882   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1883   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
1884   if (G_UNLIKELY (encoder-&gt;priv-&gt;output_state_changed
1885           || (encoder-&gt;priv-&gt;output_state &amp;&amp; needs_reconfigure))) {
1886     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
1887       GST_DEBUG_OBJECT (encoder, &quot;Failed to negotiate, fallback allocation&quot;);
1888       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1889       goto fallback;
1890     }
1891   }
1892 
1893   buffer =
1894       gst_buffer_new_allocate (encoder-&gt;priv-&gt;allocator, size,
1895       &amp;encoder-&gt;priv-&gt;params);
1896   if (!buffer) {
1897     GST_INFO_OBJECT (encoder, &quot;couldn&#39;t allocate output buffer&quot;);
1898     goto fallback;
1899   }
1900 
1901   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1902 
1903   return buffer;
1904 
1905 fallback:
1906   buffer = gst_buffer_new_allocate (NULL, size, NULL);
1907 
1908   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1909 
1910   return buffer;
1911 }
1912 
1913 /**
1914  * gst_video_encoder_allocate_output_frame:
1915  * @encoder: a #GstVideoEncoder
1916  * @frame: a #GstVideoCodecFrame
1917  * @size: size of the buffer
1918  *
1919  * Helper function that allocates a buffer to hold an encoded video frame for @encoder&#39;s
1920  * current #GstVideoCodecState.  Subclass should already have configured video
1921  * state and set src pad caps.
1922  *
1923  * The buffer allocated here is owned by the frame and you should only
1924  * keep references to the frame, not the buffer.
1925  *
1926  * Returns: %GST_FLOW_OK if an output buffer could be allocated
1927  */
1928 GstFlowReturn
1929 gst_video_encoder_allocate_output_frame (GstVideoEncoder *
1930     encoder, GstVideoCodecFrame * frame, gsize size)
1931 {
1932   gboolean needs_reconfigure = FALSE;
1933 
1934   g_return_val_if_fail (frame-&gt;output_buffer == NULL, GST_FLOW_ERROR);
1935 
1936   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1937   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
1938   if (G_UNLIKELY (encoder-&gt;priv-&gt;output_state_changed
1939           || (encoder-&gt;priv-&gt;output_state &amp;&amp; needs_reconfigure))) {
1940     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
1941       GST_DEBUG_OBJECT (encoder, &quot;Failed to negotiate, fallback allocation&quot;);
1942       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1943     }
1944   }
1945 
1946   GST_LOG_OBJECT (encoder, &quot;alloc buffer size %&quot; G_GSIZE_FORMAT, size);
1947 
1948   frame-&gt;output_buffer =
1949       gst_buffer_new_allocate (encoder-&gt;priv-&gt;allocator, size,
1950       &amp;encoder-&gt;priv-&gt;params);
1951 
1952   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1953 
1954   return frame-&gt;output_buffer ? GST_FLOW_OK : GST_FLOW_ERROR;
1955 }
1956 
1957 static void
1958 gst_video_encoder_release_frame (GstVideoEncoder * enc,
1959     GstVideoCodecFrame * frame)
1960 {
1961   GList *link;
1962 
1963   /* unref once from the list */
1964   link = g_list_find (enc-&gt;priv-&gt;frames, frame);
1965   if (link) {
1966     gst_video_codec_frame_unref (frame);
1967     enc-&gt;priv-&gt;frames = g_list_delete_link (enc-&gt;priv-&gt;frames, link);
1968   }
1969   /* unref because this function takes ownership */
1970   gst_video_codec_frame_unref (frame);
1971 }
1972 
1973 static gboolean
1974 gst_video_encoder_transform_meta_default (GstVideoEncoder *
1975     encoder, GstVideoCodecFrame * frame, GstMeta * meta)
1976 {
1977   const GstMetaInfo *info = meta-&gt;info;
1978   const gchar *const *tags;
1979 
1980   tags = gst_meta_api_type_get_tags (info-&gt;api);
1981 
1982   if (!tags || (g_strv_length ((gchar **) tags) == 1
1983           &amp;&amp; gst_meta_api_type_has_tag (info-&gt;api,
1984               g_quark_from_string (GST_META_TAG_VIDEO_STR))))
1985     return TRUE;
1986 
1987   return FALSE;
1988 }
1989 
1990 typedef struct
1991 {
1992   GstVideoEncoder *encoder;
1993   GstVideoCodecFrame *frame;
1994 } CopyMetaData;
1995 
1996 static gboolean
1997 foreach_metadata (GstBuffer * inbuf, GstMeta ** meta, gpointer user_data)
1998 {
1999   CopyMetaData *data = user_data;
2000   GstVideoEncoder *encoder = data-&gt;encoder;
2001   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
2002   GstVideoCodecFrame *frame = data-&gt;frame;
2003   const GstMetaInfo *info = (*meta)-&gt;info;
2004   gboolean do_copy = FALSE;
2005 
2006   if (gst_meta_api_type_has_tag (info-&gt;api, _gst_meta_tag_memory)) {
2007     /* never call the transform_meta with memory specific metadata */
2008     GST_DEBUG_OBJECT (encoder, &quot;not copying memory specific metadata %s&quot;,
2009         g_type_name (info-&gt;api));
2010     do_copy = FALSE;
2011   } else if (klass-&gt;transform_meta) {
2012     do_copy = klass-&gt;transform_meta (encoder, frame, *meta);
2013     GST_DEBUG_OBJECT (encoder, &quot;transformed metadata %s: copy: %d&quot;,
2014         g_type_name (info-&gt;api), do_copy);
2015   }
2016 
2017   /* we only copy metadata when the subclass implemented a transform_meta
2018    * function and when it returns %TRUE */
2019   if (do_copy &amp;&amp; info-&gt;transform_func) {
2020     GstMetaTransformCopy copy_data = { FALSE, 0, -1 };
2021     GST_DEBUG_OBJECT (encoder, &quot;copy metadata %s&quot;, g_type_name (info-&gt;api));
2022     /* simply copy then */
2023     info-&gt;transform_func (frame-&gt;output_buffer, *meta, inbuf,
2024         _gst_meta_transform_copy, &amp;copy_data);
2025   }
2026   return TRUE;
2027 }
2028 
2029 static void
2030 gst_video_encoder_drop_frame (GstVideoEncoder * enc, GstVideoCodecFrame * frame)
2031 {
2032   GstVideoEncoderPrivate *priv = enc-&gt;priv;
2033   GstClockTime stream_time, jitter, earliest_time, qostime, timestamp;
2034   GstSegment *segment;
2035   GstMessage *qos_msg;
2036   gdouble proportion;
2037 
2038   GST_DEBUG_OBJECT (enc, &quot;dropping frame %&quot; GST_TIME_FORMAT,
2039       GST_TIME_ARGS (frame-&gt;pts));
2040 
2041   priv-&gt;dropped++;
2042 
2043   /* post QoS message */
2044   GST_OBJECT_LOCK (enc);
2045   proportion = priv-&gt;proportion;
2046   earliest_time = priv-&gt;earliest_time;
2047   GST_OBJECT_UNLOCK (enc);
2048 
2049   timestamp = frame-&gt;pts;
2050   segment = &amp;enc-&gt;output_segment;
2051   if (G_UNLIKELY (segment-&gt;format == GST_FORMAT_UNDEFINED))
2052     segment = &amp;enc-&gt;input_segment;
2053   stream_time =
2054       gst_segment_to_stream_time (segment, GST_FORMAT_TIME, timestamp);
2055   qostime = gst_segment_to_running_time (segment, GST_FORMAT_TIME, timestamp);
2056   jitter = GST_CLOCK_DIFF (qostime, earliest_time);
2057   qos_msg =
2058       gst_message_new_qos (GST_OBJECT_CAST (enc), FALSE, qostime, stream_time,
2059       timestamp, GST_CLOCK_TIME_NONE);
2060   gst_message_set_qos_values (qos_msg, jitter, proportion, 1000000);
2061   gst_message_set_qos_stats (qos_msg, GST_FORMAT_BUFFERS,
2062       priv-&gt;processed, priv-&gt;dropped);
2063   gst_element_post_message (GST_ELEMENT_CAST (enc), qos_msg);
2064 }
2065 
2066 /**
2067  * gst_video_encoder_finish_frame:
2068  * @encoder: a #GstVideoEncoder
2069  * @frame: (transfer full): an encoded #GstVideoCodecFrame
2070  *
2071  * @frame must have a valid encoded data buffer, whose metadata fields
2072  * are then appropriately set according to frame data or no buffer at
2073  * all if the frame should be dropped.
2074  * It is subsequently pushed downstream or provided to @pre_push.
2075  * In any case, the frame is considered finished and released.
2076  *
2077  * After calling this function the output buffer of the frame is to be
2078  * considered read-only. This function will also change the metadata
2079  * of the buffer.
2080  *
2081  * Returns: a #GstFlowReturn resulting from sending data downstream
2082  */
2083 GstFlowReturn
2084 gst_video_encoder_finish_frame (GstVideoEncoder * encoder,
2085     GstVideoCodecFrame * frame)
2086 {
2087   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
2088   GstFlowReturn ret = GST_FLOW_OK;
2089   GstVideoEncoderClass *encoder_class;
2090   GList *l;
2091   gboolean send_headers = FALSE;
2092   gboolean discont = (frame-&gt;presentation_frame_number == 0);
2093   GstBuffer *buffer;
2094   gboolean needs_reconfigure = FALSE;
2095 
2096   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
2097 
2098   GST_LOG_OBJECT (encoder,
2099       &quot;finish frame fpn %d&quot;, frame-&gt;presentation_frame_number);
2100 
2101   GST_LOG_OBJECT (encoder, &quot;frame PTS %&quot; GST_TIME_FORMAT
2102       &quot;, DTS %&quot; GST_TIME_FORMAT, GST_TIME_ARGS (frame-&gt;pts),
2103       GST_TIME_ARGS (frame-&gt;dts));
2104 
2105   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2106 
2107   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
2108   if (G_UNLIKELY (priv-&gt;output_state_changed || (priv-&gt;output_state
2109               &amp;&amp; needs_reconfigure))) {
2110     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
2111       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
2112       if (GST_PAD_IS_FLUSHING (encoder-&gt;srcpad))
2113         ret = GST_FLOW_FLUSHING;
2114       else
2115         ret = GST_FLOW_NOT_NEGOTIATED;
2116       goto done;
2117     }
2118   }
2119 
2120   if (G_UNLIKELY (priv-&gt;output_state == NULL))
2121     goto no_output_state;
2122 
2123   /* Push all pending events that arrived before this frame */
2124   for (l = priv-&gt;frames; l; l = l-&gt;next) {
2125     GstVideoCodecFrame *tmp = l-&gt;data;
2126 
2127     if (tmp-&gt;events) {
2128       GList *k;
2129 
2130       for (k = g_list_last (tmp-&gt;events); k; k = k-&gt;prev)
2131         gst_video_encoder_push_event (encoder, k-&gt;data);
2132       g_list_free (tmp-&gt;events);
2133       tmp-&gt;events = NULL;
2134     }
2135 
2136     if (tmp == frame)
2137       break;
2138   }
2139 
2140   gst_video_encoder_check_and_push_tags (encoder);
2141 
2142   /* no buffer data means this frame is skipped/dropped */
2143   if (!frame-&gt;output_buffer) {
2144     gst_video_encoder_drop_frame (encoder, frame);
2145     goto done;
2146   }
2147 
2148   priv-&gt;processed++;
2149 
2150   if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame) &amp;&amp; priv-&gt;force_key_unit) {
2151     GstClockTime stream_time, running_time;
2152     GstEvent *ev;
2153     ForcedKeyUnitEvent *fevt = NULL;
2154     GList *l;
2155 
2156     running_time =
2157         gst_segment_to_running_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
2158         frame-&gt;pts);
2159 
2160     GST_OBJECT_LOCK (encoder);
2161     for (l = priv-&gt;force_key_unit; l; l = l-&gt;next) {
2162       ForcedKeyUnitEvent *tmp = l-&gt;data;
2163 
2164       /* Skip non-pending keyunits */
2165       if (!tmp-&gt;pending)
2166         continue;
2167 
2168       /* Exact match using the frame id */
2169       if (frame-&gt;system_frame_number == tmp-&gt;frame_id) {
2170         fevt = tmp;
2171         break;
2172       }
2173 
2174       /* Simple case, keyunit ASAP */
2175       if (tmp-&gt;running_time == GST_CLOCK_TIME_NONE) {
2176         fevt = tmp;
2177         break;
2178       }
2179 
2180       /* Event for before this frame */
2181       if (tmp-&gt;running_time &lt;= running_time) {
2182         fevt = tmp;
2183         break;
2184       }
2185     }
2186 
2187     if (fevt) {
2188       priv-&gt;force_key_unit = g_list_remove (priv-&gt;force_key_unit, fevt);
2189     }
2190     GST_OBJECT_UNLOCK (encoder);
2191 
2192     if (fevt) {
2193       stream_time =
2194           gst_segment_to_stream_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
2195           frame-&gt;pts);
2196 
2197       ev = gst_video_event_new_downstream_force_key_unit
2198           (frame-&gt;pts, stream_time, running_time,
2199           fevt-&gt;all_headers, fevt-&gt;count);
2200 
2201       gst_video_encoder_push_event (encoder, ev);
2202 
2203       if (fevt-&gt;all_headers)
2204         send_headers = TRUE;
2205 
2206       GST_DEBUG_OBJECT (encoder,
2207           &quot;Forced key unit: running-time %&quot; GST_TIME_FORMAT
2208           &quot;, all_headers %d, count %u&quot;,
2209           GST_TIME_ARGS (running_time), fevt-&gt;all_headers, fevt-&gt;count);
2210       forced_key_unit_event_free (fevt);
2211     }
2212   }
2213 
2214   if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame)) {
2215     priv-&gt;distance_from_sync = 0;
2216     GST_BUFFER_FLAG_UNSET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DELTA_UNIT);
2217     /* For keyframes, DTS = PTS, if encoder doesn&#39;t decide otherwise */
2218     if (!GST_CLOCK_TIME_IS_VALID (frame-&gt;dts)) {
2219       frame-&gt;dts = frame-&gt;pts;
2220     }
2221   } else {
2222     GST_BUFFER_FLAG_SET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DELTA_UNIT);
2223   }
2224 
2225   /* DTS is expected monotone ascending,
2226    * so a good guess is the lowest unsent PTS (all being OK) */
2227   {
2228     GstClockTime min_ts = GST_CLOCK_TIME_NONE;
2229     GstVideoCodecFrame *oframe = NULL;
2230     gboolean seen_none = FALSE;
2231 
2232     /* some maintenance regardless */
2233     for (l = priv-&gt;frames; l; l = l-&gt;next) {
2234       GstVideoCodecFrame *tmp = l-&gt;data;
2235 
2236       if (!GST_CLOCK_TIME_IS_VALID (tmp-&gt;abidata.ABI.ts)) {
2237         seen_none = TRUE;
2238         continue;
2239       }
2240 
2241       if (!GST_CLOCK_TIME_IS_VALID (min_ts) || tmp-&gt;abidata.ABI.ts &lt; min_ts) {
2242         min_ts = tmp-&gt;abidata.ABI.ts;
2243         oframe = tmp;
2244       }
2245     }
2246     /* save a ts if needed */
2247     if (oframe &amp;&amp; oframe != frame) {
2248       oframe-&gt;abidata.ABI.ts = frame-&gt;abidata.ABI.ts;
2249     }
2250 
2251     /* and set if needed */
2252     if (!GST_CLOCK_TIME_IS_VALID (frame-&gt;dts) &amp;&amp; !seen_none) {
2253       frame-&gt;dts = min_ts;
2254       GST_DEBUG_OBJECT (encoder,
2255           &quot;no valid DTS, using oldest PTS %&quot; GST_TIME_FORMAT,
2256           GST_TIME_ARGS (frame-&gt;pts));
2257     }
2258   }
2259 
2260   frame-&gt;distance_from_sync = priv-&gt;distance_from_sync;
2261   priv-&gt;distance_from_sync++;
2262 
2263   GST_BUFFER_PTS (frame-&gt;output_buffer) = frame-&gt;pts;
2264   GST_BUFFER_DTS (frame-&gt;output_buffer) = frame-&gt;dts;
2265   GST_BUFFER_DURATION (frame-&gt;output_buffer) = frame-&gt;duration;
2266 
2267   GST_OBJECT_LOCK (encoder);
2268   /* update rate estimate */
2269   priv-&gt;bytes += gst_buffer_get_size (frame-&gt;output_buffer);
2270   if (GST_CLOCK_TIME_IS_VALID (frame-&gt;duration)) {
2271     priv-&gt;time += frame-&gt;duration;
2272   } else {
2273     /* better none than nothing valid */
2274     priv-&gt;time = GST_CLOCK_TIME_NONE;
2275   }
2276   GST_OBJECT_UNLOCK (encoder);
2277 
2278   if (G_UNLIKELY (send_headers || priv-&gt;new_headers)) {
2279     GList *tmp, *copy = NULL;
2280 
2281     GST_DEBUG_OBJECT (encoder, &quot;Sending headers&quot;);
2282 
2283     /* First make all buffers metadata-writable */
2284     for (tmp = priv-&gt;headers; tmp; tmp = tmp-&gt;next) {
2285       GstBuffer *tmpbuf = GST_BUFFER (tmp-&gt;data);
2286 
2287       copy = g_list_append (copy, gst_buffer_make_writable (tmpbuf));
2288     }
2289     g_list_free (priv-&gt;headers);
2290     priv-&gt;headers = copy;
2291 
2292     for (tmp = priv-&gt;headers; tmp; tmp = tmp-&gt;next) {
2293       GstBuffer *tmpbuf = GST_BUFFER (tmp-&gt;data);
2294 
2295       GST_OBJECT_LOCK (encoder);
2296       priv-&gt;bytes += gst_buffer_get_size (tmpbuf);
2297       GST_OBJECT_UNLOCK (encoder);
2298       if (G_UNLIKELY (discont)) {
2299         GST_LOG_OBJECT (encoder, &quot;marking discont&quot;);
2300         GST_BUFFER_FLAG_SET (tmpbuf, GST_BUFFER_FLAG_DISCONT);
2301         discont = FALSE;
2302       }
2303 
<a name="8" id="anc8"></a><span class="line-added">2304       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);</span>
2305       gst_pad_push (encoder-&gt;srcpad, gst_buffer_ref (tmpbuf));
<a name="9" id="anc9"></a><span class="line-added">2306       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);</span>
2307     }
2308     priv-&gt;new_headers = FALSE;
2309   }
2310 
2311   if (G_UNLIKELY (discont)) {
2312     GST_LOG_OBJECT (encoder, &quot;marking discont&quot;);
2313     GST_BUFFER_FLAG_SET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DISCONT);
2314   }
2315 
2316   if (encoder_class-&gt;pre_push)
2317     ret = encoder_class-&gt;pre_push (encoder, frame);
2318 
2319   if (encoder_class-&gt;transform_meta) {
2320     if (G_LIKELY (frame-&gt;input_buffer)) {
2321       CopyMetaData data;
2322 
2323       data.encoder = encoder;
2324       data.frame = frame;
2325       gst_buffer_foreach_meta (frame-&gt;input_buffer, foreach_metadata, &amp;data);
2326     } else {
2327       GST_WARNING_OBJECT (encoder,
2328           &quot;Can&#39;t copy metadata because input frame disappeared&quot;);
2329     }
2330   }
2331 
2332   /* Get an additional ref to the buffer, which is going to be pushed
2333    * downstream, the original ref is owned by the frame */
2334   if (ret == GST_FLOW_OK)
2335     buffer = gst_buffer_ref (frame-&gt;output_buffer);
2336 
2337   /* Release frame so the buffer is writable when we push it downstream
2338    * if possible, i.e. if the subclass does not hold additional references
2339    * to the frame
2340    */
2341   gst_video_encoder_release_frame (encoder, frame);
2342   frame = NULL;
2343 
<a name="10" id="anc10"></a><span class="line-modified">2344   if (ret == GST_FLOW_OK) {</span>
<span class="line-added">2345     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);</span>
2346     ret = gst_pad_push (encoder-&gt;srcpad, buffer);
<a name="11" id="anc11"></a><span class="line-added">2347     GST_VIDEO_ENCODER_STREAM_LOCK (encoder);</span>
<span class="line-added">2348   }</span>
2349 
2350 done:
2351   /* handed out */
2352   if (frame)
2353     gst_video_encoder_release_frame (encoder, frame);
2354 
2355   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2356 
2357   return ret;
2358 
2359   /* ERRORS */
2360 no_output_state:
2361   {
2362     gst_video_encoder_release_frame (encoder, frame);
2363     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2364     GST_ERROR_OBJECT (encoder, &quot;Output state was not configured&quot;);
2365     return GST_FLOW_ERROR;
2366   }
2367 }
2368 
2369 /**
2370  * gst_video_encoder_get_output_state:
2371  * @encoder: a #GstVideoEncoder
2372  *
2373  * Get the current #GstVideoCodecState
2374  *
2375  * Returns: (transfer full): #GstVideoCodecState describing format of video data.
2376  */
2377 GstVideoCodecState *
2378 gst_video_encoder_get_output_state (GstVideoEncoder * encoder)
2379 {
2380   GstVideoCodecState *state;
2381 
2382   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2383   state = gst_video_codec_state_ref (encoder-&gt;priv-&gt;output_state);
2384   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2385 
2386   return state;
2387 }
2388 
2389 /**
2390  * gst_video_encoder_set_output_state:
2391  * @encoder: a #GstVideoEncoder
2392  * @caps: (transfer full): the #GstCaps to use for the output
2393  * @reference: (allow-none) (transfer none): An optional reference @GstVideoCodecState
2394  *
2395  * Creates a new #GstVideoCodecState with the specified caps as the output state
2396  * for the encoder.
2397  * Any previously set output state on @encoder will be replaced by the newly
2398  * created one.
2399  *
2400  * The specified @caps should not contain any resolution, pixel-aspect-ratio,
2401  * framerate, codec-data, .... Those should be specified instead in the returned
2402  * #GstVideoCodecState.
2403  *
2404  * If the subclass wishes to copy over existing fields (like pixel aspect ratio,
2405  * or framerate) from an existing #GstVideoCodecState, it can be provided as a
2406  * @reference.
2407  *
2408  * If the subclass wishes to override some fields from the output state (like
2409  * pixel-aspect-ratio or framerate) it can do so on the returned #GstVideoCodecState.
2410  *
2411  * The new output state will only take effect (set on pads and buffers) starting
2412  * from the next call to #gst_video_encoder_finish_frame().
2413  *
2414  * Returns: (transfer full): the newly configured output state.
2415  */
2416 GstVideoCodecState *
2417 gst_video_encoder_set_output_state (GstVideoEncoder * encoder, GstCaps * caps,
2418     GstVideoCodecState * reference)
2419 {
2420   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
2421   GstVideoCodecState *state;
2422 
2423   g_return_val_if_fail (caps != NULL, NULL);
2424 
2425   state = _new_output_state (caps, reference);
2426   if (!state)
2427     return NULL;
2428 
2429   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2430   if (priv-&gt;output_state)
2431     gst_video_codec_state_unref (priv-&gt;output_state);
2432   priv-&gt;output_state = gst_video_codec_state_ref (state);
2433 
2434   if (priv-&gt;output_state != NULL &amp;&amp; priv-&gt;output_state-&gt;info.fps_n &gt; 0) {
2435     priv-&gt;qos_frame_duration =
2436         gst_util_uint64_scale (GST_SECOND, priv-&gt;output_state-&gt;info.fps_d,
2437         priv-&gt;output_state-&gt;info.fps_n);
2438   } else {
2439     priv-&gt;qos_frame_duration = 0;
2440   }
2441 
2442   priv-&gt;output_state_changed = TRUE;
2443   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2444 
2445   return state;
2446 }
2447 
2448 /**
2449  * gst_video_encoder_set_latency:
2450  * @encoder: a #GstVideoEncoder
2451  * @min_latency: minimum latency
2452  * @max_latency: maximum latency
2453  *
2454  * Informs baseclass of encoding latency.
2455  */
2456 void
2457 gst_video_encoder_set_latency (GstVideoEncoder * encoder,
2458     GstClockTime min_latency, GstClockTime max_latency)
2459 {
2460   g_return_if_fail (GST_CLOCK_TIME_IS_VALID (min_latency));
2461   g_return_if_fail (max_latency &gt;= min_latency);
2462 
2463   GST_OBJECT_LOCK (encoder);
2464   encoder-&gt;priv-&gt;min_latency = min_latency;
2465   encoder-&gt;priv-&gt;max_latency = max_latency;
2466   GST_OBJECT_UNLOCK (encoder);
2467 
2468   gst_element_post_message (GST_ELEMENT_CAST (encoder),
2469       gst_message_new_latency (GST_OBJECT_CAST (encoder)));
2470 }
2471 
2472 /**
2473  * gst_video_encoder_get_latency:
2474  * @encoder: a #GstVideoEncoder
2475  * @min_latency: (out) (allow-none): address of variable in which to store the
2476  *     configured minimum latency, or %NULL
2477  * @max_latency: (out) (allow-none): address of variable in which to store the
2478  *     configured maximum latency, or %NULL
2479  *
2480  * Query the configured encoding latency. Results will be returned via
2481  * @min_latency and @max_latency.
2482  */
2483 void
2484 gst_video_encoder_get_latency (GstVideoEncoder * encoder,
2485     GstClockTime * min_latency, GstClockTime * max_latency)
2486 {
2487   GST_OBJECT_LOCK (encoder);
2488   if (min_latency)
2489     *min_latency = encoder-&gt;priv-&gt;min_latency;
2490   if (max_latency)
2491     *max_latency = encoder-&gt;priv-&gt;max_latency;
2492   GST_OBJECT_UNLOCK (encoder);
2493 }
2494 
2495 /**
2496  * gst_video_encoder_get_oldest_frame:
2497  * @encoder: a #GstVideoEncoder
2498  *
2499  * Get the oldest unfinished pending #GstVideoCodecFrame
2500  *
2501  * Returns: (transfer full): oldest unfinished pending #GstVideoCodecFrame
2502  */
2503 GstVideoCodecFrame *
2504 gst_video_encoder_get_oldest_frame (GstVideoEncoder * encoder)
2505 {
2506   GstVideoCodecFrame *frame = NULL;
2507 
2508   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2509   if (encoder-&gt;priv-&gt;frames)
2510     frame = gst_video_codec_frame_ref (encoder-&gt;priv-&gt;frames-&gt;data);
2511   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2512 
2513   return (GstVideoCodecFrame *) frame;
2514 }
2515 
2516 /**
2517  * gst_video_encoder_get_frame:
<a name="12" id="anc12"></a><span class="line-modified">2518  * @encoder: a #GstVideoEncoder</span>
2519  * @frame_number: system_frame_number of a frame
2520  *
2521  * Get a pending unfinished #GstVideoCodecFrame
2522  *
2523  * Returns: (transfer full): pending unfinished #GstVideoCodecFrame identified by @frame_number.
2524  */
2525 GstVideoCodecFrame *
2526 gst_video_encoder_get_frame (GstVideoEncoder * encoder, int frame_number)
2527 {
2528   GList *g;
2529   GstVideoCodecFrame *frame = NULL;
2530 
2531   GST_DEBUG_OBJECT (encoder, &quot;frame_number : %d&quot;, frame_number);
2532 
2533   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2534   for (g = encoder-&gt;priv-&gt;frames; g; g = g-&gt;next) {
2535     GstVideoCodecFrame *tmp = g-&gt;data;
2536 
2537     if (tmp-&gt;system_frame_number == frame_number) {
2538       frame = gst_video_codec_frame_ref (tmp);
2539       break;
2540     }
2541   }
2542   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2543 
2544   return frame;
2545 }
2546 
2547 /**
2548  * gst_video_encoder_get_frames:
2549  * @encoder: a #GstVideoEncoder
2550  *
2551  * Get all pending unfinished #GstVideoCodecFrame
2552  *
2553  * Returns: (transfer full) (element-type GstVideoCodecFrame): pending unfinished #GstVideoCodecFrame.
2554  */
2555 GList *
2556 gst_video_encoder_get_frames (GstVideoEncoder * encoder)
2557 {
2558   GList *frames;
2559 
2560   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2561   frames = g_list_copy (encoder-&gt;priv-&gt;frames);
2562   g_list_foreach (frames, (GFunc) gst_video_codec_frame_ref, NULL);
2563   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2564 
2565   return frames;
2566 }
2567 
2568 /**
2569  * gst_video_encoder_merge_tags:
2570  * @encoder: a #GstVideoEncoder
2571  * @tags: (allow-none): a #GstTagList to merge, or NULL to unset
2572  *     previously-set tags
2573  * @mode: the #GstTagMergeMode to use, usually #GST_TAG_MERGE_REPLACE
2574  *
2575  * Sets the video encoder tags and how they should be merged with any
2576  * upstream stream tags. This will override any tags previously-set
2577  * with gst_video_encoder_merge_tags().
2578  *
2579  * Note that this is provided for convenience, and the subclass is
2580  * not required to use this and can still do tag handling on its own.
2581  *
2582  * MT safe.
2583  */
2584 void
2585 gst_video_encoder_merge_tags (GstVideoEncoder * encoder,
2586     const GstTagList * tags, GstTagMergeMode mode)
2587 {
2588   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2589   g_return_if_fail (tags == NULL || GST_IS_TAG_LIST (tags));
2590   g_return_if_fail (tags == NULL || mode != GST_TAG_MERGE_UNDEFINED);
2591 
2592   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2593   if (encoder-&gt;priv-&gt;tags != tags) {
2594     if (encoder-&gt;priv-&gt;tags) {
2595       gst_tag_list_unref (encoder-&gt;priv-&gt;tags);
2596       encoder-&gt;priv-&gt;tags = NULL;
2597       encoder-&gt;priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
2598     }
2599     if (tags) {
2600       encoder-&gt;priv-&gt;tags = gst_tag_list_ref ((GstTagList *) tags);
2601       encoder-&gt;priv-&gt;tags_merge_mode = mode;
2602     }
2603 
2604     GST_DEBUG_OBJECT (encoder, &quot;setting encoder tags to %&quot; GST_PTR_FORMAT,
2605         tags);
2606     encoder-&gt;priv-&gt;tags_changed = TRUE;
2607   }
2608   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2609 }
2610 
2611 /**
2612  * gst_video_encoder_get_allocator:
2613  * @encoder: a #GstVideoEncoder
2614  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
2615  * used
2616  * @params: (out) (allow-none) (transfer full): the
<a name="13" id="anc13"></a><span class="line-modified">2617  * #GstAllocationParams of @allocator</span>
2618  *
2619  * Lets #GstVideoEncoder sub-classes to know the memory @allocator
2620  * used by the base class and its @params.
2621  *
2622  * Unref the @allocator after use it.
2623  */
2624 void
2625 gst_video_encoder_get_allocator (GstVideoEncoder * encoder,
2626     GstAllocator ** allocator, GstAllocationParams * params)
2627 {
2628   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2629 
2630   if (allocator)
2631     *allocator = encoder-&gt;priv-&gt;allocator ?
2632         gst_object_ref (encoder-&gt;priv-&gt;allocator) : NULL;
2633 
2634   if (params)
2635     *params = encoder-&gt;priv-&gt;params;
2636 }
2637 
2638 /**
2639  * gst_video_encoder_set_min_pts:
2640  * @encoder: a #GstVideoEncoder
2641  * @min_pts: minimal PTS that will be passed to handle_frame
2642  *
2643  * Request minimal value for PTS passed to handle_frame.
2644  *
2645  * For streams with reordered frames this can be used to ensure that there
2646  * is enough time to accomodate first DTS, which may be less than first PTS
2647  *
<a name="14" id="anc14"></a><span class="line-modified">2648  * Since: 1.6</span>
2649  */
2650 void
2651 gst_video_encoder_set_min_pts (GstVideoEncoder * encoder, GstClockTime min_pts)
2652 {
2653   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2654   encoder-&gt;priv-&gt;min_pts = min_pts;
2655   encoder-&gt;priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
2656 }
2657 
2658 /**
2659  * gst_video_encoder_get_max_encode_time:
2660  * @encoder: a #GstVideoEncoder
2661  * @frame: a #GstVideoCodecFrame
2662  *
2663  * Determines maximum possible encoding time for @frame that will
2664  * allow it to encode and arrive in time (as determined by QoS events).
2665  * In particular, a negative result means encoding in time is no longer possible
2666  * and should therefore occur as soon/skippy as possible.
2667  *
2668  * If no QoS events have been received from downstream, or if
2669  * #GstVideoEncoder:qos is disabled this function returns #G_MAXINT64.
2670  *
2671  * Returns: max decoding time.
2672  * Since: 1.14
2673  */
2674 GstClockTimeDiff
2675 gst_video_encoder_get_max_encode_time (GstVideoEncoder *
2676     encoder, GstVideoCodecFrame * frame)
2677 {
2678   GstClockTimeDiff deadline;
2679   GstClockTime earliest_time;
2680 
2681   if (!g_atomic_int_get (&amp;encoder-&gt;priv-&gt;qos_enabled))
2682     return G_MAXINT64;
2683 
2684   GST_OBJECT_LOCK (encoder);
2685   earliest_time = encoder-&gt;priv-&gt;earliest_time;
2686   if (GST_CLOCK_TIME_IS_VALID (earliest_time)
2687       &amp;&amp; GST_CLOCK_TIME_IS_VALID (frame-&gt;deadline))
2688     deadline = GST_CLOCK_DIFF (earliest_time, frame-&gt;deadline);
2689   else
2690     deadline = G_MAXINT64;
2691 
2692   GST_LOG_OBJECT (encoder, &quot;earliest %&quot; GST_TIME_FORMAT
2693       &quot;, frame deadline %&quot; GST_TIME_FORMAT &quot;, deadline %&quot; GST_STIME_FORMAT,
2694       GST_TIME_ARGS (earliest_time), GST_TIME_ARGS (frame-&gt;deadline),
2695       GST_STIME_ARGS (deadline));
2696 
2697   GST_OBJECT_UNLOCK (encoder);
2698 
2699   return deadline;
2700 }
2701 
2702 /**
2703  * gst_video_encoder_set_qos_enabled:
2704  * @encoder: the encoder
2705  * @enabled: the new qos value.
2706  *
2707  * Configures @encoder to handle Quality-of-Service events from downstream.
2708  * Since: 1.14
2709  */
2710 void
2711 gst_video_encoder_set_qos_enabled (GstVideoEncoder * encoder, gboolean enabled)
2712 {
2713   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2714 
2715   g_atomic_int_set (&amp;encoder-&gt;priv-&gt;qos_enabled, enabled);
2716 }
2717 
2718 /**
2719  * gst_video_encoder_is_qos_enabled:
2720  * @encoder: the encoder
2721  *
2722  * Checks if @encoder is currently configured to handle Quality-of-Service
2723  * events from downstream.
2724  *
2725  * Returns: %TRUE if the encoder is configured to perform Quality-of-Service.
2726  * Since: 1.14
2727  */
2728 gboolean
2729 gst_video_encoder_is_qos_enabled (GstVideoEncoder * encoder)
2730 {
2731   gboolean res;
2732 
2733   g_return_val_if_fail (GST_IS_VIDEO_ENCODER (encoder), FALSE);
2734 
2735   res = g_atomic_int_get (&amp;encoder-&gt;priv-&gt;qos_enabled);
2736 
2737   return res;
2738 }
<a name="15" id="anc15"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="15" type="hidden" />
</body>
</html>