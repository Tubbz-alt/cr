<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/gstreamer/3rd_party/glib/glib/gthread-posix.c</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /* GLIB - Library of useful routines for C programming
   2  * Copyright (C) 1995-1997  Peter Mattis, Spencer Kimball and Josh MacDonald
   3  *
   4  * gthread.c: posix thread system implementation
   5  * Copyright 1998 Sebastian Wilhelmi; University of Karlsruhe
   6  *
   7  * This library is free software; you can redistribute it and/or
   8  * modify it under the terms of the GNU Lesser General Public
   9  * License as published by the Free Software Foundation; either
  10  * version 2.1 of the License, or (at your option) any later version.
  11  *
  12  * This library is distributed in the hope that it will be useful,
  13  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  14  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  15  * Lesser General Public License for more details.
  16  *
  17  * You should have received a copy of the GNU Lesser General Public
  18  * License along with this library; if not, see &lt;http://www.gnu.org/licenses/&gt;.
  19  */
  20 
  21 /*
  22  * Modified by the GLib Team and others 1997-2000.  See the AUTHORS
  23  * file for a list of people on the GLib Team.  See the ChangeLog
  24  * files for a list of changes.  These files are distributed with
  25  * GLib at ftp://ftp.gtk.org/pub/gtk/.
  26  */
  27 
  28 /* The GMutex, GCond and GPrivate implementations in this file are some
  29  * of the lowest-level code in GLib.  All other parts of GLib (messages,
  30  * memory, slices, etc) assume that they can freely use these facilities
  31  * without risking recursion.
  32  *
  33  * As such, these functions are NOT permitted to call any other part of
  34  * GLib.
  35  *
  36  * The thread manipulation functions (create, exit, join, etc.) have
  37  * more freedom -- they can do as they please.
  38  */
  39 
  40 #include &quot;config.h&quot;
  41 
  42 #include &quot;gthread.h&quot;
  43 
  44 #include &quot;gthreadprivate.h&quot;
  45 #include &quot;gslice.h&quot;
  46 #include &quot;gmessages.h&quot;
  47 #include &quot;gstrfuncs.h&quot;
  48 #include &quot;gmain.h&quot;
  49 #include &quot;gutils.h&quot;
  50 
  51 #include &lt;stdlib.h&gt;
  52 #include &lt;stdio.h&gt;
  53 #include &lt;string.h&gt;
  54 #include &lt;errno.h&gt;
  55 #include &lt;pthread.h&gt;
  56 
  57 #include &lt;sys/time.h&gt;
  58 #include &lt;unistd.h&gt;
  59 
<a name="1" id="anc1"></a>


  60 #ifdef HAVE_SCHED_H
  61 #include &lt;sched.h&gt;
  62 #endif
  63 #ifdef G_OS_WIN32
  64 #include &lt;windows.h&gt;
  65 #endif
  66 
  67 /* clang defines __ATOMIC_SEQ_CST but doesn&#39;t support the GCC extension */
  68 #if defined(HAVE_FUTEX) &amp;&amp; defined(__ATOMIC_SEQ_CST) &amp;&amp; !defined(__clang__)
  69 #define USE_NATIVE_MUTEX
  70 #endif
  71 
  72 static void
  73 g_thread_abort (gint         status,
  74                 const gchar *function)
  75 {
  76   fprintf (stderr, &quot;GLib (gthread-posix.c): Unexpected error from C library during &#39;%s&#39;: %s.  Aborting.\n&quot;,
  77            function, strerror (status));
  78   g_abort ();
  79 }
  80 
  81 /* {{{1 GMutex */
  82 
  83 #if !defined(USE_NATIVE_MUTEX)
  84 
  85 static pthread_mutex_t *
  86 g_mutex_impl_new (void)
  87 {
  88   pthread_mutexattr_t *pattr = NULL;
  89   pthread_mutex_t *mutex;
  90   gint status;
  91 #ifdef PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP
  92   pthread_mutexattr_t attr;
  93 #endif
  94 
  95   mutex = malloc (sizeof (pthread_mutex_t));
  96   if G_UNLIKELY (mutex == NULL)
  97     g_thread_abort (errno, &quot;malloc&quot;);
  98 
  99 #ifdef PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP
 100   pthread_mutexattr_init (&amp;attr);
 101   pthread_mutexattr_settype (&amp;attr, PTHREAD_MUTEX_ADAPTIVE_NP);
 102   pattr = &amp;attr;
 103 #endif
 104 
 105   if G_UNLIKELY ((status = pthread_mutex_init (mutex, pattr)) != 0)
 106     g_thread_abort (status, &quot;pthread_mutex_init&quot;);
 107 
 108 #ifdef PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP
 109   pthread_mutexattr_destroy (&amp;attr);
 110 #endif
 111 
 112   return mutex;
 113 }
 114 
 115 static void
 116 g_mutex_impl_free (pthread_mutex_t *mutex)
 117 {
 118   pthread_mutex_destroy (mutex);
 119   free (mutex);
 120 }
 121 
 122 static inline pthread_mutex_t *
 123 g_mutex_get_impl (GMutex *mutex)
 124 {
 125   pthread_mutex_t *impl = g_atomic_pointer_get (&amp;mutex-&gt;p);
 126 
 127   if G_UNLIKELY (impl == NULL)
 128     {
 129       impl = g_mutex_impl_new ();
 130       if (!g_atomic_pointer_compare_and_exchange (&amp;mutex-&gt;p, NULL, impl))
 131         g_mutex_impl_free (impl);
 132       impl = mutex-&gt;p;
 133     }
 134 
 135   return impl;
 136 }
 137 
 138 
 139 /**
 140  * g_mutex_init:
 141  * @mutex: an uninitialized #GMutex
 142  *
 143  * Initializes a #GMutex so that it can be used.
 144  *
 145  * This function is useful to initialize a mutex that has been
 146  * allocated on the stack, or as part of a larger structure.
 147  * It is not necessary to initialize a mutex that has been
 148  * statically allocated.
 149  *
 150  * |[&lt;!-- language=&quot;C&quot; --&gt;
 151  *   typedef struct {
 152  *     GMutex m;
 153  *     ...
 154  *   } Blob;
 155  *
 156  * Blob *b;
 157  *
 158  * b = g_new (Blob, 1);
 159  * g_mutex_init (&amp;b-&gt;m);
 160  * ]|
 161  *
 162  * To undo the effect of g_mutex_init() when a mutex is no longer
 163  * needed, use g_mutex_clear().
 164  *
 165  * Calling g_mutex_init() on an already initialized #GMutex leads
 166  * to undefined behaviour.
 167  *
 168  * Since: 2.32
 169  */
 170 void
 171 g_mutex_init (GMutex *mutex)
 172 {
 173   mutex-&gt;p = g_mutex_impl_new ();
 174 }
 175 
 176 /**
 177  * g_mutex_clear:
 178  * @mutex: an initialized #GMutex
 179  *
 180  * Frees the resources allocated to a mutex with g_mutex_init().
 181  *
 182  * This function should not be used with a #GMutex that has been
 183  * statically allocated.
 184  *
 185  * Calling g_mutex_clear() on a locked mutex leads to undefined
 186  * behaviour.
 187  *
 188  * Sine: 2.32
 189  */
 190 void
 191 g_mutex_clear (GMutex *mutex)
 192 {
 193   g_mutex_impl_free (mutex-&gt;p);
 194 }
 195 
 196 /**
 197  * g_mutex_lock:
 198  * @mutex: a #GMutex
 199  *
 200  * Locks @mutex. If @mutex is already locked by another thread, the
 201  * current thread will block until @mutex is unlocked by the other
 202  * thread.
 203  *
 204  * #GMutex is neither guaranteed to be recursive nor to be
 205  * non-recursive.  As such, calling g_mutex_lock() on a #GMutex that has
 206  * already been locked by the same thread results in undefined behaviour
 207  * (including but not limited to deadlocks).
 208  */
 209 void
 210 g_mutex_lock (GMutex *mutex)
 211 {
 212   gint status;
 213 
 214   if G_UNLIKELY ((status = pthread_mutex_lock (g_mutex_get_impl (mutex))) != 0)
 215     g_thread_abort (status, &quot;pthread_mutex_lock&quot;);
 216 }
 217 
 218 /**
 219  * g_mutex_unlock:
 220  * @mutex: a #GMutex
 221  *
 222  * Unlocks @mutex. If another thread is blocked in a g_mutex_lock()
 223  * call for @mutex, it will become unblocked and can lock @mutex itself.
 224  *
 225  * Calling g_mutex_unlock() on a mutex that is not locked by the
 226  * current thread leads to undefined behaviour.
 227  */
 228 void
 229 g_mutex_unlock (GMutex *mutex)
 230 {
 231   gint status;
 232 
 233   if G_UNLIKELY ((status = pthread_mutex_unlock (g_mutex_get_impl (mutex))) != 0)
 234     g_thread_abort (status, &quot;pthread_mutex_unlock&quot;);
 235 }
 236 
 237 /**
 238  * g_mutex_trylock:
 239  * @mutex: a #GMutex
 240  *
 241  * Tries to lock @mutex. If @mutex is already locked by another thread,
 242  * it immediately returns %FALSE. Otherwise it locks @mutex and returns
 243  * %TRUE.
 244  *
 245  * #GMutex is neither guaranteed to be recursive nor to be
 246  * non-recursive.  As such, calling g_mutex_lock() on a #GMutex that has
 247  * already been locked by the same thread results in undefined behaviour
 248  * (including but not limited to deadlocks or arbitrary return values).
 249  *
 250  * Returns: %TRUE if @mutex could be locked
 251  */
 252 gboolean
 253 g_mutex_trylock (GMutex *mutex)
 254 {
 255   gint status;
 256 
 257   if G_LIKELY ((status = pthread_mutex_trylock (g_mutex_get_impl (mutex))) == 0)
 258     return TRUE;
 259 
 260   if G_UNLIKELY (status != EBUSY)
 261     g_thread_abort (status, &quot;pthread_mutex_trylock&quot;);
 262 
 263   return FALSE;
 264 }
 265 
 266 #endif /* !defined(USE_NATIVE_MUTEX) */
 267 
 268 /* {{{1 GRecMutex */
 269 
 270 static pthread_mutex_t *
 271 g_rec_mutex_impl_new (void)
 272 {
 273   pthread_mutexattr_t attr;
 274   pthread_mutex_t *mutex;
 275 
 276   mutex = malloc (sizeof (pthread_mutex_t));
 277   if G_UNLIKELY (mutex == NULL)
 278     g_thread_abort (errno, &quot;malloc&quot;);
 279 
 280   pthread_mutexattr_init (&amp;attr);
 281   pthread_mutexattr_settype (&amp;attr, PTHREAD_MUTEX_RECURSIVE);
 282   pthread_mutex_init (mutex, &amp;attr);
 283   pthread_mutexattr_destroy (&amp;attr);
 284 
 285   return mutex;
 286 }
 287 
 288 static void
 289 g_rec_mutex_impl_free (pthread_mutex_t *mutex)
 290 {
 291   pthread_mutex_destroy (mutex);
 292   free (mutex);
 293 }
 294 
 295 static inline pthread_mutex_t *
 296 g_rec_mutex_get_impl (GRecMutex *rec_mutex)
 297 {
 298   pthread_mutex_t *impl = g_atomic_pointer_get (&amp;rec_mutex-&gt;p);
 299 
 300   if G_UNLIKELY (impl == NULL)
 301     {
 302       impl = g_rec_mutex_impl_new ();
 303       if (!g_atomic_pointer_compare_and_exchange (&amp;rec_mutex-&gt;p, NULL, impl))
 304         g_rec_mutex_impl_free (impl);
 305       impl = rec_mutex-&gt;p;
 306     }
 307 
 308   return impl;
 309 }
 310 
 311 /**
 312  * g_rec_mutex_init:
 313  * @rec_mutex: an uninitialized #GRecMutex
 314  *
 315  * Initializes a #GRecMutex so that it can be used.
 316  *
 317  * This function is useful to initialize a recursive mutex
 318  * that has been allocated on the stack, or as part of a larger
 319  * structure.
 320  *
 321  * It is not necessary to initialise a recursive mutex that has been
 322  * statically allocated.
 323  *
 324  * |[&lt;!-- language=&quot;C&quot; --&gt;
 325  *   typedef struct {
 326  *     GRecMutex m;
 327  *     ...
 328  *   } Blob;
 329  *
 330  * Blob *b;
 331  *
 332  * b = g_new (Blob, 1);
 333  * g_rec_mutex_init (&amp;b-&gt;m);
 334  * ]|
 335  *
 336  * Calling g_rec_mutex_init() on an already initialized #GRecMutex
 337  * leads to undefined behaviour.
 338  *
 339  * To undo the effect of g_rec_mutex_init() when a recursive mutex
 340  * is no longer needed, use g_rec_mutex_clear().
 341  *
 342  * Since: 2.32
 343  */
 344 void
 345 g_rec_mutex_init (GRecMutex *rec_mutex)
 346 {
 347   rec_mutex-&gt;p = g_rec_mutex_impl_new ();
 348 }
 349 
 350 /**
 351  * g_rec_mutex_clear:
 352  * @rec_mutex: an initialized #GRecMutex
 353  *
 354  * Frees the resources allocated to a recursive mutex with
 355  * g_rec_mutex_init().
 356  *
 357  * This function should not be used with a #GRecMutex that has been
 358  * statically allocated.
 359  *
 360  * Calling g_rec_mutex_clear() on a locked recursive mutex leads
 361  * to undefined behaviour.
 362  *
 363  * Sine: 2.32
 364  */
 365 void
 366 g_rec_mutex_clear (GRecMutex *rec_mutex)
 367 {
 368   g_rec_mutex_impl_free (rec_mutex-&gt;p);
 369 }
 370 
 371 /**
 372  * g_rec_mutex_lock:
 373  * @rec_mutex: a #GRecMutex
 374  *
 375  * Locks @rec_mutex. If @rec_mutex is already locked by another
 376  * thread, the current thread will block until @rec_mutex is
 377  * unlocked by the other thread. If @rec_mutex is already locked
 378  * by the current thread, the &#39;lock count&#39; of @rec_mutex is increased.
 379  * The mutex will only become available again when it is unlocked
 380  * as many times as it has been locked.
 381  *
 382  * Since: 2.32
 383  */
 384 void
 385 g_rec_mutex_lock (GRecMutex *mutex)
 386 {
 387   pthread_mutex_lock (g_rec_mutex_get_impl (mutex));
 388 }
 389 
 390 /**
 391  * g_rec_mutex_unlock:
 392  * @rec_mutex: a #GRecMutex
 393  *
 394  * Unlocks @rec_mutex. If another thread is blocked in a
 395  * g_rec_mutex_lock() call for @rec_mutex, it will become unblocked
 396  * and can lock @rec_mutex itself.
 397  *
 398  * Calling g_rec_mutex_unlock() on a recursive mutex that is not
 399  * locked by the current thread leads to undefined behaviour.
 400  *
 401  * Since: 2.32
 402  */
 403 void
 404 g_rec_mutex_unlock (GRecMutex *rec_mutex)
 405 {
 406   pthread_mutex_unlock (rec_mutex-&gt;p);
 407 }
 408 
 409 /**
 410  * g_rec_mutex_trylock:
 411  * @rec_mutex: a #GRecMutex
 412  *
 413  * Tries to lock @rec_mutex. If @rec_mutex is already locked
 414  * by another thread, it immediately returns %FALSE. Otherwise
 415  * it locks @rec_mutex and returns %TRUE.
 416  *
 417  * Returns: %TRUE if @rec_mutex could be locked
 418  *
 419  * Since: 2.32
 420  */
 421 gboolean
 422 g_rec_mutex_trylock (GRecMutex *rec_mutex)
 423 {
 424   if (pthread_mutex_trylock (g_rec_mutex_get_impl (rec_mutex)) != 0)
 425     return FALSE;
 426 
 427   return TRUE;
 428 }
 429 
 430 /* {{{1 GRWLock */
 431 
 432 static pthread_rwlock_t *
 433 g_rw_lock_impl_new (void)
 434 {
 435   pthread_rwlock_t *rwlock;
 436   gint status;
 437 
 438   rwlock = malloc (sizeof (pthread_rwlock_t));
 439   if G_UNLIKELY (rwlock == NULL)
 440     g_thread_abort (errno, &quot;malloc&quot;);
 441 
 442   if G_UNLIKELY ((status = pthread_rwlock_init (rwlock, NULL)) != 0)
 443     g_thread_abort (status, &quot;pthread_rwlock_init&quot;);
 444 
 445   return rwlock;
 446 }
 447 
 448 static void
 449 g_rw_lock_impl_free (pthread_rwlock_t *rwlock)
 450 {
 451   pthread_rwlock_destroy (rwlock);
 452   free (rwlock);
 453 }
 454 
 455 static inline pthread_rwlock_t *
 456 g_rw_lock_get_impl (GRWLock *lock)
 457 {
 458   pthread_rwlock_t *impl = g_atomic_pointer_get (&amp;lock-&gt;p);
 459 
 460   if G_UNLIKELY (impl == NULL)
 461     {
 462       impl = g_rw_lock_impl_new ();
 463       if (!g_atomic_pointer_compare_and_exchange (&amp;lock-&gt;p, NULL, impl))
 464         g_rw_lock_impl_free (impl);
 465       impl = lock-&gt;p;
 466     }
 467 
 468   return impl;
 469 }
 470 
 471 /**
 472  * g_rw_lock_init:
 473  * @rw_lock: an uninitialized #GRWLock
 474  *
 475  * Initializes a #GRWLock so that it can be used.
 476  *
 477  * This function is useful to initialize a lock that has been
 478  * allocated on the stack, or as part of a larger structure.  It is not
 479  * necessary to initialise a reader-writer lock that has been statically
 480  * allocated.
 481  *
 482  * |[&lt;!-- language=&quot;C&quot; --&gt;
 483  *   typedef struct {
 484  *     GRWLock l;
 485  *     ...
 486  *   } Blob;
 487  *
 488  * Blob *b;
 489  *
 490  * b = g_new (Blob, 1);
 491  * g_rw_lock_init (&amp;b-&gt;l);
 492  * ]|
 493  *
 494  * To undo the effect of g_rw_lock_init() when a lock is no longer
 495  * needed, use g_rw_lock_clear().
 496  *
 497  * Calling g_rw_lock_init() on an already initialized #GRWLock leads
 498  * to undefined behaviour.
 499  *
 500  * Since: 2.32
 501  */
 502 void
 503 g_rw_lock_init (GRWLock *rw_lock)
 504 {
 505   rw_lock-&gt;p = g_rw_lock_impl_new ();
 506 }
 507 
 508 /**
 509  * g_rw_lock_clear:
 510  * @rw_lock: an initialized #GRWLock
 511  *
 512  * Frees the resources allocated to a lock with g_rw_lock_init().
 513  *
 514  * This function should not be used with a #GRWLock that has been
 515  * statically allocated.
 516  *
 517  * Calling g_rw_lock_clear() when any thread holds the lock
 518  * leads to undefined behaviour.
 519  *
 520  * Sine: 2.32
 521  */
 522 void
 523 g_rw_lock_clear (GRWLock *rw_lock)
 524 {
 525   g_rw_lock_impl_free (rw_lock-&gt;p);
 526 }
 527 
 528 /**
 529  * g_rw_lock_writer_lock:
 530  * @rw_lock: a #GRWLock
 531  *
 532  * Obtain a write lock on @rw_lock. If any thread already holds
 533  * a read or write lock on @rw_lock, the current thread will block
 534  * until all other threads have dropped their locks on @rw_lock.
 535  *
 536  * Since: 2.32
 537  */
 538 void
 539 g_rw_lock_writer_lock (GRWLock *rw_lock)
 540 {
 541   int retval = pthread_rwlock_wrlock (g_rw_lock_get_impl (rw_lock));
 542 
 543   if (retval != 0)
 544     g_critical (&quot;Failed to get RW lock %p: %s&quot;, rw_lock, g_strerror (retval));
 545 }
 546 
 547 /**
 548  * g_rw_lock_writer_trylock:
 549  * @rw_lock: a #GRWLock
 550  *
 551  * Tries to obtain a write lock on @rw_lock. If any other thread holds
 552  * a read or write lock on @rw_lock, it immediately returns %FALSE.
 553  * Otherwise it locks @rw_lock and returns %TRUE.
 554  *
 555  * Returns: %TRUE if @rw_lock could be locked
 556  *
 557  * Since: 2.32
 558  */
 559 gboolean
 560 g_rw_lock_writer_trylock (GRWLock *rw_lock)
 561 {
 562   if (pthread_rwlock_trywrlock (g_rw_lock_get_impl (rw_lock)) != 0)
 563     return FALSE;
 564 
 565   return TRUE;
 566 }
 567 
 568 /**
 569  * g_rw_lock_writer_unlock:
 570  * @rw_lock: a #GRWLock
 571  *
 572  * Release a write lock on @rw_lock.
 573  *
 574  * Calling g_rw_lock_writer_unlock() on a lock that is not held
 575  * by the current thread leads to undefined behaviour.
 576  *
 577  * Since: 2.32
 578  */
 579 void
 580 g_rw_lock_writer_unlock (GRWLock *rw_lock)
 581 {
 582   pthread_rwlock_unlock (g_rw_lock_get_impl (rw_lock));
 583 }
 584 
 585 /**
 586  * g_rw_lock_reader_lock:
 587  * @rw_lock: a #GRWLock
 588  *
 589  * Obtain a read lock on @rw_lock. If another thread currently holds
<a name="2" id="anc2"></a><span class="line-modified"> 590  * the write lock on @rw_lock or blocks waiting for it, the current</span>
<span class="line-modified"> 591  * thread will block. Read locks can be taken recursively.</span>


 592  *
 593  * It is implementation-defined how many threads are allowed to
 594  * hold read locks on the same lock simultaneously. If the limit is hit,
 595  * or if a deadlock is detected, a critical warning will be emitted.
 596  *
 597  * Since: 2.32
 598  */
 599 void
 600 g_rw_lock_reader_lock (GRWLock *rw_lock)
 601 {
 602   int retval = pthread_rwlock_rdlock (g_rw_lock_get_impl (rw_lock));
 603 
 604   if (retval != 0)
 605     g_critical (&quot;Failed to get RW lock %p: %s&quot;, rw_lock, g_strerror (retval));
 606 }
 607 
 608 /**
 609  * g_rw_lock_reader_trylock:
 610  * @rw_lock: a #GRWLock
 611  *
 612  * Tries to obtain a read lock on @rw_lock and returns %TRUE if
 613  * the read lock was successfully obtained. Otherwise it
 614  * returns %FALSE.
 615  *
 616  * Returns: %TRUE if @rw_lock could be locked
 617  *
 618  * Since: 2.32
 619  */
 620 gboolean
 621 g_rw_lock_reader_trylock (GRWLock *rw_lock)
 622 {
 623   if (pthread_rwlock_tryrdlock (g_rw_lock_get_impl (rw_lock)) != 0)
 624     return FALSE;
 625 
 626   return TRUE;
 627 }
 628 
 629 /**
 630  * g_rw_lock_reader_unlock:
 631  * @rw_lock: a #GRWLock
 632  *
 633  * Release a read lock on @rw_lock.
 634  *
 635  * Calling g_rw_lock_reader_unlock() on a lock that is not held
 636  * by the current thread leads to undefined behaviour.
 637  *
 638  * Since: 2.32
 639  */
 640 void
 641 g_rw_lock_reader_unlock (GRWLock *rw_lock)
 642 {
 643   pthread_rwlock_unlock (g_rw_lock_get_impl (rw_lock));
 644 }
 645 
 646 /* {{{1 GCond */
 647 
 648 #if !defined(USE_NATIVE_MUTEX)
 649 
 650 static pthread_cond_t *
 651 g_cond_impl_new (void)
 652 {
 653   pthread_condattr_t attr;
 654   pthread_cond_t *cond;
 655   gint status;
 656 
 657   pthread_condattr_init (&amp;attr);
 658 
 659 #ifdef HAVE_PTHREAD_COND_TIMEDWAIT_RELATIVE_NP
 660 #elif defined (HAVE_PTHREAD_CONDATTR_SETCLOCK) &amp;&amp; defined (CLOCK_MONOTONIC)
 661   if G_UNLIKELY ((status = pthread_condattr_setclock (&amp;attr, CLOCK_MONOTONIC)) != 0)
 662     g_thread_abort (status, &quot;pthread_condattr_setclock&quot;);
 663 #else
 664 #error Cannot support GCond on your platform.
 665 #endif
 666 
 667   cond = malloc (sizeof (pthread_cond_t));
 668   if G_UNLIKELY (cond == NULL)
 669     g_thread_abort (errno, &quot;malloc&quot;);
 670 
 671   if G_UNLIKELY ((status = pthread_cond_init (cond, &amp;attr)) != 0)
 672     g_thread_abort (status, &quot;pthread_cond_init&quot;);
 673 
 674   pthread_condattr_destroy (&amp;attr);
 675 
 676   return cond;
 677 }
 678 
 679 static void
 680 g_cond_impl_free (pthread_cond_t *cond)
 681 {
 682   pthread_cond_destroy (cond);
 683   free (cond);
 684 }
 685 
 686 static inline pthread_cond_t *
 687 g_cond_get_impl (GCond *cond)
 688 {
 689   pthread_cond_t *impl = g_atomic_pointer_get (&amp;cond-&gt;p);
 690 
 691   if G_UNLIKELY (impl == NULL)
 692     {
 693       impl = g_cond_impl_new ();
 694       if (!g_atomic_pointer_compare_and_exchange (&amp;cond-&gt;p, NULL, impl))
 695         g_cond_impl_free (impl);
 696       impl = cond-&gt;p;
 697     }
 698 
 699   return impl;
 700 }
 701 
 702 /**
 703  * g_cond_init:
 704  * @cond: an uninitialized #GCond
 705  *
 706  * Initialises a #GCond so that it can be used.
 707  *
 708  * This function is useful to initialise a #GCond that has been
 709  * allocated as part of a larger structure.  It is not necessary to
 710  * initialise a #GCond that has been statically allocated.
 711  *
 712  * To undo the effect of g_cond_init() when a #GCond is no longer
 713  * needed, use g_cond_clear().
 714  *
 715  * Calling g_cond_init() on an already-initialised #GCond leads
 716  * to undefined behaviour.
 717  *
 718  * Since: 2.32
 719  */
 720 void
 721 g_cond_init (GCond *cond)
 722 {
 723   cond-&gt;p = g_cond_impl_new ();
 724 }
 725 
 726 /**
 727  * g_cond_clear:
 728  * @cond: an initialised #GCond
 729  *
 730  * Frees the resources allocated to a #GCond with g_cond_init().
 731  *
 732  * This function should not be used with a #GCond that has been
 733  * statically allocated.
 734  *
 735  * Calling g_cond_clear() for a #GCond on which threads are
 736  * blocking leads to undefined behaviour.
 737  *
 738  * Since: 2.32
 739  */
 740 void
 741 g_cond_clear (GCond *cond)
 742 {
 743   g_cond_impl_free (cond-&gt;p);
 744 }
 745 
 746 /**
 747  * g_cond_wait:
 748  * @cond: a #GCond
 749  * @mutex: a #GMutex that is currently locked
 750  *
 751  * Atomically releases @mutex and waits until @cond is signalled.
 752  * When this function returns, @mutex is locked again and owned by the
 753  * calling thread.
 754  *
 755  * When using condition variables, it is possible that a spurious wakeup
 756  * may occur (ie: g_cond_wait() returns even though g_cond_signal() was
 757  * not called).  It&#39;s also possible that a stolen wakeup may occur.
 758  * This is when g_cond_signal() is called, but another thread acquires
 759  * @mutex before this thread and modifies the state of the program in
 760  * such a way that when g_cond_wait() is able to return, the expected
 761  * condition is no longer met.
 762  *
 763  * For this reason, g_cond_wait() must always be used in a loop.  See
 764  * the documentation for #GCond for a complete example.
 765  **/
 766 void
 767 g_cond_wait (GCond  *cond,
 768              GMutex *mutex)
 769 {
 770   gint status;
 771 
 772   if G_UNLIKELY ((status = pthread_cond_wait (g_cond_get_impl (cond), g_mutex_get_impl (mutex))) != 0)
 773     g_thread_abort (status, &quot;pthread_cond_wait&quot;);
 774 }
 775 
 776 /**
 777  * g_cond_signal:
 778  * @cond: a #GCond
 779  *
 780  * If threads are waiting for @cond, at least one of them is unblocked.
 781  * If no threads are waiting for @cond, this function has no effect.
 782  * It is good practice to hold the same lock as the waiting thread
 783  * while calling this function, though not required.
 784  */
 785 void
 786 g_cond_signal (GCond *cond)
 787 {
 788   gint status;
 789 
 790   if G_UNLIKELY ((status = pthread_cond_signal (g_cond_get_impl (cond))) != 0)
 791     g_thread_abort (status, &quot;pthread_cond_signal&quot;);
 792 }
 793 
 794 /**
 795  * g_cond_broadcast:
 796  * @cond: a #GCond
 797  *
 798  * If threads are waiting for @cond, all of them are unblocked.
 799  * If no threads are waiting for @cond, this function has no effect.
 800  * It is good practice to lock the same mutex as the waiting threads
 801  * while calling this function, though not required.
 802  */
 803 void
 804 g_cond_broadcast (GCond *cond)
 805 {
 806   gint status;
 807 
 808   if G_UNLIKELY ((status = pthread_cond_broadcast (g_cond_get_impl (cond))) != 0)
 809     g_thread_abort (status, &quot;pthread_cond_broadcast&quot;);
 810 }
 811 
 812 /**
 813  * g_cond_wait_until:
 814  * @cond: a #GCond
 815  * @mutex: a #GMutex that is currently locked
 816  * @end_time: the monotonic time to wait until
 817  *
 818  * Waits until either @cond is signalled or @end_time has passed.
 819  *
 820  * As with g_cond_wait() it is possible that a spurious or stolen wakeup
 821  * could occur.  For that reason, waiting on a condition variable should
 822  * always be in a loop, based on an explicitly-checked predicate.
 823  *
 824  * %TRUE is returned if the condition variable was signalled (or in the
 825  * case of a spurious wakeup).  %FALSE is returned if @end_time has
 826  * passed.
 827  *
 828  * The following code shows how to correctly perform a timed wait on a
 829  * condition variable (extending the example presented in the
 830  * documentation for #GCond):
 831  *
 832  * |[&lt;!-- language=&quot;C&quot; --&gt;
 833  * gpointer
 834  * pop_data_timed (void)
 835  * {
 836  *   gint64 end_time;
 837  *   gpointer data;
 838  *
 839  *   g_mutex_lock (&amp;data_mutex);
 840  *
 841  *   end_time = g_get_monotonic_time () + 5 * G_TIME_SPAN_SECOND;
 842  *   while (!current_data)
 843  *     if (!g_cond_wait_until (&amp;data_cond, &amp;data_mutex, end_time))
 844  *       {
 845  *         // timeout has passed.
 846  *         g_mutex_unlock (&amp;data_mutex);
 847  *         return NULL;
 848  *       }
 849  *
 850  *   // there is data for us
 851  *   data = current_data;
 852  *   current_data = NULL;
 853  *
 854  *   g_mutex_unlock (&amp;data_mutex);
 855  *
 856  *   return data;
 857  * }
 858  * ]|
 859  *
 860  * Notice that the end time is calculated once, before entering the
 861  * loop and reused.  This is the motivation behind the use of absolute
 862  * time on this API -- if a relative time of 5 seconds were passed
 863  * directly to the call and a spurious wakeup occurred, the program would
 864  * have to start over waiting again (which would lead to a total wait
 865  * time of more than 5 seconds).
 866  *
 867  * Returns: %TRUE on a signal, %FALSE on a timeout
 868  * Since: 2.32
 869  **/
 870 gboolean
 871 g_cond_wait_until (GCond  *cond,
 872                    GMutex *mutex,
 873                    gint64  end_time)
 874 {
 875   struct timespec ts;
 876   gint status;
 877 
 878 #ifdef HAVE_PTHREAD_COND_TIMEDWAIT_RELATIVE_NP
 879   /* end_time is given relative to the monotonic clock as returned by
 880    * g_get_monotonic_time().
 881    *
 882    * Since this pthreads wants the relative time, convert it back again.
 883    */
 884   {
 885     gint64 now = g_get_monotonic_time ();
 886     gint64 relative;
 887 
 888     if (end_time &lt;= now)
 889       return FALSE;
 890 
 891     relative = end_time - now;
 892 
 893     ts.tv_sec = relative / 1000000;
 894     ts.tv_nsec = (relative % 1000000) * 1000;
 895 
 896     if ((status = pthread_cond_timedwait_relative_np (g_cond_get_impl (cond), g_mutex_get_impl (mutex), &amp;ts)) == 0)
 897       return TRUE;
 898   }
 899 #elif defined (HAVE_PTHREAD_CONDATTR_SETCLOCK) &amp;&amp; defined (CLOCK_MONOTONIC)
 900   /* This is the exact check we used during init to set the clock to
 901    * monotonic, so if we&#39;re in this branch, timedwait() will already be
 902    * expecting a monotonic clock.
 903    */
 904   {
 905     ts.tv_sec = end_time / 1000000;
 906     ts.tv_nsec = (end_time % 1000000) * 1000;
 907 
 908     if ((status = pthread_cond_timedwait (g_cond_get_impl (cond), g_mutex_get_impl (mutex), &amp;ts)) == 0)
 909       return TRUE;
 910   }
 911 #else
 912 #error Cannot support GCond on your platform.
 913 #endif
 914 
 915   if G_UNLIKELY (status != ETIMEDOUT)
 916     g_thread_abort (status, &quot;pthread_cond_timedwait&quot;);
 917 
 918   return FALSE;
 919 }
 920 
 921 #endif /* defined(USE_NATIVE_MUTEX) */
 922 
 923 /* {{{1 GPrivate */
 924 
 925 /**
 926  * GPrivate:
 927  *
 928  * The #GPrivate struct is an opaque data structure to represent a
 929  * thread-local data key. It is approximately equivalent to the
 930  * pthread_setspecific()/pthread_getspecific() APIs on POSIX and to
 931  * TlsSetValue()/TlsGetValue() on Windows.
 932  *
 933  * If you don&#39;t already know why you might want this functionality,
 934  * then you probably don&#39;t need it.
 935  *
 936  * #GPrivate is a very limited resource (as far as 128 per program,
 937  * shared between all libraries). It is also not possible to destroy a
 938  * #GPrivate after it has been used. As such, it is only ever acceptable
 939  * to use #GPrivate in static scope, and even then sparingly so.
 940  *
 941  * See G_PRIVATE_INIT() for a couple of examples.
 942  *
 943  * The #GPrivate structure should be considered opaque.  It should only
 944  * be accessed via the g_private_ functions.
 945  */
 946 
 947 /**
 948  * G_PRIVATE_INIT:
 949  * @notify: a #GDestroyNotify
 950  *
 951  * A macro to assist with the static initialisation of a #GPrivate.
 952  *
 953  * This macro is useful for the case that a #GDestroyNotify function
 954  * should be associated with the key.  This is needed when the key will be
 955  * used to point at memory that should be deallocated when the thread
 956  * exits.
 957  *
 958  * Additionally, the #GDestroyNotify will also be called on the previous
 959  * value stored in the key when g_private_replace() is used.
 960  *
 961  * If no #GDestroyNotify is needed, then use of this macro is not
 962  * required -- if the #GPrivate is declared in static scope then it will
 963  * be properly initialised by default (ie: to all zeros).  See the
 964  * examples below.
 965  *
 966  * |[&lt;!-- language=&quot;C&quot; --&gt;
 967  * static GPrivate name_key = G_PRIVATE_INIT (g_free);
 968  *
 969  * // return value should not be freed
 970  * const gchar *
 971  * get_local_name (void)
 972  * {
 973  *   return g_private_get (&amp;name_key);
 974  * }
 975  *
 976  * void
 977  * set_local_name (const gchar *name)
 978  * {
 979  *   g_private_replace (&amp;name_key, g_strdup (name));
 980  * }
 981  *
 982  *
 983  * static GPrivate count_key;   // no free function
 984  *
 985  * gint
 986  * get_local_count (void)
 987  * {
 988  *   return GPOINTER_TO_INT (g_private_get (&amp;count_key));
 989  * }
 990  *
 991  * void
 992  * set_local_count (gint count)
 993  * {
 994  *   g_private_set (&amp;count_key, GINT_TO_POINTER (count));
 995  * }
 996  * ]|
 997  *
 998  * Since: 2.32
 999  **/
1000 
1001 static pthread_key_t *
1002 g_private_impl_new (GDestroyNotify notify)
1003 {
1004   pthread_key_t *key;
1005   gint status;
1006 
1007   key = malloc (sizeof (pthread_key_t));
1008   if G_UNLIKELY (key == NULL)
1009     g_thread_abort (errno, &quot;malloc&quot;);
1010   status = pthread_key_create (key, notify);
1011   if G_UNLIKELY (status != 0)
1012     g_thread_abort (status, &quot;pthread_key_create&quot;);
1013 
1014   return key;
1015 }
1016 
1017 static void
1018 g_private_impl_free (pthread_key_t *key)
1019 {
1020   gint status;
1021 
1022   status = pthread_key_delete (*key);
1023   if G_UNLIKELY (status != 0)
1024     g_thread_abort (status, &quot;pthread_key_delete&quot;);
1025   free (key);
1026 }
1027 
1028 static inline pthread_key_t *
1029 g_private_get_impl (GPrivate *key)
1030 {
1031   pthread_key_t *impl = g_atomic_pointer_get (&amp;key-&gt;p);
1032 
1033   if G_UNLIKELY (impl == NULL)
1034     {
1035       impl = g_private_impl_new (key-&gt;notify);
1036       if (!g_atomic_pointer_compare_and_exchange (&amp;key-&gt;p, NULL, impl))
1037         {
1038           g_private_impl_free (impl);
1039           impl = key-&gt;p;
1040         }
1041     }
1042 
1043   return impl;
1044 }
1045 
1046 /**
1047  * g_private_get:
1048  * @key: a #GPrivate
1049  *
1050  * Returns the current value of the thread local variable @key.
1051  *
1052  * If the value has not yet been set in this thread, %NULL is returned.
1053  * Values are never copied between threads (when a new thread is
1054  * created, for example).
1055  *
1056  * Returns: the thread-local value
1057  */
1058 gpointer
1059 g_private_get (GPrivate *key)
1060 {
1061   /* quote POSIX: No errors are returned from pthread_getspecific(). */
1062   return pthread_getspecific (*g_private_get_impl (key));
1063 }
1064 
1065 /**
1066  * g_private_set:
1067  * @key: a #GPrivate
1068  * @value: the new value
1069  *
1070  * Sets the thread local variable @key to have the value @value in the
1071  * current thread.
1072  *
1073  * This function differs from g_private_replace() in the following way:
1074  * the #GDestroyNotify for @key is not called on the old value.
1075  */
1076 void
1077 g_private_set (GPrivate *key,
1078                gpointer  value)
1079 {
1080   gint status;
1081 
1082   if G_UNLIKELY ((status = pthread_setspecific (*g_private_get_impl (key), value)) != 0)
1083     g_thread_abort (status, &quot;pthread_setspecific&quot;);
1084 }
1085 
1086 /**
1087  * g_private_replace:
1088  * @key: a #GPrivate
1089  * @value: the new value
1090  *
1091  * Sets the thread local variable @key to have the value @value in the
1092  * current thread.
1093  *
1094  * This function differs from g_private_set() in the following way: if
1095  * the previous value was non-%NULL then the #GDestroyNotify handler for
1096  * @key is run on it.
1097  *
1098  * Since: 2.32
1099  **/
1100 void
1101 g_private_replace (GPrivate *key,
1102                    gpointer  value)
1103 {
1104   pthread_key_t *impl = g_private_get_impl (key);
1105   gpointer old;
1106   gint status;
1107 
1108   old = pthread_getspecific (*impl);
1109   if (old &amp;&amp; key-&gt;notify)
1110     key-&gt;notify (old);
1111 
1112   if G_UNLIKELY ((status = pthread_setspecific (*impl, value)) != 0)
1113     g_thread_abort (status, &quot;pthread_setspecific&quot;);
1114 }
1115 
1116 /* {{{1 GThread */
1117 
<a name="3" id="anc3"></a><span class="line-modified">1118 #define posix_check_err(err, name) G_STMT_START{            \</span>
<span class="line-modified">1119   int error = (err);                            \</span>
<span class="line-modified">1120   if (error)                                \</span>
<span class="line-modified">1121     g_error (&quot;file %s: line %d (%s): error &#39;%s&#39; during &#39;%s&#39;&quot;,       \</span>
<span class="line-modified">1122            __FILE__, __LINE__, G_STRFUNC,               \</span>
<span class="line-modified">1123            g_strerror (error), name);                   \</span>
1124   }G_STMT_END
1125 
1126 #define posix_check_cmd(cmd) posix_check_err (cmd, #cmd)
1127 
1128 typedef struct
1129 {
1130   GRealThread thread;
1131 
1132   pthread_t system_thread;
1133   gboolean  joined;
1134   GMutex    lock;
1135 } GThreadPosix;
1136 
1137 void
1138 g_system_thread_free (GRealThread *thread)
1139 {
1140   GThreadPosix *pt = (GThreadPosix *) thread;
1141 
1142   if (!pt-&gt;joined)
1143     pthread_detach (pt-&gt;system_thread);
1144 
1145   g_mutex_clear (&amp;pt-&gt;lock);
1146 
1147   g_slice_free (GThreadPosix, pt);
1148 }
1149 
1150 GRealThread *
<a name="4" id="anc4"></a><span class="line-modified">1151 g_system_thread_new (GThreadFunc   thread_func,</span>
1152                      gulong        stack_size,
<a name="5" id="anc5"></a>


1153                      GError      **error)
1154 {
1155   GThreadPosix *thread;
<a name="6" id="anc6"></a>
1156   pthread_attr_t attr;
1157   gint ret;
1158 
1159   thread = g_slice_new0 (GThreadPosix);
<a name="7" id="anc7"></a>






1160 
1161   posix_check_cmd (pthread_attr_init (&amp;attr));
1162 
1163 #ifdef HAVE_PTHREAD_ATTR_SETSTACKSIZE
1164   if (stack_size)
1165     {
1166 #ifdef _SC_THREAD_STACK_MIN
1167       long min_stack_size = sysconf (_SC_THREAD_STACK_MIN);
1168       if (min_stack_size &gt;= 0)
<a name="8" id="anc8"></a><span class="line-modified">1169         stack_size = MAX (min_stack_size, stack_size);</span>
1170 #endif /* _SC_THREAD_STACK_MIN */
1171       /* No error check here, because some systems can&#39;t do it and
1172        * we simply don&#39;t want threads to fail because of that. */
1173       pthread_attr_setstacksize (&amp;attr, stack_size);
1174     }
1175 #endif /* HAVE_PTHREAD_ATTR_SETSTACKSIZE */
1176 
<a name="9" id="anc9"></a><span class="line-modified">1177   ret = pthread_create (&amp;thread-&gt;system_thread, &amp;attr, (void* (*)(void*))thread_func, thread);</span>
1178 
1179   posix_check_cmd (pthread_attr_destroy (&amp;attr));
1180 
1181   if (ret == EAGAIN)
1182     {
1183       g_set_error (error, G_THREAD_ERROR, G_THREAD_ERROR_AGAIN,
1184                    &quot;Error creating thread: %s&quot;, g_strerror (ret));
1185       g_slice_free (GThreadPosix, thread);
1186       return NULL;
1187     }
1188 
1189   posix_check_err (ret, &quot;pthread_create&quot;);
1190 
1191   g_mutex_init (&amp;thread-&gt;lock);
1192 
1193   return (GRealThread *) thread;
1194 }
1195 
1196 /**
1197  * g_thread_yield:
1198  *
1199  * Causes the calling thread to voluntarily relinquish the CPU, so
1200  * that other threads can run.
1201  *
1202  * This function is often used as a method to make busy wait less evil.
1203  */
1204 void
1205 g_thread_yield (void)
1206 {
1207   sched_yield ();
1208 }
1209 
1210 void
1211 g_system_thread_wait (GRealThread *thread)
1212 {
1213   GThreadPosix *pt = (GThreadPosix *) thread;
1214 
1215   g_mutex_lock (&amp;pt-&gt;lock);
1216 
1217   if (!pt-&gt;joined)
1218     {
1219       posix_check_cmd (pthread_join (pt-&gt;system_thread, NULL));
1220       pt-&gt;joined = TRUE;
1221     }
1222 
1223   g_mutex_unlock (&amp;pt-&gt;lock);
1224 }
1225 
1226 void
1227 g_system_thread_exit (void)
1228 {
1229   pthread_exit (NULL);
1230 }
1231 
1232 void
1233 g_system_thread_set_name (const gchar *name)
1234 {
<a name="10" id="anc10"></a><span class="line-modified">1235 #if defined(HAVE_PTHREAD_SETNAME_NP_WITH_TID)</span>
<span class="line-removed">1236   pthread_setname_np (pthread_self(), name); /* on Linux and Solaris */</span>
<span class="line-removed">1237 #elif defined(HAVE_PTHREAD_SETNAME_NP_WITHOUT_TID)</span>
1238   pthread_setname_np (name); /* on OS X and iOS */
<a name="11" id="anc11"></a>





1239 #endif
1240 }
1241 
1242 /* {{{1 GMutex and GCond futex implementation */
1243 
1244 #if defined(USE_NATIVE_MUTEX)
1245 
1246 #include &lt;linux/futex.h&gt;
1247 #include &lt;sys/syscall.h&gt;
1248 
1249 #ifndef FUTEX_WAIT_PRIVATE
1250 #define FUTEX_WAIT_PRIVATE FUTEX_WAIT
1251 #define FUTEX_WAKE_PRIVATE FUTEX_WAKE
1252 #endif
1253 
1254 /* We should expand the set of operations available in gatomic once we
1255  * have better C11 support in GCC in common distributions (ie: 4.9).
1256  *
1257  * Before then, let&#39;s define a couple of useful things for our own
1258  * purposes...
1259  */
1260 
1261 #define exchange_acquire(ptr, new) \
1262   __atomic_exchange_4((ptr), (new), __ATOMIC_ACQUIRE)
1263 #define compare_exchange_acquire(ptr, old, new) \
1264   __atomic_compare_exchange_4((ptr), (old), (new), 0, __ATOMIC_ACQUIRE, __ATOMIC_RELAXED)
1265 
1266 #define exchange_release(ptr, new) \
1267   __atomic_exchange_4((ptr), (new), __ATOMIC_RELEASE)
1268 #define store_release(ptr, new) \
1269   __atomic_store_4((ptr), (new), __ATOMIC_RELEASE)
1270 
1271 /* Our strategy for the mutex is pretty simple:
1272  *
1273  *  0: not in use
1274  *
1275  *  1: acquired by one thread only, no contention
1276  *
1277  *  &gt; 1: contended
1278  *
1279  *
1280  * As such, attempting to acquire the lock should involve an increment.
1281  * If we find that the previous value was 0 then we can return
1282  * immediately.
1283  *
1284  * On unlock, we always store 0 to indicate that the lock is available.
1285  * If the value there was 1 before then we didn&#39;t have contention and
1286  * can return immediately.  If the value was something other than 1 then
1287  * we have the contended case and need to wake a waiter.
1288  *
1289  * If it was not 0 then there is another thread holding it and we must
1290  * wait.  We must always ensure that we mark a value &gt;1 while we are
1291  * waiting in order to instruct the holder to do a wake operation on
1292  * unlock.
1293  */
1294 
1295 void
1296 g_mutex_init (GMutex *mutex)
1297 {
1298   mutex-&gt;i[0] = 0;
1299 }
1300 
1301 void
1302 g_mutex_clear (GMutex *mutex)
1303 {
1304   if G_UNLIKELY (mutex-&gt;i[0] != 0)
1305     {
1306       fprintf (stderr, &quot;g_mutex_clear() called on uninitialised or locked mutex\n&quot;);
1307       g_abort ();
1308     }
1309 }
1310 
1311 static void __attribute__((noinline))
1312 g_mutex_lock_slowpath (GMutex *mutex)
1313 {
1314   /* Set to 2 to indicate contention.  If it was zero before then we
1315    * just acquired the lock.
1316    *
1317    * Otherwise, sleep for as long as the 2 remains...
1318    */
1319   while (exchange_acquire (&amp;mutex-&gt;i[0], 2) != 0)
1320     syscall (__NR_futex, &amp;mutex-&gt;i[0], (gsize) FUTEX_WAIT_PRIVATE, (gsize) 2, NULL);
1321 }
1322 
1323 static void __attribute__((noinline))
1324 g_mutex_unlock_slowpath (GMutex *mutex,
1325                          guint   prev)
1326 {
1327   /* We seem to get better code for the uncontended case by splitting
1328    * this out...
1329    */
1330   if G_UNLIKELY (prev == 0)
1331     {
1332       fprintf (stderr, &quot;Attempt to unlock mutex that was not locked\n&quot;);
1333       g_abort ();
1334     }
1335 
1336   syscall (__NR_futex, &amp;mutex-&gt;i[0], (gsize) FUTEX_WAKE_PRIVATE, (gsize) 1, NULL);
1337 }
1338 
1339 void
1340 g_mutex_lock (GMutex *mutex)
1341 {
1342   /* 0 -&gt; 1 and we&#39;re done.  Anything else, and we need to wait... */
1343   if G_UNLIKELY (g_atomic_int_add (&amp;mutex-&gt;i[0], 1) != 0)
1344     g_mutex_lock_slowpath (mutex);
1345 }
1346 
1347 void
1348 g_mutex_unlock (GMutex *mutex)
1349 {
1350   guint prev;
1351 
1352   prev = exchange_release (&amp;mutex-&gt;i[0], 0);
1353 
1354   /* 1-&gt; 0 and we&#39;re done.  Anything else and we need to signal... */
1355   if G_UNLIKELY (prev != 1)
1356     g_mutex_unlock_slowpath (mutex, prev);
1357 }
1358 
1359 gboolean
1360 g_mutex_trylock (GMutex *mutex)
1361 {
1362   guint zero = 0;
1363 
1364   /* We don&#39;t want to touch the value at all unless we can move it from
1365    * exactly 0 to 1.
1366    */
1367   return compare_exchange_acquire (&amp;mutex-&gt;i[0], &amp;zero, 1);
1368 }
1369 
1370 /* Condition variables are implemented in a rather simple way as well.
1371  * In many ways, futex() as an abstraction is even more ideally suited
1372  * to condition variables than it is to mutexes.
1373  *
1374  * We store a generation counter.  We sample it with the lock held and
1375  * unlock before sleeping on the futex.
1376  *
1377  * Signalling simply involves increasing the counter and making the
1378  * appropriate futex call.
1379  *
1380  * The only thing that is the slightest bit complicated is timed waits
1381  * because we must convert our absolute time to relative.
1382  */
1383 
1384 void
1385 g_cond_init (GCond *cond)
1386 {
1387   cond-&gt;i[0] = 0;
1388 }
1389 
1390 void
1391 g_cond_clear (GCond *cond)
1392 {
1393 }
1394 
1395 void
1396 g_cond_wait (GCond  *cond,
1397              GMutex *mutex)
1398 {
1399   guint sampled = g_atomic_int_get (&amp;cond-&gt;i[0]);
1400 
1401   g_mutex_unlock (mutex);
1402   syscall (__NR_futex, &amp;cond-&gt;i[0], (gsize) FUTEX_WAIT_PRIVATE, (gsize) sampled, NULL);
1403   g_mutex_lock (mutex);
1404 }
1405 
1406 void
1407 g_cond_signal (GCond *cond)
1408 {
1409   g_atomic_int_inc (&amp;cond-&gt;i[0]);
1410 
1411   syscall (__NR_futex, &amp;cond-&gt;i[0], (gsize) FUTEX_WAKE_PRIVATE, (gsize) 1, NULL);
1412 }
1413 
1414 void
1415 g_cond_broadcast (GCond *cond)
1416 {
1417   g_atomic_int_inc (&amp;cond-&gt;i[0]);
1418 
1419   syscall (__NR_futex, &amp;cond-&gt;i[0], (gsize) FUTEX_WAKE_PRIVATE, (gsize) INT_MAX, NULL);
1420 }
1421 
1422 gboolean
1423 g_cond_wait_until (GCond  *cond,
1424                    GMutex *mutex,
1425                    gint64  end_time)
1426 {
1427   struct timespec now;
1428   struct timespec span;
1429   guint sampled;
1430   int res;
<a name="12" id="anc12"></a>
1431 
1432   if (end_time &lt; 0)
1433     return FALSE;
1434 
1435   clock_gettime (CLOCK_MONOTONIC, &amp;now);
1436   span.tv_sec = (end_time / 1000000) - now.tv_sec;
1437   span.tv_nsec = ((end_time % 1000000) * 1000) - now.tv_nsec;
1438   if (span.tv_nsec &lt; 0)
1439     {
1440       span.tv_nsec += 1000000000;
1441       span.tv_sec--;
1442     }
1443 
1444   if (span.tv_sec &lt; 0)
1445     return FALSE;
1446 
1447   sampled = cond-&gt;i[0];
1448   g_mutex_unlock (mutex);
1449   res = syscall (__NR_futex, &amp;cond-&gt;i[0], (gsize) FUTEX_WAIT_PRIVATE, (gsize) sampled, &amp;span);
<a name="13" id="anc13"></a>
1450   g_mutex_lock (mutex);
1451 
<a name="14" id="anc14"></a><span class="line-modified">1452   return (res &lt; 0 &amp;&amp; errno == ETIMEDOUT) ? FALSE : TRUE;</span>
1453 }
1454 
1455 #endif
1456 
1457   /* {{{1 Epilogue */
1458 /* vim:set foldmethod=marker: */
<a name="15" id="anc15"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="15" type="hidden" />
</body>
</html>