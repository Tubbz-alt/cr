<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/convertframe.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /* Small helper element for format conversion
  2  * Copyright (C) 2005 Tim-Philipp MÃ¼ller &lt;tim centricular net&gt;
  3  * Copyright (C) 2010 Brandon Lewis &lt;brandon.lewis@collabora.co.uk&gt;
  4  * Copyright (C) 2010 Edward Hervey &lt;edward.hervey@collabora.co.uk&gt;
  5  *
  6  * This library is free software; you can redistribute it and/or
  7  * modify it under the terms of the GNU Library General Public
  8  * License as published by the Free Software Foundation; either
  9  * version 2 of the License, or (at your option) any later version.
 10  *
 11  * This library is distributed in the hope that it will be useful,
 12  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  * Library General Public License for more details.
 15  *
 16  * You should have received a copy of the GNU Library General Public
 17  * License along with this library; if not, write to the
 18  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
 19  * Boston, MA 02110-1301, USA.
 20  */
<a name="1" id="anc1"></a><span class="line-added"> 21 #ifdef HAVE_CONFIG_H</span>
<span class="line-added"> 22 #include &quot;config.h&quot;</span>
<span class="line-added"> 23 #endif</span>
 24 
 25 #include &lt;string.h&gt;
 26 #include &quot;video.h&quot;
 27 
 28 static gboolean
 29 caps_are_raw (const GstCaps * caps)
 30 {
 31   guint i, len;
 32 
 33   len = gst_caps_get_size (caps);
 34 
 35   for (i = 0; i &lt; len; i++) {
 36     GstStructure *st = gst_caps_get_structure (caps, i);
 37     if (gst_structure_has_name (st, &quot;video/x-raw&quot;))
 38       return TRUE;
 39   }
 40 
 41   return FALSE;
 42 }
 43 
 44 static gboolean
 45 create_element (const gchar * factory_name, GstElement ** element,
 46     GError ** err)
 47 {
 48   *element = gst_element_factory_make (factory_name, NULL);
 49   if (*element)
 50     return TRUE;
 51 
 52   if (err &amp;&amp; *err == NULL) {
 53     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 54         &quot;cannot create element &#39;%s&#39; - please check your GStreamer installation&quot;,
 55         factory_name);
 56   }
 57 
 58   return FALSE;
 59 }
 60 
 61 static GstElement *
 62 get_encoder (const GstCaps * caps, GError ** err)
 63 {
 64   GList *encoders = NULL;
 65   GList *filtered = NULL;
 66   GstElementFactory *factory = NULL;
 67   GstElement *encoder = NULL;
 68 
 69   encoders =
 70       gst_element_factory_list_get_elements (GST_ELEMENT_FACTORY_TYPE_ENCODER |
 71       GST_ELEMENT_FACTORY_TYPE_MEDIA_IMAGE, GST_RANK_NONE);
 72 
 73   if (encoders == NULL) {
 74     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 75         &quot;Cannot find any image encoder&quot;);
 76     goto fail;
 77   }
 78 
 79   GST_INFO (&quot;got factory list %p&quot;, encoders);
 80   gst_plugin_feature_list_debug (encoders);
 81 
 82   filtered =
 83       gst_element_factory_list_filter (encoders, caps, GST_PAD_SRC, FALSE);
 84   GST_INFO (&quot;got filtered list %p&quot;, filtered);
 85 
 86   if (filtered == NULL) {
 87     gchar *tmp = gst_caps_to_string (caps);
 88     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 89         &quot;Cannot find any image encoder for caps %s&quot;, tmp);
 90     g_free (tmp);
 91     goto fail;
 92   }
 93 
 94   gst_plugin_feature_list_debug (filtered);
 95 
 96   factory = (GstElementFactory *) filtered-&gt;data;
 97 
 98   GST_INFO (&quot;got factory %p&quot;, factory);
 99   encoder = gst_element_factory_create (factory, NULL);
100 
101   GST_INFO (&quot;created encoder element %p, %s&quot;, encoder,
102       GST_ELEMENT_NAME (encoder));
103 
104 fail:
105   if (encoders)
106     gst_plugin_feature_list_free (encoders);
107   if (filtered)
108     gst_plugin_feature_list_free (filtered);
109 
110   return encoder;
111 }
112 
113 static GstElement *
114 build_convert_frame_pipeline (GstElement ** src_element,
115     GstElement ** sink_element, const GstCaps * from_caps,
116     GstVideoCropMeta * cmeta, const GstCaps * to_caps, GError ** err)
117 {
118   GstElement *vcrop = NULL, *csp = NULL, *csp2 = NULL, *vscale = NULL;
119   GstElement *src = NULL, *sink = NULL, *encoder = NULL, *pipeline;
120   GstVideoInfo info;
121   GError *error = NULL;
122 
123   if (cmeta) {
124     if (!create_element (&quot;videocrop&quot;, &amp;vcrop, &amp;error)) {
125       g_error_free (error);
126       g_warning
127           (&quot;build_convert_frame_pipeline: Buffer has crop metadata but videocrop element is not found. Cropping will be disabled&quot;);
128     } else {
129       if (!create_element (&quot;videoconvert&quot;, &amp;csp2, &amp;error))
130         goto no_elements;
131     }
132   }
133 
134   /* videoscale is here to correct for the pixel-aspect-ratio for us */
135   GST_DEBUG (&quot;creating elements&quot;);
136   if (!create_element (&quot;appsrc&quot;, &amp;src, &amp;error) ||
137       !create_element (&quot;videoconvert&quot;, &amp;csp, &amp;error) ||
138       !create_element (&quot;videoscale&quot;, &amp;vscale, &amp;error) ||
139       !create_element (&quot;appsink&quot;, &amp;sink, &amp;error))
140     goto no_elements;
141 
142   pipeline = gst_pipeline_new (&quot;videoconvert-pipeline&quot;);
143   if (pipeline == NULL)
144     goto no_pipeline;
145 
146   /* Add black borders if necessary to keep the DAR */
147   g_object_set (vscale, &quot;add-borders&quot;, TRUE, NULL);
148 
149   GST_DEBUG (&quot;adding elements&quot;);
150   gst_bin_add_many (GST_BIN (pipeline), src, csp, vscale, sink, NULL);
151   if (vcrop)
152     gst_bin_add_many (GST_BIN (pipeline), vcrop, csp2, NULL);
153 
154   /* set caps */
155   g_object_set (src, &quot;caps&quot;, from_caps, NULL);
156   if (vcrop) {
157     gst_video_info_from_caps (&amp;info, from_caps);
158     g_object_set (vcrop, &quot;left&quot;, cmeta-&gt;x, NULL);
159     g_object_set (vcrop, &quot;top&quot;, cmeta-&gt;y, NULL);
160     g_object_set (vcrop, &quot;right&quot;, GST_VIDEO_INFO_WIDTH (&amp;info) - cmeta-&gt;width,
161         NULL);
162     g_object_set (vcrop, &quot;bottom&quot;,
163         GST_VIDEO_INFO_HEIGHT (&amp;info) - cmeta-&gt;height, NULL);
164     GST_DEBUG (&quot;crop meta [x,y,width,height]: %d %d %d %d&quot;, cmeta-&gt;x, cmeta-&gt;y,
165         cmeta-&gt;width, cmeta-&gt;height);
166   }
167   g_object_set (sink, &quot;caps&quot;, to_caps, NULL);
168 
169   /* FIXME: linking is still way too expensive, profile this properly */
170   if (vcrop) {
171     GST_DEBUG (&quot;linking src-&gt;csp2&quot;);
172     if (!gst_element_link_pads (src, &quot;src&quot;, csp2, &quot;sink&quot;))
173       goto link_failed;
174 
175     GST_DEBUG (&quot;linking csp2-&gt;vcrop&quot;);
176     if (!gst_element_link_pads (csp2, &quot;src&quot;, vcrop, &quot;sink&quot;))
177       goto link_failed;
178 
179     GST_DEBUG (&quot;linking vcrop-&gt;csp&quot;);
180     if (!gst_element_link_pads (vcrop, &quot;src&quot;, csp, &quot;sink&quot;))
181       goto link_failed;
182   } else {
183     GST_DEBUG (&quot;linking src-&gt;csp&quot;);
184     if (!gst_element_link_pads (src, &quot;src&quot;, csp, &quot;sink&quot;))
185       goto link_failed;
186   }
187 
188   GST_DEBUG (&quot;linking csp-&gt;vscale&quot;);
189   if (!gst_element_link_pads_full (csp, &quot;src&quot;, vscale, &quot;sink&quot;,
190           GST_PAD_LINK_CHECK_NOTHING))
191     goto link_failed;
192 
193   if (caps_are_raw (to_caps)) {
194     GST_DEBUG (&quot;linking vscale-&gt;sink&quot;);
195 
196     if (!gst_element_link_pads_full (vscale, &quot;src&quot;, sink, &quot;sink&quot;,
197             GST_PAD_LINK_CHECK_NOTHING))
198       goto link_failed;
199   } else {
200     encoder = get_encoder (to_caps, &amp;error);
201     if (!encoder)
202       goto no_encoder;
203     gst_bin_add (GST_BIN (pipeline), encoder);
204 
205     GST_DEBUG (&quot;linking vscale-&gt;encoder&quot;);
206     if (!gst_element_link (vscale, encoder))
207       goto link_failed;
208 
209     GST_DEBUG (&quot;linking encoder-&gt;sink&quot;);
210     if (!gst_element_link_pads (encoder, &quot;src&quot;, sink, &quot;sink&quot;))
211       goto link_failed;
212   }
213 
214   g_object_set (src, &quot;emit-signals&quot;, TRUE, NULL);
215   g_object_set (sink, &quot;emit-signals&quot;, TRUE, NULL);
216 
217   *src_element = src;
218   *sink_element = sink;
219 
220   return pipeline;
221   /* ERRORS */
222 no_encoder:
223   {
224     gst_object_unref (pipeline);
225 
226     GST_ERROR (&quot;could not find an encoder for provided caps&quot;);
227     if (err)
228       *err = error;
229     else
230       g_error_free (error);
231 
232     return NULL;
233   }
234 no_elements:
235   {
236     if (src)
237       gst_object_unref (src);
238     if (vcrop)
239       gst_object_unref (vcrop);
240     if (csp)
241       gst_object_unref (csp);
242     if (csp2)
243       gst_object_unref (csp2);
244     if (vscale)
245       gst_object_unref (vscale);
246     if (sink)
247       gst_object_unref (sink);
248     GST_ERROR (&quot;Could not convert video frame: %s&quot;, error-&gt;message);
249     if (err)
250       *err = error;
251     else
252       g_error_free (error);
253     return NULL;
254   }
255 no_pipeline:
256   {
257     gst_object_unref (src);
258     if (vcrop)
259       gst_object_unref (vcrop);
260     gst_object_unref (csp);
261     if (csp2)
262       gst_object_unref (csp2);
263     gst_object_unref (vscale);
264     gst_object_unref (sink);
265 
266     GST_ERROR (&quot;Could not convert video frame: no pipeline (unknown error)&quot;);
267     if (err)
268       *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
269           &quot;Could not convert video frame: no pipeline (unknown error)&quot;);
270     return NULL;
271   }
272 link_failed:
273   {
274     gst_object_unref (pipeline);
275 
276     GST_ERROR (&quot;Could not convert video frame: failed to link elements&quot;);
277     if (err)
278       *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_NEGOTIATION,
279           &quot;Could not convert video frame: failed to link elements&quot;);
280     return NULL;
281   }
282 }
283 
284 /**
285  * gst_video_convert_sample:
286  * @sample: a #GstSample
287  * @to_caps: the #GstCaps to convert to
288  * @timeout: the maximum amount of time allowed for the processing.
289  * @error: pointer to a #GError. Can be %NULL.
290  *
291  * Converts a raw video buffer into the specified output caps.
292  *
293  * The output caps can be any raw video formats or any image formats (jpeg, png, ...).
294  *
295  * The width, height and pixel-aspect-ratio can also be specified in the output caps.
296  *
297  * Returns: The converted #GstSample, or %NULL if an error happened (in which case @err
298  * will point to the #GError).
299  */
300 GstSample *
301 gst_video_convert_sample (GstSample * sample, const GstCaps * to_caps,
302     GstClockTime timeout, GError ** error)
303 {
304   GstMessage *msg;
305   GstBuffer *buf;
306   GstSample *result = NULL;
307   GError *err = NULL;
308   GstBus *bus;
309   GstCaps *from_caps, *to_caps_copy = NULL;
310   GstFlowReturn ret;
311   GstElement *pipeline, *src, *sink;
312   guint i, n;
313 
314   g_return_val_if_fail (sample != NULL, NULL);
315   g_return_val_if_fail (to_caps != NULL, NULL);
316 
317   buf = gst_sample_get_buffer (sample);
318   g_return_val_if_fail (buf != NULL, NULL);
319 
320   from_caps = gst_sample_get_caps (sample);
321   g_return_val_if_fail (from_caps != NULL, NULL);
322 
<a name="2" id="anc2"></a>
323   to_caps_copy = gst_caps_new_empty ();
324   n = gst_caps_get_size (to_caps);
325   for (i = 0; i &lt; n; i++) {
326     GstStructure *s = gst_caps_get_structure (to_caps, i);
327 
328     s = gst_structure_copy (s);
329     gst_structure_remove_field (s, &quot;framerate&quot;);
330     gst_caps_append_structure (to_caps_copy, s);
331   }
332 
333   pipeline =
334       build_convert_frame_pipeline (&amp;src, &amp;sink, from_caps,
335       gst_buffer_get_video_crop_meta (buf), to_caps_copy, &amp;err);
336   if (!pipeline)
337     goto no_pipeline;
338 
339   /* now set the pipeline to the paused state, after we push the buffer into
340    * appsrc, this should preroll the converted buffer in appsink */
341   GST_DEBUG (&quot;running conversion pipeline to caps %&quot; GST_PTR_FORMAT,
342       to_caps_copy);
<a name="3" id="anc3"></a><span class="line-modified">343   if (gst_element_set_state (pipeline,</span>
<span class="line-added">344           GST_STATE_PAUSED) == GST_STATE_CHANGE_FAILURE)</span>
<span class="line-added">345     goto state_change_failed;</span>
346 
347   /* feed buffer in appsrc */
348   GST_DEBUG (&quot;feeding buffer %p, size %&quot; G_GSIZE_FORMAT &quot;, caps %&quot;
349       GST_PTR_FORMAT, buf, gst_buffer_get_size (buf), from_caps);
350   g_signal_emit_by_name (src, &quot;push-buffer&quot;, buf, &amp;ret);
351 
352   /* now see what happens. We either got an error somewhere or the pipeline
353    * prerolled */
354   bus = gst_element_get_bus (pipeline);
355   msg = gst_bus_timed_pop_filtered (bus,
356       timeout, GST_MESSAGE_ERROR | GST_MESSAGE_ASYNC_DONE);
357 
358   if (msg) {
359     switch (GST_MESSAGE_TYPE (msg)) {
360       case GST_MESSAGE_ASYNC_DONE:
361       {
362         /* we&#39;re prerolled, get the frame from appsink */
363         g_signal_emit_by_name (sink, &quot;pull-preroll&quot;, &amp;result);
364 
365         if (result) {
366           GST_DEBUG (&quot;conversion successful: result = %p&quot;, result);
367         } else {
368           GST_ERROR (&quot;prerolled but no result frame?!&quot;);
369         }
370         break;
371       }
372       case GST_MESSAGE_ERROR:{
373         gchar *dbg = NULL;
374 
375         gst_message_parse_error (msg, &amp;err, &amp;dbg);
376         if (err) {
377           GST_ERROR (&quot;Could not convert video frame: %s&quot;, err-&gt;message);
378           GST_DEBUG (&quot;%s [debug: %s]&quot;, err-&gt;message, GST_STR_NULL (dbg));
379           if (error)
380             *error = err;
381           else
382             g_error_free (err);
383         }
384         g_free (dbg);
385         break;
386       }
387       default:{
388         g_return_val_if_reached (NULL);
389       }
390     }
391     gst_message_unref (msg);
392   } else {
393     GST_ERROR (&quot;Could not convert video frame: timeout during conversion&quot;);
394     if (error)
395       *error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
396           &quot;Could not convert video frame: timeout during conversion&quot;);
397   }
398 
399   gst_element_set_state (pipeline, GST_STATE_NULL);
400   gst_object_unref (bus);
401   gst_object_unref (pipeline);
402   gst_caps_unref (to_caps_copy);
403 
404   return result;
405 
406   /* ERRORS */
407 no_pipeline:
<a name="4" id="anc4"></a><span class="line-added">408 state_change_failed:</span>
409   {
410     gst_caps_unref (to_caps_copy);
411 
412     if (error)
413       *error = err;
414     else
415       g_error_free (err);
416 
417     return NULL;
418   }
419 }
420 
421 typedef struct
422 {
<a name="5" id="anc5"></a><span class="line-added">423   gint ref_count;</span>
424   GMutex mutex;
425   GstElement *pipeline;
426   GstVideoConvertSampleCallback callback;
427   gpointer user_data;
428   GDestroyNotify destroy_notify;
429   GMainContext *context;
430   GstSample *sample;
<a name="6" id="anc6"></a>
431   GSource *timeout_source;
432   gboolean finished;
<a name="7" id="anc7"></a><span class="line-added">433 </span>
<span class="line-added">434   /* Results */</span>
<span class="line-added">435   GstSample *converted_sample;</span>
<span class="line-added">436   GError *error;</span>
437 } GstVideoConvertSampleContext;
438 
<a name="8" id="anc8"></a><span class="line-modified">439 static GstVideoConvertSampleContext *</span>
<span class="line-added">440 gst_video_convert_frame_context_ref (GstVideoConvertSampleContext * ctx)</span>
441 {
<a name="9" id="anc9"></a><span class="line-modified">442   g_atomic_int_inc (&amp;ctx-&gt;ref_count);</span>





443 
<a name="10" id="anc10"></a><span class="line-modified">444   return ctx;</span>
<span class="line-modified">445 }</span>
446 
447 static void
<a name="11" id="anc11"></a><span class="line-modified">448 gst_video_convert_frame_context_unref (GstVideoConvertSampleContext * ctx)</span>
449 {
<a name="12" id="anc12"></a><span class="line-modified">450   if (!g_atomic_int_dec_and_test (&amp;ctx-&gt;ref_count))</span>
<span class="line-modified">451     return;</span>
<span class="line-modified">452 </span>
453   g_mutex_clear (&amp;ctx-&gt;mutex);
454   if (ctx-&gt;timeout_source)
455     g_source_destroy (ctx-&gt;timeout_source);
<a name="13" id="anc13"></a>

456   if (ctx-&gt;sample)
457     gst_sample_unref (ctx-&gt;sample);
<a name="14" id="anc14"></a><span class="line-added">458   if (ctx-&gt;converted_sample)</span>
<span class="line-added">459     gst_sample_unref (ctx-&gt;converted_sample);</span>
<span class="line-added">460   g_clear_error (&amp;ctx-&gt;error);</span>
461   g_main_context_unref (ctx-&gt;context);
462 
<a name="15" id="anc15"></a><span class="line-modified">463   /* The pipeline was already destroyed in finish() earlier and we</span>
<span class="line-modified">464    * must not end up here without finish() being called */</span>
<span class="line-added">465   g_warn_if_fail (ctx-&gt;pipeline == NULL);</span>
466 
467   g_slice_free (GstVideoConvertSampleContext, ctx);
468 }
469 
<a name="16" id="anc16"></a>








470 static gboolean
<a name="17" id="anc17"></a><span class="line-modified">471 convert_frame_dispatch_callback (GstVideoConvertSampleContext * ctx)</span>
472 {
<a name="18" id="anc18"></a><span class="line-modified">473   GstSample *sample;</span>
<span class="line-added">474   GError *error;</span>
<span class="line-added">475 </span>
<span class="line-added">476   g_return_val_if_fail (ctx-&gt;converted_sample != NULL</span>
<span class="line-added">477       || ctx-&gt;error != NULL, FALSE);</span>
<span class="line-added">478 </span>
<span class="line-added">479   sample = ctx-&gt;converted_sample;</span>
<span class="line-added">480   error = ctx-&gt;error;</span>
<span class="line-added">481   ctx-&gt;converted_sample = NULL;</span>
<span class="line-added">482   ctx-&gt;error = NULL;</span>
<span class="line-added">483 </span>
<span class="line-added">484   ctx-&gt;callback (sample, error, ctx-&gt;user_data);</span>
485 
486   if (ctx-&gt;destroy_notify)
487     ctx-&gt;destroy_notify (ctx-&gt;user_data);
488 
489   return FALSE;
490 }
491 
<a name="19" id="anc19"></a><span class="line-added">492 static void</span>
<span class="line-added">493 convert_frame_stop_pipeline (GstElement * element, gpointer user_data)</span>
<span class="line-added">494 {</span>
<span class="line-added">495   gst_element_set_state (element, GST_STATE_NULL);</span>
<span class="line-added">496 }</span>
<span class="line-added">497 </span>
498 static void
499 convert_frame_finish (GstVideoConvertSampleContext * context,
500     GstSample * sample, GError * error)
501 {
502   GSource *source;
<a name="20" id="anc20"></a><span class="line-modified">503 </span>
<span class="line-added">504   g_return_if_fail (!context-&gt;finished);</span>
<span class="line-added">505   g_return_if_fail (sample != NULL || error != NULL);</span>
<span class="line-added">506 </span>
<span class="line-added">507   context-&gt;finished = TRUE;</span>
<span class="line-added">508   context-&gt;converted_sample = sample;</span>
<span class="line-added">509   context-&gt;error = error;</span>
510 
511   if (context-&gt;timeout_source)
512     g_source_destroy (context-&gt;timeout_source);
513   context-&gt;timeout_source = NULL;
514 
<a name="21" id="anc21"></a>








515   source = g_timeout_source_new (0);
516   g_source_set_callback (source,
<a name="22" id="anc22"></a><span class="line-modified">517       (GSourceFunc) convert_frame_dispatch_callback,</span>
<span class="line-modified">518       gst_video_convert_frame_context_ref (context),</span>
<span class="line-added">519       (GDestroyNotify) gst_video_convert_frame_context_unref);</span>
520   g_source_attach (source, context-&gt;context);
521   g_source_unref (source);
522 
<a name="23" id="anc23"></a><span class="line-modified">523   /* Asynchronously stop the pipeline here: this will set its</span>
<span class="line-added">524    * state to NULL and get rid of its last reference, which in turn</span>
<span class="line-added">525    * will get rid of all remaining references to our context and free</span>
<span class="line-added">526    * it too. We can&#39;t do this directly here as we might be called from</span>
<span class="line-added">527    * a streaming thread.</span>
<span class="line-added">528    *</span>
<span class="line-added">529    * We don&#39;t use the main loop here because the user might shut down it</span>
<span class="line-added">530    * immediately after getting the result of the conversion above.</span>
<span class="line-added">531    */</span>
<span class="line-added">532   if (context-&gt;pipeline) {</span>
<span class="line-added">533     gst_element_call_async (context-&gt;pipeline, convert_frame_stop_pipeline,</span>
<span class="line-added">534         NULL, NULL);</span>
<span class="line-added">535     gst_object_unref (context-&gt;pipeline);</span>
<span class="line-added">536     context-&gt;pipeline = NULL;</span>
<span class="line-added">537   }</span>
538 }
539 
540 static gboolean
541 convert_frame_timeout_callback (GstVideoConvertSampleContext * context)
542 {
543   GError *error;
544 
545   g_mutex_lock (&amp;context-&gt;mutex);
546 
547   if (context-&gt;finished)
548     goto done;
549 
550   GST_ERROR (&quot;Could not convert video frame: timeout&quot;);
551 
552   error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
553       &quot;Could not convert video frame: timeout&quot;);
554 
555   convert_frame_finish (context, NULL, error);
556 
557 done:
558   g_mutex_unlock (&amp;context-&gt;mutex);
559   return FALSE;
560 }
561 
562 static gboolean
563 convert_frame_bus_callback (GstBus * bus, GstMessage * message,
564     GstVideoConvertSampleContext * context)
565 {
566   g_mutex_lock (&amp;context-&gt;mutex);
567 
568   if (context-&gt;finished)
569     goto done;
570 
571   switch (GST_MESSAGE_TYPE (message)) {
572     case GST_MESSAGE_ERROR:{
573       GError *error;
574       gchar *dbg = NULL;
575 
576       gst_message_parse_error (message, &amp;error, &amp;dbg);
577 
578       GST_ERROR (&quot;Could not convert video frame: %s&quot;, error-&gt;message);
579       GST_DEBUG (&quot;%s [debug: %s]&quot;, error-&gt;message, GST_STR_NULL (dbg));
580 
581       convert_frame_finish (context, NULL, error);
582 
583       g_free (dbg);
584       break;
585     }
586     default:
587       break;
588   }
589 
590 done:
591   g_mutex_unlock (&amp;context-&gt;mutex);
592 
593   return FALSE;
594 }
595 
596 static void
597 convert_frame_need_data_callback (GstElement * src, guint size,
598     GstVideoConvertSampleContext * context)
599 {
600   GstFlowReturn ret = GST_FLOW_ERROR;
601   GError *error;
602   GstBuffer *buffer;
603 
604   g_mutex_lock (&amp;context-&gt;mutex);
605 
606   if (context-&gt;finished)
607     goto done;
608 
609   buffer = gst_sample_get_buffer (context-&gt;sample);
610   g_signal_emit_by_name (src, &quot;push-buffer&quot;, buffer, &amp;ret);
611   gst_sample_unref (context-&gt;sample);
612   context-&gt;sample = NULL;
613 
614   if (ret != GST_FLOW_OK) {
615     GST_ERROR (&quot;Could not push video frame: %s&quot;, gst_flow_get_name (ret));
616 
617     error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
618         &quot;Could not push video frame: %s&quot;, gst_flow_get_name (ret));
619 
620     convert_frame_finish (context, NULL, error);
621   }
622 
<a name="24" id="anc24"></a>


623 done:
624   g_mutex_unlock (&amp;context-&gt;mutex);
<a name="25" id="anc25"></a><span class="line-added">625 </span>
<span class="line-added">626   g_signal_handlers_disconnect_by_func (src, convert_frame_need_data_callback,</span>
<span class="line-added">627       context);</span>
628 }
629 
630 static GstFlowReturn
631 convert_frame_new_preroll_callback (GstElement * sink,
632     GstVideoConvertSampleContext * context)
633 {
634   GstSample *sample = NULL;
635   GError *error = NULL;
636 
637   g_mutex_lock (&amp;context-&gt;mutex);
638 
639   if (context-&gt;finished)
640     goto done;
641 
642   g_signal_emit_by_name (sink, &quot;pull-preroll&quot;, &amp;sample);
643 
644   if (!sample) {
645     error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
646         &quot;Could not get converted video sample&quot;);
647   }
648   convert_frame_finish (context, sample, error);
649 
<a name="26" id="anc26"></a>


650 done:
651   g_mutex_unlock (&amp;context-&gt;mutex);
652 
<a name="27" id="anc27"></a><span class="line-added">653   g_signal_handlers_disconnect_by_func (sink, convert_frame_need_data_callback,</span>
<span class="line-added">654       context);</span>
<span class="line-added">655 </span>
656   return GST_FLOW_OK;
657 }
658 
659 /**
660  * gst_video_convert_sample_async:
661  * @sample: a #GstSample
662  * @to_caps: the #GstCaps to convert to
663  * @timeout: the maximum amount of time allowed for the processing.
664  * @callback: %GstVideoConvertSampleCallback that will be called after conversion.
665  * @user_data: extra data that will be passed to the @callback
666  * @destroy_notify: %GDestroyNotify to be called after @user_data is not needed anymore
667  *
668  * Converts a raw video buffer into the specified output caps.
669  *
670  * The output caps can be any raw video formats or any image formats (jpeg, png, ...).
671  *
672  * The width, height and pixel-aspect-ratio can also be specified in the output caps.
673  *
674  * @callback will be called after conversion, when an error occured or if conversion didn&#39;t
675  * finish after @timeout. @callback will always be called from the thread default
676  * %GMainContext, see g_main_context_get_thread_default(). If GLib before 2.22 is used,
677  * this will always be the global default main context.
678  *
679  * @destroy_notify will be called after the callback was called and @user_data is not needed
680  * anymore.
681  */
682 void
683 gst_video_convert_sample_async (GstSample * sample,
684     const GstCaps * to_caps, GstClockTime timeout,
685     GstVideoConvertSampleCallback callback, gpointer user_data,
686     GDestroyNotify destroy_notify)
687 {
688   GMainContext *context = NULL;
689   GError *error = NULL;
690   GstBus *bus;
691   GstBuffer *buf;
692   GstCaps *from_caps, *to_caps_copy = NULL;
693   GstElement *pipeline, *src, *sink;
694   guint i, n;
695   GSource *source;
696   GstVideoConvertSampleContext *ctx;
697 
698   g_return_if_fail (sample != NULL);
699   buf = gst_sample_get_buffer (sample);
700   g_return_if_fail (buf != NULL);
701 
702   g_return_if_fail (to_caps != NULL);
703 
704   from_caps = gst_sample_get_caps (sample);
705   g_return_if_fail (from_caps != NULL);
706   g_return_if_fail (callback != NULL);
707 
708   context = g_main_context_get_thread_default ();
709 
710   if (!context)
711     context = g_main_context_default ();
712 
713   to_caps_copy = gst_caps_new_empty ();
714   n = gst_caps_get_size (to_caps);
715   for (i = 0; i &lt; n; i++) {
716     GstStructure *s = gst_caps_get_structure (to_caps, i);
717 
718     s = gst_structure_copy (s);
719     gst_structure_remove_field (s, &quot;framerate&quot;);
720     gst_caps_append_structure (to_caps_copy, s);
721   }
722 
<a name="28" id="anc28"></a><span class="line-modified">723   /* There&#39;s a reference cycle between the context and the pipeline, which is</span>
<span class="line-modified">724    * broken up once the finish() is called on the context. At latest when the</span>
<span class="line-modified">725    * timeout triggers the context will be freed */</span>





726   ctx = g_slice_new0 (GstVideoConvertSampleContext);
<a name="29" id="anc29"></a><span class="line-added">727   ctx-&gt;ref_count = 1;</span>
728   g_mutex_init (&amp;ctx-&gt;mutex);
<a name="30" id="anc30"></a>
729   ctx-&gt;sample = gst_sample_ref (sample);
730   ctx-&gt;callback = callback;
731   ctx-&gt;user_data = user_data;
732   ctx-&gt;destroy_notify = destroy_notify;
733   ctx-&gt;context = g_main_context_ref (context);
734   ctx-&gt;finished = FALSE;
<a name="31" id="anc31"></a><span class="line-added">735 </span>
<span class="line-added">736   pipeline =</span>
<span class="line-added">737       build_convert_frame_pipeline (&amp;src, &amp;sink, from_caps,</span>
<span class="line-added">738       gst_buffer_get_video_crop_meta (buf), to_caps_copy, &amp;error);</span>
<span class="line-added">739   if (!pipeline)</span>
<span class="line-added">740     goto no_pipeline;</span>
741   ctx-&gt;pipeline = pipeline;
742 
<a name="32" id="anc32"></a><span class="line-added">743   bus = gst_element_get_bus (pipeline);</span>
<span class="line-added">744 </span>
745   if (timeout != GST_CLOCK_TIME_NONE) {
746     ctx-&gt;timeout_source = g_timeout_source_new (timeout / GST_MSECOND);
747     g_source_set_callback (ctx-&gt;timeout_source,
<a name="33" id="anc33"></a><span class="line-modified">748         (GSourceFunc) convert_frame_timeout_callback,</span>
<span class="line-added">749         gst_video_convert_frame_context_ref (ctx),</span>
<span class="line-added">750         (GDestroyNotify) gst_video_convert_frame_context_unref);</span>
751     g_source_attach (ctx-&gt;timeout_source, context);
752   }
753 
<a name="34" id="anc34"></a><span class="line-modified">754   g_signal_connect_data (src, &quot;need-data&quot;,</span>
<span class="line-modified">755       G_CALLBACK (convert_frame_need_data_callback),</span>
<span class="line-modified">756       gst_video_convert_frame_context_ref (ctx),</span>
<span class="line-modified">757       (GClosureNotify) gst_video_convert_frame_context_unref, 0);</span>
<span class="line-added">758   g_signal_connect_data (sink, &quot;new-preroll&quot;,</span>
<span class="line-added">759       G_CALLBACK (convert_frame_new_preroll_callback),</span>
<span class="line-added">760       gst_video_convert_frame_context_ref (ctx),</span>
<span class="line-added">761       (GClosureNotify) gst_video_convert_frame_context_unref, 0);</span>
762 
763   source = gst_bus_create_watch (bus);
764   g_source_set_callback (source, (GSourceFunc) convert_frame_bus_callback,
<a name="35" id="anc35"></a><span class="line-modified">765       gst_video_convert_frame_context_ref (ctx),</span>
<span class="line-added">766       (GDestroyNotify) gst_video_convert_frame_context_unref);</span>
767   g_source_attach (source, context);
768   g_source_unref (source);
<a name="36" id="anc36"></a><span class="line-added">769   gst_object_unref (bus);</span>
770 
<a name="37" id="anc37"></a><span class="line-modified">771   if (gst_element_set_state (pipeline,</span>
<span class="line-added">772           GST_STATE_PAUSED) == GST_STATE_CHANGE_FAILURE)</span>
<span class="line-added">773     goto state_change_failed;</span>
774 
<a name="38" id="anc38"></a>
775   gst_caps_unref (to_caps_copy);
776 
<a name="39" id="anc39"></a><span class="line-added">777   gst_video_convert_frame_context_unref (ctx);</span>
<span class="line-added">778 </span>
779   return;
780   /* ERRORS */
781 no_pipeline:
782   {
<a name="40" id="anc40"></a><span class="line-modified">783     gst_caps_unref (to_caps_copy);</span>
<span class="line-modified">784 </span>
<span class="line-added">785     g_mutex_lock (&amp;ctx-&gt;mutex);</span>
<span class="line-added">786     convert_frame_finish (ctx, NULL, error);</span>
<span class="line-added">787     g_mutex_unlock (&amp;ctx-&gt;mutex);</span>
<span class="line-added">788     gst_video_convert_frame_context_unref (ctx);</span>
789 
<a name="41" id="anc41"></a><span class="line-added">790     return;</span>
<span class="line-added">791   }</span>
<span class="line-added">792 state_change_failed:</span>
<span class="line-added">793   {</span>
794     gst_caps_unref (to_caps_copy);
795 
<a name="42" id="anc42"></a><span class="line-modified">796     error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_STATE_CHANGE,</span>
<span class="line-modified">797         &quot;failed to change state to PLAYING&quot;);</span>
<span class="line-modified">798 </span>
<span class="line-modified">799     g_mutex_lock (&amp;ctx-&gt;mutex);</span>
<span class="line-modified">800     convert_frame_finish (ctx, NULL, error);</span>
<span class="line-modified">801     g_mutex_unlock (&amp;ctx-&gt;mutex);</span>
<span class="line-modified">802     gst_video_convert_frame_context_unref (ctx);</span>
<span class="line-modified">803 </span>
<span class="line-modified">804     return;</span>




805   }
806 }
<a name="43" id="anc43"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="43" type="hidden" />
</body>
</html>