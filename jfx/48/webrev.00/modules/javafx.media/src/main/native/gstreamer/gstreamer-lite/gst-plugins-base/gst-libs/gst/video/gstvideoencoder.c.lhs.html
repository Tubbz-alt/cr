<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/gstvideoencoder.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /* GStreamer
   2  * Copyright (C) 2008 David Schleef &lt;ds@schleef.org&gt;
   3  * Copyright (C) 2011 Mark Nauwelaerts &lt;mark.nauwelaerts@collabora.co.uk&gt;.
   4  * Copyright (C) 2011 Nokia Corporation. All rights reserved.
   5  *   Contact: Stefan Kost &lt;stefan.kost@nokia.com&gt;
   6  * Copyright (C) 2012 Collabora Ltd.
   7  *  Author : Edward Hervey &lt;edward@collabora.com&gt;
   8  *
   9  * This library is free software; you can redistribute it and/or
  10  * modify it under the terms of the GNU Library General Public
  11  * License as published by the Free Software Foundation; either
  12  * version 2 of the License, or (at your option) any later version.
  13  *
  14  * This library is distributed in the hope that it will be useful,
  15  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  16  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  17  * Library General Public License for more details.
  18  *
  19  * You should have received a copy of the GNU Library General Public
  20  * License along with this library; if not, write to the
  21  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
  22  * Boston, MA 02110-1301, USA.
  23  */
  24 
  25 /**
  26  * SECTION:gstvideoencoder
  27  * @title: GstVideoEncoder
  28  * @short_description: Base class for video encoders
  29  * @see_also:
  30  *
  31  * This base class is for video encoders turning raw video into
  32  * encoded video data.
  33  *
  34  * GstVideoEncoder and subclass should cooperate as follows.
  35  *
  36  * ## Configuration
  37  *
  38  *   * Initially, GstVideoEncoder calls @start when the encoder element
  39  *     is activated, which allows subclass to perform any global setup.
  40  *   * GstVideoEncoder calls @set_format to inform subclass of the format
  41  *     of input video data that it is about to receive.  Subclass should
  42  *     setup for encoding and configure base class as appropriate
  43  *     (e.g. latency). While unlikely, it might be called more than once,
  44  *     if changing input parameters require reconfiguration.  Baseclass
  45  *     will ensure that processing of current configuration is finished.
  46  *   * GstVideoEncoder calls @stop at end of all processing.
  47  *
  48  * ## Data processing
  49  *
  50  *     * Base class collects input data and metadata into a frame and hands
  51  *       this to subclass&#39; @handle_frame.
  52  *
  53  *     * If codec processing results in encoded data, subclass should call
  54  *       @gst_video_encoder_finish_frame to have encoded data pushed
  55  *       downstream.
  56  *
  57  *     * If implemented, baseclass calls subclass @pre_push just prior to
  58  *       pushing to allow subclasses to modify some metadata on the buffer.
  59  *       If it returns GST_FLOW_OK, the buffer is pushed downstream.
  60  *
  61  *     * GstVideoEncoderClass will handle both srcpad and sinkpad events.
  62  *       Sink events will be passed to subclass if @event callback has been
  63  *       provided.
  64  *
  65  * ## Shutdown phase
  66  *
  67  *   * GstVideoEncoder class calls @stop to inform the subclass that data
  68  *     parsing will be stopped.
  69  *
  70  * Subclass is responsible for providing pad template caps for
  71  * source and sink pads. The pads need to be named &quot;sink&quot; and &quot;src&quot;. It should
  72  * also be able to provide fixed src pad caps in @getcaps by the time it calls
  73  * @gst_video_encoder_finish_frame.
  74  *
  75  * Things that subclass need to take care of:
  76  *
  77  *   * Provide pad templates
  78  *   * Provide source pad caps before pushing the first buffer
  79  *   * Accept data in @handle_frame and provide encoded results to
  80  *      @gst_video_encoder_finish_frame.
  81  *
  82  *
  83  * The #GstVideoEncoder:qos property will enable the Quality-of-Service
  84  * features of the encoder which gather statistics about the real-time
  85  * performance of the downstream elements. If enabled, subclasses can
  86  * use gst_video_encoder_get_max_encode_time() to check if input frames
  87  * are already late and drop them right away to give a chance to the
  88  * pipeline to catch up.
  89  */
  90 
  91 #ifdef HAVE_CONFIG_H
  92 #include &quot;config.h&quot;
  93 #endif
  94 
  95 /* TODO
  96  *
  97  * * Calculate actual latency based on input/output timestamp/frame_number
  98  *   and if it exceeds the recorded one, save it and emit a GST_MESSAGE_LATENCY
  99  */
 100 
 101 #include &lt;gst/video/video.h&gt;
 102 #include &quot;gstvideoencoder.h&quot;
 103 #include &quot;gstvideoutils.h&quot;
 104 #include &quot;gstvideoutilsprivate.h&quot;
 105 
 106 #include &lt;gst/video/gstvideometa.h&gt;
 107 #include &lt;gst/video/gstvideopool.h&gt;
 108 
 109 #include &lt;string.h&gt;
 110 
 111 GST_DEBUG_CATEGORY (videoencoder_debug);
 112 #define GST_CAT_DEFAULT videoencoder_debug
 113 
<a name="1" id="anc1"></a><span class="line-removed"> 114 #define GST_VIDEO_ENCODER_GET_PRIVATE(obj)  \</span>
<span class="line-removed"> 115     (G_TYPE_INSTANCE_GET_PRIVATE ((obj), GST_TYPE_VIDEO_ENCODER, \</span>
<span class="line-removed"> 116         GstVideoEncoderPrivate))</span>
<span class="line-removed"> 117 </span>
 118 /* properties */
 119 
 120 #define DEFAULT_QOS                 FALSE
 121 
 122 enum
 123 {
 124   PROP_0,
 125   PROP_QOS,
 126   PROP_LAST
 127 };
 128 
 129 struct _GstVideoEncoderPrivate
 130 {
 131   guint64 presentation_frame_number;
 132   int distance_from_sync;
 133 
 134   /* FIXME : (and introduce a context ?) */
 135   gboolean drained;
 136 
 137   gint64 min_latency;
 138   gint64 max_latency;
 139 
 140   GList *current_frame_events;
 141 
 142   GList *headers;
 143   gboolean new_headers;         /* Whether new headers were just set */
 144 
 145   GList *force_key_unit;        /* List of pending forced keyunits */
 146 
 147   guint32 system_frame_number;
 148 
 149   GList *frames;                /* Protected with OBJECT_LOCK */
 150   GstVideoCodecState *input_state;
 151   GstVideoCodecState *output_state;
 152   gboolean output_state_changed;
 153 
 154   gint64 bytes;
 155   gint64 time;
 156 
 157   GstAllocator *allocator;
 158   GstAllocationParams params;
 159 
 160   /* upstream stream tags (global tags are passed through as-is) */
 161   GstTagList *upstream_tags;
 162 
 163   /* subclass tags */
 164   GstTagList *tags;
 165   GstTagMergeMode tags_merge_mode;
 166 
 167   gboolean tags_changed;
 168 
 169   GstClockTime min_pts;
 170   /* adjustment needed on pts, dts, segment start and stop to accomodate
 171    * min_pts */
 172   GstClockTime time_adjustment;
 173 
 174   /* QoS properties */
 175   gint qos_enabled;             /* ATOMIC */
 176   gdouble proportion;           /* OBJECT_LOCK */
 177   GstClockTime earliest_time;   /* OBJECT_LOCK */
 178   GstClockTime qos_frame_duration;      /* OBJECT_LOCK */
 179   /* qos messages: frames dropped/processed */
 180   guint dropped;
 181   guint processed;
 182 };
 183 
 184 typedef struct _ForcedKeyUnitEvent ForcedKeyUnitEvent;
 185 struct _ForcedKeyUnitEvent
 186 {
 187   GstClockTime running_time;
 188   gboolean pending;             /* TRUE if this was requested already */
 189   gboolean all_headers;
 190   guint count;
 191   guint32 frame_id;
 192 };
 193 
 194 static void
 195 forced_key_unit_event_free (ForcedKeyUnitEvent * evt)
 196 {
 197   g_slice_free (ForcedKeyUnitEvent, evt);
 198 }
 199 
 200 static ForcedKeyUnitEvent *
 201 forced_key_unit_event_new (GstClockTime running_time, gboolean all_headers,
 202     guint count)
 203 {
 204   ForcedKeyUnitEvent *evt = g_slice_new0 (ForcedKeyUnitEvent);
 205 
 206   evt-&gt;running_time = running_time;
 207   evt-&gt;all_headers = all_headers;
 208   evt-&gt;count = count;
 209 
 210   return evt;
 211 }
 212 
 213 static GstElementClass *parent_class = NULL;
<a name="2" id="anc2"></a>

 214 static void gst_video_encoder_class_init (GstVideoEncoderClass * klass);
 215 static void gst_video_encoder_init (GstVideoEncoder * enc,
 216     GstVideoEncoderClass * klass);
 217 
 218 static void gst_video_encoder_finalize (GObject * object);
 219 
 220 static gboolean gst_video_encoder_setcaps (GstVideoEncoder * enc,
 221     GstCaps * caps);
 222 static GstCaps *gst_video_encoder_sink_getcaps (GstVideoEncoder * encoder,
 223     GstCaps * filter);
 224 static gboolean gst_video_encoder_src_event (GstPad * pad, GstObject * parent,
 225     GstEvent * event);
 226 static gboolean gst_video_encoder_sink_event (GstPad * pad, GstObject * parent,
 227     GstEvent * event);
 228 static GstFlowReturn gst_video_encoder_chain (GstPad * pad, GstObject * parent,
 229     GstBuffer * buf);
 230 static GstStateChangeReturn gst_video_encoder_change_state (GstElement *
 231     element, GstStateChange transition);
 232 static gboolean gst_video_encoder_sink_query (GstPad * pad, GstObject * parent,
 233     GstQuery * query);
 234 static gboolean gst_video_encoder_src_query (GstPad * pad, GstObject * parent,
 235     GstQuery * query);
 236 static GstVideoCodecFrame *gst_video_encoder_new_frame (GstVideoEncoder *
 237     encoder, GstBuffer * buf, GstClockTime pts, GstClockTime dts,
 238     GstClockTime duration);
 239 
 240 static gboolean gst_video_encoder_sink_event_default (GstVideoEncoder * encoder,
 241     GstEvent * event);
 242 static gboolean gst_video_encoder_src_event_default (GstVideoEncoder * encoder,
 243     GstEvent * event);
 244 static gboolean gst_video_encoder_decide_allocation_default (GstVideoEncoder *
 245     encoder, GstQuery * query);
 246 static gboolean gst_video_encoder_propose_allocation_default (GstVideoEncoder *
 247     encoder, GstQuery * query);
 248 static gboolean gst_video_encoder_negotiate_default (GstVideoEncoder * encoder);
 249 static gboolean gst_video_encoder_negotiate_unlocked (GstVideoEncoder *
 250     encoder);
 251 
 252 static gboolean gst_video_encoder_sink_query_default (GstVideoEncoder * encoder,
 253     GstQuery * query);
 254 static gboolean gst_video_encoder_src_query_default (GstVideoEncoder * encoder,
 255     GstQuery * query);
 256 
 257 static gboolean gst_video_encoder_transform_meta_default (GstVideoEncoder *
 258     encoder, GstVideoCodecFrame * frame, GstMeta * meta);
 259 
 260 /* we can&#39;t use G_DEFINE_ABSTRACT_TYPE because we need the klass in the _init
 261  * method to get to the padtemplates */
 262 GType
 263 gst_video_encoder_get_type (void)
 264 {
 265   static volatile gsize type = 0;
 266 
 267   if (g_once_init_enter (&amp;type)) {
 268     GType _type;
 269     static const GTypeInfo info = {
 270       sizeof (GstVideoEncoderClass),
 271       NULL,
 272       NULL,
 273       (GClassInitFunc) gst_video_encoder_class_init,
 274       NULL,
 275       NULL,
 276       sizeof (GstVideoEncoder),
 277       0,
 278       (GInstanceInitFunc) gst_video_encoder_init,
 279     };
 280 #ifndef GSTREAMER_LITE
 281     const GInterfaceInfo preset_interface_info = {
 282       NULL,                     /* interface_init */
 283       NULL,                     /* interface_finalize */
 284       NULL                      /* interface_data */
 285     };
 286 #endif // GSTREAMER_LITE
 287 
 288     _type = g_type_register_static (GST_TYPE_ELEMENT,
 289         &quot;GstVideoEncoder&quot;, &amp;info, G_TYPE_FLAG_ABSTRACT);
<a name="3" id="anc3"></a>

 290 #ifndef GSTREAMER_LITE
 291     g_type_add_interface_static (_type, GST_TYPE_PRESET,
 292         &amp;preset_interface_info);
 293 #endif // GSTREAMER_LITE
 294     g_once_init_leave (&amp;type, _type);
 295   }
 296   return type;
 297 }
 298 
<a name="4" id="anc4"></a>





 299 static void
 300 gst_video_encoder_set_property (GObject * object, guint prop_id,
 301     const GValue * value, GParamSpec * pspec)
 302 {
 303   GstVideoEncoder *sink = GST_VIDEO_ENCODER (object);
 304 
 305   switch (prop_id) {
 306     case PROP_QOS:
 307       gst_video_encoder_set_qos_enabled (sink, g_value_get_boolean (value));
 308       break;
 309     default:
 310       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
 311       break;
 312   }
 313 }
 314 
 315 static void
 316 gst_video_encoder_get_property (GObject * object, guint prop_id, GValue * value,
 317     GParamSpec * pspec)
 318 {
 319   GstVideoEncoder *sink = GST_VIDEO_ENCODER (object);
 320 
 321   switch (prop_id) {
 322     case PROP_QOS:
 323       g_value_set_boolean (value, gst_video_encoder_is_qos_enabled (sink));
 324       break;
 325     default:
 326       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
 327       break;
 328   }
 329 }
 330 
 331 static void
 332 gst_video_encoder_class_init (GstVideoEncoderClass * klass)
 333 {
 334   GObjectClass *gobject_class;
 335   GstElementClass *gstelement_class;
 336 
 337   gobject_class = G_OBJECT_CLASS (klass);
 338   gstelement_class = GST_ELEMENT_CLASS (klass);
 339 
 340   GST_DEBUG_CATEGORY_INIT (videoencoder_debug, &quot;videoencoder&quot;, 0,
 341       &quot;Base Video Encoder&quot;);
 342 
 343   parent_class = g_type_class_peek_parent (klass);
 344 
<a name="5" id="anc5"></a><span class="line-modified"> 345   g_type_class_add_private (klass, sizeof (GstVideoEncoderPrivate));</span>

 346 
 347   gobject_class-&gt;set_property = gst_video_encoder_set_property;
 348   gobject_class-&gt;get_property = gst_video_encoder_get_property;
 349   gobject_class-&gt;finalize = gst_video_encoder_finalize;
 350 
 351   gstelement_class-&gt;change_state =
 352       GST_DEBUG_FUNCPTR (gst_video_encoder_change_state);
 353 
 354   klass-&gt;sink_event = gst_video_encoder_sink_event_default;
 355   klass-&gt;src_event = gst_video_encoder_src_event_default;
 356   klass-&gt;propose_allocation = gst_video_encoder_propose_allocation_default;
 357   klass-&gt;decide_allocation = gst_video_encoder_decide_allocation_default;
 358   klass-&gt;negotiate = gst_video_encoder_negotiate_default;
 359   klass-&gt;sink_query = gst_video_encoder_sink_query_default;
 360   klass-&gt;src_query = gst_video_encoder_src_query_default;
 361   klass-&gt;transform_meta = gst_video_encoder_transform_meta_default;
 362 
 363   g_object_class_install_property (gobject_class, PROP_QOS,
 364       g_param_spec_boolean (&quot;qos&quot;, &quot;Qos&quot;,
 365           &quot;Handle Quality-of-Service events from downstream&quot;, DEFAULT_QOS,
 366           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 367 }
 368 
 369 static GList *
 370 _flush_events (GstPad * pad, GList * events)
 371 {
 372   GList *tmp;
 373 
 374   for (tmp = events; tmp; tmp = tmp-&gt;next) {
 375     if (GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_EOS &amp;&amp;
 376         GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_SEGMENT &amp;&amp;
 377         GST_EVENT_IS_STICKY (tmp-&gt;data)) {
 378       gst_pad_store_sticky_event (pad, GST_EVENT_CAST (tmp-&gt;data));
 379     }
 380     gst_event_unref (tmp-&gt;data);
 381   }
 382   g_list_free (events);
 383 
 384   return NULL;
 385 }
 386 
 387 static gboolean
 388 gst_video_encoder_reset (GstVideoEncoder * encoder, gboolean hard)
 389 {
 390   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
 391   gboolean ret = TRUE;
 392 
 393   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 394 
 395   priv-&gt;presentation_frame_number = 0;
 396   priv-&gt;distance_from_sync = 0;
 397 
 398   g_list_foreach (priv-&gt;force_key_unit, (GFunc) forced_key_unit_event_free,
 399       NULL);
 400   g_list_free (priv-&gt;force_key_unit);
 401   priv-&gt;force_key_unit = NULL;
 402 
 403   priv-&gt;drained = TRUE;
 404 
 405   GST_OBJECT_LOCK (encoder);
 406   priv-&gt;bytes = 0;
 407   priv-&gt;time = 0;
 408   GST_OBJECT_UNLOCK (encoder);
 409 
 410   priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
 411 
 412   if (hard) {
 413     gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
 414     gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
 415 
 416     if (priv-&gt;input_state)
 417       gst_video_codec_state_unref (priv-&gt;input_state);
 418     priv-&gt;input_state = NULL;
 419     if (priv-&gt;output_state)
 420       gst_video_codec_state_unref (priv-&gt;output_state);
 421     priv-&gt;output_state = NULL;
 422 
 423     if (priv-&gt;upstream_tags) {
 424       gst_tag_list_unref (priv-&gt;upstream_tags);
 425       priv-&gt;upstream_tags = NULL;
 426     }
 427     if (priv-&gt;tags)
 428       gst_tag_list_unref (priv-&gt;tags);
 429     priv-&gt;tags = NULL;
 430     priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
 431     priv-&gt;tags_changed = FALSE;
 432 
 433     g_list_foreach (priv-&gt;headers, (GFunc) gst_event_unref, NULL);
 434     g_list_free (priv-&gt;headers);
 435     priv-&gt;headers = NULL;
 436     priv-&gt;new_headers = FALSE;
 437 
 438     if (priv-&gt;allocator) {
 439       gst_object_unref (priv-&gt;allocator);
 440       priv-&gt;allocator = NULL;
 441     }
 442 
 443     g_list_foreach (priv-&gt;current_frame_events, (GFunc) gst_event_unref, NULL);
 444     g_list_free (priv-&gt;current_frame_events);
 445     priv-&gt;current_frame_events = NULL;
 446 
 447     GST_OBJECT_LOCK (encoder);
 448     priv-&gt;proportion = 0.5;
 449     priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
 450     priv-&gt;qos_frame_duration = 0;
 451     GST_OBJECT_UNLOCK (encoder);
 452 
 453     priv-&gt;dropped = 0;
 454     priv-&gt;processed = 0;
 455   } else {
 456     GList *l;
 457 
 458     for (l = priv-&gt;frames; l; l = l-&gt;next) {
 459       GstVideoCodecFrame *frame = l-&gt;data;
 460 
 461       frame-&gt;events = _flush_events (encoder-&gt;srcpad, frame-&gt;events);
 462     }
 463     priv-&gt;current_frame_events = _flush_events (encoder-&gt;srcpad,
 464         encoder-&gt;priv-&gt;current_frame_events);
 465   }
 466 
 467   g_list_foreach (priv-&gt;frames, (GFunc) gst_video_codec_frame_unref, NULL);
 468   g_list_free (priv-&gt;frames);
 469   priv-&gt;frames = NULL;
 470 
 471   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 472 
 473   return ret;
 474 }
 475 
 476 /* Always call reset() in one way or another after this */
 477 static gboolean
 478 gst_video_encoder_flush (GstVideoEncoder * encoder)
 479 {
 480   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 481   gboolean ret = TRUE;
 482 
 483   if (klass-&gt;flush)
 484     ret = klass-&gt;flush (encoder);
 485 
 486   return ret;
 487 }
 488 
 489 static void
 490 gst_video_encoder_init (GstVideoEncoder * encoder, GstVideoEncoderClass * klass)
 491 {
 492   GstVideoEncoderPrivate *priv;
 493   GstPadTemplate *pad_template;
 494   GstPad *pad;
 495 
 496   GST_DEBUG_OBJECT (encoder, &quot;gst_video_encoder_init&quot;);
 497 
<a name="6" id="anc6"></a><span class="line-modified"> 498   priv = encoder-&gt;priv = GST_VIDEO_ENCODER_GET_PRIVATE (encoder);</span>
 499 
 500   pad_template =
 501       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 502   g_return_if_fail (pad_template != NULL);
 503 
 504   encoder-&gt;sinkpad = pad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 505 
 506   gst_pad_set_chain_function (pad, GST_DEBUG_FUNCPTR (gst_video_encoder_chain));
 507   gst_pad_set_event_function (pad,
 508       GST_DEBUG_FUNCPTR (gst_video_encoder_sink_event));
 509   gst_pad_set_query_function (pad,
 510       GST_DEBUG_FUNCPTR (gst_video_encoder_sink_query));
 511   gst_element_add_pad (GST_ELEMENT (encoder), encoder-&gt;sinkpad);
 512 
 513   pad_template =
 514       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 515   g_return_if_fail (pad_template != NULL);
 516 
 517   encoder-&gt;srcpad = pad = gst_pad_new_from_template (pad_template, &quot;src&quot;);
 518 
 519   gst_pad_set_query_function (pad,
 520       GST_DEBUG_FUNCPTR (gst_video_encoder_src_query));
 521   gst_pad_set_event_function (pad,
 522       GST_DEBUG_FUNCPTR (gst_video_encoder_src_event));
 523   gst_element_add_pad (GST_ELEMENT (encoder), encoder-&gt;srcpad);
 524 
 525   gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
 526   gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
 527 
 528   g_rec_mutex_init (&amp;encoder-&gt;stream_lock);
 529 
 530   priv-&gt;headers = NULL;
 531   priv-&gt;new_headers = FALSE;
 532 
 533   priv-&gt;min_latency = 0;
 534   priv-&gt;max_latency = 0;
 535   priv-&gt;min_pts = GST_CLOCK_TIME_NONE;
 536   priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
 537 
 538   gst_video_encoder_reset (encoder, TRUE);
 539 }
 540 
 541 /**
 542  * gst_video_encoder_set_headers:
 543  * @encoder: a #GstVideoEncoder
 544  * @headers: (transfer full) (element-type GstBuffer): a list of #GstBuffer containing the codec header
 545  *
 546  * Set the codec headers to be sent downstream whenever requested.
 547  */
 548 void
 549 gst_video_encoder_set_headers (GstVideoEncoder * video_encoder, GList * headers)
 550 {
 551   GST_VIDEO_ENCODER_STREAM_LOCK (video_encoder);
 552 
 553   GST_DEBUG_OBJECT (video_encoder, &quot;new headers %p&quot;, headers);
 554   if (video_encoder-&gt;priv-&gt;headers) {
 555     g_list_foreach (video_encoder-&gt;priv-&gt;headers, (GFunc) gst_buffer_unref,
 556         NULL);
 557     g_list_free (video_encoder-&gt;priv-&gt;headers);
 558   }
 559   video_encoder-&gt;priv-&gt;headers = headers;
 560   video_encoder-&gt;priv-&gt;new_headers = TRUE;
 561 
 562   GST_VIDEO_ENCODER_STREAM_UNLOCK (video_encoder);
 563 }
 564 
 565 static GstVideoCodecState *
 566 _new_output_state (GstCaps * caps, GstVideoCodecState * reference)
 567 {
 568   GstVideoCodecState *state;
 569 
 570   state = g_slice_new0 (GstVideoCodecState);
 571   state-&gt;ref_count = 1;
 572   gst_video_info_init (&amp;state-&gt;info);
 573 
 574   if (!gst_video_info_set_format (&amp;state-&gt;info, GST_VIDEO_FORMAT_ENCODED, 0, 0)) {
 575     g_slice_free (GstVideoCodecState, state);
 576     return NULL;
 577   }
 578 
 579   state-&gt;caps = caps;
 580 
 581   if (reference) {
 582     GstVideoInfo *tgt, *ref;
 583 
 584     tgt = &amp;state-&gt;info;
 585     ref = &amp;reference-&gt;info;
 586 
 587     /* Copy over extra fields from reference state */
 588     tgt-&gt;interlace_mode = ref-&gt;interlace_mode;
 589     tgt-&gt;flags = ref-&gt;flags;
 590     tgt-&gt;width = ref-&gt;width;
 591     tgt-&gt;height = ref-&gt;height;
 592     tgt-&gt;chroma_site = ref-&gt;chroma_site;
 593     tgt-&gt;colorimetry = ref-&gt;colorimetry;
 594     tgt-&gt;par_n = ref-&gt;par_n;
 595     tgt-&gt;par_d = ref-&gt;par_d;
 596     tgt-&gt;fps_n = ref-&gt;fps_n;
 597     tgt-&gt;fps_d = ref-&gt;fps_d;
 598 
 599     GST_VIDEO_INFO_FIELD_ORDER (tgt) = GST_VIDEO_INFO_FIELD_ORDER (ref);
 600 
 601     GST_VIDEO_INFO_MULTIVIEW_MODE (tgt) = GST_VIDEO_INFO_MULTIVIEW_MODE (ref);
 602     GST_VIDEO_INFO_MULTIVIEW_FLAGS (tgt) = GST_VIDEO_INFO_MULTIVIEW_FLAGS (ref);
 603   }
 604 
 605   return state;
 606 }
 607 
 608 static GstVideoCodecState *
 609 _new_input_state (GstCaps * caps)
 610 {
 611   GstVideoCodecState *state;
 612 
 613   state = g_slice_new0 (GstVideoCodecState);
 614   state-&gt;ref_count = 1;
 615   gst_video_info_init (&amp;state-&gt;info);
 616   if (G_UNLIKELY (!gst_video_info_from_caps (&amp;state-&gt;info, caps)))
 617     goto parse_fail;
 618   state-&gt;caps = gst_caps_ref (caps);
 619 
 620   return state;
 621 
 622 parse_fail:
 623   {
 624     g_slice_free (GstVideoCodecState, state);
 625     return NULL;
 626   }
 627 }
 628 
 629 static gboolean
 630 gst_video_encoder_setcaps (GstVideoEncoder * encoder, GstCaps * caps)
 631 {
 632   GstVideoEncoderClass *encoder_class;
 633   GstVideoCodecState *state;
 634   gboolean ret;
 635 
 636   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 637 
 638   /* subclass should do something here ... */
 639   g_return_val_if_fail (encoder_class-&gt;set_format != NULL, FALSE);
 640 
 641   GST_DEBUG_OBJECT (encoder, &quot;setcaps %&quot; GST_PTR_FORMAT, caps);
 642 
 643   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 644 
 645   if (encoder-&gt;priv-&gt;input_state) {
 646     GST_DEBUG_OBJECT (encoder,
 647         &quot;Checking if caps changed old %&quot; GST_PTR_FORMAT &quot; new %&quot; GST_PTR_FORMAT,
 648         encoder-&gt;priv-&gt;input_state-&gt;caps, caps);
 649     if (gst_caps_is_equal (encoder-&gt;priv-&gt;input_state-&gt;caps, caps))
 650       goto caps_not_changed;
 651   }
 652 
 653   state = _new_input_state (caps);
 654   if (G_UNLIKELY (!state))
 655     goto parse_fail;
 656 
 657   if (encoder-&gt;priv-&gt;input_state
 658       &amp;&amp; gst_video_info_is_equal (&amp;state-&gt;info,
 659           &amp;encoder-&gt;priv-&gt;input_state-&gt;info)) {
 660     gst_video_codec_state_unref (state);
 661     goto caps_not_changed;
 662   }
 663 
 664   if (encoder_class-&gt;reset) {
 665     GST_FIXME_OBJECT (encoder, &quot;GstVideoEncoder::reset() is deprecated&quot;);
 666     encoder_class-&gt;reset (encoder, TRUE);
 667   }
 668 
 669   /* and subclass should be ready to configure format at any time around */
 670   ret = encoder_class-&gt;set_format (encoder, state);
 671   if (ret) {
 672     if (encoder-&gt;priv-&gt;input_state)
 673       gst_video_codec_state_unref (encoder-&gt;priv-&gt;input_state);
 674     encoder-&gt;priv-&gt;input_state = state;
 675   } else {
 676     gst_video_codec_state_unref (state);
 677   }
 678 
 679   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 680 
 681   if (!ret)
 682     GST_WARNING_OBJECT (encoder, &quot;rejected caps %&quot; GST_PTR_FORMAT, caps);
 683 
 684   return ret;
 685 
 686 caps_not_changed:
 687   {
 688     GST_DEBUG_OBJECT (encoder, &quot;Caps did not change - ignore&quot;);
 689     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 690     return TRUE;
 691   }
 692 
 693   /* ERRORS */
 694 parse_fail:
 695   {
 696     GST_WARNING_OBJECT (encoder, &quot;Failed to parse caps&quot;);
 697     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 698     return FALSE;
 699   }
 700 }
 701 
 702 /**
 703  * gst_video_encoder_proxy_getcaps:
 704  * @enc: a #GstVideoEncoder
 705  * @caps: (allow-none): initial caps
 706  * @filter: (allow-none): filter caps
 707  *
 708  * Returns caps that express @caps (or sink template caps if @caps == NULL)
 709  * restricted to resolution/format/... combinations supported by downstream
 710  * elements (e.g. muxers).
 711  *
 712  * Returns: (transfer full): a #GstCaps owned by caller
 713  */
 714 GstCaps *
 715 gst_video_encoder_proxy_getcaps (GstVideoEncoder * encoder, GstCaps * caps,
 716     GstCaps * filter)
 717 {
 718   return __gst_video_element_proxy_getcaps (GST_ELEMENT_CAST (encoder),
 719       GST_VIDEO_ENCODER_SINK_PAD (encoder),
 720       GST_VIDEO_ENCODER_SRC_PAD (encoder), caps, filter);
 721 }
 722 
 723 static GstCaps *
 724 gst_video_encoder_sink_getcaps (GstVideoEncoder * encoder, GstCaps * filter)
 725 {
 726   GstVideoEncoderClass *klass;
 727   GstCaps *caps;
 728 
 729   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 730 
 731   if (klass-&gt;getcaps)
 732     caps = klass-&gt;getcaps (encoder, filter);
 733   else
 734     caps = gst_video_encoder_proxy_getcaps (encoder, NULL, filter);
 735 
 736   GST_LOG_OBJECT (encoder, &quot;Returning caps %&quot; GST_PTR_FORMAT, caps);
 737 
 738   return caps;
 739 }
 740 
 741 static gboolean
 742 gst_video_encoder_decide_allocation_default (GstVideoEncoder * encoder,
 743     GstQuery * query)
 744 {
 745   GstAllocator *allocator = NULL;
 746   GstAllocationParams params;
 747   gboolean update_allocator;
 748 
 749   /* we got configuration from our peer or the decide_allocation method,
 750    * parse them */
 751   if (gst_query_get_n_allocation_params (query) &gt; 0) {
 752     /* try the allocator */
 753     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 754     update_allocator = TRUE;
 755   } else {
 756     allocator = NULL;
 757     gst_allocation_params_init (&amp;params);
 758     update_allocator = FALSE;
 759   }
 760 
 761   if (update_allocator)
 762     gst_query_set_nth_allocation_param (query, 0, allocator, &amp;params);
 763   else
 764     gst_query_add_allocation_param (query, allocator, &amp;params);
 765   if (allocator)
 766     gst_object_unref (allocator);
 767 
 768   return TRUE;
 769 }
 770 
 771 static gboolean
 772 gst_video_encoder_propose_allocation_default (GstVideoEncoder * encoder,
 773     GstQuery * query)
 774 {
 775   GstCaps *caps;
 776   GstVideoInfo info;
 777   GstBufferPool *pool;
 778   guint size;
 779 
 780   gst_query_parse_allocation (query, &amp;caps, NULL);
 781 
 782   if (caps == NULL)
 783     return FALSE;
 784 
 785   if (!gst_video_info_from_caps (&amp;info, caps))
 786     return FALSE;
 787 
 788   size = GST_VIDEO_INFO_SIZE (&amp;info);
 789 
 790   if (gst_query_get_n_allocation_pools (query) == 0) {
 791     GstStructure *structure;
 792     GstAllocator *allocator = NULL;
 793     GstAllocationParams params = { 0, 15, 0, 0 };
 794 
 795     if (gst_query_get_n_allocation_params (query) &gt; 0)
 796       gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 797     else
 798       gst_query_add_allocation_param (query, allocator, &amp;params);
 799 
 800     pool = gst_video_buffer_pool_new ();
 801 
 802     structure = gst_buffer_pool_get_config (pool);
 803     gst_buffer_pool_config_set_params (structure, caps, size, 0, 0);
 804     gst_buffer_pool_config_set_allocator (structure, allocator, &amp;params);
 805 
 806     if (allocator)
 807       gst_object_unref (allocator);
 808 
 809     if (!gst_buffer_pool_set_config (pool, structure))
 810       goto config_failed;
 811 
 812     gst_query_add_allocation_pool (query, pool, size, 0, 0);
 813     gst_object_unref (pool);
 814     gst_query_add_allocation_meta (query, GST_VIDEO_META_API_TYPE, NULL);
 815   }
 816 
 817   return TRUE;
 818 
 819   /* ERRORS */
 820 config_failed:
 821   {
 822     GST_ERROR_OBJECT (encoder, &quot;failed to set config&quot;);
 823     gst_object_unref (pool);
 824     return FALSE;
 825   }
 826 }
 827 
 828 static gboolean
 829 gst_video_encoder_sink_query_default (GstVideoEncoder * encoder,
 830     GstQuery * query)
 831 {
 832   GstPad *pad = GST_VIDEO_ENCODER_SINK_PAD (encoder);
 833   gboolean res = FALSE;
 834 
 835   switch (GST_QUERY_TYPE (query)) {
 836     case GST_QUERY_CAPS:
 837     {
 838       GstCaps *filter, *caps;
 839 
 840       gst_query_parse_caps (query, &amp;filter);
 841       caps = gst_video_encoder_sink_getcaps (encoder, filter);
 842       gst_query_set_caps_result (query, caps);
 843       gst_caps_unref (caps);
 844       res = TRUE;
 845       break;
 846     }
 847     case GST_QUERY_CONVERT:
 848     {
 849       GstFormat src_fmt, dest_fmt;
 850       gint64 src_val, dest_val;
 851 
 852       GST_DEBUG_OBJECT (encoder, &quot;convert query&quot;);
 853 
 854       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
 855       GST_OBJECT_LOCK (encoder);
 856       if (encoder-&gt;priv-&gt;input_state != NULL)
 857         res = __gst_video_rawvideo_convert (encoder-&gt;priv-&gt;input_state,
 858             src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
 859       else
 860         res = FALSE;
 861       GST_OBJECT_UNLOCK (encoder);
 862       if (!res)
 863         goto error;
 864       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
 865       break;
 866     }
 867     case GST_QUERY_ALLOCATION:
 868     {
 869       GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 870 
 871       if (klass-&gt;propose_allocation)
 872         res = klass-&gt;propose_allocation (encoder, query);
 873       break;
 874     }
 875     default:
 876       res = gst_pad_query_default (pad, GST_OBJECT (encoder), query);
 877       break;
 878   }
 879   return res;
 880 
 881 error:
 882   GST_DEBUG_OBJECT (encoder, &quot;query failed&quot;);
 883   return res;
 884 }
 885 
 886 static gboolean
 887 gst_video_encoder_sink_query (GstPad * pad, GstObject * parent,
 888     GstQuery * query)
 889 {
 890   GstVideoEncoder *encoder;
 891   GstVideoEncoderClass *encoder_class;
 892   gboolean ret = FALSE;
 893 
 894   encoder = GST_VIDEO_ENCODER (parent);
 895   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
 896 
 897   GST_DEBUG_OBJECT (encoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
 898       GST_QUERY_TYPE_NAME (query));
 899 
 900   if (encoder_class-&gt;sink_query)
 901     ret = encoder_class-&gt;sink_query (encoder, query);
 902 
 903   return ret;
 904 }
 905 
 906 static void
 907 gst_video_encoder_finalize (GObject * object)
 908 {
 909   GstVideoEncoder *encoder;
 910 
 911   GST_DEBUG_OBJECT (object, &quot;finalize&quot;);
 912 
 913   encoder = GST_VIDEO_ENCODER (object);
 914   g_rec_mutex_clear (&amp;encoder-&gt;stream_lock);
 915 
 916   if (encoder-&gt;priv-&gt;allocator) {
 917     gst_object_unref (encoder-&gt;priv-&gt;allocator);
 918     encoder-&gt;priv-&gt;allocator = NULL;
 919   }
 920 
 921   G_OBJECT_CLASS (parent_class)-&gt;finalize (object);
 922 }
 923 
 924 static gboolean
 925 gst_video_encoder_push_event (GstVideoEncoder * encoder, GstEvent * event)
 926 {
 927   switch (GST_EVENT_TYPE (event)) {
 928     case GST_EVENT_SEGMENT:
 929     {
 930       GstSegment segment;
 931 
 932       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
 933 
 934       gst_event_copy_segment (event, &amp;segment);
 935 
 936       GST_DEBUG_OBJECT (encoder, &quot;segment %&quot; GST_SEGMENT_FORMAT, &amp;segment);
 937 
 938       if (segment.format != GST_FORMAT_TIME) {
 939         GST_DEBUG_OBJECT (encoder, &quot;received non TIME segment&quot;);
 940         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 941         break;
 942       }
 943 
 944       if (encoder-&gt;priv-&gt;time_adjustment != GST_CLOCK_TIME_NONE) {
 945         segment.start += encoder-&gt;priv-&gt;time_adjustment;
<a name="7" id="anc7"></a>


 946         if (GST_CLOCK_TIME_IS_VALID (segment.stop)) {
 947           segment.stop += encoder-&gt;priv-&gt;time_adjustment;
 948         }
 949       }
 950 
 951       encoder-&gt;output_segment = segment;
 952       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
 953 
 954       gst_event_unref (event);
 955       event = gst_event_new_segment (&amp;encoder-&gt;output_segment);
 956 
 957       break;
 958     }
 959     default:
 960       break;
 961   }
 962 
 963   return gst_pad_push_event (encoder-&gt;srcpad, event);
 964 }
 965 
 966 static GstEvent *
 967 gst_video_encoder_create_merged_tags_event (GstVideoEncoder * enc)
 968 {
 969   GstTagList *merged_tags;
 970 
 971   GST_LOG_OBJECT (enc, &quot;upstream : %&quot; GST_PTR_FORMAT, enc-&gt;priv-&gt;upstream_tags);
 972   GST_LOG_OBJECT (enc, &quot;encoder  : %&quot; GST_PTR_FORMAT, enc-&gt;priv-&gt;tags);
 973   GST_LOG_OBJECT (enc, &quot;mode     : %d&quot;, enc-&gt;priv-&gt;tags_merge_mode);
 974 
 975   merged_tags =
 976       gst_tag_list_merge (enc-&gt;priv-&gt;upstream_tags, enc-&gt;priv-&gt;tags,
 977       enc-&gt;priv-&gt;tags_merge_mode);
 978 
 979   GST_DEBUG_OBJECT (enc, &quot;merged   : %&quot; GST_PTR_FORMAT, merged_tags);
 980 
 981   if (merged_tags == NULL)
 982     return NULL;
 983 
 984   if (gst_tag_list_is_empty (merged_tags)) {
 985     gst_tag_list_unref (merged_tags);
 986     return NULL;
 987   }
 988 
 989   return gst_event_new_tag (merged_tags);
 990 }
 991 
 992 static inline void
 993 gst_video_encoder_check_and_push_tags (GstVideoEncoder * encoder)
 994 {
 995   if (encoder-&gt;priv-&gt;tags_changed) {
 996     GstEvent *tags_event;
 997 
 998     tags_event = gst_video_encoder_create_merged_tags_event (encoder);
 999 
1000     if (tags_event != NULL)
1001       gst_video_encoder_push_event (encoder, tags_event);
1002 
1003     encoder-&gt;priv-&gt;tags_changed = FALSE;
1004   }
1005 }
1006 
1007 static gboolean
1008 gst_video_encoder_sink_event_default (GstVideoEncoder * encoder,
1009     GstEvent * event)
1010 {
1011   GstVideoEncoderClass *encoder_class;
1012   gboolean ret = FALSE;
1013 
1014   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1015 
1016   switch (GST_EVENT_TYPE (event)) {
1017     case GST_EVENT_CAPS:
1018     {
1019       GstCaps *caps;
1020 
1021       gst_event_parse_caps (event, &amp;caps);
1022       ret = gst_video_encoder_setcaps (encoder, caps);
1023 
1024       gst_event_unref (event);
1025       event = NULL;
1026       break;
1027     }
1028     case GST_EVENT_EOS:
1029     {
1030       GstFlowReturn flow_ret;
1031 
1032       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1033 
1034       if (encoder_class-&gt;finish) {
1035         flow_ret = encoder_class-&gt;finish (encoder);
1036       } else {
1037         flow_ret = GST_FLOW_OK;
1038       }
1039 
1040       if (encoder-&gt;priv-&gt;current_frame_events) {
1041         GList *l;
1042 
1043         for (l = g_list_last (encoder-&gt;priv-&gt;current_frame_events); l;
1044             l = g_list_previous (l)) {
1045           GstEvent *event = GST_EVENT (l-&gt;data);
1046 
1047           gst_video_encoder_push_event (encoder, event);
1048         }
1049       }
1050       g_list_free (encoder-&gt;priv-&gt;current_frame_events);
1051       encoder-&gt;priv-&gt;current_frame_events = NULL;
1052 
1053       gst_video_encoder_check_and_push_tags (encoder);
1054 
1055       ret = (flow_ret == GST_FLOW_OK);
1056       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1057       break;
1058     }
1059     case GST_EVENT_SEGMENT:
1060     {
1061       GstSegment segment;
1062 
1063       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1064 
1065       gst_event_copy_segment (event, &amp;segment);
1066 
1067       GST_DEBUG_OBJECT (encoder, &quot;segment %&quot; GST_SEGMENT_FORMAT, &amp;segment);
1068 
1069       if (segment.format != GST_FORMAT_TIME) {
1070         GST_DEBUG_OBJECT (encoder, &quot;received non TIME newsegment&quot;);
1071         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1072         break;
1073       }
1074 
1075       encoder-&gt;input_segment = segment;
1076       ret = TRUE;
1077       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1078       break;
1079     }
1080     case GST_EVENT_CUSTOM_DOWNSTREAM:
1081     {
1082       if (gst_video_event_is_force_key_unit (event)) {
1083         GstClockTime running_time;
1084         gboolean all_headers;
1085         guint count;
1086 
1087         if (gst_video_event_parse_downstream_force_key_unit (event,
1088                 NULL, NULL, &amp;running_time, &amp;all_headers, &amp;count)) {
1089           ForcedKeyUnitEvent *fevt;
1090 
1091           GST_OBJECT_LOCK (encoder);
1092           fevt = forced_key_unit_event_new (running_time, all_headers, count);
1093           encoder-&gt;priv-&gt;force_key_unit =
1094               g_list_append (encoder-&gt;priv-&gt;force_key_unit, fevt);
1095           GST_OBJECT_UNLOCK (encoder);
1096 
1097           GST_DEBUG_OBJECT (encoder,
1098               &quot;force-key-unit event: running-time %&quot; GST_TIME_FORMAT
1099               &quot;, all_headers %d, count %u&quot;,
1100               GST_TIME_ARGS (running_time), all_headers, count);
1101         }
1102         gst_event_unref (event);
1103         event = NULL;
1104         ret = TRUE;
1105       }
1106       break;
1107     }
1108     case GST_EVENT_STREAM_START:
1109     {
1110       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1111       /* Flush upstream tags after a STREAM_START */
1112       GST_DEBUG_OBJECT (encoder, &quot;STREAM_START, clearing upstream tags&quot;);
1113       if (encoder-&gt;priv-&gt;upstream_tags) {
1114         gst_tag_list_unref (encoder-&gt;priv-&gt;upstream_tags);
1115         encoder-&gt;priv-&gt;upstream_tags = NULL;
1116         encoder-&gt;priv-&gt;tags_changed = TRUE;
1117       }
1118       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1119       break;
1120     }
1121     case GST_EVENT_TAG:
1122     {
1123       GstTagList *tags;
1124 
1125       gst_event_parse_tag (event, &amp;tags);
1126 
1127       if (gst_tag_list_get_scope (tags) == GST_TAG_SCOPE_STREAM) {
1128         GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1129         if (encoder-&gt;priv-&gt;upstream_tags != tags) {
1130           tags = gst_tag_list_copy (tags);
1131 
1132           /* FIXME: make generic based on GST_TAG_FLAG_ENCODED */
1133           gst_tag_list_remove_tag (tags, GST_TAG_CODEC);
1134           gst_tag_list_remove_tag (tags, GST_TAG_AUDIO_CODEC);
1135           gst_tag_list_remove_tag (tags, GST_TAG_VIDEO_CODEC);
1136           gst_tag_list_remove_tag (tags, GST_TAG_SUBTITLE_CODEC);
1137           gst_tag_list_remove_tag (tags, GST_TAG_CONTAINER_FORMAT);
1138           gst_tag_list_remove_tag (tags, GST_TAG_BITRATE);
1139           gst_tag_list_remove_tag (tags, GST_TAG_NOMINAL_BITRATE);
1140           gst_tag_list_remove_tag (tags, GST_TAG_MAXIMUM_BITRATE);
1141           gst_tag_list_remove_tag (tags, GST_TAG_MINIMUM_BITRATE);
1142           gst_tag_list_remove_tag (tags, GST_TAG_ENCODER);
1143           gst_tag_list_remove_tag (tags, GST_TAG_ENCODER_VERSION);
1144 
1145           if (encoder-&gt;priv-&gt;upstream_tags)
1146             gst_tag_list_unref (encoder-&gt;priv-&gt;upstream_tags);
1147           encoder-&gt;priv-&gt;upstream_tags = tags;
1148           GST_INFO_OBJECT (encoder, &quot;upstream tags: %&quot; GST_PTR_FORMAT, tags);
1149         }
1150         gst_event_unref (event);
1151         event = gst_video_encoder_create_merged_tags_event (encoder);
1152         GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1153         if (!event)
1154           ret = TRUE;
1155       }
1156       break;
1157     }
1158     case GST_EVENT_FLUSH_STOP:{
1159       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1160       gst_video_encoder_flush (encoder);
1161       gst_segment_init (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME);
1162       gst_segment_init (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME);
1163       gst_video_encoder_reset (encoder, FALSE);
1164       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1165       break;
1166     }
1167     default:
1168       break;
1169   }
1170 
1171   /* Forward non-serialized events and EOS/FLUSH_STOP immediately.
1172    * For EOS this is required because no buffer or serialized event
1173    * will come after EOS and nothing could trigger another
1174    * _finish_frame() call.   *
1175    * If the subclass handles sending of EOS manually it can simply
1176    * not chain up to the parent class&#39; event handler
1177    *
1178    * For FLUSH_STOP this is required because it is expected
1179    * to be forwarded immediately and no buffers are queued anyway.
1180    */
1181   if (event) {
1182     if (!GST_EVENT_IS_SERIALIZED (event)
1183         || GST_EVENT_TYPE (event) == GST_EVENT_EOS
1184         || GST_EVENT_TYPE (event) == GST_EVENT_FLUSH_STOP) {
1185       ret = gst_video_encoder_push_event (encoder, event);
1186     } else {
1187       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1188       encoder-&gt;priv-&gt;current_frame_events =
1189           g_list_prepend (encoder-&gt;priv-&gt;current_frame_events, event);
1190       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1191       ret = TRUE;
1192     }
1193   }
1194 
1195   return ret;
1196 }
1197 
1198 static gboolean
1199 gst_video_encoder_sink_event (GstPad * pad, GstObject * parent,
1200     GstEvent * event)
1201 {
1202   GstVideoEncoder *enc;
1203   GstVideoEncoderClass *klass;
1204   gboolean ret = TRUE;
1205 
1206   enc = GST_VIDEO_ENCODER (parent);
1207   klass = GST_VIDEO_ENCODER_GET_CLASS (enc);
1208 
1209   GST_DEBUG_OBJECT (enc, &quot;received event %d, %s&quot;, GST_EVENT_TYPE (event),
1210       GST_EVENT_TYPE_NAME (event));
1211 
1212   if (klass-&gt;sink_event)
1213     ret = klass-&gt;sink_event (enc, event);
1214 
1215   return ret;
1216 }
1217 
1218 static gboolean
1219 gst_video_encoder_src_event_default (GstVideoEncoder * encoder,
1220     GstEvent * event)
1221 {
1222   gboolean ret = FALSE;
1223   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
1224 
1225   switch (GST_EVENT_TYPE (event)) {
1226     case GST_EVENT_CUSTOM_UPSTREAM:
1227     {
1228       if (gst_video_event_is_force_key_unit (event)) {
1229         GstClockTime running_time;
1230         gboolean all_headers;
1231         guint count;
1232 
1233         if (gst_video_event_parse_upstream_force_key_unit (event,
1234                 &amp;running_time, &amp;all_headers, &amp;count)) {
1235           ForcedKeyUnitEvent *fevt;
1236 
1237           GST_OBJECT_LOCK (encoder);
1238           fevt = forced_key_unit_event_new (running_time, all_headers, count);
1239           encoder-&gt;priv-&gt;force_key_unit =
1240               g_list_append (encoder-&gt;priv-&gt;force_key_unit, fevt);
1241           GST_OBJECT_UNLOCK (encoder);
1242 
1243           GST_DEBUG_OBJECT (encoder,
1244               &quot;force-key-unit event: running-time %&quot; GST_TIME_FORMAT
1245               &quot;, all_headers %d, count %u&quot;,
1246               GST_TIME_ARGS (running_time), all_headers, count);
1247         }
1248         gst_event_unref (event);
1249         event = NULL;
1250         ret = TRUE;
1251       }
1252       break;
1253     }
1254     case GST_EVENT_QOS:
1255     {
1256       GstQOSType type;
1257       gdouble proportion;
1258       GstClockTimeDiff diff;
1259       GstClockTime timestamp;
1260 
1261       if (!g_atomic_int_get (&amp;priv-&gt;qos_enabled))
1262         break;
1263 
1264       gst_event_parse_qos (event, &amp;type, &amp;proportion, &amp;diff, &amp;timestamp);
1265 
1266       GST_OBJECT_LOCK (encoder);
1267       priv-&gt;proportion = proportion;
1268       if (G_LIKELY (GST_CLOCK_TIME_IS_VALID (timestamp))) {
1269         if (G_UNLIKELY (diff &gt; 0)) {
1270           priv-&gt;earliest_time = timestamp + 2 * diff + priv-&gt;qos_frame_duration;
1271         } else {
1272           priv-&gt;earliest_time = timestamp + diff;
1273         }
1274       } else {
1275         priv-&gt;earliest_time = GST_CLOCK_TIME_NONE;
1276       }
1277       GST_OBJECT_UNLOCK (encoder);
1278 
1279       GST_DEBUG_OBJECT (encoder,
1280           &quot;got QoS %&quot; GST_TIME_FORMAT &quot;, %&quot; GST_STIME_FORMAT &quot;, %g&quot;,
1281           GST_TIME_ARGS (timestamp), GST_STIME_ARGS (diff), proportion);
1282 
1283       ret = gst_pad_push_event (encoder-&gt;sinkpad, event);
1284       event = NULL;
1285       break;
1286     }
1287     default:
1288       break;
1289   }
1290 
1291   if (event)
1292     ret =
1293         gst_pad_event_default (encoder-&gt;srcpad, GST_OBJECT_CAST (encoder),
1294         event);
1295 
1296   return ret;
1297 }
1298 
1299 static gboolean
1300 gst_video_encoder_src_event (GstPad * pad, GstObject * parent, GstEvent * event)
1301 {
1302   GstVideoEncoder *encoder;
1303   GstVideoEncoderClass *klass;
1304   gboolean ret = FALSE;
1305 
1306   encoder = GST_VIDEO_ENCODER (parent);
1307   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1308 
1309   GST_LOG_OBJECT (encoder, &quot;handling event: %&quot; GST_PTR_FORMAT, event);
1310 
1311   if (klass-&gt;src_event)
1312     ret = klass-&gt;src_event (encoder, event);
1313 
1314   return ret;
1315 }
1316 
1317 static gboolean
1318 gst_video_encoder_src_query_default (GstVideoEncoder * enc, GstQuery * query)
1319 {
1320   GstPad *pad = GST_VIDEO_ENCODER_SRC_PAD (enc);
1321   GstVideoEncoderPrivate *priv;
1322   gboolean res;
1323 
1324   priv = enc-&gt;priv;
1325 
1326   GST_LOG_OBJECT (enc, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
1327 
1328   switch (GST_QUERY_TYPE (query)) {
1329     case GST_QUERY_CONVERT:
1330     {
1331       GstFormat src_fmt, dest_fmt;
1332       gint64 src_val, dest_val;
1333 
1334       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
1335       GST_OBJECT_LOCK (enc);
1336       res =
1337           __gst_video_encoded_video_convert (priv-&gt;bytes, priv-&gt;time, src_fmt,
1338           src_val, &amp;dest_fmt, &amp;dest_val);
1339       GST_OBJECT_UNLOCK (enc);
1340       if (!res)
1341         goto error;
1342       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
1343       break;
1344     }
1345     case GST_QUERY_LATENCY:
1346     {
1347       gboolean live;
1348       GstClockTime min_latency, max_latency;
1349 
1350       res = gst_pad_peer_query (enc-&gt;sinkpad, query);
1351       if (res) {
1352         gst_query_parse_latency (query, &amp;live, &amp;min_latency, &amp;max_latency);
1353         GST_DEBUG_OBJECT (enc, &quot;Peer latency: live %d, min %&quot;
1354             GST_TIME_FORMAT &quot; max %&quot; GST_TIME_FORMAT, live,
1355             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
1356 
1357         GST_OBJECT_LOCK (enc);
1358         min_latency += priv-&gt;min_latency;
1359         if (max_latency == GST_CLOCK_TIME_NONE
1360             || enc-&gt;priv-&gt;max_latency == GST_CLOCK_TIME_NONE)
1361           max_latency = GST_CLOCK_TIME_NONE;
1362         else
1363           max_latency += enc-&gt;priv-&gt;max_latency;
1364         GST_OBJECT_UNLOCK (enc);
1365 
1366         gst_query_set_latency (query, live, min_latency, max_latency);
1367       }
1368     }
1369       break;
1370     default:
1371       res = gst_pad_query_default (pad, GST_OBJECT (enc), query);
1372   }
1373   return res;
1374 
1375 error:
1376   GST_DEBUG_OBJECT (enc, &quot;query failed&quot;);
1377   return res;
1378 }
1379 
1380 static gboolean
1381 gst_video_encoder_src_query (GstPad * pad, GstObject * parent, GstQuery * query)
1382 {
1383   GstVideoEncoder *encoder;
1384   GstVideoEncoderClass *encoder_class;
1385   gboolean ret = FALSE;
1386 
1387   encoder = GST_VIDEO_ENCODER (parent);
1388   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1389 
1390   GST_DEBUG_OBJECT (encoder, &quot;received query %d, %s&quot;, GST_QUERY_TYPE (query),
1391       GST_QUERY_TYPE_NAME (query));
1392 
1393   if (encoder_class-&gt;src_query)
1394     ret = encoder_class-&gt;src_query (encoder, query);
1395 
1396   return ret;
1397 }
1398 
1399 static GstVideoCodecFrame *
1400 gst_video_encoder_new_frame (GstVideoEncoder * encoder, GstBuffer * buf,
1401     GstClockTime pts, GstClockTime dts, GstClockTime duration)
1402 {
1403   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
1404   GstVideoCodecFrame *frame;
1405 
1406   frame = g_slice_new0 (GstVideoCodecFrame);
1407 
1408   frame-&gt;ref_count = 1;
1409 
1410   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1411   frame-&gt;system_frame_number = priv-&gt;system_frame_number;
1412   priv-&gt;system_frame_number++;
1413 
1414   frame-&gt;presentation_frame_number = priv-&gt;presentation_frame_number;
1415   priv-&gt;presentation_frame_number++;
1416   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1417 
1418   frame-&gt;events = priv-&gt;current_frame_events;
1419   priv-&gt;current_frame_events = NULL;
1420   frame-&gt;input_buffer = buf;
1421   frame-&gt;pts = pts;
1422   frame-&gt;dts = dts;
1423   frame-&gt;duration = duration;
1424   frame-&gt;abidata.ABI.ts = pts;
1425 
1426   return frame;
1427 }
1428 
1429 
1430 static GstFlowReturn
1431 gst_video_encoder_chain (GstPad * pad, GstObject * parent, GstBuffer * buf)
1432 {
1433   GstVideoEncoder *encoder;
1434   GstVideoEncoderPrivate *priv;
1435   GstVideoEncoderClass *klass;
1436   GstVideoCodecFrame *frame;
1437   GstClockTime pts, duration;
1438   GstFlowReturn ret = GST_FLOW_OK;
1439   guint64 start, stop, cstart, cstop;
1440 
1441   encoder = GST_VIDEO_ENCODER (parent);
1442   priv = encoder-&gt;priv;
1443   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1444 
1445   g_return_val_if_fail (klass-&gt;handle_frame != NULL, GST_FLOW_ERROR);
1446 
1447   if (!encoder-&gt;priv-&gt;input_state)
1448     goto not_negotiated;
1449 
1450   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1451 
1452   pts = GST_BUFFER_PTS (buf);
1453   duration = GST_BUFFER_DURATION (buf);
1454 
1455   GST_LOG_OBJECT (encoder,
1456       &quot;received buffer of size %&quot; G_GSIZE_FORMAT &quot; with PTS %&quot; GST_TIME_FORMAT
1457       &quot;, DTS %&quot; GST_TIME_FORMAT &quot;, duration %&quot; GST_TIME_FORMAT,
1458       gst_buffer_get_size (buf), GST_TIME_ARGS (pts),
1459       GST_TIME_ARGS (GST_BUFFER_DTS (buf)), GST_TIME_ARGS (duration));
1460 
1461   start = pts;
1462   if (GST_CLOCK_TIME_IS_VALID (duration))
1463     stop = start + duration;
1464   else
1465     stop = GST_CLOCK_TIME_NONE;
1466 
1467   /* Drop buffers outside of segment */
1468   if (!gst_segment_clip (&amp;encoder-&gt;input_segment,
1469           GST_FORMAT_TIME, start, stop, &amp;cstart, &amp;cstop)) {
1470     GST_DEBUG_OBJECT (encoder, &quot;clipping to segment dropped frame&quot;);
1471     gst_buffer_unref (buf);
1472     goto done;
1473   }
1474 
1475   if (GST_CLOCK_TIME_IS_VALID (cstop))
1476     duration = cstop - cstart;
1477   else
1478     duration = GST_CLOCK_TIME_NONE;
1479 
1480   if (priv-&gt;min_pts != GST_CLOCK_TIME_NONE
1481       &amp;&amp; priv-&gt;time_adjustment == GST_CLOCK_TIME_NONE) {
1482     if (cstart &lt; priv-&gt;min_pts) {
1483       priv-&gt;time_adjustment = priv-&gt;min_pts - cstart;
1484     }
1485   }
1486 
1487   if (priv-&gt;time_adjustment != GST_CLOCK_TIME_NONE) {
1488     cstart += priv-&gt;time_adjustment;
1489   }
1490 
1491   /* incoming DTS is not really relevant and does not make sense anyway,
1492    * so pass along _NONE and maybe come up with something better later on */
1493   frame = gst_video_encoder_new_frame (encoder, buf, cstart,
1494       GST_CLOCK_TIME_NONE, duration);
1495 
1496   GST_OBJECT_LOCK (encoder);
1497   if (priv-&gt;force_key_unit) {
1498     ForcedKeyUnitEvent *fevt = NULL;
1499     GstClockTime running_time;
1500     GList *l;
1501 
1502     running_time =
1503         gst_segment_to_running_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
1504         cstart);
1505 
1506     for (l = priv-&gt;force_key_unit; l; l = l-&gt;next) {
1507       ForcedKeyUnitEvent *tmp = l-&gt;data;
1508 
1509       /* Skip pending keyunits */
1510       if (tmp-&gt;pending)
1511         continue;
1512 
1513       /* Simple case, keyunit ASAP */
1514       if (tmp-&gt;running_time == GST_CLOCK_TIME_NONE) {
1515         fevt = tmp;
1516         break;
1517       }
1518 
1519       /* Event for before this frame */
1520       if (tmp-&gt;running_time &lt;= running_time) {
1521         fevt = tmp;
1522         break;
1523       }
1524     }
1525 
1526     if (fevt) {
1527       fevt-&gt;frame_id = frame-&gt;system_frame_number;
1528       GST_DEBUG_OBJECT (encoder,
1529           &quot;Forcing a key unit at running time %&quot; GST_TIME_FORMAT,
1530           GST_TIME_ARGS (running_time));
1531       GST_VIDEO_CODEC_FRAME_SET_FORCE_KEYFRAME (frame);
1532       if (fevt-&gt;all_headers)
1533         GST_VIDEO_CODEC_FRAME_SET_FORCE_KEYFRAME_HEADERS (frame);
1534       fevt-&gt;pending = TRUE;
1535     }
1536   }
1537   GST_OBJECT_UNLOCK (encoder);
1538 
1539   gst_video_codec_frame_ref (frame);
1540   priv-&gt;frames = g_list_append (priv-&gt;frames, frame);
1541 
1542   /* new data, more finish needed */
1543   priv-&gt;drained = FALSE;
1544 
1545   GST_LOG_OBJECT (encoder, &quot;passing frame pfn %d to subclass&quot;,
1546       frame-&gt;presentation_frame_number);
1547 
1548   frame-&gt;deadline =
1549       gst_segment_to_running_time (&amp;encoder-&gt;input_segment, GST_FORMAT_TIME,
1550       frame-&gt;pts);
1551 
1552   ret = klass-&gt;handle_frame (encoder, frame);
1553 
1554 done:
1555   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1556 
1557   return ret;
1558 
1559   /* ERRORS */
1560 not_negotiated:
1561   {
1562     GST_ELEMENT_ERROR (encoder, CORE, NEGOTIATION, (NULL),
1563         (&quot;encoder not initialized&quot;));
1564     gst_buffer_unref (buf);
1565     return GST_FLOW_NOT_NEGOTIATED;
1566   }
1567 }
1568 
1569 static GstStateChangeReturn
1570 gst_video_encoder_change_state (GstElement * element, GstStateChange transition)
1571 {
1572   GstVideoEncoder *encoder;
1573   GstVideoEncoderClass *encoder_class;
1574   GstStateChangeReturn ret;
1575 
1576   encoder = GST_VIDEO_ENCODER (element);
1577   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (element);
1578 
1579   switch (transition) {
1580     case GST_STATE_CHANGE_NULL_TO_READY:
1581       /* open device/library if needed */
1582       if (encoder_class-&gt;open &amp;&amp; !encoder_class-&gt;open (encoder))
1583         goto open_failed;
1584       break;
1585     case GST_STATE_CHANGE_READY_TO_PAUSED:
1586       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1587       gst_video_encoder_reset (encoder, TRUE);
1588       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1589 
1590       /* Initialize device/library if needed */
1591       if (encoder_class-&gt;start &amp;&amp; !encoder_class-&gt;start (encoder))
1592         goto start_failed;
1593       break;
1594     default:
1595       break;
1596   }
1597 
1598   ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition);
1599 
1600   switch (transition) {
1601     case GST_STATE_CHANGE_PAUSED_TO_READY:{
1602       gboolean stopped = TRUE;
1603 
1604       if (encoder_class-&gt;stop)
1605         stopped = encoder_class-&gt;stop (encoder);
1606 
1607       GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1608       gst_video_encoder_reset (encoder, TRUE);
1609       GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1610 
1611       if (!stopped)
1612         goto stop_failed;
1613       break;
1614     }
1615     case GST_STATE_CHANGE_READY_TO_NULL:
1616       /* close device/library if needed */
1617       if (encoder_class-&gt;close &amp;&amp; !encoder_class-&gt;close (encoder))
1618         goto close_failed;
1619       break;
1620     default:
1621       break;
1622   }
1623 
1624   return ret;
1625 
1626   /* Errors */
1627 
1628 open_failed:
1629   {
1630     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1631         (&quot;Failed to open encoder&quot;));
1632     return GST_STATE_CHANGE_FAILURE;
1633   }
1634 
1635 start_failed:
1636   {
1637     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1638         (&quot;Failed to start encoder&quot;));
1639     return GST_STATE_CHANGE_FAILURE;
1640   }
1641 
1642 stop_failed:
1643   {
1644     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1645         (&quot;Failed to stop encoder&quot;));
1646     return GST_STATE_CHANGE_FAILURE;
1647   }
1648 
1649 close_failed:
1650   {
1651     GST_ELEMENT_ERROR (encoder, LIBRARY, INIT, (NULL),
1652         (&quot;Failed to close encoder&quot;));
1653     return GST_STATE_CHANGE_FAILURE;
1654   }
1655 }
1656 
1657 static gboolean
1658 gst_video_encoder_negotiate_default (GstVideoEncoder * encoder)
1659 {
1660   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1661   GstAllocator *allocator;
1662   GstAllocationParams params;
1663   gboolean ret = TRUE;
1664   GstVideoCodecState *state = encoder-&gt;priv-&gt;output_state;
1665   GstVideoInfo *info = &amp;state-&gt;info;
1666   GstQuery *query = NULL;
1667   GstVideoCodecFrame *frame;
1668   GstCaps *prevcaps;
1669   gchar *colorimetry;
1670 
1671   g_return_val_if_fail (state-&gt;caps != NULL, FALSE);
1672 
1673   if (encoder-&gt;priv-&gt;output_state_changed) {
1674     state-&gt;caps = gst_caps_make_writable (state-&gt;caps);
1675 
1676     /* Fill caps */
1677     gst_caps_set_simple (state-&gt;caps, &quot;width&quot;, G_TYPE_INT, info-&gt;width,
1678         &quot;height&quot;, G_TYPE_INT, info-&gt;height,
1679         &quot;pixel-aspect-ratio&quot;, GST_TYPE_FRACTION,
1680         info-&gt;par_n, info-&gt;par_d, NULL);
1681     if (info-&gt;flags &amp; GST_VIDEO_FLAG_VARIABLE_FPS &amp;&amp; info-&gt;fps_n != 0) {
1682       /* variable fps with a max-framerate */
1683       gst_caps_set_simple (state-&gt;caps, &quot;framerate&quot;, GST_TYPE_FRACTION, 0, 1,
1684           &quot;max-framerate&quot;, GST_TYPE_FRACTION, info-&gt;fps_n, info-&gt;fps_d, NULL);
1685     } else {
1686       /* no variable fps or no max-framerate */
1687       gst_caps_set_simple (state-&gt;caps, &quot;framerate&quot;, GST_TYPE_FRACTION,
1688           info-&gt;fps_n, info-&gt;fps_d, NULL);
1689     }
1690     if (state-&gt;codec_data)
1691       gst_caps_set_simple (state-&gt;caps, &quot;codec_data&quot;, GST_TYPE_BUFFER,
1692           state-&gt;codec_data, NULL);
1693 
1694     gst_caps_set_simple (state-&gt;caps, &quot;interlace-mode&quot;, G_TYPE_STRING,
1695         gst_video_interlace_mode_to_string (info-&gt;interlace_mode), NULL);
1696     if (info-&gt;interlace_mode == GST_VIDEO_INTERLACE_MODE_INTERLEAVED &amp;&amp;
1697         GST_VIDEO_INFO_FIELD_ORDER (info) != GST_VIDEO_FIELD_ORDER_UNKNOWN)
1698       gst_caps_set_simple (state-&gt;caps, &quot;field-order&quot;, G_TYPE_STRING,
1699           gst_video_field_order_to_string (GST_VIDEO_INFO_FIELD_ORDER (info)),
1700           NULL);
1701 
1702     colorimetry = gst_video_colorimetry_to_string (&amp;info-&gt;colorimetry);
1703     if (colorimetry)
1704       gst_caps_set_simple (state-&gt;caps, &quot;colorimetry&quot;, G_TYPE_STRING,
1705           colorimetry, NULL);
1706     g_free (colorimetry);
1707 
1708     if (info-&gt;chroma_site != GST_VIDEO_CHROMA_SITE_UNKNOWN)
1709       gst_caps_set_simple (state-&gt;caps, &quot;chroma-site&quot;, G_TYPE_STRING,
1710           gst_video_chroma_to_string (info-&gt;chroma_site), NULL);
1711 
1712     if (GST_VIDEO_INFO_MULTIVIEW_MODE (info) != GST_VIDEO_MULTIVIEW_MODE_NONE) {
1713       const gchar *caps_mview_mode =
1714           gst_video_multiview_mode_to_caps_string (GST_VIDEO_INFO_MULTIVIEW_MODE
1715           (info));
1716 
1717       gst_caps_set_simple (state-&gt;caps, &quot;multiview-mode&quot;, G_TYPE_STRING,
1718           caps_mview_mode, &quot;multiview-flags&quot;, GST_TYPE_VIDEO_MULTIVIEW_FLAGSET,
1719           GST_VIDEO_INFO_MULTIVIEW_FLAGS (info), GST_FLAG_SET_MASK_EXACT, NULL);
1720     }
1721     encoder-&gt;priv-&gt;output_state_changed = FALSE;
1722   }
1723 
1724   if (state-&gt;allocation_caps == NULL)
1725     state-&gt;allocation_caps = gst_caps_ref (state-&gt;caps);
1726 
1727   /* Push all pending pre-caps events of the oldest frame before
1728    * setting caps */
1729   frame = encoder-&gt;priv-&gt;frames ? encoder-&gt;priv-&gt;frames-&gt;data : NULL;
1730   if (frame || encoder-&gt;priv-&gt;current_frame_events) {
1731     GList **events, *l;
1732 
1733     if (frame) {
1734       events = &amp;frame-&gt;events;
1735     } else {
1736       events = &amp;encoder-&gt;priv-&gt;current_frame_events;
1737     }
1738 
1739     for (l = g_list_last (*events); l;) {
1740       GstEvent *event = GST_EVENT (l-&gt;data);
1741       GList *tmp;
1742 
1743       if (GST_EVENT_TYPE (event) &lt; GST_EVENT_CAPS) {
1744         gst_video_encoder_push_event (encoder, event);
1745         tmp = l;
1746         l = l-&gt;prev;
1747         *events = g_list_delete_link (*events, tmp);
1748       } else {
1749         l = l-&gt;prev;
1750       }
1751     }
1752   }
1753 
1754   prevcaps = gst_pad_get_current_caps (encoder-&gt;srcpad);
1755   if (!prevcaps || !gst_caps_is_equal (prevcaps, state-&gt;caps))
1756     ret = gst_pad_set_caps (encoder-&gt;srcpad, state-&gt;caps);
1757   else
1758     ret = TRUE;
1759   if (prevcaps)
1760     gst_caps_unref (prevcaps);
1761 
1762   if (!ret)
1763     goto done;
1764 
1765   query = gst_query_new_allocation (state-&gt;allocation_caps, TRUE);
1766   if (!gst_pad_peer_query (encoder-&gt;srcpad, query)) {
1767     GST_DEBUG_OBJECT (encoder, &quot;didn&#39;t get downstream ALLOCATION hints&quot;);
1768   }
1769 
1770   g_assert (klass-&gt;decide_allocation != NULL);
1771   ret = klass-&gt;decide_allocation (encoder, query);
1772 
1773   GST_DEBUG_OBJECT (encoder, &quot;ALLOCATION (%d) params: %&quot; GST_PTR_FORMAT, ret,
1774       query);
1775 
1776   if (!ret)
1777     goto no_decide_allocation;
1778 
1779   /* we got configuration from our peer or the decide_allocation method,
1780    * parse them */
1781   if (gst_query_get_n_allocation_params (query) &gt; 0) {
1782     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
1783   } else {
1784     allocator = NULL;
1785     gst_allocation_params_init (&amp;params);
1786   }
1787 
1788   if (encoder-&gt;priv-&gt;allocator)
1789     gst_object_unref (encoder-&gt;priv-&gt;allocator);
1790   encoder-&gt;priv-&gt;allocator = allocator;
1791   encoder-&gt;priv-&gt;params = params;
1792 
1793 done:
1794   if (query)
1795     gst_query_unref (query);
1796 
1797   return ret;
1798 
1799   /* Errors */
1800 no_decide_allocation:
1801   {
1802     GST_WARNING_OBJECT (encoder, &quot;Subclass failed to decide allocation&quot;);
1803     goto done;
1804   }
1805 }
1806 
1807 static gboolean
1808 gst_video_encoder_negotiate_unlocked (GstVideoEncoder * encoder)
1809 {
1810   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1811   gboolean ret = TRUE;
1812 
1813   if (G_LIKELY (klass-&gt;negotiate))
1814     ret = klass-&gt;negotiate (encoder);
1815 
1816   return ret;
1817 }
1818 
1819 /**
1820  * gst_video_encoder_negotiate:
1821  * @encoder: a #GstVideoEncoder
1822  *
1823  * Negotiate with downstream elements to currently configured #GstVideoCodecState.
1824  * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
1825  * negotiate fails.
1826  *
1827  * Returns: %TRUE if the negotiation succeeded, else %FALSE.
1828  */
1829 gboolean
1830 gst_video_encoder_negotiate (GstVideoEncoder * encoder)
1831 {
1832   GstVideoEncoderClass *klass;
1833   gboolean ret = TRUE;
1834 
1835   g_return_val_if_fail (GST_IS_VIDEO_ENCODER (encoder), FALSE);
1836   g_return_val_if_fail (encoder-&gt;priv-&gt;output_state, FALSE);
1837 
1838   klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1839 
1840   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1841   gst_pad_check_reconfigure (encoder-&gt;srcpad);
1842   if (klass-&gt;negotiate) {
1843     ret = klass-&gt;negotiate (encoder);
1844     if (!ret)
1845       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1846   }
1847   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1848 
1849   return ret;
1850 }
1851 
1852 /**
1853  * gst_video_encoder_allocate_output_buffer:
1854  * @encoder: a #GstVideoEncoder
1855  * @size: size of the buffer
1856  *
1857  * Helper function that allocates a buffer to hold an encoded video frame
1858  * for @encoder&#39;s current #GstVideoCodecState.
1859  *
1860  * Returns: (transfer full): allocated buffer
1861  */
1862 GstBuffer *
1863 gst_video_encoder_allocate_output_buffer (GstVideoEncoder * encoder, gsize size)
1864 {
1865   GstBuffer *buffer;
1866   gboolean needs_reconfigure = FALSE;
1867 
1868   g_return_val_if_fail (size &gt; 0, NULL);
1869 
1870   GST_DEBUG (&quot;alloc src buffer&quot;);
1871 
1872   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1873   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
1874   if (G_UNLIKELY (encoder-&gt;priv-&gt;output_state_changed
1875           || (encoder-&gt;priv-&gt;output_state &amp;&amp; needs_reconfigure))) {
1876     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
1877       GST_DEBUG_OBJECT (encoder, &quot;Failed to negotiate, fallback allocation&quot;);
1878       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1879       goto fallback;
1880     }
1881   }
1882 
1883   buffer =
1884       gst_buffer_new_allocate (encoder-&gt;priv-&gt;allocator, size,
1885       &amp;encoder-&gt;priv-&gt;params);
1886   if (!buffer) {
1887     GST_INFO_OBJECT (encoder, &quot;couldn&#39;t allocate output buffer&quot;);
1888     goto fallback;
1889   }
1890 
1891   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1892 
1893   return buffer;
1894 
1895 fallback:
1896   buffer = gst_buffer_new_allocate (NULL, size, NULL);
1897 
1898   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1899 
1900   return buffer;
1901 }
1902 
1903 /**
1904  * gst_video_encoder_allocate_output_frame:
1905  * @encoder: a #GstVideoEncoder
1906  * @frame: a #GstVideoCodecFrame
1907  * @size: size of the buffer
1908  *
1909  * Helper function that allocates a buffer to hold an encoded video frame for @encoder&#39;s
1910  * current #GstVideoCodecState.  Subclass should already have configured video
1911  * state and set src pad caps.
1912  *
1913  * The buffer allocated here is owned by the frame and you should only
1914  * keep references to the frame, not the buffer.
1915  *
1916  * Returns: %GST_FLOW_OK if an output buffer could be allocated
1917  */
1918 GstFlowReturn
1919 gst_video_encoder_allocate_output_frame (GstVideoEncoder *
1920     encoder, GstVideoCodecFrame * frame, gsize size)
1921 {
1922   gboolean needs_reconfigure = FALSE;
1923 
1924   g_return_val_if_fail (frame-&gt;output_buffer == NULL, GST_FLOW_ERROR);
1925 
1926   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
1927   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
1928   if (G_UNLIKELY (encoder-&gt;priv-&gt;output_state_changed
1929           || (encoder-&gt;priv-&gt;output_state &amp;&amp; needs_reconfigure))) {
1930     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
1931       GST_DEBUG_OBJECT (encoder, &quot;Failed to negotiate, fallback allocation&quot;);
1932       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
1933     }
1934   }
1935 
1936   GST_LOG_OBJECT (encoder, &quot;alloc buffer size %&quot; G_GSIZE_FORMAT, size);
1937 
1938   frame-&gt;output_buffer =
1939       gst_buffer_new_allocate (encoder-&gt;priv-&gt;allocator, size,
1940       &amp;encoder-&gt;priv-&gt;params);
1941 
1942   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
1943 
1944   return frame-&gt;output_buffer ? GST_FLOW_OK : GST_FLOW_ERROR;
1945 }
1946 
1947 static void
1948 gst_video_encoder_release_frame (GstVideoEncoder * enc,
1949     GstVideoCodecFrame * frame)
1950 {
1951   GList *link;
1952 
1953   /* unref once from the list */
1954   link = g_list_find (enc-&gt;priv-&gt;frames, frame);
1955   if (link) {
1956     gst_video_codec_frame_unref (frame);
1957     enc-&gt;priv-&gt;frames = g_list_delete_link (enc-&gt;priv-&gt;frames, link);
1958   }
1959   /* unref because this function takes ownership */
1960   gst_video_codec_frame_unref (frame);
1961 }
1962 
1963 static gboolean
1964 gst_video_encoder_transform_meta_default (GstVideoEncoder *
1965     encoder, GstVideoCodecFrame * frame, GstMeta * meta)
1966 {
1967   const GstMetaInfo *info = meta-&gt;info;
1968   const gchar *const *tags;
1969 
1970   tags = gst_meta_api_type_get_tags (info-&gt;api);
1971 
1972   if (!tags || (g_strv_length ((gchar **) tags) == 1
1973           &amp;&amp; gst_meta_api_type_has_tag (info-&gt;api,
1974               g_quark_from_string (GST_META_TAG_VIDEO_STR))))
1975     return TRUE;
1976 
1977   return FALSE;
1978 }
1979 
1980 typedef struct
1981 {
1982   GstVideoEncoder *encoder;
1983   GstVideoCodecFrame *frame;
1984 } CopyMetaData;
1985 
1986 static gboolean
1987 foreach_metadata (GstBuffer * inbuf, GstMeta ** meta, gpointer user_data)
1988 {
1989   CopyMetaData *data = user_data;
1990   GstVideoEncoder *encoder = data-&gt;encoder;
1991   GstVideoEncoderClass *klass = GST_VIDEO_ENCODER_GET_CLASS (encoder);
1992   GstVideoCodecFrame *frame = data-&gt;frame;
1993   const GstMetaInfo *info = (*meta)-&gt;info;
1994   gboolean do_copy = FALSE;
1995 
1996   if (gst_meta_api_type_has_tag (info-&gt;api, _gst_meta_tag_memory)) {
1997     /* never call the transform_meta with memory specific metadata */
1998     GST_DEBUG_OBJECT (encoder, &quot;not copying memory specific metadata %s&quot;,
1999         g_type_name (info-&gt;api));
2000     do_copy = FALSE;
2001   } else if (klass-&gt;transform_meta) {
2002     do_copy = klass-&gt;transform_meta (encoder, frame, *meta);
2003     GST_DEBUG_OBJECT (encoder, &quot;transformed metadata %s: copy: %d&quot;,
2004         g_type_name (info-&gt;api), do_copy);
2005   }
2006 
2007   /* we only copy metadata when the subclass implemented a transform_meta
2008    * function and when it returns %TRUE */
2009   if (do_copy &amp;&amp; info-&gt;transform_func) {
2010     GstMetaTransformCopy copy_data = { FALSE, 0, -1 };
2011     GST_DEBUG_OBJECT (encoder, &quot;copy metadata %s&quot;, g_type_name (info-&gt;api));
2012     /* simply copy then */
2013     info-&gt;transform_func (frame-&gt;output_buffer, *meta, inbuf,
2014         _gst_meta_transform_copy, &amp;copy_data);
2015   }
2016   return TRUE;
2017 }
2018 
2019 static void
2020 gst_video_encoder_drop_frame (GstVideoEncoder * enc, GstVideoCodecFrame * frame)
2021 {
2022   GstVideoEncoderPrivate *priv = enc-&gt;priv;
2023   GstClockTime stream_time, jitter, earliest_time, qostime, timestamp;
2024   GstSegment *segment;
2025   GstMessage *qos_msg;
2026   gdouble proportion;
2027 
2028   GST_DEBUG_OBJECT (enc, &quot;dropping frame %&quot; GST_TIME_FORMAT,
2029       GST_TIME_ARGS (frame-&gt;pts));
2030 
2031   priv-&gt;dropped++;
2032 
2033   /* post QoS message */
2034   GST_OBJECT_LOCK (enc);
2035   proportion = priv-&gt;proportion;
2036   earliest_time = priv-&gt;earliest_time;
2037   GST_OBJECT_UNLOCK (enc);
2038 
2039   timestamp = frame-&gt;pts;
2040   segment = &amp;enc-&gt;output_segment;
2041   if (G_UNLIKELY (segment-&gt;format == GST_FORMAT_UNDEFINED))
2042     segment = &amp;enc-&gt;input_segment;
2043   stream_time =
2044       gst_segment_to_stream_time (segment, GST_FORMAT_TIME, timestamp);
2045   qostime = gst_segment_to_running_time (segment, GST_FORMAT_TIME, timestamp);
2046   jitter = GST_CLOCK_DIFF (qostime, earliest_time);
2047   qos_msg =
2048       gst_message_new_qos (GST_OBJECT_CAST (enc), FALSE, qostime, stream_time,
2049       timestamp, GST_CLOCK_TIME_NONE);
2050   gst_message_set_qos_values (qos_msg, jitter, proportion, 1000000);
2051   gst_message_set_qos_stats (qos_msg, GST_FORMAT_BUFFERS,
2052       priv-&gt;processed, priv-&gt;dropped);
2053   gst_element_post_message (GST_ELEMENT_CAST (enc), qos_msg);
2054 }
2055 
2056 /**
2057  * gst_video_encoder_finish_frame:
2058  * @encoder: a #GstVideoEncoder
2059  * @frame: (transfer full): an encoded #GstVideoCodecFrame
2060  *
2061  * @frame must have a valid encoded data buffer, whose metadata fields
2062  * are then appropriately set according to frame data or no buffer at
2063  * all if the frame should be dropped.
2064  * It is subsequently pushed downstream or provided to @pre_push.
2065  * In any case, the frame is considered finished and released.
2066  *
2067  * After calling this function the output buffer of the frame is to be
2068  * considered read-only. This function will also change the metadata
2069  * of the buffer.
2070  *
2071  * Returns: a #GstFlowReturn resulting from sending data downstream
2072  */
2073 GstFlowReturn
2074 gst_video_encoder_finish_frame (GstVideoEncoder * encoder,
2075     GstVideoCodecFrame * frame)
2076 {
2077   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
2078   GstFlowReturn ret = GST_FLOW_OK;
2079   GstVideoEncoderClass *encoder_class;
2080   GList *l;
2081   gboolean send_headers = FALSE;
2082   gboolean discont = (frame-&gt;presentation_frame_number == 0);
2083   GstBuffer *buffer;
2084   gboolean needs_reconfigure = FALSE;
2085 
2086   encoder_class = GST_VIDEO_ENCODER_GET_CLASS (encoder);
2087 
2088   GST_LOG_OBJECT (encoder,
2089       &quot;finish frame fpn %d&quot;, frame-&gt;presentation_frame_number);
2090 
2091   GST_LOG_OBJECT (encoder, &quot;frame PTS %&quot; GST_TIME_FORMAT
2092       &quot;, DTS %&quot; GST_TIME_FORMAT, GST_TIME_ARGS (frame-&gt;pts),
2093       GST_TIME_ARGS (frame-&gt;dts));
2094 
2095   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2096 
2097   needs_reconfigure = gst_pad_check_reconfigure (encoder-&gt;srcpad);
2098   if (G_UNLIKELY (priv-&gt;output_state_changed || (priv-&gt;output_state
2099               &amp;&amp; needs_reconfigure))) {
2100     if (!gst_video_encoder_negotiate_unlocked (encoder)) {
2101       gst_pad_mark_reconfigure (encoder-&gt;srcpad);
2102       if (GST_PAD_IS_FLUSHING (encoder-&gt;srcpad))
2103         ret = GST_FLOW_FLUSHING;
2104       else
2105         ret = GST_FLOW_NOT_NEGOTIATED;
2106       goto done;
2107     }
2108   }
2109 
2110   if (G_UNLIKELY (priv-&gt;output_state == NULL))
2111     goto no_output_state;
2112 
2113   /* Push all pending events that arrived before this frame */
2114   for (l = priv-&gt;frames; l; l = l-&gt;next) {
2115     GstVideoCodecFrame *tmp = l-&gt;data;
2116 
2117     if (tmp-&gt;events) {
2118       GList *k;
2119 
2120       for (k = g_list_last (tmp-&gt;events); k; k = k-&gt;prev)
2121         gst_video_encoder_push_event (encoder, k-&gt;data);
2122       g_list_free (tmp-&gt;events);
2123       tmp-&gt;events = NULL;
2124     }
2125 
2126     if (tmp == frame)
2127       break;
2128   }
2129 
2130   gst_video_encoder_check_and_push_tags (encoder);
2131 
2132   /* no buffer data means this frame is skipped/dropped */
2133   if (!frame-&gt;output_buffer) {
2134     gst_video_encoder_drop_frame (encoder, frame);
2135     goto done;
2136   }
2137 
2138   priv-&gt;processed++;
2139 
2140   if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame) &amp;&amp; priv-&gt;force_key_unit) {
2141     GstClockTime stream_time, running_time;
2142     GstEvent *ev;
2143     ForcedKeyUnitEvent *fevt = NULL;
2144     GList *l;
2145 
2146     running_time =
2147         gst_segment_to_running_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
2148         frame-&gt;pts);
2149 
2150     GST_OBJECT_LOCK (encoder);
2151     for (l = priv-&gt;force_key_unit; l; l = l-&gt;next) {
2152       ForcedKeyUnitEvent *tmp = l-&gt;data;
2153 
2154       /* Skip non-pending keyunits */
2155       if (!tmp-&gt;pending)
2156         continue;
2157 
2158       /* Exact match using the frame id */
2159       if (frame-&gt;system_frame_number == tmp-&gt;frame_id) {
2160         fevt = tmp;
2161         break;
2162       }
2163 
2164       /* Simple case, keyunit ASAP */
2165       if (tmp-&gt;running_time == GST_CLOCK_TIME_NONE) {
2166         fevt = tmp;
2167         break;
2168       }
2169 
2170       /* Event for before this frame */
2171       if (tmp-&gt;running_time &lt;= running_time) {
2172         fevt = tmp;
2173         break;
2174       }
2175     }
2176 
2177     if (fevt) {
2178       priv-&gt;force_key_unit = g_list_remove (priv-&gt;force_key_unit, fevt);
2179     }
2180     GST_OBJECT_UNLOCK (encoder);
2181 
2182     if (fevt) {
2183       stream_time =
2184           gst_segment_to_stream_time (&amp;encoder-&gt;output_segment, GST_FORMAT_TIME,
2185           frame-&gt;pts);
2186 
2187       ev = gst_video_event_new_downstream_force_key_unit
2188           (frame-&gt;pts, stream_time, running_time,
2189           fevt-&gt;all_headers, fevt-&gt;count);
2190 
2191       gst_video_encoder_push_event (encoder, ev);
2192 
2193       if (fevt-&gt;all_headers)
2194         send_headers = TRUE;
2195 
2196       GST_DEBUG_OBJECT (encoder,
2197           &quot;Forced key unit: running-time %&quot; GST_TIME_FORMAT
2198           &quot;, all_headers %d, count %u&quot;,
2199           GST_TIME_ARGS (running_time), fevt-&gt;all_headers, fevt-&gt;count);
2200       forced_key_unit_event_free (fevt);
2201     }
2202   }
2203 
2204   if (GST_VIDEO_CODEC_FRAME_IS_SYNC_POINT (frame)) {
2205     priv-&gt;distance_from_sync = 0;
2206     GST_BUFFER_FLAG_UNSET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DELTA_UNIT);
2207     /* For keyframes, DTS = PTS, if encoder doesn&#39;t decide otherwise */
2208     if (!GST_CLOCK_TIME_IS_VALID (frame-&gt;dts)) {
2209       frame-&gt;dts = frame-&gt;pts;
2210     }
2211   } else {
2212     GST_BUFFER_FLAG_SET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DELTA_UNIT);
2213   }
2214 
2215   /* DTS is expected monotone ascending,
2216    * so a good guess is the lowest unsent PTS (all being OK) */
2217   {
2218     GstClockTime min_ts = GST_CLOCK_TIME_NONE;
2219     GstVideoCodecFrame *oframe = NULL;
2220     gboolean seen_none = FALSE;
2221 
2222     /* some maintenance regardless */
2223     for (l = priv-&gt;frames; l; l = l-&gt;next) {
2224       GstVideoCodecFrame *tmp = l-&gt;data;
2225 
2226       if (!GST_CLOCK_TIME_IS_VALID (tmp-&gt;abidata.ABI.ts)) {
2227         seen_none = TRUE;
2228         continue;
2229       }
2230 
2231       if (!GST_CLOCK_TIME_IS_VALID (min_ts) || tmp-&gt;abidata.ABI.ts &lt; min_ts) {
2232         min_ts = tmp-&gt;abidata.ABI.ts;
2233         oframe = tmp;
2234       }
2235     }
2236     /* save a ts if needed */
2237     if (oframe &amp;&amp; oframe != frame) {
2238       oframe-&gt;abidata.ABI.ts = frame-&gt;abidata.ABI.ts;
2239     }
2240 
2241     /* and set if needed */
2242     if (!GST_CLOCK_TIME_IS_VALID (frame-&gt;dts) &amp;&amp; !seen_none) {
2243       frame-&gt;dts = min_ts;
2244       GST_DEBUG_OBJECT (encoder,
2245           &quot;no valid DTS, using oldest PTS %&quot; GST_TIME_FORMAT,
2246           GST_TIME_ARGS (frame-&gt;pts));
2247     }
2248   }
2249 
2250   frame-&gt;distance_from_sync = priv-&gt;distance_from_sync;
2251   priv-&gt;distance_from_sync++;
2252 
2253   GST_BUFFER_PTS (frame-&gt;output_buffer) = frame-&gt;pts;
2254   GST_BUFFER_DTS (frame-&gt;output_buffer) = frame-&gt;dts;
2255   GST_BUFFER_DURATION (frame-&gt;output_buffer) = frame-&gt;duration;
2256 
2257   GST_OBJECT_LOCK (encoder);
2258   /* update rate estimate */
2259   priv-&gt;bytes += gst_buffer_get_size (frame-&gt;output_buffer);
2260   if (GST_CLOCK_TIME_IS_VALID (frame-&gt;duration)) {
2261     priv-&gt;time += frame-&gt;duration;
2262   } else {
2263     /* better none than nothing valid */
2264     priv-&gt;time = GST_CLOCK_TIME_NONE;
2265   }
2266   GST_OBJECT_UNLOCK (encoder);
2267 
2268   if (G_UNLIKELY (send_headers || priv-&gt;new_headers)) {
2269     GList *tmp, *copy = NULL;
2270 
2271     GST_DEBUG_OBJECT (encoder, &quot;Sending headers&quot;);
2272 
2273     /* First make all buffers metadata-writable */
2274     for (tmp = priv-&gt;headers; tmp; tmp = tmp-&gt;next) {
2275       GstBuffer *tmpbuf = GST_BUFFER (tmp-&gt;data);
2276 
2277       copy = g_list_append (copy, gst_buffer_make_writable (tmpbuf));
2278     }
2279     g_list_free (priv-&gt;headers);
2280     priv-&gt;headers = copy;
2281 
2282     for (tmp = priv-&gt;headers; tmp; tmp = tmp-&gt;next) {
2283       GstBuffer *tmpbuf = GST_BUFFER (tmp-&gt;data);
2284 
2285       GST_OBJECT_LOCK (encoder);
2286       priv-&gt;bytes += gst_buffer_get_size (tmpbuf);
2287       GST_OBJECT_UNLOCK (encoder);
2288       if (G_UNLIKELY (discont)) {
2289         GST_LOG_OBJECT (encoder, &quot;marking discont&quot;);
2290         GST_BUFFER_FLAG_SET (tmpbuf, GST_BUFFER_FLAG_DISCONT);
2291         discont = FALSE;
2292       }
2293 
<a name="8" id="anc8"></a>
2294       gst_pad_push (encoder-&gt;srcpad, gst_buffer_ref (tmpbuf));
<a name="9" id="anc9"></a>
2295     }
2296     priv-&gt;new_headers = FALSE;
2297   }
2298 
2299   if (G_UNLIKELY (discont)) {
2300     GST_LOG_OBJECT (encoder, &quot;marking discont&quot;);
2301     GST_BUFFER_FLAG_SET (frame-&gt;output_buffer, GST_BUFFER_FLAG_DISCONT);
2302   }
2303 
2304   if (encoder_class-&gt;pre_push)
2305     ret = encoder_class-&gt;pre_push (encoder, frame);
2306 
2307   if (encoder_class-&gt;transform_meta) {
2308     if (G_LIKELY (frame-&gt;input_buffer)) {
2309       CopyMetaData data;
2310 
2311       data.encoder = encoder;
2312       data.frame = frame;
2313       gst_buffer_foreach_meta (frame-&gt;input_buffer, foreach_metadata, &amp;data);
2314     } else {
2315       GST_WARNING_OBJECT (encoder,
2316           &quot;Can&#39;t copy metadata because input frame disappeared&quot;);
2317     }
2318   }
2319 
2320   /* Get an additional ref to the buffer, which is going to be pushed
2321    * downstream, the original ref is owned by the frame */
2322   if (ret == GST_FLOW_OK)
2323     buffer = gst_buffer_ref (frame-&gt;output_buffer);
2324 
2325   /* Release frame so the buffer is writable when we push it downstream
2326    * if possible, i.e. if the subclass does not hold additional references
2327    * to the frame
2328    */
2329   gst_video_encoder_release_frame (encoder, frame);
2330   frame = NULL;
2331 
<a name="10" id="anc10"></a><span class="line-modified">2332   if (ret == GST_FLOW_OK)</span>

2333     ret = gst_pad_push (encoder-&gt;srcpad, buffer);
<a name="11" id="anc11"></a>

2334 
2335 done:
2336   /* handed out */
2337   if (frame)
2338     gst_video_encoder_release_frame (encoder, frame);
2339 
2340   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2341 
2342   return ret;
2343 
2344   /* ERRORS */
2345 no_output_state:
2346   {
2347     gst_video_encoder_release_frame (encoder, frame);
2348     GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2349     GST_ERROR_OBJECT (encoder, &quot;Output state was not configured&quot;);
2350     return GST_FLOW_ERROR;
2351   }
2352 }
2353 
2354 /**
2355  * gst_video_encoder_get_output_state:
2356  * @encoder: a #GstVideoEncoder
2357  *
2358  * Get the current #GstVideoCodecState
2359  *
2360  * Returns: (transfer full): #GstVideoCodecState describing format of video data.
2361  */
2362 GstVideoCodecState *
2363 gst_video_encoder_get_output_state (GstVideoEncoder * encoder)
2364 {
2365   GstVideoCodecState *state;
2366 
2367   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2368   state = gst_video_codec_state_ref (encoder-&gt;priv-&gt;output_state);
2369   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2370 
2371   return state;
2372 }
2373 
2374 /**
2375  * gst_video_encoder_set_output_state:
2376  * @encoder: a #GstVideoEncoder
2377  * @caps: (transfer full): the #GstCaps to use for the output
2378  * @reference: (allow-none) (transfer none): An optional reference @GstVideoCodecState
2379  *
2380  * Creates a new #GstVideoCodecState with the specified caps as the output state
2381  * for the encoder.
2382  * Any previously set output state on @encoder will be replaced by the newly
2383  * created one.
2384  *
2385  * The specified @caps should not contain any resolution, pixel-aspect-ratio,
2386  * framerate, codec-data, .... Those should be specified instead in the returned
2387  * #GstVideoCodecState.
2388  *
2389  * If the subclass wishes to copy over existing fields (like pixel aspect ratio,
2390  * or framerate) from an existing #GstVideoCodecState, it can be provided as a
2391  * @reference.
2392  *
2393  * If the subclass wishes to override some fields from the output state (like
2394  * pixel-aspect-ratio or framerate) it can do so on the returned #GstVideoCodecState.
2395  *
2396  * The new output state will only take effect (set on pads and buffers) starting
2397  * from the next call to #gst_video_encoder_finish_frame().
2398  *
2399  * Returns: (transfer full): the newly configured output state.
2400  */
2401 GstVideoCodecState *
2402 gst_video_encoder_set_output_state (GstVideoEncoder * encoder, GstCaps * caps,
2403     GstVideoCodecState * reference)
2404 {
2405   GstVideoEncoderPrivate *priv = encoder-&gt;priv;
2406   GstVideoCodecState *state;
2407 
2408   g_return_val_if_fail (caps != NULL, NULL);
2409 
2410   state = _new_output_state (caps, reference);
2411   if (!state)
2412     return NULL;
2413 
2414   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2415   if (priv-&gt;output_state)
2416     gst_video_codec_state_unref (priv-&gt;output_state);
2417   priv-&gt;output_state = gst_video_codec_state_ref (state);
2418 
2419   if (priv-&gt;output_state != NULL &amp;&amp; priv-&gt;output_state-&gt;info.fps_n &gt; 0) {
2420     priv-&gt;qos_frame_duration =
2421         gst_util_uint64_scale (GST_SECOND, priv-&gt;output_state-&gt;info.fps_d,
2422         priv-&gt;output_state-&gt;info.fps_n);
2423   } else {
2424     priv-&gt;qos_frame_duration = 0;
2425   }
2426 
2427   priv-&gt;output_state_changed = TRUE;
2428   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2429 
2430   return state;
2431 }
2432 
2433 /**
2434  * gst_video_encoder_set_latency:
2435  * @encoder: a #GstVideoEncoder
2436  * @min_latency: minimum latency
2437  * @max_latency: maximum latency
2438  *
2439  * Informs baseclass of encoding latency.
2440  */
2441 void
2442 gst_video_encoder_set_latency (GstVideoEncoder * encoder,
2443     GstClockTime min_latency, GstClockTime max_latency)
2444 {
2445   g_return_if_fail (GST_CLOCK_TIME_IS_VALID (min_latency));
2446   g_return_if_fail (max_latency &gt;= min_latency);
2447 
2448   GST_OBJECT_LOCK (encoder);
2449   encoder-&gt;priv-&gt;min_latency = min_latency;
2450   encoder-&gt;priv-&gt;max_latency = max_latency;
2451   GST_OBJECT_UNLOCK (encoder);
2452 
2453   gst_element_post_message (GST_ELEMENT_CAST (encoder),
2454       gst_message_new_latency (GST_OBJECT_CAST (encoder)));
2455 }
2456 
2457 /**
2458  * gst_video_encoder_get_latency:
2459  * @encoder: a #GstVideoEncoder
2460  * @min_latency: (out) (allow-none): address of variable in which to store the
2461  *     configured minimum latency, or %NULL
2462  * @max_latency: (out) (allow-none): address of variable in which to store the
2463  *     configured maximum latency, or %NULL
2464  *
2465  * Query the configured encoding latency. Results will be returned via
2466  * @min_latency and @max_latency.
2467  */
2468 void
2469 gst_video_encoder_get_latency (GstVideoEncoder * encoder,
2470     GstClockTime * min_latency, GstClockTime * max_latency)
2471 {
2472   GST_OBJECT_LOCK (encoder);
2473   if (min_latency)
2474     *min_latency = encoder-&gt;priv-&gt;min_latency;
2475   if (max_latency)
2476     *max_latency = encoder-&gt;priv-&gt;max_latency;
2477   GST_OBJECT_UNLOCK (encoder);
2478 }
2479 
2480 /**
2481  * gst_video_encoder_get_oldest_frame:
2482  * @encoder: a #GstVideoEncoder
2483  *
2484  * Get the oldest unfinished pending #GstVideoCodecFrame
2485  *
2486  * Returns: (transfer full): oldest unfinished pending #GstVideoCodecFrame
2487  */
2488 GstVideoCodecFrame *
2489 gst_video_encoder_get_oldest_frame (GstVideoEncoder * encoder)
2490 {
2491   GstVideoCodecFrame *frame = NULL;
2492 
2493   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2494   if (encoder-&gt;priv-&gt;frames)
2495     frame = gst_video_codec_frame_ref (encoder-&gt;priv-&gt;frames-&gt;data);
2496   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2497 
2498   return (GstVideoCodecFrame *) frame;
2499 }
2500 
2501 /**
2502  * gst_video_encoder_get_frame:
<a name="12" id="anc12"></a><span class="line-modified">2503  * @encoder: a #GstVideoEnccoder</span>
2504  * @frame_number: system_frame_number of a frame
2505  *
2506  * Get a pending unfinished #GstVideoCodecFrame
2507  *
2508  * Returns: (transfer full): pending unfinished #GstVideoCodecFrame identified by @frame_number.
2509  */
2510 GstVideoCodecFrame *
2511 gst_video_encoder_get_frame (GstVideoEncoder * encoder, int frame_number)
2512 {
2513   GList *g;
2514   GstVideoCodecFrame *frame = NULL;
2515 
2516   GST_DEBUG_OBJECT (encoder, &quot;frame_number : %d&quot;, frame_number);
2517 
2518   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2519   for (g = encoder-&gt;priv-&gt;frames; g; g = g-&gt;next) {
2520     GstVideoCodecFrame *tmp = g-&gt;data;
2521 
2522     if (tmp-&gt;system_frame_number == frame_number) {
2523       frame = gst_video_codec_frame_ref (tmp);
2524       break;
2525     }
2526   }
2527   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2528 
2529   return frame;
2530 }
2531 
2532 /**
2533  * gst_video_encoder_get_frames:
2534  * @encoder: a #GstVideoEncoder
2535  *
2536  * Get all pending unfinished #GstVideoCodecFrame
2537  *
2538  * Returns: (transfer full) (element-type GstVideoCodecFrame): pending unfinished #GstVideoCodecFrame.
2539  */
2540 GList *
2541 gst_video_encoder_get_frames (GstVideoEncoder * encoder)
2542 {
2543   GList *frames;
2544 
2545   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2546   frames = g_list_copy (encoder-&gt;priv-&gt;frames);
2547   g_list_foreach (frames, (GFunc) gst_video_codec_frame_ref, NULL);
2548   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2549 
2550   return frames;
2551 }
2552 
2553 /**
2554  * gst_video_encoder_merge_tags:
2555  * @encoder: a #GstVideoEncoder
2556  * @tags: (allow-none): a #GstTagList to merge, or NULL to unset
2557  *     previously-set tags
2558  * @mode: the #GstTagMergeMode to use, usually #GST_TAG_MERGE_REPLACE
2559  *
2560  * Sets the video encoder tags and how they should be merged with any
2561  * upstream stream tags. This will override any tags previously-set
2562  * with gst_video_encoder_merge_tags().
2563  *
2564  * Note that this is provided for convenience, and the subclass is
2565  * not required to use this and can still do tag handling on its own.
2566  *
2567  * MT safe.
2568  */
2569 void
2570 gst_video_encoder_merge_tags (GstVideoEncoder * encoder,
2571     const GstTagList * tags, GstTagMergeMode mode)
2572 {
2573   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2574   g_return_if_fail (tags == NULL || GST_IS_TAG_LIST (tags));
2575   g_return_if_fail (tags == NULL || mode != GST_TAG_MERGE_UNDEFINED);
2576 
2577   GST_VIDEO_ENCODER_STREAM_LOCK (encoder);
2578   if (encoder-&gt;priv-&gt;tags != tags) {
2579     if (encoder-&gt;priv-&gt;tags) {
2580       gst_tag_list_unref (encoder-&gt;priv-&gt;tags);
2581       encoder-&gt;priv-&gt;tags = NULL;
2582       encoder-&gt;priv-&gt;tags_merge_mode = GST_TAG_MERGE_APPEND;
2583     }
2584     if (tags) {
2585       encoder-&gt;priv-&gt;tags = gst_tag_list_ref ((GstTagList *) tags);
2586       encoder-&gt;priv-&gt;tags_merge_mode = mode;
2587     }
2588 
2589     GST_DEBUG_OBJECT (encoder, &quot;setting encoder tags to %&quot; GST_PTR_FORMAT,
2590         tags);
2591     encoder-&gt;priv-&gt;tags_changed = TRUE;
2592   }
2593   GST_VIDEO_ENCODER_STREAM_UNLOCK (encoder);
2594 }
2595 
2596 /**
2597  * gst_video_encoder_get_allocator:
2598  * @encoder: a #GstVideoEncoder
2599  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
2600  * used
2601  * @params: (out) (allow-none) (transfer full): the
<a name="13" id="anc13"></a><span class="line-modified">2602  * #GstAllocatorParams of @allocator</span>
2603  *
2604  * Lets #GstVideoEncoder sub-classes to know the memory @allocator
2605  * used by the base class and its @params.
2606  *
2607  * Unref the @allocator after use it.
2608  */
2609 void
2610 gst_video_encoder_get_allocator (GstVideoEncoder * encoder,
2611     GstAllocator ** allocator, GstAllocationParams * params)
2612 {
2613   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2614 
2615   if (allocator)
2616     *allocator = encoder-&gt;priv-&gt;allocator ?
2617         gst_object_ref (encoder-&gt;priv-&gt;allocator) : NULL;
2618 
2619   if (params)
2620     *params = encoder-&gt;priv-&gt;params;
2621 }
2622 
2623 /**
2624  * gst_video_encoder_set_min_pts:
2625  * @encoder: a #GstVideoEncoder
2626  * @min_pts: minimal PTS that will be passed to handle_frame
2627  *
2628  * Request minimal value for PTS passed to handle_frame.
2629  *
2630  * For streams with reordered frames this can be used to ensure that there
2631  * is enough time to accomodate first DTS, which may be less than first PTS
2632  *
<a name="14" id="anc14"></a><span class="line-modified">2633  * Since 1.6</span>
2634  */
2635 void
2636 gst_video_encoder_set_min_pts (GstVideoEncoder * encoder, GstClockTime min_pts)
2637 {
2638   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2639   encoder-&gt;priv-&gt;min_pts = min_pts;
2640   encoder-&gt;priv-&gt;time_adjustment = GST_CLOCK_TIME_NONE;
2641 }
2642 
2643 /**
2644  * gst_video_encoder_get_max_encode_time:
2645  * @encoder: a #GstVideoEncoder
2646  * @frame: a #GstVideoCodecFrame
2647  *
2648  * Determines maximum possible encoding time for @frame that will
2649  * allow it to encode and arrive in time (as determined by QoS events).
2650  * In particular, a negative result means encoding in time is no longer possible
2651  * and should therefore occur as soon/skippy as possible.
2652  *
2653  * If no QoS events have been received from downstream, or if
2654  * #GstVideoEncoder:qos is disabled this function returns #G_MAXINT64.
2655  *
2656  * Returns: max decoding time.
2657  * Since: 1.14
2658  */
2659 GstClockTimeDiff
2660 gst_video_encoder_get_max_encode_time (GstVideoEncoder *
2661     encoder, GstVideoCodecFrame * frame)
2662 {
2663   GstClockTimeDiff deadline;
2664   GstClockTime earliest_time;
2665 
2666   if (!g_atomic_int_get (&amp;encoder-&gt;priv-&gt;qos_enabled))
2667     return G_MAXINT64;
2668 
2669   GST_OBJECT_LOCK (encoder);
2670   earliest_time = encoder-&gt;priv-&gt;earliest_time;
2671   if (GST_CLOCK_TIME_IS_VALID (earliest_time)
2672       &amp;&amp; GST_CLOCK_TIME_IS_VALID (frame-&gt;deadline))
2673     deadline = GST_CLOCK_DIFF (earliest_time, frame-&gt;deadline);
2674   else
2675     deadline = G_MAXINT64;
2676 
2677   GST_LOG_OBJECT (encoder, &quot;earliest %&quot; GST_TIME_FORMAT
2678       &quot;, frame deadline %&quot; GST_TIME_FORMAT &quot;, deadline %&quot; GST_STIME_FORMAT,
2679       GST_TIME_ARGS (earliest_time), GST_TIME_ARGS (frame-&gt;deadline),
2680       GST_STIME_ARGS (deadline));
2681 
2682   GST_OBJECT_UNLOCK (encoder);
2683 
2684   return deadline;
2685 }
2686 
2687 /**
2688  * gst_video_encoder_set_qos_enabled:
2689  * @encoder: the encoder
2690  * @enabled: the new qos value.
2691  *
2692  * Configures @encoder to handle Quality-of-Service events from downstream.
2693  * Since: 1.14
2694  */
2695 void
2696 gst_video_encoder_set_qos_enabled (GstVideoEncoder * encoder, gboolean enabled)
2697 {
2698   g_return_if_fail (GST_IS_VIDEO_ENCODER (encoder));
2699 
2700   g_atomic_int_set (&amp;encoder-&gt;priv-&gt;qos_enabled, enabled);
2701 }
2702 
2703 /**
2704  * gst_video_encoder_is_qos_enabled:
2705  * @encoder: the encoder
2706  *
2707  * Checks if @encoder is currently configured to handle Quality-of-Service
2708  * events from downstream.
2709  *
2710  * Returns: %TRUE if the encoder is configured to perform Quality-of-Service.
2711  * Since: 1.14
2712  */
2713 gboolean
2714 gst_video_encoder_is_qos_enabled (GstVideoEncoder * encoder)
2715 {
2716   gboolean res;
2717 
2718   g_return_val_if_fail (GST_IS_VIDEO_ENCODER (encoder), FALSE);
2719 
2720   res = g_atomic_int_get (&amp;encoder-&gt;priv-&gt;qos_enabled);
2721 
2722   return res;
2723 }
<a name="15" id="anc15"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="15" type="hidden" />
</body>
</html>