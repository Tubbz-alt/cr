<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="gstaudiobasesrc.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="gstaudiodecoder.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  76  *
  77  * Subclass is responsible for providing pad template caps for
  78  * source and sink pads. The pads need to be named &quot;sink&quot; and &quot;src&quot;. It also
  79  * needs to set the fixed caps on srcpad, when the format is ensured.  This
  80  * is typically when base class calls subclass&#39; @set_format function, though
  81  * it might be delayed until calling @gst_audio_decoder_finish_frame.
  82  *
  83  * In summary, above process should have subclass concentrating on
  84  * codec data processing while leaving other matters to base class,
  85  * such as most notably timestamp handling.  While it may exert more control
  86  * in this area (see e.g. @pre_push), it is very much not recommended.
  87  *
  88  * In particular, base class will try to arrange for perfect output timestamps
  89  * as much as possible while tracking upstream timestamps.
  90  * To this end, if deviation between the next ideal expected perfect timestamp
  91  * and upstream exceeds #GstAudioDecoder:tolerance, then resync to upstream
  92  * occurs (which would happen always if the tolerance mechanism is disabled).
  93  *
  94  * In non-live pipelines, baseclass can also (configurably) arrange for
  95  * output buffer aggregation which may help to redue large(r) numbers of
<span class="line-modified">  96  * small(er) buffers being pushed and processed downstream.</span>



  97  *
  98  * On the other hand, it should be noted that baseclass only provides limited
  99  * seeking support (upon explicit subclass request), as full-fledged support
 100  * should rather be left to upstream demuxer, parser or alike.  This simple
 101  * approach caters for seeking and duration reporting using estimated input
 102  * bitrates.
 103  *
 104  * Things that subclass need to take care of:
 105  *
 106  *   * Provide pad templates
 107  *   * Set source pad caps when appropriate
 108  *   * Set user-configurable properties to sane defaults for format and
 109  *      implementing codec at hand, and convey some subclass capabilities and
 110  *      expectations in context.
 111  *
 112  *   * Accept data in @handle_frame and provide encoded results to
 113  *      @gst_audio_decoder_finish_frame.  If it is prepared to perform
 114  *      PLC, it should also accept NULL data in @handle_frame and provide for
 115  *      data for indicated duration.
 116  *
 117  */
 118 
 119 #ifdef HAVE_CONFIG_H
 120 #include &quot;config.h&quot;
 121 #endif
 122 
 123 #include &quot;gstaudiodecoder.h&quot;
 124 #include &quot;gstaudioutilsprivate.h&quot;
 125 #include &lt;gst/pbutils/descriptions.h&gt;
 126 
 127 #include &lt;string.h&gt;
 128 
 129 GST_DEBUG_CATEGORY (audiodecoder_debug);
 130 #define GST_CAT_DEFAULT audiodecoder_debug
 131 
<span class="line-removed"> 132 #define GST_AUDIO_DECODER_GET_PRIVATE(obj)  \</span>
<span class="line-removed"> 133     (G_TYPE_INSTANCE_GET_PRIVATE ((obj), GST_TYPE_AUDIO_DECODER, \</span>
<span class="line-removed"> 134         GstAudioDecoderPrivate))</span>
<span class="line-removed"> 135 </span>
 136 enum
 137 {
 138   LAST_SIGNAL
 139 };
 140 
 141 enum
 142 {
 143   PROP_0,
 144   PROP_LATENCY,
 145   PROP_TOLERANCE,
 146   PROP_PLC
 147 };
 148 
 149 #define DEFAULT_LATENCY    0
 150 #define DEFAULT_TOLERANCE  0
 151 #define DEFAULT_PLC        FALSE
 152 #define DEFAULT_DRAINABLE  TRUE
 153 #define DEFAULT_NEEDS_FORMAT  FALSE
 154 
 155 typedef struct _GstAudioDecoderContext
 156 {
 157   /* last negotiated input caps */
 158   GstCaps *input_caps;
 159 
 160   /* (output) audio format */
 161   GstAudioInfo info;

 162   gboolean output_format_changed;
 163 
 164   /* parsing state */
 165   gboolean eos;
 166   gboolean sync;
 167 
 168   gboolean had_output_data;
 169   gboolean had_input_data;
 170 
 171   /* misc */
 172   gint delay;
 173 
 174   /* output */
 175   gboolean do_plc;
 176   gboolean do_estimate_rate;
 177   gint max_errors;
 178   GstCaps *allocation_caps;
 179   /* MT-protected (with LOCK) */
 180   GstClockTime min_latency;
 181   GstClockTime max_latency;
</pre>
<hr />
<pre>
 200   GstClockTime prev_ts;
 201   guint64 prev_distance;
 202   /* frames obtained from input */
 203   GQueue frames;
 204   /* collected output data */
 205   GstAdapter *adapter_out;
 206   /* ts and duration for output data collected above */
 207   GstClockTime out_ts, out_dur;
 208   /* mark outgoing discont */
 209   gboolean discont;
 210 
 211   /* subclass gave all it could already */
 212   gboolean drained;
 213   /* subclass currently being forcibly drained */
 214   gboolean force;
 215   /* input_segment are output_segment identical */
 216   gboolean in_out_segment_sync;
 217   /* expecting the buffer with DISCONT flag */
 218   gboolean expecting_discont_buf;
 219 


 220 
 221   /* input bps estimatation */
 222   /* global in bytes seen */
 223   guint64 bytes_in;
 224   /* global samples sent out */
 225   guint64 samples_out;
 226   /* bytes flushed during parsing */
 227   guint sync_flush;
 228   /* error count */
 229   gint error_count;
 230 
 231   /* upstream stream tags (global tags are passed through as-is) */
 232   GstTagList *upstream_tags;
 233 
 234   /* subclass tags */
 235   GstTagList *taglist;          /* FIXME: rename to decoder_tags */
 236   GstTagMergeMode decoder_tags_merge_mode;
 237 
 238   gboolean taglist_changed;     /* FIXME: rename to tags_changed */
 239 
</pre>
<hr />
<pre>
 294 static gboolean gst_audio_decoder_sink_query (GstPad * pad, GstObject * parent,
 295     GstQuery * query);
 296 static void gst_audio_decoder_reset (GstAudioDecoder * dec, gboolean full);
 297 
 298 static gboolean gst_audio_decoder_decide_allocation_default (GstAudioDecoder *
 299     dec, GstQuery * query);
 300 static gboolean gst_audio_decoder_propose_allocation_default (GstAudioDecoder *
 301     dec, GstQuery * query);
 302 static gboolean gst_audio_decoder_negotiate_default (GstAudioDecoder * dec);
 303 static gboolean gst_audio_decoder_negotiate_unlocked (GstAudioDecoder * dec);
 304 static gboolean gst_audio_decoder_handle_gap (GstAudioDecoder * dec,
 305     GstEvent * event);
 306 static gboolean gst_audio_decoder_sink_query_default (GstAudioDecoder * dec,
 307     GstQuery * query);
 308 static gboolean gst_audio_decoder_src_query_default (GstAudioDecoder * dec,
 309     GstQuery * query);
 310 
 311 static gboolean gst_audio_decoder_transform_meta_default (GstAudioDecoder *
 312     decoder, GstBuffer * outbuf, GstMeta * meta, GstBuffer * inbuf);
 313 




 314 static GstElementClass *parent_class = NULL;

 315 
 316 static void gst_audio_decoder_class_init (GstAudioDecoderClass * klass);
 317 static void gst_audio_decoder_init (GstAudioDecoder * dec,
 318     GstAudioDecoderClass * klass);
 319 
 320 GType
 321 gst_audio_decoder_get_type (void)
 322 {
 323   static volatile gsize audio_decoder_type = 0;
 324 
 325   if (g_once_init_enter (&amp;audio_decoder_type)) {
 326     GType _type;
 327     static const GTypeInfo audio_decoder_info = {
 328       sizeof (GstAudioDecoderClass),
 329       NULL,
 330       NULL,
 331       (GClassInitFunc) gst_audio_decoder_class_init,
 332       NULL,
 333       NULL,
 334       sizeof (GstAudioDecoder),
 335       0,
 336       (GInstanceInitFunc) gst_audio_decoder_init,
 337     };
 338 
 339     _type = g_type_register_static (GST_TYPE_ELEMENT,
 340         &quot;GstAudioDecoder&quot;, &amp;audio_decoder_info, G_TYPE_FLAG_ABSTRACT);




 341     g_once_init_leave (&amp;audio_decoder_type, _type);
 342   }
 343   return audio_decoder_type;
 344 }
 345 





 346 
 347 static void
 348 gst_audio_decoder_class_init (GstAudioDecoderClass * klass)
 349 {
 350   GObjectClass *gobject_class;
 351   GstElementClass *element_class;
 352   GstAudioDecoderClass *audiodecoder_class;
 353 
 354   gobject_class = G_OBJECT_CLASS (klass);
 355   element_class = GST_ELEMENT_CLASS (klass);
 356   audiodecoder_class = GST_AUDIO_DECODER_CLASS (klass);
 357 
 358   parent_class = g_type_class_peek_parent (klass);
 359 
<span class="line-modified"> 360   g_type_class_add_private (klass, sizeof (GstAudioDecoderPrivate));</span>

 361 
 362   GST_DEBUG_CATEGORY_INIT (audiodecoder_debug, &quot;audiodecoder&quot;, 0,
 363       &quot;audio decoder base class&quot;);
 364 
 365   gobject_class-&gt;set_property = gst_audio_decoder_set_property;
 366   gobject_class-&gt;get_property = gst_audio_decoder_get_property;
 367   gobject_class-&gt;finalize = gst_audio_decoder_finalize;
 368 
 369   element_class-&gt;change_state =
 370       GST_DEBUG_FUNCPTR (gst_audio_decoder_change_state);
 371 
 372   /* Properties */
 373   g_object_class_install_property (gobject_class, PROP_LATENCY,
 374       g_param_spec_int64 (&quot;min-latency&quot;, &quot;Minimum Latency&quot;,
 375           &quot;Aggregate output data to a minimum of latency time (ns)&quot;,
 376           0, G_MAXINT64, DEFAULT_LATENCY,
 377           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 378 
 379   g_object_class_install_property (gobject_class, PROP_TOLERANCE,
 380       g_param_spec_int64 (&quot;tolerance&quot;, &quot;Tolerance&quot;,
</pre>
<hr />
<pre>
 395       GST_DEBUG_FUNCPTR (gst_audio_decoder_propose_allocation_default);
 396   audiodecoder_class-&gt;decide_allocation =
 397       GST_DEBUG_FUNCPTR (gst_audio_decoder_decide_allocation_default);
 398   audiodecoder_class-&gt;negotiate =
 399       GST_DEBUG_FUNCPTR (gst_audio_decoder_negotiate_default);
 400   audiodecoder_class-&gt;sink_query =
 401       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_query_default);
 402   audiodecoder_class-&gt;src_query =
 403       GST_DEBUG_FUNCPTR (gst_audio_decoder_src_query_default);
 404   audiodecoder_class-&gt;transform_meta =
 405       GST_DEBUG_FUNCPTR (gst_audio_decoder_transform_meta_default);
 406 }
 407 
 408 static void
 409 gst_audio_decoder_init (GstAudioDecoder * dec, GstAudioDecoderClass * klass)
 410 {
 411   GstPadTemplate *pad_template;
 412 
 413   GST_DEBUG_OBJECT (dec, &quot;gst_audio_decoder_init&quot;);
 414 
<span class="line-modified"> 415   dec-&gt;priv = GST_AUDIO_DECODER_GET_PRIVATE (dec);</span>
 416 
 417   /* Setup sink pad */
 418   pad_template =
 419       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 420   g_return_if_fail (pad_template != NULL);
 421 
 422   dec-&gt;sinkpad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 423   gst_pad_set_event_function (dec-&gt;sinkpad,
 424       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_event));
 425   gst_pad_set_chain_function (dec-&gt;sinkpad,
 426       GST_DEBUG_FUNCPTR (gst_audio_decoder_chain));
 427   gst_pad_set_query_function (dec-&gt;sinkpad,
 428       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_query));
 429   gst_element_add_pad (GST_ELEMENT (dec), dec-&gt;sinkpad);
 430   GST_DEBUG_OBJECT (dec, &quot;sinkpad created&quot;);
 431 
 432   /* Setup source pad */
 433   pad_template =
 434       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 435   g_return_if_fail (pad_template != NULL);
</pre>
<hr />
<pre>
 486     dec-&gt;priv-&gt;decoder_tags_merge_mode = GST_TAG_MERGE_KEEP_ALL;
 487     if (dec-&gt;priv-&gt;upstream_tags) {
 488       gst_tag_list_unref (dec-&gt;priv-&gt;upstream_tags);
 489       dec-&gt;priv-&gt;upstream_tags = NULL;
 490     }
 491     dec-&gt;priv-&gt;taglist_changed = FALSE;
 492 
 493     gst_segment_init (&amp;dec-&gt;input_segment, GST_FORMAT_TIME);
 494     gst_segment_init (&amp;dec-&gt;output_segment, GST_FORMAT_TIME);
 495     dec-&gt;priv-&gt;in_out_segment_sync = TRUE;
 496 
 497     g_list_foreach (dec-&gt;priv-&gt;pending_events, (GFunc) gst_event_unref, NULL);
 498     g_list_free (dec-&gt;priv-&gt;pending_events);
 499     dec-&gt;priv-&gt;pending_events = NULL;
 500 
 501     if (dec-&gt;priv-&gt;ctx.allocator)
 502       gst_object_unref (dec-&gt;priv-&gt;ctx.allocator);
 503 
 504     GST_OBJECT_LOCK (dec);
 505     gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.input_caps, NULL);

 506     gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.allocation_caps, NULL);
 507 
 508     memset (&amp;dec-&gt;priv-&gt;ctx, 0, sizeof (dec-&gt;priv-&gt;ctx));
 509 
 510     gst_audio_info_init (&amp;dec-&gt;priv-&gt;ctx.info);
 511     GST_OBJECT_UNLOCK (dec);
 512     dec-&gt;priv-&gt;ctx.max_errors = GST_AUDIO_DECODER_MAX_ERRORS;
 513     dec-&gt;priv-&gt;ctx.had_output_data = FALSE;
 514     dec-&gt;priv-&gt;ctx.had_input_data = FALSE;
 515   }
 516 
 517   g_queue_foreach (&amp;dec-&gt;priv-&gt;frames, (GFunc) gst_buffer_unref, NULL);
 518   g_queue_clear (&amp;dec-&gt;priv-&gt;frames);
 519   gst_adapter_clear (dec-&gt;priv-&gt;adapter);
 520   gst_adapter_clear (dec-&gt;priv-&gt;adapter_out);
 521   dec-&gt;priv-&gt;out_ts = GST_CLOCK_TIME_NONE;
 522   dec-&gt;priv-&gt;out_dur = 0;
 523   dec-&gt;priv-&gt;prev_ts = GST_CLOCK_TIME_NONE;
 524   dec-&gt;priv-&gt;prev_distance = 0;
 525   dec-&gt;priv-&gt;drained = TRUE;
</pre>
<hr />
<pre>
 598     default:
 599       break;
 600   }
 601 
 602   return gst_pad_push_event (dec-&gt;srcpad, event);
 603 }
 604 
 605 static gboolean
 606 gst_audio_decoder_negotiate_default (GstAudioDecoder * dec)
 607 {
 608   GstAudioDecoderClass *klass;
 609   gboolean res = TRUE;
 610   GstCaps *caps;
 611   GstCaps *prevcaps;
 612   GstQuery *query = NULL;
 613   GstAllocator *allocator;
 614   GstAllocationParams params;
 615 
 616   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
 617   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (&amp;dec-&gt;priv-&gt;ctx.info), FALSE);

 618 
 619   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 620 
<span class="line-modified"> 621   caps = gst_audio_info_to_caps (&amp;dec-&gt;priv-&gt;ctx.info);</span>
 622   if (dec-&gt;priv-&gt;ctx.allocation_caps == NULL)
 623     dec-&gt;priv-&gt;ctx.allocation_caps = gst_caps_ref (caps);
 624 
 625   GST_DEBUG_OBJECT (dec, &quot;setting src caps %&quot; GST_PTR_FORMAT, caps);
 626 
 627   if (dec-&gt;priv-&gt;pending_events) {
 628     GList **pending_events, *l;
 629 
 630     pending_events = &amp;dec-&gt;priv-&gt;pending_events;
 631 
 632     GST_DEBUG_OBJECT (dec, &quot;Pushing pending events&quot;);
 633     for (l = *pending_events; l;) {
 634       GstEvent *event = GST_EVENT (l-&gt;data);
 635       GList *tmp;
 636 
 637       if (GST_EVENT_TYPE (event) &lt; GST_EVENT_CAPS) {
 638         gst_audio_decoder_push_event (dec, l-&gt;data);
 639         tmp = l;
 640         l = l-&gt;next;
 641         *pending_events = g_list_delete_link (*pending_events, tmp);
</pre>
<hr />
<pre>
 670     goto no_decide_allocation;
 671 
 672   /* we got configuration from our peer or the decide_allocation method,
 673    * parse them */
 674   if (gst_query_get_n_allocation_params (query) &gt; 0) {
 675     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 676   } else {
 677     allocator = NULL;
 678     gst_allocation_params_init (&amp;params);
 679   }
 680 
 681   if (dec-&gt;priv-&gt;ctx.allocator)
 682     gst_object_unref (dec-&gt;priv-&gt;ctx.allocator);
 683   dec-&gt;priv-&gt;ctx.allocator = allocator;
 684   dec-&gt;priv-&gt;ctx.params = params;
 685 
 686 done:
 687 
 688   if (query)
 689     gst_query_unref (query);
<span class="line-removed"> 690   gst_caps_unref (caps);</span>
 691 
 692   return res;
 693 
 694   /* ERRORS */
 695 no_decide_allocation:
 696   {
 697     GST_WARNING_OBJECT (dec, &quot;Subclass failed to decide allocation&quot;);
 698     goto done;
 699   }
 700 }
 701 
 702 static gboolean
 703 gst_audio_decoder_negotiate_unlocked (GstAudioDecoder * dec)
 704 {
 705   GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 706   gboolean ret = TRUE;
 707 
 708   if (G_LIKELY (klass-&gt;negotiate))
 709     ret = klass-&gt;negotiate (dec);
 710 
</pre>
<hr />
<pre>
 740   }
 741   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 742 
 743   return res;
 744 }
 745 
 746 /**
 747  * gst_audio_decoder_set_output_format:
 748  * @dec: a #GstAudioDecoder
 749  * @info: #GstAudioInfo
 750  *
 751  * Configure output info on the srcpad of @dec.
 752  *
 753  * Returns: %TRUE on success.
 754  **/
 755 gboolean
 756 gst_audio_decoder_set_output_format (GstAudioDecoder * dec,
 757     const GstAudioInfo * info)
 758 {
 759   gboolean res = TRUE;
<span class="line-removed"> 760   guint old_rate;</span>
 761   GstCaps *caps = NULL;
<span class="line-removed"> 762   GstCaps *templ_caps;</span>
 763 
 764   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
 765   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (info), FALSE);
 766 
<span class="line-removed"> 767   GST_DEBUG_OBJECT (dec, &quot;Setting output format&quot;);</span>
<span class="line-removed"> 768 </span>
<span class="line-removed"> 769   GST_AUDIO_DECODER_STREAM_LOCK (dec);</span>
<span class="line-removed"> 770 </span>
 771   /* If the audio info can&#39;t be converted to caps,
 772    * it was invalid */
 773   caps = gst_audio_info_to_caps (info);
<span class="line-modified"> 774   if (!caps)</span>











































 775     goto refuse_caps;
 776 
 777   /* Only allow caps that are a subset of the template caps */
 778   templ_caps = gst_pad_get_pad_template_caps (dec-&gt;srcpad);
 779   if (!gst_caps_is_subset (caps, templ_caps)) {
 780     GST_WARNING_OBJECT (dec, &quot;Requested output format %&quot; GST_PTR_FORMAT
 781         &quot; do not match template %&quot; GST_PTR_FORMAT, caps, templ_caps);
 782     gst_caps_unref (templ_caps);
 783     goto refuse_caps;
 784   }
 785   gst_caps_unref (templ_caps);
 786 
 787   /* adjust ts tracking to new sample rate */
 788   old_rate = GST_AUDIO_INFO_RATE (&amp;dec-&gt;priv-&gt;ctx.info);
 789   if (GST_CLOCK_TIME_IS_VALID (dec-&gt;priv-&gt;base_ts) &amp;&amp; old_rate) {
 790     dec-&gt;priv-&gt;base_ts +=
 791         GST_FRAMES_TO_CLOCK_TIME (dec-&gt;priv-&gt;samples, old_rate);
 792     dec-&gt;priv-&gt;samples = 0;
 793   }
 794 
 795   /* copy the GstAudioInfo */
 796   GST_OBJECT_LOCK (dec);
<span class="line-modified"> 797   dec-&gt;priv-&gt;ctx.info = *info;</span>
 798   GST_OBJECT_UNLOCK (dec);


 799   dec-&gt;priv-&gt;ctx.output_format_changed = TRUE;
 800 
 801 done:
 802   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 803 
<span class="line-removed"> 804   if (caps)</span>
<span class="line-removed"> 805     gst_caps_unref (caps);</span>
<span class="line-removed"> 806 </span>
 807   return res;
 808 
 809   /* ERRORS */
 810 refuse_caps:
 811   {
 812     GST_WARNING_OBJECT (dec, &quot;invalid output format&quot;);
 813     res = FALSE;
 814     goto done;
 815   }
 816 }
 817 
 818 static gboolean
 819 gst_audio_decoder_sink_setcaps (GstAudioDecoder * dec, GstCaps * caps)
 820 {
 821   GstAudioDecoderClass *klass;
 822   gboolean res = TRUE;
 823 
 824   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 825 
 826   GST_DEBUG_OBJECT (dec, &quot;caps: %&quot; GST_PTR_FORMAT, caps);
</pre>
<hr />
<pre>
 895     return GST_FLOW_OK;
 896   }
 897 
 898   ctx-&gt;had_output_data = TRUE;
 899   ts = GST_BUFFER_TIMESTAMP (buf);
 900 
 901   GST_LOG_OBJECT (dec,
 902       &quot;clipping buffer of size %&quot; G_GSIZE_FORMAT &quot; with ts %&quot; GST_TIME_FORMAT
 903       &quot;, duration %&quot; GST_TIME_FORMAT, gst_buffer_get_size (buf),
 904       GST_TIME_ARGS (GST_BUFFER_TIMESTAMP (buf)),
 905       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
 906 
 907   /* clip buffer */
 908   buf = gst_audio_buffer_clip (buf, &amp;dec-&gt;output_segment, ctx-&gt;info.rate,
 909       ctx-&gt;info.bpf);
 910   if (G_UNLIKELY (!buf)) {
 911     GST_DEBUG_OBJECT (dec, &quot;no data after clipping to segment&quot;);
 912     /* only check and return EOS if upstream still
 913      * in the same segment and interested as such */
 914     if (dec-&gt;priv-&gt;in_out_segment_sync) {
<span class="line-modified"> 915     if (dec-&gt;output_segment.rate &gt;= 0) {</span>
<span class="line-modified"> 916       if (ts &gt;= dec-&gt;output_segment.stop)</span>


 917         ret = GST_FLOW_EOS;
<span class="line-modified"> 918     } else if (ts &lt; dec-&gt;output_segment.start) {</span>
<span class="line-removed"> 919       ret = GST_FLOW_EOS;</span>
<span class="line-removed"> 920     }</span>
 921     }
 922     goto exit;
 923   }
 924 
 925   /* decorate */
 926   if (G_UNLIKELY (priv-&gt;discont)) {
 927     GST_LOG_OBJECT (dec, &quot;marking discont&quot;);
 928     GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DISCONT);
 929     priv-&gt;discont = FALSE;
 930   }
 931 
 932   /* track where we are */
 933   if (G_LIKELY (GST_BUFFER_TIMESTAMP_IS_VALID (buf))) {
 934     /* duration should always be valid for raw audio */
 935     g_assert (GST_BUFFER_DURATION_IS_VALID (buf));
 936     dec-&gt;output_segment.position =
 937         GST_BUFFER_TIMESTAMP (buf) + GST_BUFFER_DURATION (buf);
 938   }
 939 
 940   if (klass-&gt;pre_push) {
</pre>
<hr />
<pre>
 968 {
 969   GstAudioDecoderPrivate *priv;
 970   GstFlowReturn ret = GST_FLOW_OK;
 971   GstBuffer *inbuf = NULL;
 972 
 973   priv = dec-&gt;priv;
 974 
 975   if (G_UNLIKELY (priv-&gt;agg &lt; 0))
 976     gst_audio_decoder_setup (dec);
 977 
 978   if (G_LIKELY (buf)) {
 979     GST_LOG_OBJECT (dec,
 980         &quot;output buffer of size %&quot; G_GSIZE_FORMAT &quot; with ts %&quot; GST_TIME_FORMAT
 981         &quot;, duration %&quot; GST_TIME_FORMAT, gst_buffer_get_size (buf),
 982         GST_TIME_ARGS (GST_BUFFER_TIMESTAMP (buf)),
 983         GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
 984   }
 985 
 986 again:
 987   inbuf = NULL;
<span class="line-modified"> 988   if (priv-&gt;agg &amp;&amp; dec-&gt;priv-&gt;latency &gt; 0) {</span>

 989     gint av;
 990     gboolean assemble = FALSE;
 991     const GstClockTimeDiff tol = 10 * GST_MSECOND;
 992     GstClockTimeDiff diff = -100 * GST_MSECOND;
 993 
 994     av = gst_adapter_available (priv-&gt;adapter_out);
 995     if (G_UNLIKELY (!buf)) {
 996       /* forcibly send current */
 997       assemble = TRUE;
 998       GST_LOG_OBJECT (dec, &quot;forcing fragment flush&quot;);
 999     } else if (av &amp;&amp; (!GST_BUFFER_TIMESTAMP_IS_VALID (buf) ||
1000             !GST_CLOCK_TIME_IS_VALID (priv-&gt;out_ts) ||
1001             ((diff = GST_CLOCK_DIFF (GST_BUFFER_TIMESTAMP (buf),
1002                         priv-&gt;out_ts + priv-&gt;out_dur)) &gt; tol) || diff &lt; -tol)) {
1003       assemble = TRUE;
1004       GST_LOG_OBJECT (dec, &quot;buffer %d ms apart from current fragment&quot;,
1005           (gint) (diff / GST_MSECOND));
1006     } else {
1007       /* add or start collecting */
1008       if (!av) {
</pre>
<hr />
<pre>
1159         g_type_name (info-&gt;api));
1160     do_copy = FALSE;
1161   } else if (klass-&gt;transform_meta) {
1162     do_copy = klass-&gt;transform_meta (decoder, outbuf, *meta, inbuf);
1163     GST_DEBUG_OBJECT (decoder, &quot;transformed metadata %s: copy: %d&quot;,
1164         g_type_name (info-&gt;api), do_copy);
1165   }
1166 
1167   /* we only copy metadata when the subclass implemented a transform_meta
1168    * function and when it returns %TRUE */
1169   if (do_copy &amp;&amp; info-&gt;transform_func) {
1170     GstMetaTransformCopy copy_data = { FALSE, 0, -1 };
1171     GST_DEBUG_OBJECT (decoder, &quot;copy metadata %s&quot;, g_type_name (info-&gt;api));
1172     /* simply copy then */
1173     info-&gt;transform_func (outbuf, *meta, inbuf,
1174         _gst_meta_transform_copy, &amp;copy_data);
1175   }
1176   return TRUE;
1177 }
1178 


































1179 /**
1180  * gst_audio_decoder_finish_frame:
1181  * @dec: a #GstAudioDecoder
1182  * @buf: decoded data
1183  * @frames: number of decoded frames represented by decoded data
1184  *
1185  * Collects decoded data and pushes it downstream.
1186  *
1187  * @buf may be NULL in which case the indicated number of frames
1188  * are discarded and considered to have produced no output
1189  * (e.g. lead-in or setup frames).
1190  * Otherwise, source pad caps must be set when it is called with valid
1191  * data in @buf.
1192  *
<span class="line-modified">1193  * Note that a frame received in gst_audio_decoder_handle_frame() may be</span>
1194  * invalidated by a call to this function.
1195  *
1196  * Returns: a #GstFlowReturn that should be escalated to caller (of caller)
1197  */
1198 GstFlowReturn
1199 gst_audio_decoder_finish_frame (GstAudioDecoder * dec, GstBuffer * buf,
1200     gint frames)














1201 {
1202   GstAudioDecoderPrivate *priv;
1203   GstAudioDecoderContext *ctx;
1204   GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
<span class="line-modified">1205   gint samples = 0;</span>
1206   GstClockTime ts, next_ts;
<span class="line-modified">1207   gsize size;</span>
1208   GstFlowReturn ret = GST_FLOW_OK;
1209   GQueue inbufs = G_QUEUE_INIT;


1210 
1211   /* subclass should not hand us no data */
1212   g_return_val_if_fail (buf == NULL || gst_buffer_get_size (buf) &gt; 0,
1213       GST_FLOW_ERROR);
<span class="line-modified">1214   /* no dummy calls please */</span>
<span class="line-modified">1215   g_return_val_if_fail (frames != 0, GST_FLOW_ERROR);</span>

1216 
1217   priv = dec-&gt;priv;
1218   ctx = &amp;dec-&gt;priv-&gt;ctx;

1219   size = buf ? gst_buffer_get_size (buf) : 0;

1220 
1221   /* must know the output format by now */
1222   g_return_val_if_fail (buf == NULL || GST_AUDIO_INFO_IS_VALID (&amp;ctx-&gt;info),
1223       GST_FLOW_ERROR);
1224 
1225   GST_LOG_OBJECT (dec,
1226       &quot;accepting %&quot; G_GSIZE_FORMAT &quot; bytes == %&quot; G_GSIZE_FORMAT
<span class="line-modified">1227       &quot; samples for %d frames&quot;, buf ? size : -1,</span>
<span class="line-removed">1228       buf ? size / ctx-&gt;info.bpf : -1, frames);</span>
1229 
1230   GST_AUDIO_DECODER_STREAM_LOCK (dec);
1231 
<span class="line-modified">1232   if (buf) {</span>
1233     ret = check_pending_reconfigure (dec);
1234     if (ret == GST_FLOW_FLUSHING || ret == GST_FLOW_NOT_NEGOTIATED) {
1235       gst_buffer_unref (buf);
1236       goto exit;
1237     }
1238 
1239     if (priv-&gt;pending_events)
1240       send_pending_events (dec);
1241   }
1242 
<span class="line-modified">1243   /* output shoud be whole number of sample frames */</span>
1244   if (G_LIKELY (buf &amp;&amp; ctx-&gt;info.bpf)) {
<span class="line-modified">1245     if (size % ctx-&gt;info.bpf)</span>
<span class="line-modified">1246       goto wrong_buffer;</span>
<span class="line-modified">1247     /* per channel least */</span>
<span class="line-modified">1248     samples = size / ctx-&gt;info.bpf;</span>








1249   }
1250 
1251   /* frame and ts book-keeping */
1252   if (G_UNLIKELY (frames &lt; 0)) {
1253     if (G_UNLIKELY (-frames - 1 &gt; priv-&gt;frames.length)) {
1254       GST_ELEMENT_WARNING (dec, STREAM, DECODE,
1255           (&quot;received more decoded frames %d than provided %d&quot;, frames,
1256               priv-&gt;frames.length), (NULL));
1257       frames = 0;
1258     } else {
1259       frames = priv-&gt;frames.length + frames + 1;
1260     }
1261   } else if (G_UNLIKELY (frames &gt; priv-&gt;frames.length)) {
1262     if (G_LIKELY (!priv-&gt;force)) {
1263       GST_ELEMENT_WARNING (dec, STREAM, DECODE,
1264           (&quot;received more decoded frames %d than provided %d&quot;, frames,
1265               priv-&gt;frames.length), (NULL));
1266     }
1267     frames = priv-&gt;frames.length;
1268   }
1269 
1270   if (G_LIKELY (priv-&gt;frames.length))
1271     ts = GST_BUFFER_TIMESTAMP (priv-&gt;frames.head-&gt;data);
1272   else
1273     ts = GST_CLOCK_TIME_NONE;
1274 
1275   GST_DEBUG_OBJECT (dec, &quot;leading frame ts %&quot; GST_TIME_FORMAT,
1276       GST_TIME_ARGS (ts));
1277 




1278   while (priv-&gt;frames.length &amp;&amp; frames) {
1279     g_queue_push_tail (&amp;inbufs, g_queue_pop_head (&amp;priv-&gt;frames));
1280     dec-&gt;priv-&gt;ctx.delay = dec-&gt;priv-&gt;frames.length;
1281     frames--;
1282   }
1283 
1284   if (G_UNLIKELY (!buf))
1285     goto exit;
1286 
1287   /* lock on */
1288   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts))) {
1289     priv-&gt;base_ts = ts;
1290     GST_DEBUG_OBJECT (dec, &quot;base_ts now %&quot; GST_TIME_FORMAT, GST_TIME_ARGS (ts));
1291   }
1292 
1293   /* still no valid ts, track the segment one */
1294   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts)) &amp;&amp;
1295       dec-&gt;output_segment.rate &gt; 0.0) {
1296     priv-&gt;base_ts = dec-&gt;output_segment.start;
1297   }
1298 
<span class="line-modified">1299   /* slightly convoluted approach caters for perfect ts if subclass desires */</span>
<span class="line-modified">1300   if (GST_CLOCK_TIME_IS_VALID (ts)) {</span>



1301     if (dec-&gt;priv-&gt;tolerance &gt; 0) {
1302       GstClockTimeDiff diff;
1303 
1304       g_assert (GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts));
1305       next_ts = priv-&gt;base_ts +
1306           gst_util_uint64_scale (priv-&gt;samples, GST_SECOND, ctx-&gt;info.rate);
1307       GST_LOG_OBJECT (dec,
1308           &quot;buffer is %&quot; G_GUINT64_FORMAT &quot; samples past base_ts %&quot;
1309           GST_TIME_FORMAT &quot;, expected ts %&quot; GST_TIME_FORMAT, priv-&gt;samples,
1310           GST_TIME_ARGS (priv-&gt;base_ts), GST_TIME_ARGS (next_ts));
1311       diff = GST_CLOCK_DIFF (next_ts, ts);
1312       GST_LOG_OBJECT (dec, &quot;ts diff %d ms&quot;, (gint) (diff / GST_MSECOND));
1313       /* if within tolerance,
1314        * discard buffer ts and carry on producing perfect stream,
1315        * otherwise resync to ts */
1316       if (G_UNLIKELY (diff &lt; (gint64) - dec-&gt;priv-&gt;tolerance ||
1317               diff &gt; (gint64) dec-&gt;priv-&gt;tolerance)) {
1318         GST_DEBUG_OBJECT (dec, &quot;base_ts resync&quot;);
1319         priv-&gt;base_ts = ts;
1320         priv-&gt;samples = 0;
</pre>
<hr />
<pre>
1345         GST_FRAMES_TO_CLOCK_TIME (priv-&gt;samples, ctx-&gt;info.rate);
1346     GST_BUFFER_DURATION (buf) = priv-&gt;base_ts +
1347         GST_FRAMES_TO_CLOCK_TIME (priv-&gt;samples + samples, ctx-&gt;info.rate) -
1348         GST_BUFFER_TIMESTAMP (buf);
1349   } else {
1350     GST_BUFFER_TIMESTAMP (buf) = GST_CLOCK_TIME_NONE;
1351     GST_BUFFER_DURATION (buf) =
1352         GST_FRAMES_TO_CLOCK_TIME (samples, ctx-&gt;info.rate);
1353   }
1354 
1355   if (klass-&gt;transform_meta) {
1356     if (inbufs.length) {
1357       GList *l;
1358       for (l = inbufs.head; l; l = l-&gt;next) {
1359         CopyMetaData data;
1360 
1361         data.decoder = dec;
1362         data.outbuf = buf;
1363         gst_buffer_foreach_meta (l-&gt;data, foreach_metadata, &amp;data);
1364       }










1365     } else {
1366       GST_WARNING_OBJECT (dec,
1367           &quot;Can&#39;t copy metadata because input buffers disappeared&quot;);
1368     }
1369   }
1370 
1371   GST_OBJECT_LOCK (dec);
1372   priv-&gt;samples += samples;
1373   priv-&gt;samples_out += samples;
1374   GST_OBJECT_UNLOCK (dec);
1375 
1376   /* we got data, so note things are looking up */
1377   if (G_UNLIKELY (dec-&gt;priv-&gt;error_count))
1378     dec-&gt;priv-&gt;error_count = 0;
1379 
1380   ret = gst_audio_decoder_output (dec, buf);
1381 
1382 exit:
1383   g_queue_foreach (&amp;inbufs, (GFunc) gst_buffer_unref, NULL);
1384   g_queue_clear (&amp;inbufs);
1385 





1386   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
1387 
1388   return ret;
1389 
1390   /* ERRORS */
1391 wrong_buffer:
1392   {

1393     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),
1394         (&quot;buffer size %&quot; G_GSIZE_FORMAT &quot; not a multiple of %d&quot;, size,
1395             ctx-&gt;info.bpf));
1396     gst_buffer_unref (buf);
1397     ret = GST_FLOW_ERROR;
1398     goto exit;
1399   }




















1400 }
1401 
1402 static GstFlowReturn
1403 gst_audio_decoder_handle_frame (GstAudioDecoder * dec,
1404     GstAudioDecoderClass * klass, GstBuffer * buffer)
1405 {
1406   /* Skip decoding and send a GAP instead if
1407    * GST_SEGMENT_FLAG_TRICKMODE_NO_AUDIO is set and we have timestamps
1408    * FIXME: We only do this for forward playback atm, because reverse
1409    * playback would require accumulating GAP events and pushing them
1410    * out in reverse order as for normal audio samples
1411    */
1412   if (G_UNLIKELY (dec-&gt;input_segment.rate &gt; 0.0
1413           &amp;&amp; dec-&gt;input_segment.flags &amp; GST_SEGMENT_FLAG_TRICKMODE_NO_AUDIO)) {
1414     if (buffer) {
1415       GstClockTime ts = GST_BUFFER_PTS (buffer);
1416       if (GST_CLOCK_TIME_IS_VALID (ts)) {
1417         GstEvent *event = gst_event_new_gap (ts, GST_BUFFER_DURATION (buffer));
1418 
1419         gst_buffer_unref (buffer);
</pre>
<hr />
<pre>
1555   /* ERRORS */
1556 parse_failed:
1557   {
1558     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL), (&quot;failed to parse stream&quot;));
1559     return GST_FLOW_ERROR;
1560   }
1561 }
1562 
1563 static GstFlowReturn
1564 gst_audio_decoder_drain (GstAudioDecoder * dec)
1565 {
1566   GstFlowReturn ret;
1567 
1568   if (dec-&gt;priv-&gt;drained &amp;&amp; !dec-&gt;priv-&gt;gather)
1569     return GST_FLOW_OK;
1570 
1571   /* Apply any pending events before draining, as that
1572    * may update the pending segment info */
1573   apply_pending_events (dec);
1574 
<span class="line-modified">1575     /* dispatch reverse pending buffers */</span>
<span class="line-modified">1576     /* chain eventually calls upon drain as well, but by that time</span>
<span class="line-modified">1577      * gather list should be clear, so ok ... */</span>
<span class="line-modified">1578     if (dec-&gt;output_segment.rate &lt; 0.0 &amp;&amp; dec-&gt;priv-&gt;gather)</span>
<span class="line-modified">1579       gst_audio_decoder_chain_reverse (dec, NULL);</span>
<span class="line-modified">1580     /* have subclass give all it can */</span>
<span class="line-modified">1581     ret = gst_audio_decoder_push_buffers (dec, TRUE);</span>
1582   if (ret != GST_FLOW_OK) {
1583     GST_WARNING_OBJECT (dec, &quot;audio decoder push buffers failed&quot;);
1584     goto drain_failed;
1585   }
<span class="line-modified">1586     /* ensure all output sent */</span>
<span class="line-modified">1587     ret = gst_audio_decoder_output (dec, NULL);</span>
1588   if (ret != GST_FLOW_OK)
1589     GST_WARNING_OBJECT (dec, &quot;audio decoder output failed&quot;);
1590 
1591 drain_failed:
<span class="line-modified">1592     /* everything should be away now */</span>
<span class="line-modified">1593     if (dec-&gt;priv-&gt;frames.length) {</span>
<span class="line-modified">1594       /* not fatal/impossible though if subclass/codec eats stuff */</span>
<span class="line-modified">1595       GST_WARNING_OBJECT (dec, &quot;still %d frames left after draining&quot;,</span>
<span class="line-modified">1596           dec-&gt;priv-&gt;frames.length);</span>
<span class="line-modified">1597       g_queue_foreach (&amp;dec-&gt;priv-&gt;frames, (GFunc) gst_buffer_unref, NULL);</span>
<span class="line-modified">1598       g_queue_clear (&amp;dec-&gt;priv-&gt;frames);</span>
<span class="line-removed">1599     }</span>
<span class="line-removed">1600 </span>
<span class="line-removed">1601     /* discard (unparsed) leftover */</span>
<span class="line-removed">1602     gst_adapter_clear (dec-&gt;priv-&gt;adapter);</span>
<span class="line-removed">1603     return ret;</span>
1604   }
1605 





1606 /* hard == FLUSH, otherwise discont */
1607 static GstFlowReturn
1608 gst_audio_decoder_flush (GstAudioDecoder * dec, gboolean hard)
1609 {
1610   GstAudioDecoderClass *klass;
1611   GstFlowReturn ret = GST_FLOW_OK;
1612 
1613   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
1614 
1615   GST_LOG_OBJECT (dec, &quot;flush hard %d&quot;, hard);
1616 
1617   if (!hard) {
1618     ret = gst_audio_decoder_drain (dec);
1619   } else {
1620     gst_audio_decoder_clear_queues (dec);
1621     gst_segment_init (&amp;dec-&gt;input_segment, GST_FORMAT_TIME);
1622     gst_segment_init (&amp;dec-&gt;output_segment, GST_FORMAT_TIME);
1623     dec-&gt;priv-&gt;error_count = 0;
1624   }
1625   /* only bother subclass with flushing if known it is already alive
</pre>
<hr />
<pre>
1987 
1988     if (gst_structure_get_int (structure, &quot;channels&quot;, &amp;channels)) {
1989       for (i = 0; i &lt; caps_size; i++) {
1990         gst_structure_set (gst_caps_get_structure (caps, i), &quot;channels&quot;,
1991             G_TYPE_INT, channels, NULL);
1992       }
1993     }
1994 
1995     if (gst_structure_get (structure, &quot;channel-mask&quot;, GST_TYPE_BITMASK,
1996             &amp;channel_mask, NULL)) {
1997       for (i = 0; i &lt; caps_size; i++) {
1998         gst_structure_set (gst_caps_get_structure (caps, i), &quot;channel-mask&quot;,
1999             GST_TYPE_BITMASK, channel_mask, NULL);
2000       }
2001     }
2002   }
2003 
2004   for (i = 0; i &lt; caps_size; i++) {
2005     structure = gst_caps_get_structure (caps, i);
2006     if (gst_structure_has_field (structure, &quot;channels&quot;))
<span class="line-modified">2007     gst_structure_fixate_field_nearest_int (structure,</span>
<span class="line-modified">2008         &quot;channels&quot;, GST_AUDIO_DEF_CHANNELS);</span>
2009     else
2010       gst_structure_set (structure, &quot;channels&quot;, G_TYPE_INT,
2011           GST_AUDIO_DEF_CHANNELS, NULL);
2012     if (gst_structure_has_field (structure, &quot;rate&quot;))
<span class="line-modified">2013     gst_structure_fixate_field_nearest_int (structure,</span>
<span class="line-modified">2014         &quot;rate&quot;, GST_AUDIO_DEF_RATE);</span>
2015     else
2016       gst_structure_set (structure, &quot;rate&quot;, G_TYPE_INT, GST_AUDIO_DEF_RATE,
2017           NULL);
2018   }
2019   caps = gst_caps_fixate (caps);
2020   structure = gst_caps_get_structure (caps, 0);
2021 
2022   /* Need to add a channel-mask if channels &gt; 2 */
2023   gst_structure_get_int (structure, &quot;channels&quot;, &amp;channels);
2024   if (channels &gt; 2 &amp;&amp; !gst_structure_has_field (structure, &quot;channel-mask&quot;)) {
2025     channel_mask = gst_audio_channel_get_fallback_mask (channels);
2026     if (channel_mask != 0) {
2027       gst_structure_set (structure, &quot;channel-mask&quot;,
2028           GST_TYPE_BITMASK, channel_mask, NULL);
2029     } else {
2030       GST_WARNING_OBJECT (dec, &quot;No default channel-mask for %d channels&quot;,
2031           channels);
2032     }
2033   }
2034 
2035   if (!caps || !gst_audio_info_from_caps (&amp;info, caps))
2036     goto caps_error;
2037 
2038   GST_OBJECT_LOCK (dec);
2039   dec-&gt;priv-&gt;ctx.info = info;

2040   GST_OBJECT_UNLOCK (dec);
2041 
2042   GST_INFO_OBJECT (dec,
2043       &quot;Chose default caps %&quot; GST_PTR_FORMAT &quot; for initial gap&quot;, caps);
<span class="line-removed">2044   gst_caps_unref (caps);</span>
2045 
2046   return TRUE;
2047 
2048 caps_error:
2049   {
2050     if (caps)
2051       gst_caps_unref (caps);
2052     return FALSE;
2053   }
2054 }
2055 
2056 static gboolean
2057 gst_audio_decoder_handle_gap (GstAudioDecoder * dec, GstEvent * event)
2058 {
2059   gboolean ret;
2060   GstClockTime timestamp, duration;
2061   gboolean needs_reconfigure = FALSE;
2062 
2063   /* Ensure we have caps first */
2064   GST_AUDIO_DECODER_STREAM_LOCK (dec);
2065   if (!GST_AUDIO_INFO_IS_VALID (&amp;dec-&gt;priv-&gt;ctx.info)) {
2066     if (!gst_audio_decoder_negotiate_default_caps (dec)) {
2067       GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2068       GST_ELEMENT_ERROR (dec, STREAM, FORMAT, (NULL),
2069           (&quot;Decoder output not negotiated before GAP event.&quot;));

2070       return FALSE;
2071     }
2072     needs_reconfigure = TRUE;
2073   }
2074   needs_reconfigure = gst_pad_check_reconfigure (dec-&gt;srcpad)
2075       || needs_reconfigure;
2076   if (G_UNLIKELY (dec-&gt;priv-&gt;ctx.output_format_changed || needs_reconfigure)) {
2077     if (!gst_audio_decoder_negotiate_unlocked (dec)) {
2078       GST_WARNING_OBJECT (dec, &quot;Failed to negotiate with downstream&quot;);
2079       gst_pad_mark_reconfigure (dec-&gt;srcpad);
2080     }
2081   }
2082   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2083 
2084   gst_event_parse_gap (event, &amp;timestamp, &amp;duration);
2085 
2086   /* time progressed without data, see if we can fill the gap with
2087    * some concealment data */
2088   GST_DEBUG_OBJECT (dec,
2089       &quot;gap event: plc %d, do_plc %d, position %&quot; GST_TIME_FORMAT
</pre>
<hr />
<pre>
2098     /* hand subclass empty frame with duration that needs covering */
2099     buf = gst_buffer_new ();
2100     GST_BUFFER_TIMESTAMP (buf) = timestamp;
2101     GST_BUFFER_DURATION (buf) = duration;
2102     /* best effort, not much error handling */
2103     gst_audio_decoder_handle_frame (dec, klass, buf);
2104     ret = TRUE;
2105     dec-&gt;priv-&gt;expecting_discont_buf = TRUE;
2106     gst_event_unref (event);
2107   } else {
2108     GstFlowReturn flowret;
2109 
2110     /* sub-class doesn&#39;t know how to handle empty buffers,
2111      * so just try sending GAP downstream */
2112     flowret = check_pending_reconfigure (dec);
2113     if (flowret == GST_FLOW_OK) {
2114       send_pending_events (dec);
2115       ret = gst_audio_decoder_push_event (dec, event);
2116     } else {
2117       ret = FALSE;

2118     }
2119   }
2120   return ret;
<span class="line-modified">2121   }</span>
2122 
2123 static GList *
2124 _flush_events (GstPad * pad, GList * events)
2125 {
2126   GList *tmp;
2127 
2128   for (tmp = events; tmp; tmp = tmp-&gt;next) {
2129     if (GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_EOS &amp;&amp;
2130         GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_SEGMENT &amp;&amp;
2131         GST_EVENT_IS_STICKY (tmp-&gt;data)) {
2132       gst_pad_store_sticky_event (pad, GST_EVENT_CAST (tmp-&gt;data));
2133     }
2134     gst_event_unref (tmp-&gt;data);
2135   }
2136   g_list_free (events);
2137 
2138   return NULL;
2139 }
2140 
2141 static gboolean
</pre>
<hr />
<pre>
2189           GST_DEBUG_OBJECT (dec, &quot;converted to TIME start %&quot; GST_TIME_FORMAT,
2190               GST_TIME_ARGS (nstart));
2191           seg.format = GST_FORMAT_TIME;
2192           seg.start = nstart;
2193           seg.time = nstart;
2194           seg.stop = GST_CLOCK_TIME_NONE;
2195           /* replace event */
2196           gst_event_unref (event);
2197           event = gst_event_new_segment (&amp;seg);
2198         } else {
2199           GST_DEBUG_OBJECT (dec, &quot;unsupported format; ignoring&quot;);
2200           GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2201           gst_event_unref (event);
2202           ret = FALSE;
2203           break;
2204         }
2205       }
2206 
2207       /* prepare for next segment */
2208       /* Use the segment start as a base timestamp
<span class="line-modified">2209          * in case upstream does not come up with anything better</span>
<span class="line-modified">2210          * (e.g. upstream BYTE) */</span>
<span class="line-modified">2211         if (format != GST_FORMAT_TIME) {</span>
<span class="line-modified">2212           dec-&gt;priv-&gt;base_ts = seg.start;</span>
<span class="line-modified">2213           dec-&gt;priv-&gt;samples = 0;</span>
<span class="line-modified">2214         }</span>
2215 
2216       /* and follow along with segment */
2217       dec-&gt;priv-&gt;in_out_segment_sync = FALSE;
2218       dec-&gt;input_segment = seg;
2219       dec-&gt;priv-&gt;pending_events =
2220           g_list_append (dec-&gt;priv-&gt;pending_events, event);
2221       GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2222 
2223       ret = TRUE;
2224       break;
2225     }
2226     case GST_EVENT_GAP:
2227       ret = gst_audio_decoder_handle_gap (dec, event);
2228       break;
2229     case GST_EVENT_FLUSH_STOP:
2230       GST_AUDIO_DECODER_STREAM_LOCK (dec);
2231       /* prepare for fresh start */
2232       gst_audio_decoder_flush (dec, TRUE);
2233 
2234       dec-&gt;priv-&gt;pending_events = _flush_events (dec-&gt;srcpad,
</pre>
<hr />
<pre>
2283     {
2284       GstTagList *tags;
2285 
2286       gst_event_parse_tag (event, &amp;tags);
2287 
2288       if (gst_tag_list_get_scope (tags) == GST_TAG_SCOPE_STREAM) {
2289         GST_AUDIO_DECODER_STREAM_LOCK (dec);
2290         if (dec-&gt;priv-&gt;upstream_tags != tags) {
2291           if (dec-&gt;priv-&gt;upstream_tags)
2292             gst_tag_list_unref (dec-&gt;priv-&gt;upstream_tags);
2293           dec-&gt;priv-&gt;upstream_tags = gst_tag_list_ref (tags);
2294           GST_INFO_OBJECT (dec, &quot;upstream stream tags: %&quot; GST_PTR_FORMAT, tags);
2295         }
2296         gst_event_unref (event);
2297         event = gst_audio_decoder_create_merged_tags_event (dec);
2298         dec-&gt;priv-&gt;taglist_changed = FALSE;
2299         GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2300 
2301         /* No tags, go out of here instead of fall through */
2302         if (!event) {
<span class="line-modified">2303         ret = TRUE;</span>
<span class="line-modified">2304         break;</span>
<span class="line-modified">2305       }</span>
2306       }
2307 
2308       /* fall through */
2309     }
2310     default:
2311       if (!GST_EVENT_IS_SERIALIZED (event)) {
2312         ret =
2313             gst_pad_event_default (dec-&gt;sinkpad, GST_OBJECT_CAST (dec), event);
2314       } else {
2315         GST_DEBUG_OBJECT (dec, &quot;Enqueuing event %d, %s&quot;, GST_EVENT_TYPE (event),
2316             GST_EVENT_TYPE_NAME (event));
2317         GST_AUDIO_DECODER_STREAM_LOCK (dec);
2318         dec-&gt;priv-&gt;pending_events =
2319             g_list_append (dec-&gt;priv-&gt;pending_events, event);
2320         GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2321         ret = TRUE;
2322       }
2323       break;
2324   }
2325   return ret;
</pre>
<hr />
<pre>
2553       GST_AUDIO_DECODER_SINK_PAD (decoder),
2554       GST_AUDIO_DECODER_SRC_PAD (decoder), caps, filter);
2555 }
2556 
2557 static GstCaps *
2558 gst_audio_decoder_sink_getcaps (GstAudioDecoder * decoder, GstCaps * filter)
2559 {
2560   GstAudioDecoderClass *klass;
2561   GstCaps *caps;
2562 
2563   klass = GST_AUDIO_DECODER_GET_CLASS (decoder);
2564 
2565   if (klass-&gt;getcaps)
2566     caps = klass-&gt;getcaps (decoder, filter);
2567   else
2568     caps = gst_audio_decoder_proxy_getcaps (decoder, NULL, filter);
2569 
2570   GST_LOG_OBJECT (decoder, &quot;Returning caps %&quot; GST_PTR_FORMAT, caps);
2571 
2572   return caps;
<span class="line-modified">2573       }</span>
2574 
2575 static gboolean
2576 gst_audio_decoder_sink_query_default (GstAudioDecoder * dec, GstQuery * query)
2577 {
2578   GstPad *pad = GST_AUDIO_DECODER_SINK_PAD (dec);
2579   gboolean res = FALSE;
2580 
2581   GST_LOG_OBJECT (dec, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
2582 
2583   switch (GST_QUERY_TYPE (query)) {
2584     case GST_QUERY_FORMATS:
2585     {
2586       gst_query_set_formats (query, 2, GST_FORMAT_TIME, GST_FORMAT_BYTES);
2587       res = TRUE;
2588       break;
2589     }
2590     case GST_QUERY_CONVERT:
2591     {
2592       GstFormat src_fmt, dest_fmt;
2593       gint64 src_val, dest_val;
2594 
2595       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
2596       GST_OBJECT_LOCK (dec);
2597       res = __gst_audio_encoded_audio_convert (&amp;dec-&gt;priv-&gt;ctx.info,
<span class="line-modified">2598                   dec-&gt;priv-&gt;bytes_in, dec-&gt;priv-&gt;samples_out,</span>
2599           src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
2600       GST_OBJECT_UNLOCK (dec);
2601       if (!res)
2602         goto error;
2603       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
2604       break;
2605     }
2606     case GST_QUERY_ALLOCATION:
2607     {
2608       GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
2609 
2610       if (klass-&gt;propose_allocation)
2611         res = klass-&gt;propose_allocation (dec, query);
2612       break;
2613     }
2614     case GST_QUERY_CAPS:{
2615       GstCaps *filter, *caps;
2616 
2617       gst_query_parse_caps (query, &amp;filter);
2618       caps = gst_audio_decoder_sink_getcaps (dec, filter);
</pre>
<hr />
<pre>
2790           src_fmt, src_val, dest_fmt, &amp;dest_val);
2791       GST_OBJECT_UNLOCK (dec);
2792       if (!res)
2793         break;
2794       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
2795       break;
2796     }
2797     case GST_QUERY_LATENCY:
2798     {
2799       if ((res = gst_pad_peer_query (dec-&gt;sinkpad, query))) {
2800         gboolean live;
2801         GstClockTime min_latency, max_latency;
2802 
2803         gst_query_parse_latency (query, &amp;live, &amp;min_latency, &amp;max_latency);
2804         GST_DEBUG_OBJECT (dec, &quot;Peer latency: live %d, min %&quot;
2805             GST_TIME_FORMAT &quot; max %&quot; GST_TIME_FORMAT, live,
2806             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
2807 
2808         GST_OBJECT_LOCK (dec);
2809         /* add our latency */
<span class="line-modified">2810           min_latency += dec-&gt;priv-&gt;ctx.min_latency;</span>
2811         if (max_latency == -1 || dec-&gt;priv-&gt;ctx.max_latency == -1)
2812           max_latency = -1;
2813         else
2814           max_latency += dec-&gt;priv-&gt;ctx.max_latency;
2815         GST_OBJECT_UNLOCK (dec);
2816 
2817         gst_query_set_latency (query, live, min_latency, max_latency);
2818       }
2819       break;
2820     }
2821     default:
2822       res = gst_pad_query_default (pad, GST_OBJECT_CAST (dec), query);
2823       break;
2824   }
2825 
2826   return res;
2827 }
2828 
2829 static gboolean
2830 gst_audio_decoder_src_query (GstPad * pad, GstObject * parent, GstQuery * query)
</pre>
<hr />
<pre>
3484 gst_audio_decoder_merge_tags (GstAudioDecoder * dec,
3485     const GstTagList * tags, GstTagMergeMode mode)
3486 {
3487   g_return_if_fail (GST_IS_AUDIO_DECODER (dec));
3488   g_return_if_fail (tags == NULL || GST_IS_TAG_LIST (tags));
3489   g_return_if_fail (mode != GST_TAG_MERGE_UNDEFINED);
3490 
3491   GST_AUDIO_DECODER_STREAM_LOCK (dec);
3492   if (dec-&gt;priv-&gt;taglist != tags) {
3493     if (dec-&gt;priv-&gt;taglist) {
3494       gst_tag_list_unref (dec-&gt;priv-&gt;taglist);
3495       dec-&gt;priv-&gt;taglist = NULL;
3496       dec-&gt;priv-&gt;decoder_tags_merge_mode = GST_TAG_MERGE_KEEP_ALL;
3497     }
3498     if (tags) {
3499       dec-&gt;priv-&gt;taglist = gst_tag_list_ref ((GstTagList *) tags);
3500       dec-&gt;priv-&gt;decoder_tags_merge_mode = mode;
3501     }
3502 
3503     GST_DEBUG_OBJECT (dec, &quot;setting decoder tags to %&quot; GST_PTR_FORMAT, tags);
<span class="line-modified">3504   dec-&gt;priv-&gt;taglist_changed = TRUE;</span>
3505   }
3506   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3507 }
3508 
3509 /**
3510  * gst_audio_decoder_allocate_output_buffer:
3511  * @dec: a #GstAudioDecoder
3512  * @size: size of the buffer
3513  *
3514  * Helper function that allocates a buffer to hold an audio frame
3515  * for @dec&#39;s current output format.
3516  *
3517  * Returns: (transfer full): allocated buffer
3518  */
3519 GstBuffer *
3520 gst_audio_decoder_allocate_output_buffer (GstAudioDecoder * dec, gsize size)
3521 {
3522   GstBuffer *buffer = NULL;
3523   gboolean needs_reconfigure = FALSE;
3524 
</pre>
<hr />
<pre>
3546     GST_INFO_OBJECT (dec, &quot;couldn&#39;t allocate output buffer&quot;);
3547     goto fallback;
3548   }
3549 
3550   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3551 
3552   return buffer;
3553 fallback:
3554   buffer = gst_buffer_new_allocate (NULL, size, NULL);
3555   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3556 
3557   return buffer;
3558 }
3559 
3560 /**
3561  * gst_audio_decoder_get_allocator:
3562  * @dec: a #GstAudioDecoder
3563  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
3564  * used
3565  * @params: (out) (allow-none) (transfer full): the
<span class="line-modified">3566  * #GstAllocatorParams of @allocator</span>
3567  *
3568  * Lets #GstAudioDecoder sub-classes to know the memory @allocator
3569  * used by the base class and its @params.
3570  *
3571  * Unref the @allocator after use it.
3572  */
3573 void
3574 gst_audio_decoder_get_allocator (GstAudioDecoder * dec,
3575     GstAllocator ** allocator, GstAllocationParams * params)
3576 {
3577   g_return_if_fail (GST_IS_AUDIO_DECODER (dec));
3578 
3579   if (allocator)
3580     *allocator = dec-&gt;priv-&gt;ctx.allocator ?
3581         gst_object_ref (dec-&gt;priv-&gt;ctx.allocator) : NULL;
3582 
3583   if (params)
3584     *params = dec-&gt;priv-&gt;ctx.params;
3585 }
3586 
</pre>
</td>
<td>
<hr />
<pre>
  76  *
  77  * Subclass is responsible for providing pad template caps for
  78  * source and sink pads. The pads need to be named &quot;sink&quot; and &quot;src&quot;. It also
  79  * needs to set the fixed caps on srcpad, when the format is ensured.  This
  80  * is typically when base class calls subclass&#39; @set_format function, though
  81  * it might be delayed until calling @gst_audio_decoder_finish_frame.
  82  *
  83  * In summary, above process should have subclass concentrating on
  84  * codec data processing while leaving other matters to base class,
  85  * such as most notably timestamp handling.  While it may exert more control
  86  * in this area (see e.g. @pre_push), it is very much not recommended.
  87  *
  88  * In particular, base class will try to arrange for perfect output timestamps
  89  * as much as possible while tracking upstream timestamps.
  90  * To this end, if deviation between the next ideal expected perfect timestamp
  91  * and upstream exceeds #GstAudioDecoder:tolerance, then resync to upstream
  92  * occurs (which would happen always if the tolerance mechanism is disabled).
  93  *
  94  * In non-live pipelines, baseclass can also (configurably) arrange for
  95  * output buffer aggregation which may help to redue large(r) numbers of
<span class="line-modified">  96  * small(er) buffers being pushed and processed downstream. Note that this</span>
<span class="line-added">  97  * feature is only available if the buffer layout is interleaved. For planar</span>
<span class="line-added">  98  * buffers, the decoder implementation is fully responsible for the output</span>
<span class="line-added">  99  * buffer size.</span>
 100  *
 101  * On the other hand, it should be noted that baseclass only provides limited
 102  * seeking support (upon explicit subclass request), as full-fledged support
 103  * should rather be left to upstream demuxer, parser or alike.  This simple
 104  * approach caters for seeking and duration reporting using estimated input
 105  * bitrates.
 106  *
 107  * Things that subclass need to take care of:
 108  *
 109  *   * Provide pad templates
 110  *   * Set source pad caps when appropriate
 111  *   * Set user-configurable properties to sane defaults for format and
 112  *      implementing codec at hand, and convey some subclass capabilities and
 113  *      expectations in context.
 114  *
 115  *   * Accept data in @handle_frame and provide encoded results to
 116  *      @gst_audio_decoder_finish_frame.  If it is prepared to perform
 117  *      PLC, it should also accept NULL data in @handle_frame and provide for
 118  *      data for indicated duration.
 119  *
 120  */
 121 
 122 #ifdef HAVE_CONFIG_H
 123 #include &quot;config.h&quot;
 124 #endif
 125 
 126 #include &quot;gstaudiodecoder.h&quot;
 127 #include &quot;gstaudioutilsprivate.h&quot;
 128 #include &lt;gst/pbutils/descriptions.h&gt;
 129 
 130 #include &lt;string.h&gt;
 131 
 132 GST_DEBUG_CATEGORY (audiodecoder_debug);
 133 #define GST_CAT_DEFAULT audiodecoder_debug
 134 




 135 enum
 136 {
 137   LAST_SIGNAL
 138 };
 139 
 140 enum
 141 {
 142   PROP_0,
 143   PROP_LATENCY,
 144   PROP_TOLERANCE,
 145   PROP_PLC
 146 };
 147 
 148 #define DEFAULT_LATENCY    0
 149 #define DEFAULT_TOLERANCE  0
 150 #define DEFAULT_PLC        FALSE
 151 #define DEFAULT_DRAINABLE  TRUE
 152 #define DEFAULT_NEEDS_FORMAT  FALSE
 153 
 154 typedef struct _GstAudioDecoderContext
 155 {
 156   /* last negotiated input caps */
 157   GstCaps *input_caps;
 158 
 159   /* (output) audio format */
 160   GstAudioInfo info;
<span class="line-added"> 161   GstCaps *caps;</span>
 162   gboolean output_format_changed;
 163 
 164   /* parsing state */
 165   gboolean eos;
 166   gboolean sync;
 167 
 168   gboolean had_output_data;
 169   gboolean had_input_data;
 170 
 171   /* misc */
 172   gint delay;
 173 
 174   /* output */
 175   gboolean do_plc;
 176   gboolean do_estimate_rate;
 177   gint max_errors;
 178   GstCaps *allocation_caps;
 179   /* MT-protected (with LOCK) */
 180   GstClockTime min_latency;
 181   GstClockTime max_latency;
</pre>
<hr />
<pre>
 200   GstClockTime prev_ts;
 201   guint64 prev_distance;
 202   /* frames obtained from input */
 203   GQueue frames;
 204   /* collected output data */
 205   GstAdapter *adapter_out;
 206   /* ts and duration for output data collected above */
 207   GstClockTime out_ts, out_dur;
 208   /* mark outgoing discont */
 209   gboolean discont;
 210 
 211   /* subclass gave all it could already */
 212   gboolean drained;
 213   /* subclass currently being forcibly drained */
 214   gboolean force;
 215   /* input_segment are output_segment identical */
 216   gboolean in_out_segment_sync;
 217   /* expecting the buffer with DISCONT flag */
 218   gboolean expecting_discont_buf;
 219 
<span class="line-added"> 220   /* number of samples pushed out via _finish_subframe(), resets on _finish_frame() */</span>
<span class="line-added"> 221   guint subframe_samples;</span>
 222 
 223   /* input bps estimatation */
 224   /* global in bytes seen */
 225   guint64 bytes_in;
 226   /* global samples sent out */
 227   guint64 samples_out;
 228   /* bytes flushed during parsing */
 229   guint sync_flush;
 230   /* error count */
 231   gint error_count;
 232 
 233   /* upstream stream tags (global tags are passed through as-is) */
 234   GstTagList *upstream_tags;
 235 
 236   /* subclass tags */
 237   GstTagList *taglist;          /* FIXME: rename to decoder_tags */
 238   GstTagMergeMode decoder_tags_merge_mode;
 239 
 240   gboolean taglist_changed;     /* FIXME: rename to tags_changed */
 241 
</pre>
<hr />
<pre>
 296 static gboolean gst_audio_decoder_sink_query (GstPad * pad, GstObject * parent,
 297     GstQuery * query);
 298 static void gst_audio_decoder_reset (GstAudioDecoder * dec, gboolean full);
 299 
 300 static gboolean gst_audio_decoder_decide_allocation_default (GstAudioDecoder *
 301     dec, GstQuery * query);
 302 static gboolean gst_audio_decoder_propose_allocation_default (GstAudioDecoder *
 303     dec, GstQuery * query);
 304 static gboolean gst_audio_decoder_negotiate_default (GstAudioDecoder * dec);
 305 static gboolean gst_audio_decoder_negotiate_unlocked (GstAudioDecoder * dec);
 306 static gboolean gst_audio_decoder_handle_gap (GstAudioDecoder * dec,
 307     GstEvent * event);
 308 static gboolean gst_audio_decoder_sink_query_default (GstAudioDecoder * dec,
 309     GstQuery * query);
 310 static gboolean gst_audio_decoder_src_query_default (GstAudioDecoder * dec,
 311     GstQuery * query);
 312 
 313 static gboolean gst_audio_decoder_transform_meta_default (GstAudioDecoder *
 314     decoder, GstBuffer * outbuf, GstMeta * meta, GstBuffer * inbuf);
 315 
<span class="line-added"> 316 static GstFlowReturn</span>
<span class="line-added"> 317 gst_audio_decoder_finish_frame_or_subframe (GstAudioDecoder * dec,</span>
<span class="line-added"> 318     GstBuffer * buf, gint frames);</span>
<span class="line-added"> 319 </span>
 320 static GstElementClass *parent_class = NULL;
<span class="line-added"> 321 static gint private_offset = 0;</span>
 322 
 323 static void gst_audio_decoder_class_init (GstAudioDecoderClass * klass);
 324 static void gst_audio_decoder_init (GstAudioDecoder * dec,
 325     GstAudioDecoderClass * klass);
 326 
 327 GType
 328 gst_audio_decoder_get_type (void)
 329 {
 330   static volatile gsize audio_decoder_type = 0;
 331 
 332   if (g_once_init_enter (&amp;audio_decoder_type)) {
 333     GType _type;
 334     static const GTypeInfo audio_decoder_info = {
 335       sizeof (GstAudioDecoderClass),
 336       NULL,
 337       NULL,
 338       (GClassInitFunc) gst_audio_decoder_class_init,
 339       NULL,
 340       NULL,
 341       sizeof (GstAudioDecoder),
 342       0,
 343       (GInstanceInitFunc) gst_audio_decoder_init,
 344     };
 345 
 346     _type = g_type_register_static (GST_TYPE_ELEMENT,
 347         &quot;GstAudioDecoder&quot;, &amp;audio_decoder_info, G_TYPE_FLAG_ABSTRACT);
<span class="line-added"> 348 </span>
<span class="line-added"> 349     private_offset =</span>
<span class="line-added"> 350         g_type_add_instance_private (_type, sizeof (GstAudioDecoderPrivate));</span>
<span class="line-added"> 351 </span>
 352     g_once_init_leave (&amp;audio_decoder_type, _type);
 353   }
 354   return audio_decoder_type;
 355 }
 356 
<span class="line-added"> 357 static inline GstAudioDecoderPrivate *</span>
<span class="line-added"> 358 gst_audio_decoder_get_instance_private (GstAudioDecoder * self)</span>
<span class="line-added"> 359 {</span>
<span class="line-added"> 360   return (G_STRUCT_MEMBER_P (self, private_offset));</span>
<span class="line-added"> 361 }</span>
 362 
 363 static void
 364 gst_audio_decoder_class_init (GstAudioDecoderClass * klass)
 365 {
 366   GObjectClass *gobject_class;
 367   GstElementClass *element_class;
 368   GstAudioDecoderClass *audiodecoder_class;
 369 
 370   gobject_class = G_OBJECT_CLASS (klass);
 371   element_class = GST_ELEMENT_CLASS (klass);
 372   audiodecoder_class = GST_AUDIO_DECODER_CLASS (klass);
 373 
 374   parent_class = g_type_class_peek_parent (klass);
 375 
<span class="line-modified"> 376   if (private_offset != 0)</span>
<span class="line-added"> 377     g_type_class_adjust_private_offset (klass, &amp;private_offset);</span>
 378 
 379   GST_DEBUG_CATEGORY_INIT (audiodecoder_debug, &quot;audiodecoder&quot;, 0,
 380       &quot;audio decoder base class&quot;);
 381 
 382   gobject_class-&gt;set_property = gst_audio_decoder_set_property;
 383   gobject_class-&gt;get_property = gst_audio_decoder_get_property;
 384   gobject_class-&gt;finalize = gst_audio_decoder_finalize;
 385 
 386   element_class-&gt;change_state =
 387       GST_DEBUG_FUNCPTR (gst_audio_decoder_change_state);
 388 
 389   /* Properties */
 390   g_object_class_install_property (gobject_class, PROP_LATENCY,
 391       g_param_spec_int64 (&quot;min-latency&quot;, &quot;Minimum Latency&quot;,
 392           &quot;Aggregate output data to a minimum of latency time (ns)&quot;,
 393           0, G_MAXINT64, DEFAULT_LATENCY,
 394           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 395 
 396   g_object_class_install_property (gobject_class, PROP_TOLERANCE,
 397       g_param_spec_int64 (&quot;tolerance&quot;, &quot;Tolerance&quot;,
</pre>
<hr />
<pre>
 412       GST_DEBUG_FUNCPTR (gst_audio_decoder_propose_allocation_default);
 413   audiodecoder_class-&gt;decide_allocation =
 414       GST_DEBUG_FUNCPTR (gst_audio_decoder_decide_allocation_default);
 415   audiodecoder_class-&gt;negotiate =
 416       GST_DEBUG_FUNCPTR (gst_audio_decoder_negotiate_default);
 417   audiodecoder_class-&gt;sink_query =
 418       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_query_default);
 419   audiodecoder_class-&gt;src_query =
 420       GST_DEBUG_FUNCPTR (gst_audio_decoder_src_query_default);
 421   audiodecoder_class-&gt;transform_meta =
 422       GST_DEBUG_FUNCPTR (gst_audio_decoder_transform_meta_default);
 423 }
 424 
 425 static void
 426 gst_audio_decoder_init (GstAudioDecoder * dec, GstAudioDecoderClass * klass)
 427 {
 428   GstPadTemplate *pad_template;
 429 
 430   GST_DEBUG_OBJECT (dec, &quot;gst_audio_decoder_init&quot;);
 431 
<span class="line-modified"> 432   dec-&gt;priv = gst_audio_decoder_get_instance_private (dec);</span>
 433 
 434   /* Setup sink pad */
 435   pad_template =
 436       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;sink&quot;);
 437   g_return_if_fail (pad_template != NULL);
 438 
 439   dec-&gt;sinkpad = gst_pad_new_from_template (pad_template, &quot;sink&quot;);
 440   gst_pad_set_event_function (dec-&gt;sinkpad,
 441       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_event));
 442   gst_pad_set_chain_function (dec-&gt;sinkpad,
 443       GST_DEBUG_FUNCPTR (gst_audio_decoder_chain));
 444   gst_pad_set_query_function (dec-&gt;sinkpad,
 445       GST_DEBUG_FUNCPTR (gst_audio_decoder_sink_query));
 446   gst_element_add_pad (GST_ELEMENT (dec), dec-&gt;sinkpad);
 447   GST_DEBUG_OBJECT (dec, &quot;sinkpad created&quot;);
 448 
 449   /* Setup source pad */
 450   pad_template =
 451       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), &quot;src&quot;);
 452   g_return_if_fail (pad_template != NULL);
</pre>
<hr />
<pre>
 503     dec-&gt;priv-&gt;decoder_tags_merge_mode = GST_TAG_MERGE_KEEP_ALL;
 504     if (dec-&gt;priv-&gt;upstream_tags) {
 505       gst_tag_list_unref (dec-&gt;priv-&gt;upstream_tags);
 506       dec-&gt;priv-&gt;upstream_tags = NULL;
 507     }
 508     dec-&gt;priv-&gt;taglist_changed = FALSE;
 509 
 510     gst_segment_init (&amp;dec-&gt;input_segment, GST_FORMAT_TIME);
 511     gst_segment_init (&amp;dec-&gt;output_segment, GST_FORMAT_TIME);
 512     dec-&gt;priv-&gt;in_out_segment_sync = TRUE;
 513 
 514     g_list_foreach (dec-&gt;priv-&gt;pending_events, (GFunc) gst_event_unref, NULL);
 515     g_list_free (dec-&gt;priv-&gt;pending_events);
 516     dec-&gt;priv-&gt;pending_events = NULL;
 517 
 518     if (dec-&gt;priv-&gt;ctx.allocator)
 519       gst_object_unref (dec-&gt;priv-&gt;ctx.allocator);
 520 
 521     GST_OBJECT_LOCK (dec);
 522     gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.input_caps, NULL);
<span class="line-added"> 523     gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.caps, NULL);</span>
 524     gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.allocation_caps, NULL);
 525 
 526     memset (&amp;dec-&gt;priv-&gt;ctx, 0, sizeof (dec-&gt;priv-&gt;ctx));
 527 
 528     gst_audio_info_init (&amp;dec-&gt;priv-&gt;ctx.info);
 529     GST_OBJECT_UNLOCK (dec);
 530     dec-&gt;priv-&gt;ctx.max_errors = GST_AUDIO_DECODER_MAX_ERRORS;
 531     dec-&gt;priv-&gt;ctx.had_output_data = FALSE;
 532     dec-&gt;priv-&gt;ctx.had_input_data = FALSE;
 533   }
 534 
 535   g_queue_foreach (&amp;dec-&gt;priv-&gt;frames, (GFunc) gst_buffer_unref, NULL);
 536   g_queue_clear (&amp;dec-&gt;priv-&gt;frames);
 537   gst_adapter_clear (dec-&gt;priv-&gt;adapter);
 538   gst_adapter_clear (dec-&gt;priv-&gt;adapter_out);
 539   dec-&gt;priv-&gt;out_ts = GST_CLOCK_TIME_NONE;
 540   dec-&gt;priv-&gt;out_dur = 0;
 541   dec-&gt;priv-&gt;prev_ts = GST_CLOCK_TIME_NONE;
 542   dec-&gt;priv-&gt;prev_distance = 0;
 543   dec-&gt;priv-&gt;drained = TRUE;
</pre>
<hr />
<pre>
 616     default:
 617       break;
 618   }
 619 
 620   return gst_pad_push_event (dec-&gt;srcpad, event);
 621 }
 622 
 623 static gboolean
 624 gst_audio_decoder_negotiate_default (GstAudioDecoder * dec)
 625 {
 626   GstAudioDecoderClass *klass;
 627   gboolean res = TRUE;
 628   GstCaps *caps;
 629   GstCaps *prevcaps;
 630   GstQuery *query = NULL;
 631   GstAllocator *allocator;
 632   GstAllocationParams params;
 633 
 634   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
 635   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (&amp;dec-&gt;priv-&gt;ctx.info), FALSE);
<span class="line-added"> 636   g_return_val_if_fail (GST_IS_CAPS (dec-&gt;priv-&gt;ctx.caps), FALSE);</span>
 637 
 638   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 639 
<span class="line-modified"> 640   caps = dec-&gt;priv-&gt;ctx.caps;</span>
 641   if (dec-&gt;priv-&gt;ctx.allocation_caps == NULL)
 642     dec-&gt;priv-&gt;ctx.allocation_caps = gst_caps_ref (caps);
 643 
 644   GST_DEBUG_OBJECT (dec, &quot;setting src caps %&quot; GST_PTR_FORMAT, caps);
 645 
 646   if (dec-&gt;priv-&gt;pending_events) {
 647     GList **pending_events, *l;
 648 
 649     pending_events = &amp;dec-&gt;priv-&gt;pending_events;
 650 
 651     GST_DEBUG_OBJECT (dec, &quot;Pushing pending events&quot;);
 652     for (l = *pending_events; l;) {
 653       GstEvent *event = GST_EVENT (l-&gt;data);
 654       GList *tmp;
 655 
 656       if (GST_EVENT_TYPE (event) &lt; GST_EVENT_CAPS) {
 657         gst_audio_decoder_push_event (dec, l-&gt;data);
 658         tmp = l;
 659         l = l-&gt;next;
 660         *pending_events = g_list_delete_link (*pending_events, tmp);
</pre>
<hr />
<pre>
 689     goto no_decide_allocation;
 690 
 691   /* we got configuration from our peer or the decide_allocation method,
 692    * parse them */
 693   if (gst_query_get_n_allocation_params (query) &gt; 0) {
 694     gst_query_parse_nth_allocation_param (query, 0, &amp;allocator, &amp;params);
 695   } else {
 696     allocator = NULL;
 697     gst_allocation_params_init (&amp;params);
 698   }
 699 
 700   if (dec-&gt;priv-&gt;ctx.allocator)
 701     gst_object_unref (dec-&gt;priv-&gt;ctx.allocator);
 702   dec-&gt;priv-&gt;ctx.allocator = allocator;
 703   dec-&gt;priv-&gt;ctx.params = params;
 704 
 705 done:
 706 
 707   if (query)
 708     gst_query_unref (query);

 709 
 710   return res;
 711 
 712   /* ERRORS */
 713 no_decide_allocation:
 714   {
 715     GST_WARNING_OBJECT (dec, &quot;Subclass failed to decide allocation&quot;);
 716     goto done;
 717   }
 718 }
 719 
 720 static gboolean
 721 gst_audio_decoder_negotiate_unlocked (GstAudioDecoder * dec)
 722 {
 723   GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 724   gboolean ret = TRUE;
 725 
 726   if (G_LIKELY (klass-&gt;negotiate))
 727     ret = klass-&gt;negotiate (dec);
 728 
</pre>
<hr />
<pre>
 758   }
 759   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 760 
 761   return res;
 762 }
 763 
 764 /**
 765  * gst_audio_decoder_set_output_format:
 766  * @dec: a #GstAudioDecoder
 767  * @info: #GstAudioInfo
 768  *
 769  * Configure output info on the srcpad of @dec.
 770  *
 771  * Returns: %TRUE on success.
 772  **/
 773 gboolean
 774 gst_audio_decoder_set_output_format (GstAudioDecoder * dec,
 775     const GstAudioInfo * info)
 776 {
 777   gboolean res = TRUE;

 778   GstCaps *caps = NULL;

 779 
 780   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
 781   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (info), FALSE);
 782 




 783   /* If the audio info can&#39;t be converted to caps,
 784    * it was invalid */
 785   caps = gst_audio_info_to_caps (info);
<span class="line-modified"> 786   if (!caps) {</span>
<span class="line-added"> 787     GST_WARNING_OBJECT (dec, &quot;invalid output format&quot;);</span>
<span class="line-added"> 788     return FALSE;</span>
<span class="line-added"> 789   }</span>
<span class="line-added"> 790 </span>
<span class="line-added"> 791   res = gst_audio_decoder_set_output_caps (dec, caps);</span>
<span class="line-added"> 792   gst_caps_unref (caps);</span>
<span class="line-added"> 793 </span>
<span class="line-added"> 794   return res;</span>
<span class="line-added"> 795 }</span>
<span class="line-added"> 796 </span>
<span class="line-added"> 797 /**</span>
<span class="line-added"> 798  * gst_audio_decoder_set_output_caps:</span>
<span class="line-added"> 799  * @dec: a #GstAudioDecoder</span>
<span class="line-added"> 800  * @caps: (transfer none): (fixed) #GstCaps</span>
<span class="line-added"> 801  *</span>
<span class="line-added"> 802  * Configure output caps on the srcpad of @dec. Similar to</span>
<span class="line-added"> 803  * gst_audio_decoder_set_output_format(), but allows subclasses to specify</span>
<span class="line-added"> 804  * output caps that can&#39;t be expressed via #GstAudioInfo e.g. caps that have</span>
<span class="line-added"> 805  * caps features.</span>
<span class="line-added"> 806  *</span>
<span class="line-added"> 807  * Returns: %TRUE on success.</span>
<span class="line-added"> 808  *</span>
<span class="line-added"> 809  * Since: 1.16</span>
<span class="line-added"> 810  **/</span>
<span class="line-added"> 811 gboolean</span>
<span class="line-added"> 812 gst_audio_decoder_set_output_caps (GstAudioDecoder * dec, GstCaps * caps)</span>
<span class="line-added"> 813 {</span>
<span class="line-added"> 814   gboolean res = TRUE;</span>
<span class="line-added"> 815   guint old_rate;</span>
<span class="line-added"> 816   GstCaps *templ_caps;</span>
<span class="line-added"> 817   GstAudioInfo info;</span>
<span class="line-added"> 818 </span>
<span class="line-added"> 819   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);</span>
<span class="line-added"> 820 </span>
<span class="line-added"> 821   GST_DEBUG_OBJECT (dec, &quot;Setting srcpad caps %&quot; GST_PTR_FORMAT, caps);</span>
<span class="line-added"> 822 </span>
<span class="line-added"> 823   GST_AUDIO_DECODER_STREAM_LOCK (dec);</span>
<span class="line-added"> 824 </span>
<span class="line-added"> 825   if (!gst_caps_is_fixed (caps))</span>
<span class="line-added"> 826     goto refuse_caps;</span>
<span class="line-added"> 827 </span>
<span class="line-added"> 828   /* check if caps can be parsed */</span>
<span class="line-added"> 829   if (!gst_audio_info_from_caps (&amp;info, caps))</span>
 830     goto refuse_caps;
 831 
 832   /* Only allow caps that are a subset of the template caps */
 833   templ_caps = gst_pad_get_pad_template_caps (dec-&gt;srcpad);
 834   if (!gst_caps_is_subset (caps, templ_caps)) {
 835     GST_WARNING_OBJECT (dec, &quot;Requested output format %&quot; GST_PTR_FORMAT
 836         &quot; do not match template %&quot; GST_PTR_FORMAT, caps, templ_caps);
 837     gst_caps_unref (templ_caps);
 838     goto refuse_caps;
 839   }
 840   gst_caps_unref (templ_caps);
 841 
 842   /* adjust ts tracking to new sample rate */
 843   old_rate = GST_AUDIO_INFO_RATE (&amp;dec-&gt;priv-&gt;ctx.info);
 844   if (GST_CLOCK_TIME_IS_VALID (dec-&gt;priv-&gt;base_ts) &amp;&amp; old_rate) {
 845     dec-&gt;priv-&gt;base_ts +=
 846         GST_FRAMES_TO_CLOCK_TIME (dec-&gt;priv-&gt;samples, old_rate);
 847     dec-&gt;priv-&gt;samples = 0;
 848   }
 849 
 850   /* copy the GstAudioInfo */
 851   GST_OBJECT_LOCK (dec);
<span class="line-modified"> 852   dec-&gt;priv-&gt;ctx.info = info;</span>
 853   GST_OBJECT_UNLOCK (dec);
<span class="line-added"> 854 </span>
<span class="line-added"> 855   gst_caps_replace (&amp;dec-&gt;priv-&gt;ctx.caps, caps);</span>
 856   dec-&gt;priv-&gt;ctx.output_format_changed = TRUE;
 857 
 858 done:
 859   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 860 



 861   return res;
 862 
 863   /* ERRORS */
 864 refuse_caps:
 865   {
 866     GST_WARNING_OBJECT (dec, &quot;invalid output format&quot;);
 867     res = FALSE;
 868     goto done;
 869   }
 870 }
 871 
 872 static gboolean
 873 gst_audio_decoder_sink_setcaps (GstAudioDecoder * dec, GstCaps * caps)
 874 {
 875   GstAudioDecoderClass *klass;
 876   gboolean res = TRUE;
 877 
 878   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 879 
 880   GST_DEBUG_OBJECT (dec, &quot;caps: %&quot; GST_PTR_FORMAT, caps);
</pre>
<hr />
<pre>
 949     return GST_FLOW_OK;
 950   }
 951 
 952   ctx-&gt;had_output_data = TRUE;
 953   ts = GST_BUFFER_TIMESTAMP (buf);
 954 
 955   GST_LOG_OBJECT (dec,
 956       &quot;clipping buffer of size %&quot; G_GSIZE_FORMAT &quot; with ts %&quot; GST_TIME_FORMAT
 957       &quot;, duration %&quot; GST_TIME_FORMAT, gst_buffer_get_size (buf),
 958       GST_TIME_ARGS (GST_BUFFER_TIMESTAMP (buf)),
 959       GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
 960 
 961   /* clip buffer */
 962   buf = gst_audio_buffer_clip (buf, &amp;dec-&gt;output_segment, ctx-&gt;info.rate,
 963       ctx-&gt;info.bpf);
 964   if (G_UNLIKELY (!buf)) {
 965     GST_DEBUG_OBJECT (dec, &quot;no data after clipping to segment&quot;);
 966     /* only check and return EOS if upstream still
 967      * in the same segment and interested as such */
 968     if (dec-&gt;priv-&gt;in_out_segment_sync) {
<span class="line-modified"> 969       if (dec-&gt;output_segment.rate &gt;= 0) {</span>
<span class="line-modified"> 970         if (ts &gt;= dec-&gt;output_segment.stop)</span>
<span class="line-added"> 971           ret = GST_FLOW_EOS;</span>
<span class="line-added"> 972       } else if (ts &lt; dec-&gt;output_segment.start) {</span>
 973         ret = GST_FLOW_EOS;
<span class="line-modified"> 974       }</span>


 975     }
 976     goto exit;
 977   }
 978 
 979   /* decorate */
 980   if (G_UNLIKELY (priv-&gt;discont)) {
 981     GST_LOG_OBJECT (dec, &quot;marking discont&quot;);
 982     GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DISCONT);
 983     priv-&gt;discont = FALSE;
 984   }
 985 
 986   /* track where we are */
 987   if (G_LIKELY (GST_BUFFER_TIMESTAMP_IS_VALID (buf))) {
 988     /* duration should always be valid for raw audio */
 989     g_assert (GST_BUFFER_DURATION_IS_VALID (buf));
 990     dec-&gt;output_segment.position =
 991         GST_BUFFER_TIMESTAMP (buf) + GST_BUFFER_DURATION (buf);
 992   }
 993 
 994   if (klass-&gt;pre_push) {
</pre>
<hr />
<pre>
1022 {
1023   GstAudioDecoderPrivate *priv;
1024   GstFlowReturn ret = GST_FLOW_OK;
1025   GstBuffer *inbuf = NULL;
1026 
1027   priv = dec-&gt;priv;
1028 
1029   if (G_UNLIKELY (priv-&gt;agg &lt; 0))
1030     gst_audio_decoder_setup (dec);
1031 
1032   if (G_LIKELY (buf)) {
1033     GST_LOG_OBJECT (dec,
1034         &quot;output buffer of size %&quot; G_GSIZE_FORMAT &quot; with ts %&quot; GST_TIME_FORMAT
1035         &quot;, duration %&quot; GST_TIME_FORMAT, gst_buffer_get_size (buf),
1036         GST_TIME_ARGS (GST_BUFFER_TIMESTAMP (buf)),
1037         GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
1038   }
1039 
1040 again:
1041   inbuf = NULL;
<span class="line-modified">1042   if (priv-&gt;agg &amp;&amp; dec-&gt;priv-&gt;latency &gt; 0 &amp;&amp;</span>
<span class="line-added">1043       priv-&gt;ctx.info.layout == GST_AUDIO_LAYOUT_INTERLEAVED) {</span>
1044     gint av;
1045     gboolean assemble = FALSE;
1046     const GstClockTimeDiff tol = 10 * GST_MSECOND;
1047     GstClockTimeDiff diff = -100 * GST_MSECOND;
1048 
1049     av = gst_adapter_available (priv-&gt;adapter_out);
1050     if (G_UNLIKELY (!buf)) {
1051       /* forcibly send current */
1052       assemble = TRUE;
1053       GST_LOG_OBJECT (dec, &quot;forcing fragment flush&quot;);
1054     } else if (av &amp;&amp; (!GST_BUFFER_TIMESTAMP_IS_VALID (buf) ||
1055             !GST_CLOCK_TIME_IS_VALID (priv-&gt;out_ts) ||
1056             ((diff = GST_CLOCK_DIFF (GST_BUFFER_TIMESTAMP (buf),
1057                         priv-&gt;out_ts + priv-&gt;out_dur)) &gt; tol) || diff &lt; -tol)) {
1058       assemble = TRUE;
1059       GST_LOG_OBJECT (dec, &quot;buffer %d ms apart from current fragment&quot;,
1060           (gint) (diff / GST_MSECOND));
1061     } else {
1062       /* add or start collecting */
1063       if (!av) {
</pre>
<hr />
<pre>
1214         g_type_name (info-&gt;api));
1215     do_copy = FALSE;
1216   } else if (klass-&gt;transform_meta) {
1217     do_copy = klass-&gt;transform_meta (decoder, outbuf, *meta, inbuf);
1218     GST_DEBUG_OBJECT (decoder, &quot;transformed metadata %s: copy: %d&quot;,
1219         g_type_name (info-&gt;api), do_copy);
1220   }
1221 
1222   /* we only copy metadata when the subclass implemented a transform_meta
1223    * function and when it returns %TRUE */
1224   if (do_copy &amp;&amp; info-&gt;transform_func) {
1225     GstMetaTransformCopy copy_data = { FALSE, 0, -1 };
1226     GST_DEBUG_OBJECT (decoder, &quot;copy metadata %s&quot;, g_type_name (info-&gt;api));
1227     /* simply copy then */
1228     info-&gt;transform_func (outbuf, *meta, inbuf,
1229         _gst_meta_transform_copy, &amp;copy_data);
1230   }
1231   return TRUE;
1232 }
1233 
<span class="line-added">1234 /**</span>
<span class="line-added">1235  * gst_audio_decoder_finish_subframe:</span>
<span class="line-added">1236  * @dec: a #GstAudioDecoder</span>
<span class="line-added">1237  * @buf: decoded data</span>
<span class="line-added">1238  *</span>
<span class="line-added">1239  * Collects decoded data and pushes it downstream. This function may be called</span>
<span class="line-added">1240  * multiple times for a given input frame.</span>
<span class="line-added">1241  *</span>
<span class="line-added">1242  * @buf may be NULL in which case it is assumed that the current input frame is</span>
<span class="line-added">1243  * finished. This is equivalent to calling gst_audio_decoder_finish_subframe()</span>
<span class="line-added">1244  * with a NULL buffer and frames=1 after having pushed out all decoded audio</span>
<span class="line-added">1245  * subframes using this function.</span>
<span class="line-added">1246  *</span>
<span class="line-added">1247  * When called with valid data in @buf the source pad caps must have been set</span>
<span class="line-added">1248  * already.</span>
<span class="line-added">1249  *</span>
<span class="line-added">1250  * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be</span>
<span class="line-added">1251  * invalidated by a call to this function.</span>
<span class="line-added">1252  *</span>
<span class="line-added">1253  * Returns: a #GstFlowReturn that should be escalated to caller (of caller)</span>
<span class="line-added">1254  *</span>
<span class="line-added">1255  * Since: 1.16</span>
<span class="line-added">1256  */</span>
<span class="line-added">1257 GstFlowReturn</span>
<span class="line-added">1258 gst_audio_decoder_finish_subframe (GstAudioDecoder * dec, GstBuffer * buf)</span>
<span class="line-added">1259 {</span>
<span class="line-added">1260   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), GST_FLOW_ERROR);</span>
<span class="line-added">1261 </span>
<span class="line-added">1262   if (buf == NULL)</span>
<span class="line-added">1263     return gst_audio_decoder_finish_frame_or_subframe (dec, NULL, 1);</span>
<span class="line-added">1264   else</span>
<span class="line-added">1265     return gst_audio_decoder_finish_frame_or_subframe (dec, buf, 0);</span>
<span class="line-added">1266 }</span>
<span class="line-added">1267 </span>
1268 /**
1269  * gst_audio_decoder_finish_frame:
1270  * @dec: a #GstAudioDecoder
1271  * @buf: decoded data
1272  * @frames: number of decoded frames represented by decoded data
1273  *
1274  * Collects decoded data and pushes it downstream.
1275  *
1276  * @buf may be NULL in which case the indicated number of frames
1277  * are discarded and considered to have produced no output
1278  * (e.g. lead-in or setup frames).
1279  * Otherwise, source pad caps must be set when it is called with valid
1280  * data in @buf.
1281  *
<span class="line-modified">1282  * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be</span>
1283  * invalidated by a call to this function.
1284  *
1285  * Returns: a #GstFlowReturn that should be escalated to caller (of caller)
1286  */
1287 GstFlowReturn
1288 gst_audio_decoder_finish_frame (GstAudioDecoder * dec, GstBuffer * buf,
1289     gint frames)
<span class="line-added">1290 {</span>
<span class="line-added">1291   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), GST_FLOW_ERROR);</span>
<span class="line-added">1292 </span>
<span class="line-added">1293   /* no dummy calls please */</span>
<span class="line-added">1294   g_return_val_if_fail (frames != 0, GST_FLOW_ERROR);</span>
<span class="line-added">1295 </span>
<span class="line-added">1296   return gst_audio_decoder_finish_frame_or_subframe (dec, buf, frames);</span>
<span class="line-added">1297 }</span>
<span class="line-added">1298 </span>
<span class="line-added">1299 /* frames == 0 indicates that this is a sub-frame and further sub-frames may</span>
<span class="line-added">1300  * follow for the current input frame. */</span>
<span class="line-added">1301 static GstFlowReturn</span>
<span class="line-added">1302 gst_audio_decoder_finish_frame_or_subframe (GstAudioDecoder * dec,</span>
<span class="line-added">1303     GstBuffer * buf, gint frames)</span>
1304 {
1305   GstAudioDecoderPrivate *priv;
1306   GstAudioDecoderContext *ctx;
1307   GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
<span class="line-modified">1308   GstAudioMeta *meta;</span>
1309   GstClockTime ts, next_ts;
<span class="line-modified">1310   gsize size, samples = 0;</span>
1311   GstFlowReturn ret = GST_FLOW_OK;
1312   GQueue inbufs = G_QUEUE_INIT;
<span class="line-added">1313   gboolean is_subframe = (frames == 0);</span>
<span class="line-added">1314   gboolean do_check_resync;</span>
1315 
1316   /* subclass should not hand us no data */
1317   g_return_val_if_fail (buf == NULL || gst_buffer_get_size (buf) &gt; 0,
1318       GST_FLOW_ERROR);
<span class="line-modified">1319 </span>
<span class="line-modified">1320   /* if it&#39;s a subframe (frames == 0) we must have a valid buffer */</span>
<span class="line-added">1321   g_assert (!is_subframe || buf != NULL);</span>
1322 
1323   priv = dec-&gt;priv;
1324   ctx = &amp;dec-&gt;priv-&gt;ctx;
<span class="line-added">1325   meta = buf ? gst_buffer_get_audio_meta (buf) : NULL;</span>
1326   size = buf ? gst_buffer_get_size (buf) : 0;
<span class="line-added">1327   samples = buf ? (meta ? meta-&gt;samples : size / ctx-&gt;info.bpf) : 0;</span>
1328 
1329   /* must know the output format by now */
1330   g_return_val_if_fail (buf == NULL || GST_AUDIO_INFO_IS_VALID (&amp;ctx-&gt;info),
1331       GST_FLOW_ERROR);
1332 
1333   GST_LOG_OBJECT (dec,
1334       &quot;accepting %&quot; G_GSIZE_FORMAT &quot; bytes == %&quot; G_GSIZE_FORMAT
<span class="line-modified">1335       &quot; samples for %d frames&quot;, buf ? size : 0, samples, frames);</span>

1336 
1337   GST_AUDIO_DECODER_STREAM_LOCK (dec);
1338 
<span class="line-modified">1339   if (buf != NULL &amp;&amp; priv-&gt;subframe_samples == 0) {</span>
1340     ret = check_pending_reconfigure (dec);
1341     if (ret == GST_FLOW_FLUSHING || ret == GST_FLOW_NOT_NEGOTIATED) {
1342       gst_buffer_unref (buf);
1343       goto exit;
1344     }
1345 
1346     if (priv-&gt;pending_events)
1347       send_pending_events (dec);
1348   }
1349 
<span class="line-modified">1350   /* sanity checking */</span>
1351   if (G_LIKELY (buf &amp;&amp; ctx-&gt;info.bpf)) {
<span class="line-modified">1352     if (!meta || meta-&gt;info.layout == GST_AUDIO_LAYOUT_INTERLEAVED) {</span>
<span class="line-modified">1353       /* output shoud be whole number of sample frames */</span>
<span class="line-modified">1354       if (size % ctx-&gt;info.bpf)</span>
<span class="line-modified">1355         goto wrong_buffer;</span>
<span class="line-added">1356       /* output should have no additional padding */</span>
<span class="line-added">1357       if (samples != size / ctx-&gt;info.bpf)</span>
<span class="line-added">1358         goto wrong_samples;</span>
<span class="line-added">1359     } else {</span>
<span class="line-added">1360       /* can&#39;t have more samples than what the buffer fits */</span>
<span class="line-added">1361       if (samples &gt; size / ctx-&gt;info.bpf)</span>
<span class="line-added">1362         goto wrong_samples;</span>
<span class="line-added">1363     }</span>
1364   }
1365 
1366   /* frame and ts book-keeping */
1367   if (G_UNLIKELY (frames &lt; 0)) {
1368     if (G_UNLIKELY (-frames - 1 &gt; priv-&gt;frames.length)) {
1369       GST_ELEMENT_WARNING (dec, STREAM, DECODE,
1370           (&quot;received more decoded frames %d than provided %d&quot;, frames,
1371               priv-&gt;frames.length), (NULL));
1372       frames = 0;
1373     } else {
1374       frames = priv-&gt;frames.length + frames + 1;
1375     }
1376   } else if (G_UNLIKELY (frames &gt; priv-&gt;frames.length)) {
1377     if (G_LIKELY (!priv-&gt;force)) {
1378       GST_ELEMENT_WARNING (dec, STREAM, DECODE,
1379           (&quot;received more decoded frames %d than provided %d&quot;, frames,
1380               priv-&gt;frames.length), (NULL));
1381     }
1382     frames = priv-&gt;frames.length;
1383   }
1384 
1385   if (G_LIKELY (priv-&gt;frames.length))
1386     ts = GST_BUFFER_TIMESTAMP (priv-&gt;frames.head-&gt;data);
1387   else
1388     ts = GST_CLOCK_TIME_NONE;
1389 
1390   GST_DEBUG_OBJECT (dec, &quot;leading frame ts %&quot; GST_TIME_FORMAT,
1391       GST_TIME_ARGS (ts));
1392 
<span class="line-added">1393   if (is_subframe &amp;&amp; priv-&gt;frames.length == 0)</span>
<span class="line-added">1394     goto subframe_without_pending_input_frame;</span>
<span class="line-added">1395 </span>
<span class="line-added">1396   /* this will be skipped in the is_subframe case because frames will be 0 */</span>
1397   while (priv-&gt;frames.length &amp;&amp; frames) {
1398     g_queue_push_tail (&amp;inbufs, g_queue_pop_head (&amp;priv-&gt;frames));
1399     dec-&gt;priv-&gt;ctx.delay = dec-&gt;priv-&gt;frames.length;
1400     frames--;
1401   }
1402 
1403   if (G_UNLIKELY (!buf))
1404     goto exit;
1405 
1406   /* lock on */
1407   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts))) {
1408     priv-&gt;base_ts = ts;
1409     GST_DEBUG_OBJECT (dec, &quot;base_ts now %&quot; GST_TIME_FORMAT, GST_TIME_ARGS (ts));
1410   }
1411 
1412   /* still no valid ts, track the segment one */
1413   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts)) &amp;&amp;
1414       dec-&gt;output_segment.rate &gt; 0.0) {
1415     priv-&gt;base_ts = dec-&gt;output_segment.start;
1416   }
1417 
<span class="line-modified">1418   /* only check for resync at the beginning of an input/output frame */</span>
<span class="line-modified">1419   do_check_resync = !is_subframe || priv-&gt;subframe_samples == 0;</span>
<span class="line-added">1420 </span>
<span class="line-added">1421   /* slightly convoluted approach caters for perfect ts if subclass desires. */</span>
<span class="line-added">1422   if (do_check_resync &amp;&amp; GST_CLOCK_TIME_IS_VALID (ts)) {</span>
1423     if (dec-&gt;priv-&gt;tolerance &gt; 0) {
1424       GstClockTimeDiff diff;
1425 
1426       g_assert (GST_CLOCK_TIME_IS_VALID (priv-&gt;base_ts));
1427       next_ts = priv-&gt;base_ts +
1428           gst_util_uint64_scale (priv-&gt;samples, GST_SECOND, ctx-&gt;info.rate);
1429       GST_LOG_OBJECT (dec,
1430           &quot;buffer is %&quot; G_GUINT64_FORMAT &quot; samples past base_ts %&quot;
1431           GST_TIME_FORMAT &quot;, expected ts %&quot; GST_TIME_FORMAT, priv-&gt;samples,
1432           GST_TIME_ARGS (priv-&gt;base_ts), GST_TIME_ARGS (next_ts));
1433       diff = GST_CLOCK_DIFF (next_ts, ts);
1434       GST_LOG_OBJECT (dec, &quot;ts diff %d ms&quot;, (gint) (diff / GST_MSECOND));
1435       /* if within tolerance,
1436        * discard buffer ts and carry on producing perfect stream,
1437        * otherwise resync to ts */
1438       if (G_UNLIKELY (diff &lt; (gint64) - dec-&gt;priv-&gt;tolerance ||
1439               diff &gt; (gint64) dec-&gt;priv-&gt;tolerance)) {
1440         GST_DEBUG_OBJECT (dec, &quot;base_ts resync&quot;);
1441         priv-&gt;base_ts = ts;
1442         priv-&gt;samples = 0;
</pre>
<hr />
<pre>
1467         GST_FRAMES_TO_CLOCK_TIME (priv-&gt;samples, ctx-&gt;info.rate);
1468     GST_BUFFER_DURATION (buf) = priv-&gt;base_ts +
1469         GST_FRAMES_TO_CLOCK_TIME (priv-&gt;samples + samples, ctx-&gt;info.rate) -
1470         GST_BUFFER_TIMESTAMP (buf);
1471   } else {
1472     GST_BUFFER_TIMESTAMP (buf) = GST_CLOCK_TIME_NONE;
1473     GST_BUFFER_DURATION (buf) =
1474         GST_FRAMES_TO_CLOCK_TIME (samples, ctx-&gt;info.rate);
1475   }
1476 
1477   if (klass-&gt;transform_meta) {
1478     if (inbufs.length) {
1479       GList *l;
1480       for (l = inbufs.head; l; l = l-&gt;next) {
1481         CopyMetaData data;
1482 
1483         data.decoder = dec;
1484         data.outbuf = buf;
1485         gst_buffer_foreach_meta (l-&gt;data, foreach_metadata, &amp;data);
1486       }
<span class="line-added">1487     } else if (is_subframe) {</span>
<span class="line-added">1488       CopyMetaData data;</span>
<span class="line-added">1489       GstBuffer *in_buf;</span>
<span class="line-added">1490 </span>
<span class="line-added">1491       /* For subframes we assume a 1:N relationship for now, so we just take</span>
<span class="line-added">1492        * metas from the first pending input buf */</span>
<span class="line-added">1493       in_buf = g_queue_peek_head (&amp;priv-&gt;frames);</span>
<span class="line-added">1494       data.decoder = dec;</span>
<span class="line-added">1495       data.outbuf = buf;</span>
<span class="line-added">1496       gst_buffer_foreach_meta (in_buf, foreach_metadata, &amp;data);</span>
1497     } else {
1498       GST_WARNING_OBJECT (dec,
1499           &quot;Can&#39;t copy metadata because input buffers disappeared&quot;);
1500     }
1501   }
1502 
1503   GST_OBJECT_LOCK (dec);
1504   priv-&gt;samples += samples;
1505   priv-&gt;samples_out += samples;
1506   GST_OBJECT_UNLOCK (dec);
1507 
1508   /* we got data, so note things are looking up */
1509   if (G_UNLIKELY (dec-&gt;priv-&gt;error_count))
1510     dec-&gt;priv-&gt;error_count = 0;
1511 
1512   ret = gst_audio_decoder_output (dec, buf);
1513 
1514 exit:
1515   g_queue_foreach (&amp;inbufs, (GFunc) gst_buffer_unref, NULL);
1516   g_queue_clear (&amp;inbufs);
1517 
<span class="line-added">1518   if (is_subframe)</span>
<span class="line-added">1519     dec-&gt;priv-&gt;subframe_samples += samples;</span>
<span class="line-added">1520   else</span>
<span class="line-added">1521     dec-&gt;priv-&gt;subframe_samples = 0;</span>
<span class="line-added">1522 </span>
1523   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
1524 
1525   return ret;
1526 
1527   /* ERRORS */
1528 wrong_buffer:
1529   {
<span class="line-added">1530     /* arguably more of a programming error? */</span>
1531     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),
1532         (&quot;buffer size %&quot; G_GSIZE_FORMAT &quot; not a multiple of %d&quot;, size,
1533             ctx-&gt;info.bpf));
1534     gst_buffer_unref (buf);
1535     ret = GST_FLOW_ERROR;
1536     goto exit;
1537   }
<span class="line-added">1538 wrong_samples:</span>
<span class="line-added">1539   {</span>
<span class="line-added">1540     /* arguably more of a programming error? */</span>
<span class="line-added">1541     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),</span>
<span class="line-added">1542         (&quot;GstAudioMeta samples (%&quot; G_GSIZE_FORMAT &quot;) are inconsistent with &quot;</span>
<span class="line-added">1543             &quot;the buffer size and layout (size/bpf = %&quot; G_GSIZE_FORMAT &quot;)&quot;,</span>
<span class="line-added">1544             meta-&gt;samples, size / ctx-&gt;info.bpf));</span>
<span class="line-added">1545     gst_buffer_unref (buf);</span>
<span class="line-added">1546     ret = GST_FLOW_ERROR;</span>
<span class="line-added">1547     goto exit;</span>
<span class="line-added">1548   }</span>
<span class="line-added">1549 subframe_without_pending_input_frame:</span>
<span class="line-added">1550   {</span>
<span class="line-added">1551     /* arguably more of a programming error? */</span>
<span class="line-added">1552     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),</span>
<span class="line-added">1553         (&quot;Received decoded subframe, but no pending frame&quot;));</span>
<span class="line-added">1554     gst_buffer_unref (buf);</span>
<span class="line-added">1555     ret = GST_FLOW_ERROR;</span>
<span class="line-added">1556     goto exit;</span>
<span class="line-added">1557   }</span>
1558 }
1559 
1560 static GstFlowReturn
1561 gst_audio_decoder_handle_frame (GstAudioDecoder * dec,
1562     GstAudioDecoderClass * klass, GstBuffer * buffer)
1563 {
1564   /* Skip decoding and send a GAP instead if
1565    * GST_SEGMENT_FLAG_TRICKMODE_NO_AUDIO is set and we have timestamps
1566    * FIXME: We only do this for forward playback atm, because reverse
1567    * playback would require accumulating GAP events and pushing them
1568    * out in reverse order as for normal audio samples
1569    */
1570   if (G_UNLIKELY (dec-&gt;input_segment.rate &gt; 0.0
1571           &amp;&amp; dec-&gt;input_segment.flags &amp; GST_SEGMENT_FLAG_TRICKMODE_NO_AUDIO)) {
1572     if (buffer) {
1573       GstClockTime ts = GST_BUFFER_PTS (buffer);
1574       if (GST_CLOCK_TIME_IS_VALID (ts)) {
1575         GstEvent *event = gst_event_new_gap (ts, GST_BUFFER_DURATION (buffer));
1576 
1577         gst_buffer_unref (buffer);
</pre>
<hr />
<pre>
1713   /* ERRORS */
1714 parse_failed:
1715   {
1716     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL), (&quot;failed to parse stream&quot;));
1717     return GST_FLOW_ERROR;
1718   }
1719 }
1720 
1721 static GstFlowReturn
1722 gst_audio_decoder_drain (GstAudioDecoder * dec)
1723 {
1724   GstFlowReturn ret;
1725 
1726   if (dec-&gt;priv-&gt;drained &amp;&amp; !dec-&gt;priv-&gt;gather)
1727     return GST_FLOW_OK;
1728 
1729   /* Apply any pending events before draining, as that
1730    * may update the pending segment info */
1731   apply_pending_events (dec);
1732 
<span class="line-modified">1733   /* dispatch reverse pending buffers */</span>
<span class="line-modified">1734   /* chain eventually calls upon drain as well, but by that time</span>
<span class="line-modified">1735    * gather list should be clear, so ok ... */</span>
<span class="line-modified">1736   if (dec-&gt;output_segment.rate &lt; 0.0 &amp;&amp; dec-&gt;priv-&gt;gather)</span>
<span class="line-modified">1737     gst_audio_decoder_chain_reverse (dec, NULL);</span>
<span class="line-modified">1738   /* have subclass give all it can */</span>
<span class="line-modified">1739   ret = gst_audio_decoder_push_buffers (dec, TRUE);</span>
1740   if (ret != GST_FLOW_OK) {
1741     GST_WARNING_OBJECT (dec, &quot;audio decoder push buffers failed&quot;);
1742     goto drain_failed;
1743   }
<span class="line-modified">1744   /* ensure all output sent */</span>
<span class="line-modified">1745   ret = gst_audio_decoder_output (dec, NULL);</span>
1746   if (ret != GST_FLOW_OK)
1747     GST_WARNING_OBJECT (dec, &quot;audio decoder output failed&quot;);
1748 
1749 drain_failed:
<span class="line-modified">1750   /* everything should be away now */</span>
<span class="line-modified">1751   if (dec-&gt;priv-&gt;frames.length) {</span>
<span class="line-modified">1752     /* not fatal/impossible though if subclass/codec eats stuff */</span>
<span class="line-modified">1753     GST_WARNING_OBJECT (dec, &quot;still %d frames left after draining&quot;,</span>
<span class="line-modified">1754         dec-&gt;priv-&gt;frames.length);</span>
<span class="line-modified">1755     g_queue_foreach (&amp;dec-&gt;priv-&gt;frames, (GFunc) gst_buffer_unref, NULL);</span>
<span class="line-modified">1756     g_queue_clear (&amp;dec-&gt;priv-&gt;frames);</span>





1757   }
1758 
<span class="line-added">1759   /* discard (unparsed) leftover */</span>
<span class="line-added">1760   gst_adapter_clear (dec-&gt;priv-&gt;adapter);</span>
<span class="line-added">1761   return ret;</span>
<span class="line-added">1762 }</span>
<span class="line-added">1763 </span>
1764 /* hard == FLUSH, otherwise discont */
1765 static GstFlowReturn
1766 gst_audio_decoder_flush (GstAudioDecoder * dec, gboolean hard)
1767 {
1768   GstAudioDecoderClass *klass;
1769   GstFlowReturn ret = GST_FLOW_OK;
1770 
1771   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
1772 
1773   GST_LOG_OBJECT (dec, &quot;flush hard %d&quot;, hard);
1774 
1775   if (!hard) {
1776     ret = gst_audio_decoder_drain (dec);
1777   } else {
1778     gst_audio_decoder_clear_queues (dec);
1779     gst_segment_init (&amp;dec-&gt;input_segment, GST_FORMAT_TIME);
1780     gst_segment_init (&amp;dec-&gt;output_segment, GST_FORMAT_TIME);
1781     dec-&gt;priv-&gt;error_count = 0;
1782   }
1783   /* only bother subclass with flushing if known it is already alive
</pre>
<hr />
<pre>
2145 
2146     if (gst_structure_get_int (structure, &quot;channels&quot;, &amp;channels)) {
2147       for (i = 0; i &lt; caps_size; i++) {
2148         gst_structure_set (gst_caps_get_structure (caps, i), &quot;channels&quot;,
2149             G_TYPE_INT, channels, NULL);
2150       }
2151     }
2152 
2153     if (gst_structure_get (structure, &quot;channel-mask&quot;, GST_TYPE_BITMASK,
2154             &amp;channel_mask, NULL)) {
2155       for (i = 0; i &lt; caps_size; i++) {
2156         gst_structure_set (gst_caps_get_structure (caps, i), &quot;channel-mask&quot;,
2157             GST_TYPE_BITMASK, channel_mask, NULL);
2158       }
2159     }
2160   }
2161 
2162   for (i = 0; i &lt; caps_size; i++) {
2163     structure = gst_caps_get_structure (caps, i);
2164     if (gst_structure_has_field (structure, &quot;channels&quot;))
<span class="line-modified">2165       gst_structure_fixate_field_nearest_int (structure,</span>
<span class="line-modified">2166           &quot;channels&quot;, GST_AUDIO_DEF_CHANNELS);</span>
2167     else
2168       gst_structure_set (structure, &quot;channels&quot;, G_TYPE_INT,
2169           GST_AUDIO_DEF_CHANNELS, NULL);
2170     if (gst_structure_has_field (structure, &quot;rate&quot;))
<span class="line-modified">2171       gst_structure_fixate_field_nearest_int (structure,</span>
<span class="line-modified">2172           &quot;rate&quot;, GST_AUDIO_DEF_RATE);</span>
2173     else
2174       gst_structure_set (structure, &quot;rate&quot;, G_TYPE_INT, GST_AUDIO_DEF_RATE,
2175           NULL);
2176   }
2177   caps = gst_caps_fixate (caps);
2178   structure = gst_caps_get_structure (caps, 0);
2179 
2180   /* Need to add a channel-mask if channels &gt; 2 */
2181   gst_structure_get_int (structure, &quot;channels&quot;, &amp;channels);
2182   if (channels &gt; 2 &amp;&amp; !gst_structure_has_field (structure, &quot;channel-mask&quot;)) {
2183     channel_mask = gst_audio_channel_get_fallback_mask (channels);
2184     if (channel_mask != 0) {
2185       gst_structure_set (structure, &quot;channel-mask&quot;,
2186           GST_TYPE_BITMASK, channel_mask, NULL);
2187     } else {
2188       GST_WARNING_OBJECT (dec, &quot;No default channel-mask for %d channels&quot;,
2189           channels);
2190     }
2191   }
2192 
2193   if (!caps || !gst_audio_info_from_caps (&amp;info, caps))
2194     goto caps_error;
2195 
2196   GST_OBJECT_LOCK (dec);
2197   dec-&gt;priv-&gt;ctx.info = info;
<span class="line-added">2198   dec-&gt;priv-&gt;ctx.caps = caps;</span>
2199   GST_OBJECT_UNLOCK (dec);
2200 
2201   GST_INFO_OBJECT (dec,
2202       &quot;Chose default caps %&quot; GST_PTR_FORMAT &quot; for initial gap&quot;, caps);

2203 
2204   return TRUE;
2205 
2206 caps_error:
2207   {
2208     if (caps)
2209       gst_caps_unref (caps);
2210     return FALSE;
2211   }
2212 }
2213 
2214 static gboolean
2215 gst_audio_decoder_handle_gap (GstAudioDecoder * dec, GstEvent * event)
2216 {
2217   gboolean ret;
2218   GstClockTime timestamp, duration;
2219   gboolean needs_reconfigure = FALSE;
2220 
2221   /* Ensure we have caps first */
2222   GST_AUDIO_DECODER_STREAM_LOCK (dec);
2223   if (!GST_AUDIO_INFO_IS_VALID (&amp;dec-&gt;priv-&gt;ctx.info)) {
2224     if (!gst_audio_decoder_negotiate_default_caps (dec)) {
2225       GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2226       GST_ELEMENT_ERROR (dec, STREAM, FORMAT, (NULL),
2227           (&quot;Decoder output not negotiated before GAP event.&quot;));
<span class="line-added">2228       gst_event_unref (event);</span>
2229       return FALSE;
2230     }
2231     needs_reconfigure = TRUE;
2232   }
2233   needs_reconfigure = gst_pad_check_reconfigure (dec-&gt;srcpad)
2234       || needs_reconfigure;
2235   if (G_UNLIKELY (dec-&gt;priv-&gt;ctx.output_format_changed || needs_reconfigure)) {
2236     if (!gst_audio_decoder_negotiate_unlocked (dec)) {
2237       GST_WARNING_OBJECT (dec, &quot;Failed to negotiate with downstream&quot;);
2238       gst_pad_mark_reconfigure (dec-&gt;srcpad);
2239     }
2240   }
2241   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2242 
2243   gst_event_parse_gap (event, &amp;timestamp, &amp;duration);
2244 
2245   /* time progressed without data, see if we can fill the gap with
2246    * some concealment data */
2247   GST_DEBUG_OBJECT (dec,
2248       &quot;gap event: plc %d, do_plc %d, position %&quot; GST_TIME_FORMAT
</pre>
<hr />
<pre>
2257     /* hand subclass empty frame with duration that needs covering */
2258     buf = gst_buffer_new ();
2259     GST_BUFFER_TIMESTAMP (buf) = timestamp;
2260     GST_BUFFER_DURATION (buf) = duration;
2261     /* best effort, not much error handling */
2262     gst_audio_decoder_handle_frame (dec, klass, buf);
2263     ret = TRUE;
2264     dec-&gt;priv-&gt;expecting_discont_buf = TRUE;
2265     gst_event_unref (event);
2266   } else {
2267     GstFlowReturn flowret;
2268 
2269     /* sub-class doesn&#39;t know how to handle empty buffers,
2270      * so just try sending GAP downstream */
2271     flowret = check_pending_reconfigure (dec);
2272     if (flowret == GST_FLOW_OK) {
2273       send_pending_events (dec);
2274       ret = gst_audio_decoder_push_event (dec, event);
2275     } else {
2276       ret = FALSE;
<span class="line-added">2277       gst_event_unref (event);</span>
2278     }
2279   }
2280   return ret;
<span class="line-modified">2281 }</span>
2282 
2283 static GList *
2284 _flush_events (GstPad * pad, GList * events)
2285 {
2286   GList *tmp;
2287 
2288   for (tmp = events; tmp; tmp = tmp-&gt;next) {
2289     if (GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_EOS &amp;&amp;
2290         GST_EVENT_TYPE (tmp-&gt;data) != GST_EVENT_SEGMENT &amp;&amp;
2291         GST_EVENT_IS_STICKY (tmp-&gt;data)) {
2292       gst_pad_store_sticky_event (pad, GST_EVENT_CAST (tmp-&gt;data));
2293     }
2294     gst_event_unref (tmp-&gt;data);
2295   }
2296   g_list_free (events);
2297 
2298   return NULL;
2299 }
2300 
2301 static gboolean
</pre>
<hr />
<pre>
2349           GST_DEBUG_OBJECT (dec, &quot;converted to TIME start %&quot; GST_TIME_FORMAT,
2350               GST_TIME_ARGS (nstart));
2351           seg.format = GST_FORMAT_TIME;
2352           seg.start = nstart;
2353           seg.time = nstart;
2354           seg.stop = GST_CLOCK_TIME_NONE;
2355           /* replace event */
2356           gst_event_unref (event);
2357           event = gst_event_new_segment (&amp;seg);
2358         } else {
2359           GST_DEBUG_OBJECT (dec, &quot;unsupported format; ignoring&quot;);
2360           GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2361           gst_event_unref (event);
2362           ret = FALSE;
2363           break;
2364         }
2365       }
2366 
2367       /* prepare for next segment */
2368       /* Use the segment start as a base timestamp
<span class="line-modified">2369        * in case upstream does not come up with anything better</span>
<span class="line-modified">2370        * (e.g. upstream BYTE) */</span>
<span class="line-modified">2371       if (format != GST_FORMAT_TIME) {</span>
<span class="line-modified">2372         dec-&gt;priv-&gt;base_ts = seg.start;</span>
<span class="line-modified">2373         dec-&gt;priv-&gt;samples = 0;</span>
<span class="line-modified">2374       }</span>
2375 
2376       /* and follow along with segment */
2377       dec-&gt;priv-&gt;in_out_segment_sync = FALSE;
2378       dec-&gt;input_segment = seg;
2379       dec-&gt;priv-&gt;pending_events =
2380           g_list_append (dec-&gt;priv-&gt;pending_events, event);
2381       GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2382 
2383       ret = TRUE;
2384       break;
2385     }
2386     case GST_EVENT_GAP:
2387       ret = gst_audio_decoder_handle_gap (dec, event);
2388       break;
2389     case GST_EVENT_FLUSH_STOP:
2390       GST_AUDIO_DECODER_STREAM_LOCK (dec);
2391       /* prepare for fresh start */
2392       gst_audio_decoder_flush (dec, TRUE);
2393 
2394       dec-&gt;priv-&gt;pending_events = _flush_events (dec-&gt;srcpad,
</pre>
<hr />
<pre>
2443     {
2444       GstTagList *tags;
2445 
2446       gst_event_parse_tag (event, &amp;tags);
2447 
2448       if (gst_tag_list_get_scope (tags) == GST_TAG_SCOPE_STREAM) {
2449         GST_AUDIO_DECODER_STREAM_LOCK (dec);
2450         if (dec-&gt;priv-&gt;upstream_tags != tags) {
2451           if (dec-&gt;priv-&gt;upstream_tags)
2452             gst_tag_list_unref (dec-&gt;priv-&gt;upstream_tags);
2453           dec-&gt;priv-&gt;upstream_tags = gst_tag_list_ref (tags);
2454           GST_INFO_OBJECT (dec, &quot;upstream stream tags: %&quot; GST_PTR_FORMAT, tags);
2455         }
2456         gst_event_unref (event);
2457         event = gst_audio_decoder_create_merged_tags_event (dec);
2458         dec-&gt;priv-&gt;taglist_changed = FALSE;
2459         GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2460 
2461         /* No tags, go out of here instead of fall through */
2462         if (!event) {
<span class="line-modified">2463           ret = TRUE;</span>
<span class="line-modified">2464           break;</span>
<span class="line-modified">2465         }</span>
2466       }
2467 
2468       /* fall through */
2469     }
2470     default:
2471       if (!GST_EVENT_IS_SERIALIZED (event)) {
2472         ret =
2473             gst_pad_event_default (dec-&gt;sinkpad, GST_OBJECT_CAST (dec), event);
2474       } else {
2475         GST_DEBUG_OBJECT (dec, &quot;Enqueuing event %d, %s&quot;, GST_EVENT_TYPE (event),
2476             GST_EVENT_TYPE_NAME (event));
2477         GST_AUDIO_DECODER_STREAM_LOCK (dec);
2478         dec-&gt;priv-&gt;pending_events =
2479             g_list_append (dec-&gt;priv-&gt;pending_events, event);
2480         GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
2481         ret = TRUE;
2482       }
2483       break;
2484   }
2485   return ret;
</pre>
<hr />
<pre>
2713       GST_AUDIO_DECODER_SINK_PAD (decoder),
2714       GST_AUDIO_DECODER_SRC_PAD (decoder), caps, filter);
2715 }
2716 
2717 static GstCaps *
2718 gst_audio_decoder_sink_getcaps (GstAudioDecoder * decoder, GstCaps * filter)
2719 {
2720   GstAudioDecoderClass *klass;
2721   GstCaps *caps;
2722 
2723   klass = GST_AUDIO_DECODER_GET_CLASS (decoder);
2724 
2725   if (klass-&gt;getcaps)
2726     caps = klass-&gt;getcaps (decoder, filter);
2727   else
2728     caps = gst_audio_decoder_proxy_getcaps (decoder, NULL, filter);
2729 
2730   GST_LOG_OBJECT (decoder, &quot;Returning caps %&quot; GST_PTR_FORMAT, caps);
2731 
2732   return caps;
<span class="line-modified">2733 }</span>
2734 
2735 static gboolean
2736 gst_audio_decoder_sink_query_default (GstAudioDecoder * dec, GstQuery * query)
2737 {
2738   GstPad *pad = GST_AUDIO_DECODER_SINK_PAD (dec);
2739   gboolean res = FALSE;
2740 
2741   GST_LOG_OBJECT (dec, &quot;handling query: %&quot; GST_PTR_FORMAT, query);
2742 
2743   switch (GST_QUERY_TYPE (query)) {
2744     case GST_QUERY_FORMATS:
2745     {
2746       gst_query_set_formats (query, 2, GST_FORMAT_TIME, GST_FORMAT_BYTES);
2747       res = TRUE;
2748       break;
2749     }
2750     case GST_QUERY_CONVERT:
2751     {
2752       GstFormat src_fmt, dest_fmt;
2753       gint64 src_val, dest_val;
2754 
2755       gst_query_parse_convert (query, &amp;src_fmt, &amp;src_val, &amp;dest_fmt, &amp;dest_val);
2756       GST_OBJECT_LOCK (dec);
2757       res = __gst_audio_encoded_audio_convert (&amp;dec-&gt;priv-&gt;ctx.info,
<span class="line-modified">2758           dec-&gt;priv-&gt;bytes_in, dec-&gt;priv-&gt;samples_out,</span>
2759           src_fmt, src_val, &amp;dest_fmt, &amp;dest_val);
2760       GST_OBJECT_UNLOCK (dec);
2761       if (!res)
2762         goto error;
2763       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
2764       break;
2765     }
2766     case GST_QUERY_ALLOCATION:
2767     {
2768       GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
2769 
2770       if (klass-&gt;propose_allocation)
2771         res = klass-&gt;propose_allocation (dec, query);
2772       break;
2773     }
2774     case GST_QUERY_CAPS:{
2775       GstCaps *filter, *caps;
2776 
2777       gst_query_parse_caps (query, &amp;filter);
2778       caps = gst_audio_decoder_sink_getcaps (dec, filter);
</pre>
<hr />
<pre>
2950           src_fmt, src_val, dest_fmt, &amp;dest_val);
2951       GST_OBJECT_UNLOCK (dec);
2952       if (!res)
2953         break;
2954       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
2955       break;
2956     }
2957     case GST_QUERY_LATENCY:
2958     {
2959       if ((res = gst_pad_peer_query (dec-&gt;sinkpad, query))) {
2960         gboolean live;
2961         GstClockTime min_latency, max_latency;
2962 
2963         gst_query_parse_latency (query, &amp;live, &amp;min_latency, &amp;max_latency);
2964         GST_DEBUG_OBJECT (dec, &quot;Peer latency: live %d, min %&quot;
2965             GST_TIME_FORMAT &quot; max %&quot; GST_TIME_FORMAT, live,
2966             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
2967 
2968         GST_OBJECT_LOCK (dec);
2969         /* add our latency */
<span class="line-modified">2970         min_latency += dec-&gt;priv-&gt;ctx.min_latency;</span>
2971         if (max_latency == -1 || dec-&gt;priv-&gt;ctx.max_latency == -1)
2972           max_latency = -1;
2973         else
2974           max_latency += dec-&gt;priv-&gt;ctx.max_latency;
2975         GST_OBJECT_UNLOCK (dec);
2976 
2977         gst_query_set_latency (query, live, min_latency, max_latency);
2978       }
2979       break;
2980     }
2981     default:
2982       res = gst_pad_query_default (pad, GST_OBJECT_CAST (dec), query);
2983       break;
2984   }
2985 
2986   return res;
2987 }
2988 
2989 static gboolean
2990 gst_audio_decoder_src_query (GstPad * pad, GstObject * parent, GstQuery * query)
</pre>
<hr />
<pre>
3644 gst_audio_decoder_merge_tags (GstAudioDecoder * dec,
3645     const GstTagList * tags, GstTagMergeMode mode)
3646 {
3647   g_return_if_fail (GST_IS_AUDIO_DECODER (dec));
3648   g_return_if_fail (tags == NULL || GST_IS_TAG_LIST (tags));
3649   g_return_if_fail (mode != GST_TAG_MERGE_UNDEFINED);
3650 
3651   GST_AUDIO_DECODER_STREAM_LOCK (dec);
3652   if (dec-&gt;priv-&gt;taglist != tags) {
3653     if (dec-&gt;priv-&gt;taglist) {
3654       gst_tag_list_unref (dec-&gt;priv-&gt;taglist);
3655       dec-&gt;priv-&gt;taglist = NULL;
3656       dec-&gt;priv-&gt;decoder_tags_merge_mode = GST_TAG_MERGE_KEEP_ALL;
3657     }
3658     if (tags) {
3659       dec-&gt;priv-&gt;taglist = gst_tag_list_ref ((GstTagList *) tags);
3660       dec-&gt;priv-&gt;decoder_tags_merge_mode = mode;
3661     }
3662 
3663     GST_DEBUG_OBJECT (dec, &quot;setting decoder tags to %&quot; GST_PTR_FORMAT, tags);
<span class="line-modified">3664     dec-&gt;priv-&gt;taglist_changed = TRUE;</span>
3665   }
3666   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3667 }
3668 
3669 /**
3670  * gst_audio_decoder_allocate_output_buffer:
3671  * @dec: a #GstAudioDecoder
3672  * @size: size of the buffer
3673  *
3674  * Helper function that allocates a buffer to hold an audio frame
3675  * for @dec&#39;s current output format.
3676  *
3677  * Returns: (transfer full): allocated buffer
3678  */
3679 GstBuffer *
3680 gst_audio_decoder_allocate_output_buffer (GstAudioDecoder * dec, gsize size)
3681 {
3682   GstBuffer *buffer = NULL;
3683   gboolean needs_reconfigure = FALSE;
3684 
</pre>
<hr />
<pre>
3706     GST_INFO_OBJECT (dec, &quot;couldn&#39;t allocate output buffer&quot;);
3707     goto fallback;
3708   }
3709 
3710   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3711 
3712   return buffer;
3713 fallback:
3714   buffer = gst_buffer_new_allocate (NULL, size, NULL);
3715   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
3716 
3717   return buffer;
3718 }
3719 
3720 /**
3721  * gst_audio_decoder_get_allocator:
3722  * @dec: a #GstAudioDecoder
3723  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
3724  * used
3725  * @params: (out) (allow-none) (transfer full): the
<span class="line-modified">3726  * #GstAllocationParams of @allocator</span>
3727  *
3728  * Lets #GstAudioDecoder sub-classes to know the memory @allocator
3729  * used by the base class and its @params.
3730  *
3731  * Unref the @allocator after use it.
3732  */
3733 void
3734 gst_audio_decoder_get_allocator (GstAudioDecoder * dec,
3735     GstAllocator ** allocator, GstAllocationParams * params)
3736 {
3737   g_return_if_fail (GST_IS_AUDIO_DECODER (dec));
3738 
3739   if (allocator)
3740     *allocator = dec-&gt;priv-&gt;ctx.allocator ?
3741         gst_object_ref (dec-&gt;priv-&gt;ctx.allocator) : NULL;
3742 
3743   if (params)
3744     *params = dec-&gt;priv-&gt;ctx.params;
3745 }
3746 
</pre>
</td>
</tr>
</table>
<center><a href="gstaudiobasesrc.c.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="gstaudiodecoder.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>