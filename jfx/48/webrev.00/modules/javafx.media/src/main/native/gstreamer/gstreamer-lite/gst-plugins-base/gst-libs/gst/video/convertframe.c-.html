<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/video/convertframe.c</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /* Small helper element for format conversion
  2  * Copyright (C) 2005 Tim-Philipp MÃ¼ller &lt;tim centricular net&gt;
  3  * Copyright (C) 2010 Brandon Lewis &lt;brandon.lewis@collabora.co.uk&gt;
  4  * Copyright (C) 2010 Edward Hervey &lt;edward.hervey@collabora.co.uk&gt;
  5  *
  6  * This library is free software; you can redistribute it and/or
  7  * modify it under the terms of the GNU Library General Public
  8  * License as published by the Free Software Foundation; either
  9  * version 2 of the License, or (at your option) any later version.
 10  *
 11  * This library is distributed in the hope that it will be useful,
 12  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  * Library General Public License for more details.
 15  *
 16  * You should have received a copy of the GNU Library General Public
 17  * License along with this library; if not, write to the
 18  * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
 19  * Boston, MA 02110-1301, USA.
 20  */
 21 
 22 #include &lt;string.h&gt;
 23 #include &quot;video.h&quot;
 24 
 25 static gboolean
 26 caps_are_raw (const GstCaps * caps)
 27 {
 28   guint i, len;
 29 
 30   len = gst_caps_get_size (caps);
 31 
 32   for (i = 0; i &lt; len; i++) {
 33     GstStructure *st = gst_caps_get_structure (caps, i);
 34     if (gst_structure_has_name (st, &quot;video/x-raw&quot;))
 35       return TRUE;
 36   }
 37 
 38   return FALSE;
 39 }
 40 
 41 static gboolean
 42 create_element (const gchar * factory_name, GstElement ** element,
 43     GError ** err)
 44 {
 45   *element = gst_element_factory_make (factory_name, NULL);
 46   if (*element)
 47     return TRUE;
 48 
 49   if (err &amp;&amp; *err == NULL) {
 50     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 51         &quot;cannot create element &#39;%s&#39; - please check your GStreamer installation&quot;,
 52         factory_name);
 53   }
 54 
 55   return FALSE;
 56 }
 57 
 58 static GstElement *
 59 get_encoder (const GstCaps * caps, GError ** err)
 60 {
 61   GList *encoders = NULL;
 62   GList *filtered = NULL;
 63   GstElementFactory *factory = NULL;
 64   GstElement *encoder = NULL;
 65 
 66   encoders =
 67       gst_element_factory_list_get_elements (GST_ELEMENT_FACTORY_TYPE_ENCODER |
 68       GST_ELEMENT_FACTORY_TYPE_MEDIA_IMAGE, GST_RANK_NONE);
 69 
 70   if (encoders == NULL) {
 71     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 72         &quot;Cannot find any image encoder&quot;);
 73     goto fail;
 74   }
 75 
 76   GST_INFO (&quot;got factory list %p&quot;, encoders);
 77   gst_plugin_feature_list_debug (encoders);
 78 
 79   filtered =
 80       gst_element_factory_list_filter (encoders, caps, GST_PAD_SRC, FALSE);
 81   GST_INFO (&quot;got filtered list %p&quot;, filtered);
 82 
 83   if (filtered == NULL) {
 84     gchar *tmp = gst_caps_to_string (caps);
 85     *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN,
 86         &quot;Cannot find any image encoder for caps %s&quot;, tmp);
 87     g_free (tmp);
 88     goto fail;
 89   }
 90 
 91   gst_plugin_feature_list_debug (filtered);
 92 
 93   factory = (GstElementFactory *) filtered-&gt;data;
 94 
 95   GST_INFO (&quot;got factory %p&quot;, factory);
 96   encoder = gst_element_factory_create (factory, NULL);
 97 
 98   GST_INFO (&quot;created encoder element %p, %s&quot;, encoder,
 99       GST_ELEMENT_NAME (encoder));
100 
101 fail:
102   if (encoders)
103     gst_plugin_feature_list_free (encoders);
104   if (filtered)
105     gst_plugin_feature_list_free (filtered);
106 
107   return encoder;
108 }
109 
110 static GstElement *
111 build_convert_frame_pipeline (GstElement ** src_element,
112     GstElement ** sink_element, const GstCaps * from_caps,
113     GstVideoCropMeta * cmeta, const GstCaps * to_caps, GError ** err)
114 {
115   GstElement *vcrop = NULL, *csp = NULL, *csp2 = NULL, *vscale = NULL;
116   GstElement *src = NULL, *sink = NULL, *encoder = NULL, *pipeline;
117   GstVideoInfo info;
118   GError *error = NULL;
119 
120   if (cmeta) {
121     if (!create_element (&quot;videocrop&quot;, &amp;vcrop, &amp;error)) {
122       g_error_free (error);
123       g_warning
124           (&quot;build_convert_frame_pipeline: Buffer has crop metadata but videocrop element is not found. Cropping will be disabled&quot;);
125     } else {
126       if (!create_element (&quot;videoconvert&quot;, &amp;csp2, &amp;error))
127         goto no_elements;
128     }
129   }
130 
131   /* videoscale is here to correct for the pixel-aspect-ratio for us */
132   GST_DEBUG (&quot;creating elements&quot;);
133   if (!create_element (&quot;appsrc&quot;, &amp;src, &amp;error) ||
134       !create_element (&quot;videoconvert&quot;, &amp;csp, &amp;error) ||
135       !create_element (&quot;videoscale&quot;, &amp;vscale, &amp;error) ||
136       !create_element (&quot;appsink&quot;, &amp;sink, &amp;error))
137     goto no_elements;
138 
139   pipeline = gst_pipeline_new (&quot;videoconvert-pipeline&quot;);
140   if (pipeline == NULL)
141     goto no_pipeline;
142 
143   /* Add black borders if necessary to keep the DAR */
144   g_object_set (vscale, &quot;add-borders&quot;, TRUE, NULL);
145 
146   GST_DEBUG (&quot;adding elements&quot;);
147   gst_bin_add_many (GST_BIN (pipeline), src, csp, vscale, sink, NULL);
148   if (vcrop)
149     gst_bin_add_many (GST_BIN (pipeline), vcrop, csp2, NULL);
150 
151   /* set caps */
152   g_object_set (src, &quot;caps&quot;, from_caps, NULL);
153   if (vcrop) {
154     gst_video_info_from_caps (&amp;info, from_caps);
155     g_object_set (vcrop, &quot;left&quot;, cmeta-&gt;x, NULL);
156     g_object_set (vcrop, &quot;top&quot;, cmeta-&gt;y, NULL);
157     g_object_set (vcrop, &quot;right&quot;, GST_VIDEO_INFO_WIDTH (&amp;info) - cmeta-&gt;width,
158         NULL);
159     g_object_set (vcrop, &quot;bottom&quot;,
160         GST_VIDEO_INFO_HEIGHT (&amp;info) - cmeta-&gt;height, NULL);
161     GST_DEBUG (&quot;crop meta [x,y,width,height]: %d %d %d %d&quot;, cmeta-&gt;x, cmeta-&gt;y,
162         cmeta-&gt;width, cmeta-&gt;height);
163   }
164   g_object_set (sink, &quot;caps&quot;, to_caps, NULL);
165 
166   /* FIXME: linking is still way too expensive, profile this properly */
167   if (vcrop) {
168     GST_DEBUG (&quot;linking src-&gt;csp2&quot;);
169     if (!gst_element_link_pads (src, &quot;src&quot;, csp2, &quot;sink&quot;))
170       goto link_failed;
171 
172     GST_DEBUG (&quot;linking csp2-&gt;vcrop&quot;);
173     if (!gst_element_link_pads (csp2, &quot;src&quot;, vcrop, &quot;sink&quot;))
174       goto link_failed;
175 
176     GST_DEBUG (&quot;linking vcrop-&gt;csp&quot;);
177     if (!gst_element_link_pads (vcrop, &quot;src&quot;, csp, &quot;sink&quot;))
178       goto link_failed;
179   } else {
180     GST_DEBUG (&quot;linking src-&gt;csp&quot;);
181     if (!gst_element_link_pads (src, &quot;src&quot;, csp, &quot;sink&quot;))
182       goto link_failed;
183   }
184 
185   GST_DEBUG (&quot;linking csp-&gt;vscale&quot;);
186   if (!gst_element_link_pads_full (csp, &quot;src&quot;, vscale, &quot;sink&quot;,
187           GST_PAD_LINK_CHECK_NOTHING))
188     goto link_failed;
189 
190   if (caps_are_raw (to_caps)) {
191     GST_DEBUG (&quot;linking vscale-&gt;sink&quot;);
192 
193     if (!gst_element_link_pads_full (vscale, &quot;src&quot;, sink, &quot;sink&quot;,
194             GST_PAD_LINK_CHECK_NOTHING))
195       goto link_failed;
196   } else {
197     encoder = get_encoder (to_caps, &amp;error);
198     if (!encoder)
199       goto no_encoder;
200     gst_bin_add (GST_BIN (pipeline), encoder);
201 
202     GST_DEBUG (&quot;linking vscale-&gt;encoder&quot;);
203     if (!gst_element_link (vscale, encoder))
204       goto link_failed;
205 
206     GST_DEBUG (&quot;linking encoder-&gt;sink&quot;);
207     if (!gst_element_link_pads (encoder, &quot;src&quot;, sink, &quot;sink&quot;))
208       goto link_failed;
209   }
210 
211   g_object_set (src, &quot;emit-signals&quot;, TRUE, NULL);
212   g_object_set (sink, &quot;emit-signals&quot;, TRUE, NULL);
213 
214   *src_element = src;
215   *sink_element = sink;
216 
217   return pipeline;
218   /* ERRORS */
219 no_encoder:
220   {
221     gst_object_unref (pipeline);
222 
223     GST_ERROR (&quot;could not find an encoder for provided caps&quot;);
224     if (err)
225       *err = error;
226     else
227       g_error_free (error);
228 
229     return NULL;
230   }
231 no_elements:
232   {
233     if (src)
234       gst_object_unref (src);
235     if (vcrop)
236       gst_object_unref (vcrop);
237     if (csp)
238       gst_object_unref (csp);
239     if (csp2)
240       gst_object_unref (csp2);
241     if (vscale)
242       gst_object_unref (vscale);
243     if (sink)
244       gst_object_unref (sink);
245     GST_ERROR (&quot;Could not convert video frame: %s&quot;, error-&gt;message);
246     if (err)
247       *err = error;
248     else
249       g_error_free (error);
250     return NULL;
251   }
252 no_pipeline:
253   {
254     gst_object_unref (src);
255     if (vcrop)
256       gst_object_unref (vcrop);
257     gst_object_unref (csp);
258     if (csp2)
259       gst_object_unref (csp2);
260     gst_object_unref (vscale);
261     gst_object_unref (sink);
262 
263     GST_ERROR (&quot;Could not convert video frame: no pipeline (unknown error)&quot;);
264     if (err)
265       *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
266           &quot;Could not convert video frame: no pipeline (unknown error)&quot;);
267     return NULL;
268   }
269 link_failed:
270   {
271     gst_object_unref (pipeline);
272 
273     GST_ERROR (&quot;Could not convert video frame: failed to link elements&quot;);
274     if (err)
275       *err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_NEGOTIATION,
276           &quot;Could not convert video frame: failed to link elements&quot;);
277     return NULL;
278   }
279 }
280 
281 /**
282  * gst_video_convert_sample:
283  * @sample: a #GstSample
284  * @to_caps: the #GstCaps to convert to
285  * @timeout: the maximum amount of time allowed for the processing.
286  * @error: pointer to a #GError. Can be %NULL.
287  *
288  * Converts a raw video buffer into the specified output caps.
289  *
290  * The output caps can be any raw video formats or any image formats (jpeg, png, ...).
291  *
292  * The width, height and pixel-aspect-ratio can also be specified in the output caps.
293  *
294  * Returns: The converted #GstSample, or %NULL if an error happened (in which case @err
295  * will point to the #GError).
296  */
297 GstSample *
298 gst_video_convert_sample (GstSample * sample, const GstCaps * to_caps,
299     GstClockTime timeout, GError ** error)
300 {
301   GstMessage *msg;
302   GstBuffer *buf;
303   GstSample *result = NULL;
304   GError *err = NULL;
305   GstBus *bus;
306   GstCaps *from_caps, *to_caps_copy = NULL;
307   GstFlowReturn ret;
308   GstElement *pipeline, *src, *sink;
309   guint i, n;
310 
311   g_return_val_if_fail (sample != NULL, NULL);
312   g_return_val_if_fail (to_caps != NULL, NULL);
313 
314   buf = gst_sample_get_buffer (sample);
315   g_return_val_if_fail (buf != NULL, NULL);
316 
317   from_caps = gst_sample_get_caps (sample);
318   g_return_val_if_fail (from_caps != NULL, NULL);
319 
320 
321   to_caps_copy = gst_caps_new_empty ();
322   n = gst_caps_get_size (to_caps);
323   for (i = 0; i &lt; n; i++) {
324     GstStructure *s = gst_caps_get_structure (to_caps, i);
325 
326     s = gst_structure_copy (s);
327     gst_structure_remove_field (s, &quot;framerate&quot;);
328     gst_caps_append_structure (to_caps_copy, s);
329   }
330 
331   pipeline =
332       build_convert_frame_pipeline (&amp;src, &amp;sink, from_caps,
333       gst_buffer_get_video_crop_meta (buf), to_caps_copy, &amp;err);
334   if (!pipeline)
335     goto no_pipeline;
336 
337   /* now set the pipeline to the paused state, after we push the buffer into
338    * appsrc, this should preroll the converted buffer in appsink */
339   GST_DEBUG (&quot;running conversion pipeline to caps %&quot; GST_PTR_FORMAT,
340       to_caps_copy);
341   gst_element_set_state (pipeline, GST_STATE_PAUSED);
342 
343   /* feed buffer in appsrc */
344   GST_DEBUG (&quot;feeding buffer %p, size %&quot; G_GSIZE_FORMAT &quot;, caps %&quot;
345       GST_PTR_FORMAT, buf, gst_buffer_get_size (buf), from_caps);
346   g_signal_emit_by_name (src, &quot;push-buffer&quot;, buf, &amp;ret);
347 
348   /* now see what happens. We either got an error somewhere or the pipeline
349    * prerolled */
350   bus = gst_element_get_bus (pipeline);
351   msg = gst_bus_timed_pop_filtered (bus,
352       timeout, GST_MESSAGE_ERROR | GST_MESSAGE_ASYNC_DONE);
353 
354   if (msg) {
355     switch (GST_MESSAGE_TYPE (msg)) {
356       case GST_MESSAGE_ASYNC_DONE:
357       {
358         /* we&#39;re prerolled, get the frame from appsink */
359         g_signal_emit_by_name (sink, &quot;pull-preroll&quot;, &amp;result);
360 
361         if (result) {
362           GST_DEBUG (&quot;conversion successful: result = %p&quot;, result);
363         } else {
364           GST_ERROR (&quot;prerolled but no result frame?!&quot;);
365         }
366         break;
367       }
368       case GST_MESSAGE_ERROR:{
369         gchar *dbg = NULL;
370 
371         gst_message_parse_error (msg, &amp;err, &amp;dbg);
372         if (err) {
373           GST_ERROR (&quot;Could not convert video frame: %s&quot;, err-&gt;message);
374           GST_DEBUG (&quot;%s [debug: %s]&quot;, err-&gt;message, GST_STR_NULL (dbg));
375           if (error)
376             *error = err;
377           else
378             g_error_free (err);
379         }
380         g_free (dbg);
381         break;
382       }
383       default:{
384         g_return_val_if_reached (NULL);
385       }
386     }
387     gst_message_unref (msg);
388   } else {
389     GST_ERROR (&quot;Could not convert video frame: timeout during conversion&quot;);
390     if (error)
391       *error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
392           &quot;Could not convert video frame: timeout during conversion&quot;);
393   }
394 
395   gst_element_set_state (pipeline, GST_STATE_NULL);
396   gst_object_unref (bus);
397   gst_object_unref (pipeline);
398   gst_caps_unref (to_caps_copy);
399 
400   return result;
401 
402   /* ERRORS */
403 no_pipeline:
404   {
405     gst_caps_unref (to_caps_copy);
406 
407     if (error)
408       *error = err;
409     else
410       g_error_free (err);
411 
412     return NULL;
413   }
414 }
415 
416 typedef struct
417 {
418   GMutex mutex;
419   GstElement *pipeline;
420   GstVideoConvertSampleCallback callback;
421   gpointer user_data;
422   GDestroyNotify destroy_notify;
423   GMainContext *context;
424   GstSample *sample;
425   //GstBuffer *buffer;
426   GSource *timeout_source;
427   gboolean finished;
428 } GstVideoConvertSampleContext;
429 
430 typedef struct
431 {
432   GstVideoConvertSampleCallback callback;
433   GstSample *sample;
434   //GstBuffer *buffer;
435   GError *error;
436   gpointer user_data;
437   GDestroyNotify destroy_notify;
438 
439   GstVideoConvertSampleContext *context;
440 } GstVideoConvertSampleCallbackContext;
441 
442 static void
443 gst_video_convert_frame_context_free (GstVideoConvertSampleContext * ctx)
444 {
445   /* Wait until all users of the mutex are done */
446   g_mutex_lock (&amp;ctx-&gt;mutex);
447   g_mutex_unlock (&amp;ctx-&gt;mutex);
448   g_mutex_clear (&amp;ctx-&gt;mutex);
449   if (ctx-&gt;timeout_source)
450     g_source_destroy (ctx-&gt;timeout_source);
451   //if (ctx-&gt;buffer)
452   //  gst_buffer_unref (ctx-&gt;buffer);
453   if (ctx-&gt;sample)
454     gst_sample_unref (ctx-&gt;sample);
455   g_main_context_unref (ctx-&gt;context);
456 
457   gst_element_set_state (ctx-&gt;pipeline, GST_STATE_NULL);
458   gst_object_unref (ctx-&gt;pipeline);
459 
460   g_slice_free (GstVideoConvertSampleContext, ctx);
461 }
462 
463 static void
464     gst_video_convert_frame_callback_context_free
465     (GstVideoConvertSampleCallbackContext * ctx)
466 {
467   if (ctx-&gt;context)
468     gst_video_convert_frame_context_free (ctx-&gt;context);
469   g_slice_free (GstVideoConvertSampleCallbackContext, ctx);
470 }
471 
472 static gboolean
473 convert_frame_dispatch_callback (GstVideoConvertSampleCallbackContext * ctx)
474 {
475   ctx-&gt;callback (ctx-&gt;sample, ctx-&gt;error, ctx-&gt;user_data);
476 
477   if (ctx-&gt;destroy_notify)
478     ctx-&gt;destroy_notify (ctx-&gt;user_data);
479 
480   return FALSE;
481 }
482 
483 static void
484 convert_frame_finish (GstVideoConvertSampleContext * context,
485     GstSample * sample, GError * error)
486 {
487   GSource *source;
488   GstVideoConvertSampleCallbackContext *ctx;
489 
490   if (context-&gt;timeout_source)
491     g_source_destroy (context-&gt;timeout_source);
492   context-&gt;timeout_source = NULL;
493 
494   ctx = g_slice_new (GstVideoConvertSampleCallbackContext);
495   ctx-&gt;callback = context-&gt;callback;
496   ctx-&gt;user_data = context-&gt;user_data;
497   ctx-&gt;destroy_notify = context-&gt;destroy_notify;
498   ctx-&gt;sample = sample;
499   //ctx-&gt;buffer = buffer;
500   ctx-&gt;error = error;
501   ctx-&gt;context = context;
502 
503   source = g_timeout_source_new (0);
504   g_source_set_callback (source,
505       (GSourceFunc) convert_frame_dispatch_callback, ctx,
506       (GDestroyNotify) gst_video_convert_frame_callback_context_free);
507   g_source_attach (source, context-&gt;context);
508   g_source_unref (source);
509 
510   context-&gt;finished = TRUE;
511 }
512 
513 static gboolean
514 convert_frame_timeout_callback (GstVideoConvertSampleContext * context)
515 {
516   GError *error;
517 
518   g_mutex_lock (&amp;context-&gt;mutex);
519 
520   if (context-&gt;finished)
521     goto done;
522 
523   GST_ERROR (&quot;Could not convert video frame: timeout&quot;);
524 
525   error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
526       &quot;Could not convert video frame: timeout&quot;);
527 
528   convert_frame_finish (context, NULL, error);
529 
530 done:
531   g_mutex_unlock (&amp;context-&gt;mutex);
532   return FALSE;
533 }
534 
535 static gboolean
536 convert_frame_bus_callback (GstBus * bus, GstMessage * message,
537     GstVideoConvertSampleContext * context)
538 {
539   g_mutex_lock (&amp;context-&gt;mutex);
540 
541   if (context-&gt;finished)
542     goto done;
543 
544   switch (GST_MESSAGE_TYPE (message)) {
545     case GST_MESSAGE_ERROR:{
546       GError *error;
547       gchar *dbg = NULL;
548 
549       gst_message_parse_error (message, &amp;error, &amp;dbg);
550 
551       GST_ERROR (&quot;Could not convert video frame: %s&quot;, error-&gt;message);
552       GST_DEBUG (&quot;%s [debug: %s]&quot;, error-&gt;message, GST_STR_NULL (dbg));
553 
554       convert_frame_finish (context, NULL, error);
555 
556       g_free (dbg);
557       break;
558     }
559     default:
560       break;
561   }
562 
563 done:
564   g_mutex_unlock (&amp;context-&gt;mutex);
565 
566   return FALSE;
567 }
568 
569 static void
570 convert_frame_need_data_callback (GstElement * src, guint size,
571     GstVideoConvertSampleContext * context)
572 {
573   GstFlowReturn ret = GST_FLOW_ERROR;
574   GError *error;
575   GstBuffer *buffer;
576 
577   g_mutex_lock (&amp;context-&gt;mutex);
578 
579   if (context-&gt;finished)
580     goto done;
581 
582   buffer = gst_sample_get_buffer (context-&gt;sample);
583   g_signal_emit_by_name (src, &quot;push-buffer&quot;, buffer, &amp;ret);
584   gst_sample_unref (context-&gt;sample);
585   context-&gt;sample = NULL;
586 
587   if (ret != GST_FLOW_OK) {
588     GST_ERROR (&quot;Could not push video frame: %s&quot;, gst_flow_get_name (ret));
589 
590     error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
591         &quot;Could not push video frame: %s&quot;, gst_flow_get_name (ret));
592 
593     convert_frame_finish (context, NULL, error);
594   }
595 
596   g_signal_handlers_disconnect_by_func (src, convert_frame_need_data_callback,
597       context);
598 
599 done:
600   g_mutex_unlock (&amp;context-&gt;mutex);
601 }
602 
603 static GstFlowReturn
604 convert_frame_new_preroll_callback (GstElement * sink,
605     GstVideoConvertSampleContext * context)
606 {
607   GstSample *sample = NULL;
608   GError *error = NULL;
609 
610   g_mutex_lock (&amp;context-&gt;mutex);
611 
612   if (context-&gt;finished)
613     goto done;
614 
615   g_signal_emit_by_name (sink, &quot;pull-preroll&quot;, &amp;sample);
616 
617   if (!sample) {
618     error = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_FAILED,
619         &quot;Could not get converted video sample&quot;);
620   }
621   convert_frame_finish (context, sample, error);
622 
623   g_signal_handlers_disconnect_by_func (sink, convert_frame_need_data_callback,
624       context);
625 
626 done:
627   g_mutex_unlock (&amp;context-&gt;mutex);
628 
629   return GST_FLOW_OK;
630 }
631 
632 /**
633  * gst_video_convert_sample_async:
634  * @sample: a #GstSample
635  * @to_caps: the #GstCaps to convert to
636  * @timeout: the maximum amount of time allowed for the processing.
637  * @callback: %GstVideoConvertSampleCallback that will be called after conversion.
638  * @user_data: extra data that will be passed to the @callback
639  * @destroy_notify: %GDestroyNotify to be called after @user_data is not needed anymore
640  *
641  * Converts a raw video buffer into the specified output caps.
642  *
643  * The output caps can be any raw video formats or any image formats (jpeg, png, ...).
644  *
645  * The width, height and pixel-aspect-ratio can also be specified in the output caps.
646  *
647  * @callback will be called after conversion, when an error occured or if conversion didn&#39;t
648  * finish after @timeout. @callback will always be called from the thread default
649  * %GMainContext, see g_main_context_get_thread_default(). If GLib before 2.22 is used,
650  * this will always be the global default main context.
651  *
652  * @destroy_notify will be called after the callback was called and @user_data is not needed
653  * anymore.
654  */
655 void
656 gst_video_convert_sample_async (GstSample * sample,
657     const GstCaps * to_caps, GstClockTime timeout,
658     GstVideoConvertSampleCallback callback, gpointer user_data,
659     GDestroyNotify destroy_notify)
660 {
661   GMainContext *context = NULL;
662   GError *error = NULL;
663   GstBus *bus;
664   GstBuffer *buf;
665   GstCaps *from_caps, *to_caps_copy = NULL;
666   GstElement *pipeline, *src, *sink;
667   guint i, n;
668   GSource *source;
669   GstVideoConvertSampleContext *ctx;
670 
671   g_return_if_fail (sample != NULL);
672   buf = gst_sample_get_buffer (sample);
673   g_return_if_fail (buf != NULL);
674 
675   g_return_if_fail (to_caps != NULL);
676 
677   from_caps = gst_sample_get_caps (sample);
678   g_return_if_fail (from_caps != NULL);
679   g_return_if_fail (callback != NULL);
680 
681   context = g_main_context_get_thread_default ();
682 
683   if (!context)
684     context = g_main_context_default ();
685 
686   to_caps_copy = gst_caps_new_empty ();
687   n = gst_caps_get_size (to_caps);
688   for (i = 0; i &lt; n; i++) {
689     GstStructure *s = gst_caps_get_structure (to_caps, i);
690 
691     s = gst_structure_copy (s);
692     gst_structure_remove_field (s, &quot;framerate&quot;);
693     gst_caps_append_structure (to_caps_copy, s);
694   }
695 
696   pipeline =
697       build_convert_frame_pipeline (&amp;src, &amp;sink, from_caps,
698       gst_buffer_get_video_crop_meta (buf), to_caps_copy, &amp;error);
699   if (!pipeline)
700     goto no_pipeline;
701 
702   bus = gst_element_get_bus (pipeline);
703 
704   ctx = g_slice_new0 (GstVideoConvertSampleContext);
705   g_mutex_init (&amp;ctx-&gt;mutex);
706   //ctx-&gt;buffer = gst_buffer_ref (buf);
707   ctx-&gt;sample = gst_sample_ref (sample);
708   ctx-&gt;callback = callback;
709   ctx-&gt;user_data = user_data;
710   ctx-&gt;destroy_notify = destroy_notify;
711   ctx-&gt;context = g_main_context_ref (context);
712   ctx-&gt;finished = FALSE;
713   ctx-&gt;pipeline = pipeline;
714 
715   if (timeout != GST_CLOCK_TIME_NONE) {
716     ctx-&gt;timeout_source = g_timeout_source_new (timeout / GST_MSECOND);
717     g_source_set_callback (ctx-&gt;timeout_source,
718         (GSourceFunc) convert_frame_timeout_callback, ctx, NULL);
719     g_source_attach (ctx-&gt;timeout_source, context);
720   }
721 
722   g_signal_connect (src, &quot;need-data&quot;,
723       G_CALLBACK (convert_frame_need_data_callback), ctx);
724   g_signal_connect (sink, &quot;new-preroll&quot;,
725       G_CALLBACK (convert_frame_new_preroll_callback), ctx);
726 
727   source = gst_bus_create_watch (bus);
728   g_source_set_callback (source, (GSourceFunc) convert_frame_bus_callback,
729       ctx, NULL);
730   g_source_attach (source, context);
731   g_source_unref (source);
732 
733   gst_element_set_state (pipeline, GST_STATE_PLAYING);
734 
735   gst_object_unref (bus);
736   gst_caps_unref (to_caps_copy);
737 
738   return;
739   /* ERRORS */
740 no_pipeline:
741   {
742     GstVideoConvertSampleCallbackContext *ctx;
743     GSource *source;
744 
745     gst_caps_unref (to_caps_copy);
746 
747     ctx = g_slice_new0 (GstVideoConvertSampleCallbackContext);
748     ctx-&gt;callback = callback;
749     ctx-&gt;user_data = user_data;
750     ctx-&gt;destroy_notify = destroy_notify;
751     ctx-&gt;sample = NULL;
752     ctx-&gt;error = error;
753 
754     source = g_timeout_source_new (0);
755     g_source_set_callback (source,
756         (GSourceFunc) convert_frame_dispatch_callback, ctx,
757         (GDestroyNotify) gst_video_convert_frame_callback_context_free);
758     g_source_attach (source, context);
759     g_source_unref (source);
760   }
761 }
    </pre>
  </body>
</html>