diff a/modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c b/modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c
--- a/modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c
+++ b/modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/gst-plugins-base/gst-libs/gst/audio/gstaudiodecoder.c
@@ -91,11 +91,14 @@
  * and upstream exceeds #GstAudioDecoder:tolerance, then resync to upstream
  * occurs (which would happen always if the tolerance mechanism is disabled).
  *
  * In non-live pipelines, baseclass can also (configurably) arrange for
  * output buffer aggregation which may help to redue large(r) numbers of
- * small(er) buffers being pushed and processed downstream.
+ * small(er) buffers being pushed and processed downstream. Note that this
+ * feature is only available if the buffer layout is interleaved. For planar
+ * buffers, the decoder implementation is fully responsible for the output
+ * buffer size.
  *
  * On the other hand, it should be noted that baseclass only provides limited
  * seeking support (upon explicit subclass request), as full-fledged support
  * should rather be left to upstream demuxer, parser or alike.  This simple
  * approach caters for seeking and duration reporting using estimated input
@@ -127,14 +130,10 @@
 #include <string.h>
 
 GST_DEBUG_CATEGORY (audiodecoder_debug);
 #define GST_CAT_DEFAULT audiodecoder_debug
 
-#define GST_AUDIO_DECODER_GET_PRIVATE(obj)  \
-    (G_TYPE_INSTANCE_GET_PRIVATE ((obj), GST_TYPE_AUDIO_DECODER, \
-        GstAudioDecoderPrivate))
-
 enum
 {
   LAST_SIGNAL
 };
 
@@ -157,10 +156,11 @@
   /* last negotiated input caps */
   GstCaps *input_caps;
 
   /* (output) audio format */
   GstAudioInfo info;
+  GstCaps *caps;
   gboolean output_format_changed;
 
   /* parsing state */
   gboolean eos;
   gboolean sync;
@@ -215,10 +215,12 @@
   /* input_segment are output_segment identical */
   gboolean in_out_segment_sync;
   /* expecting the buffer with DISCONT flag */
   gboolean expecting_discont_buf;
 
+  /* number of samples pushed out via _finish_subframe(), resets on _finish_frame() */
+  guint subframe_samples;
 
   /* input bps estimatation */
   /* global in bytes seen */
   guint64 bytes_in;
   /* global samples sent out */
@@ -309,11 +311,16 @@
     GstQuery * query);
 
 static gboolean gst_audio_decoder_transform_meta_default (GstAudioDecoder *
     decoder, GstBuffer * outbuf, GstMeta * meta, GstBuffer * inbuf);
 
+static GstFlowReturn
+gst_audio_decoder_finish_frame_or_subframe (GstAudioDecoder * dec,
+    GstBuffer * buf, gint frames);
+
 static GstElementClass *parent_class = NULL;
+static gint private_offset = 0;
 
 static void gst_audio_decoder_class_init (GstAudioDecoderClass * klass);
 static void gst_audio_decoder_init (GstAudioDecoder * dec,
     GstAudioDecoderClass * klass);
 
@@ -336,15 +343,24 @@
       (GInstanceInitFunc) gst_audio_decoder_init,
     };
 
     _type = g_type_register_static (GST_TYPE_ELEMENT,
         "GstAudioDecoder", &audio_decoder_info, G_TYPE_FLAG_ABSTRACT);
+
+    private_offset =
+        g_type_add_instance_private (_type, sizeof (GstAudioDecoderPrivate));
+
     g_once_init_leave (&audio_decoder_type, _type);
   }
   return audio_decoder_type;
 }
 
+static inline GstAudioDecoderPrivate *
+gst_audio_decoder_get_instance_private (GstAudioDecoder * self)
+{
+  return (G_STRUCT_MEMBER_P (self, private_offset));
+}
 
 static void
 gst_audio_decoder_class_init (GstAudioDecoderClass * klass)
 {
   GObjectClass *gobject_class;
@@ -355,11 +371,12 @@
   element_class = GST_ELEMENT_CLASS (klass);
   audiodecoder_class = GST_AUDIO_DECODER_CLASS (klass);
 
   parent_class = g_type_class_peek_parent (klass);
 
-  g_type_class_add_private (klass, sizeof (GstAudioDecoderPrivate));
+  if (private_offset != 0)
+    g_type_class_adjust_private_offset (klass, &private_offset);
 
   GST_DEBUG_CATEGORY_INIT (audiodecoder_debug, "audiodecoder", 0,
       "audio decoder base class");
 
   gobject_class->set_property = gst_audio_decoder_set_property;
@@ -410,11 +427,11 @@
 {
   GstPadTemplate *pad_template;
 
   GST_DEBUG_OBJECT (dec, "gst_audio_decoder_init");
 
-  dec->priv = GST_AUDIO_DECODER_GET_PRIVATE (dec);
+  dec->priv = gst_audio_decoder_get_instance_private (dec);
 
   /* Setup sink pad */
   pad_template =
       gst_element_class_get_pad_template (GST_ELEMENT_CLASS (klass), "sink");
   g_return_if_fail (pad_template != NULL);
@@ -501,10 +518,11 @@
     if (dec->priv->ctx.allocator)
       gst_object_unref (dec->priv->ctx.allocator);
 
     GST_OBJECT_LOCK (dec);
     gst_caps_replace (&dec->priv->ctx.input_caps, NULL);
+    gst_caps_replace (&dec->priv->ctx.caps, NULL);
     gst_caps_replace (&dec->priv->ctx.allocation_caps, NULL);
 
     memset (&dec->priv->ctx, 0, sizeof (dec->priv->ctx));
 
     gst_audio_info_init (&dec->priv->ctx.info);
@@ -613,14 +631,15 @@
   GstAllocator *allocator;
   GstAllocationParams params;
 
   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (&dec->priv->ctx.info), FALSE);
+  g_return_val_if_fail (GST_IS_CAPS (dec->priv->ctx.caps), FALSE);
 
   klass = GST_AUDIO_DECODER_GET_CLASS (dec);
 
-  caps = gst_audio_info_to_caps (&dec->priv->ctx.info);
+  caps = dec->priv->ctx.caps;
   if (dec->priv->ctx.allocation_caps == NULL)
     dec->priv->ctx.allocation_caps = gst_caps_ref (caps);
 
   GST_DEBUG_OBJECT (dec, "setting src caps %" GST_PTR_FORMAT, caps);
 
@@ -685,11 +704,10 @@
 
 done:
 
   if (query)
     gst_query_unref (query);
-  gst_caps_unref (caps);
 
   return res;
 
   /* ERRORS */
 no_decide_allocation:
@@ -755,25 +773,62 @@
 gboolean
 gst_audio_decoder_set_output_format (GstAudioDecoder * dec,
     const GstAudioInfo * info)
 {
   gboolean res = TRUE;
-  guint old_rate;
   GstCaps *caps = NULL;
-  GstCaps *templ_caps;
 
   g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
   g_return_val_if_fail (GST_AUDIO_INFO_IS_VALID (info), FALSE);
 
-  GST_DEBUG_OBJECT (dec, "Setting output format");
-
-  GST_AUDIO_DECODER_STREAM_LOCK (dec);
-
   /* If the audio info can't be converted to caps,
    * it was invalid */
   caps = gst_audio_info_to_caps (info);
-  if (!caps)
+  if (!caps) {
+    GST_WARNING_OBJECT (dec, "invalid output format");
+    return FALSE;
+  }
+
+  res = gst_audio_decoder_set_output_caps (dec, caps);
+  gst_caps_unref (caps);
+
+  return res;
+}
+
+/**
+ * gst_audio_decoder_set_output_caps:
+ * @dec: a #GstAudioDecoder
+ * @caps: (transfer none): (fixed) #GstCaps
+ *
+ * Configure output caps on the srcpad of @dec. Similar to
+ * gst_audio_decoder_set_output_format(), but allows subclasses to specify
+ * output caps that can't be expressed via #GstAudioInfo e.g. caps that have
+ * caps features.
+ *
+ * Returns: %TRUE on success.
+ *
+ * Since: 1.16
+ **/
+gboolean
+gst_audio_decoder_set_output_caps (GstAudioDecoder * dec, GstCaps * caps)
+{
+  gboolean res = TRUE;
+  guint old_rate;
+  GstCaps *templ_caps;
+  GstAudioInfo info;
+
+  g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), FALSE);
+
+  GST_DEBUG_OBJECT (dec, "Setting srcpad caps %" GST_PTR_FORMAT, caps);
+
+  GST_AUDIO_DECODER_STREAM_LOCK (dec);
+
+  if (!gst_caps_is_fixed (caps))
+    goto refuse_caps;
+
+  /* check if caps can be parsed */
+  if (!gst_audio_info_from_caps (&info, caps))
     goto refuse_caps;
 
   /* Only allow caps that are a subset of the template caps */
   templ_caps = gst_pad_get_pad_template_caps (dec->srcpad);
   if (!gst_caps_is_subset (caps, templ_caps)) {
@@ -792,20 +847,19 @@
     dec->priv->samples = 0;
   }
 
   /* copy the GstAudioInfo */
   GST_OBJECT_LOCK (dec);
-  dec->priv->ctx.info = *info;
+  dec->priv->ctx.info = info;
   GST_OBJECT_UNLOCK (dec);
+
+  gst_caps_replace (&dec->priv->ctx.caps, caps);
   dec->priv->ctx.output_format_changed = TRUE;
 
 done:
   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 
-  if (caps)
-    gst_caps_unref (caps);
-
   return res;
 
   /* ERRORS */
 refuse_caps:
   {
@@ -910,16 +964,16 @@
   if (G_UNLIKELY (!buf)) {
     GST_DEBUG_OBJECT (dec, "no data after clipping to segment");
     /* only check and return EOS if upstream still
      * in the same segment and interested as such */
     if (dec->priv->in_out_segment_sync) {
-    if (dec->output_segment.rate >= 0) {
-      if (ts >= dec->output_segment.stop)
+      if (dec->output_segment.rate >= 0) {
+        if (ts >= dec->output_segment.stop)
+          ret = GST_FLOW_EOS;
+      } else if (ts < dec->output_segment.start) {
         ret = GST_FLOW_EOS;
-    } else if (ts < dec->output_segment.start) {
-      ret = GST_FLOW_EOS;
-    }
+      }
     }
     goto exit;
   }
 
   /* decorate */
@@ -983,11 +1037,12 @@
         GST_TIME_ARGS (GST_BUFFER_DURATION (buf)));
   }
 
 again:
   inbuf = NULL;
-  if (priv->agg && dec->priv->latency > 0) {
+  if (priv->agg && dec->priv->latency > 0 &&
+      priv->ctx.info.layout == GST_AUDIO_LAYOUT_INTERLEAVED) {
     gint av;
     gboolean assemble = FALSE;
     const GstClockTimeDiff tol = 10 * GST_MSECOND;
     GstClockTimeDiff diff = -100 * GST_MSECOND;
 
@@ -1174,10 +1229,44 @@
         _gst_meta_transform_copy, &copy_data);
   }
   return TRUE;
 }
 
+/**
+ * gst_audio_decoder_finish_subframe:
+ * @dec: a #GstAudioDecoder
+ * @buf: decoded data
+ *
+ * Collects decoded data and pushes it downstream. This function may be called
+ * multiple times for a given input frame.
+ *
+ * @buf may be NULL in which case it is assumed that the current input frame is
+ * finished. This is equivalent to calling gst_audio_decoder_finish_subframe()
+ * with a NULL buffer and frames=1 after having pushed out all decoded audio
+ * subframes using this function.
+ *
+ * When called with valid data in @buf the source pad caps must have been set
+ * already.
+ *
+ * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be
+ * invalidated by a call to this function.
+ *
+ * Returns: a #GstFlowReturn that should be escalated to caller (of caller)
+ *
+ * Since: 1.16
+ */
+GstFlowReturn
+gst_audio_decoder_finish_subframe (GstAudioDecoder * dec, GstBuffer * buf)
+{
+  g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), GST_FLOW_ERROR);
+
+  if (buf == NULL)
+    return gst_audio_decoder_finish_frame_or_subframe (dec, NULL, 1);
+  else
+    return gst_audio_decoder_finish_frame_or_subframe (dec, buf, 0);
+}
+
 /**
  * gst_audio_decoder_finish_frame:
  * @dec: a #GstAudioDecoder
  * @buf: decoded data
  * @frames: number of decoded frames represented by decoded data
@@ -1188,66 +1277,92 @@
  * are discarded and considered to have produced no output
  * (e.g. lead-in or setup frames).
  * Otherwise, source pad caps must be set when it is called with valid
  * data in @buf.
  *
- * Note that a frame received in gst_audio_decoder_handle_frame() may be
+ * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be
  * invalidated by a call to this function.
  *
  * Returns: a #GstFlowReturn that should be escalated to caller (of caller)
  */
 GstFlowReturn
 gst_audio_decoder_finish_frame (GstAudioDecoder * dec, GstBuffer * buf,
     gint frames)
+{
+  g_return_val_if_fail (GST_IS_AUDIO_DECODER (dec), GST_FLOW_ERROR);
+
+  /* no dummy calls please */
+  g_return_val_if_fail (frames != 0, GST_FLOW_ERROR);
+
+  return gst_audio_decoder_finish_frame_or_subframe (dec, buf, frames);
+}
+
+/* frames == 0 indicates that this is a sub-frame and further sub-frames may
+ * follow for the current input frame. */
+static GstFlowReturn
+gst_audio_decoder_finish_frame_or_subframe (GstAudioDecoder * dec,
+    GstBuffer * buf, gint frames)
 {
   GstAudioDecoderPrivate *priv;
   GstAudioDecoderContext *ctx;
   GstAudioDecoderClass *klass = GST_AUDIO_DECODER_GET_CLASS (dec);
-  gint samples = 0;
+  GstAudioMeta *meta;
   GstClockTime ts, next_ts;
-  gsize size;
+  gsize size, samples = 0;
   GstFlowReturn ret = GST_FLOW_OK;
   GQueue inbufs = G_QUEUE_INIT;
+  gboolean is_subframe = (frames == 0);
+  gboolean do_check_resync;
 
   /* subclass should not hand us no data */
   g_return_val_if_fail (buf == NULL || gst_buffer_get_size (buf) > 0,
       GST_FLOW_ERROR);
-  /* no dummy calls please */
-  g_return_val_if_fail (frames != 0, GST_FLOW_ERROR);
+
+  /* if it's a subframe (frames == 0) we must have a valid buffer */
+  g_assert (!is_subframe || buf != NULL);
 
   priv = dec->priv;
   ctx = &dec->priv->ctx;
+  meta = buf ? gst_buffer_get_audio_meta (buf) : NULL;
   size = buf ? gst_buffer_get_size (buf) : 0;
+  samples = buf ? (meta ? meta->samples : size / ctx->info.bpf) : 0;
 
   /* must know the output format by now */
   g_return_val_if_fail (buf == NULL || GST_AUDIO_INFO_IS_VALID (&ctx->info),
       GST_FLOW_ERROR);
 
   GST_LOG_OBJECT (dec,
       "accepting %" G_GSIZE_FORMAT " bytes == %" G_GSIZE_FORMAT
-      " samples for %d frames", buf ? size : -1,
-      buf ? size / ctx->info.bpf : -1, frames);
+      " samples for %d frames", buf ? size : 0, samples, frames);
 
   GST_AUDIO_DECODER_STREAM_LOCK (dec);
 
-  if (buf) {
+  if (buf != NULL && priv->subframe_samples == 0) {
     ret = check_pending_reconfigure (dec);
     if (ret == GST_FLOW_FLUSHING || ret == GST_FLOW_NOT_NEGOTIATED) {
       gst_buffer_unref (buf);
       goto exit;
     }
 
     if (priv->pending_events)
       send_pending_events (dec);
   }
 
-  /* output shoud be whole number of sample frames */
+  /* sanity checking */
   if (G_LIKELY (buf && ctx->info.bpf)) {
-    if (size % ctx->info.bpf)
-      goto wrong_buffer;
-    /* per channel least */
-    samples = size / ctx->info.bpf;
+    if (!meta || meta->info.layout == GST_AUDIO_LAYOUT_INTERLEAVED) {
+      /* output shoud be whole number of sample frames */
+      if (size % ctx->info.bpf)
+        goto wrong_buffer;
+      /* output should have no additional padding */
+      if (samples != size / ctx->info.bpf)
+        goto wrong_samples;
+    } else {
+      /* can't have more samples than what the buffer fits */
+      if (samples > size / ctx->info.bpf)
+        goto wrong_samples;
+    }
   }
 
   /* frame and ts book-keeping */
   if (G_UNLIKELY (frames < 0)) {
     if (G_UNLIKELY (-frames - 1 > priv->frames.length)) {
@@ -1273,10 +1388,14 @@
     ts = GST_CLOCK_TIME_NONE;
 
   GST_DEBUG_OBJECT (dec, "leading frame ts %" GST_TIME_FORMAT,
       GST_TIME_ARGS (ts));
 
+  if (is_subframe && priv->frames.length == 0)
+    goto subframe_without_pending_input_frame;
+
+  /* this will be skipped in the is_subframe case because frames will be 0 */
   while (priv->frames.length && frames) {
     g_queue_push_tail (&inbufs, g_queue_pop_head (&priv->frames));
     dec->priv->ctx.delay = dec->priv->frames.length;
     frames--;
   }
@@ -1294,12 +1413,15 @@
   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (priv->base_ts)) &&
       dec->output_segment.rate > 0.0) {
     priv->base_ts = dec->output_segment.start;
   }
 
-  /* slightly convoluted approach caters for perfect ts if subclass desires */
-  if (GST_CLOCK_TIME_IS_VALID (ts)) {
+  /* only check for resync at the beginning of an input/output frame */
+  do_check_resync = !is_subframe || priv->subframe_samples == 0;
+
+  /* slightly convoluted approach caters for perfect ts if subclass desires. */
+  if (do_check_resync && GST_CLOCK_TIME_IS_VALID (ts)) {
     if (dec->priv->tolerance > 0) {
       GstClockTimeDiff diff;
 
       g_assert (GST_CLOCK_TIME_IS_VALID (priv->base_ts));
       next_ts = priv->base_ts +
@@ -1360,10 +1482,20 @@
 
         data.decoder = dec;
         data.outbuf = buf;
         gst_buffer_foreach_meta (l->data, foreach_metadata, &data);
       }
+    } else if (is_subframe) {
+      CopyMetaData data;
+      GstBuffer *in_buf;
+
+      /* For subframes we assume a 1:N relationship for now, so we just take
+       * metas from the first pending input buf */
+      in_buf = g_queue_peek_head (&priv->frames);
+      data.decoder = dec;
+      data.outbuf = buf;
+      gst_buffer_foreach_meta (in_buf, foreach_metadata, &data);
     } else {
       GST_WARNING_OBJECT (dec,
           "Can't copy metadata because input buffers disappeared");
     }
   }
@@ -1381,24 +1513,50 @@
 
 exit:
   g_queue_foreach (&inbufs, (GFunc) gst_buffer_unref, NULL);
   g_queue_clear (&inbufs);
 
+  if (is_subframe)
+    dec->priv->subframe_samples += samples;
+  else
+    dec->priv->subframe_samples = 0;
+
   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 
   return ret;
 
   /* ERRORS */
 wrong_buffer:
   {
+    /* arguably more of a programming error? */
     GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),
         ("buffer size %" G_GSIZE_FORMAT " not a multiple of %d", size,
             ctx->info.bpf));
     gst_buffer_unref (buf);
     ret = GST_FLOW_ERROR;
     goto exit;
   }
+wrong_samples:
+  {
+    /* arguably more of a programming error? */
+    GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),
+        ("GstAudioMeta samples (%" G_GSIZE_FORMAT ") are inconsistent with "
+            "the buffer size and layout (size/bpf = %" G_GSIZE_FORMAT ")",
+            meta->samples, size / ctx->info.bpf));
+    gst_buffer_unref (buf);
+    ret = GST_FLOW_ERROR;
+    goto exit;
+  }
+subframe_without_pending_input_frame:
+  {
+    /* arguably more of a programming error? */
+    GST_ELEMENT_ERROR (dec, STREAM, DECODE, (NULL),
+        ("Received decoded subframe, but no pending frame"));
+    gst_buffer_unref (buf);
+    ret = GST_FLOW_ERROR;
+    goto exit;
+  }
 }
 
 static GstFlowReturn
 gst_audio_decoder_handle_frame (GstAudioDecoder * dec,
     GstAudioDecoderClass * klass, GstBuffer * buffer)
@@ -1570,41 +1728,41 @@
 
   /* Apply any pending events before draining, as that
    * may update the pending segment info */
   apply_pending_events (dec);
 
-    /* dispatch reverse pending buffers */
-    /* chain eventually calls upon drain as well, but by that time
-     * gather list should be clear, so ok ... */
-    if (dec->output_segment.rate < 0.0 && dec->priv->gather)
-      gst_audio_decoder_chain_reverse (dec, NULL);
-    /* have subclass give all it can */
-    ret = gst_audio_decoder_push_buffers (dec, TRUE);
+  /* dispatch reverse pending buffers */
+  /* chain eventually calls upon drain as well, but by that time
+   * gather list should be clear, so ok ... */
+  if (dec->output_segment.rate < 0.0 && dec->priv->gather)
+    gst_audio_decoder_chain_reverse (dec, NULL);
+  /* have subclass give all it can */
+  ret = gst_audio_decoder_push_buffers (dec, TRUE);
   if (ret != GST_FLOW_OK) {
     GST_WARNING_OBJECT (dec, "audio decoder push buffers failed");
     goto drain_failed;
   }
-    /* ensure all output sent */
-    ret = gst_audio_decoder_output (dec, NULL);
+  /* ensure all output sent */
+  ret = gst_audio_decoder_output (dec, NULL);
   if (ret != GST_FLOW_OK)
     GST_WARNING_OBJECT (dec, "audio decoder output failed");
 
 drain_failed:
-    /* everything should be away now */
-    if (dec->priv->frames.length) {
-      /* not fatal/impossible though if subclass/codec eats stuff */
-      GST_WARNING_OBJECT (dec, "still %d frames left after draining",
-          dec->priv->frames.length);
-      g_queue_foreach (&dec->priv->frames, (GFunc) gst_buffer_unref, NULL);
-      g_queue_clear (&dec->priv->frames);
-    }
-
-    /* discard (unparsed) leftover */
-    gst_adapter_clear (dec->priv->adapter);
-    return ret;
+  /* everything should be away now */
+  if (dec->priv->frames.length) {
+    /* not fatal/impossible though if subclass/codec eats stuff */
+    GST_WARNING_OBJECT (dec, "still %d frames left after draining",
+        dec->priv->frames.length);
+    g_queue_foreach (&dec->priv->frames, (GFunc) gst_buffer_unref, NULL);
+    g_queue_clear (&dec->priv->frames);
   }
 
+  /* discard (unparsed) leftover */
+  gst_adapter_clear (dec->priv->adapter);
+  return ret;
+}
+
 /* hard == FLUSH, otherwise discont */
 static GstFlowReturn
 gst_audio_decoder_flush (GstAudioDecoder * dec, gboolean hard)
 {
   GstAudioDecoderClass *klass;
@@ -2002,18 +2160,18 @@
   }
 
   for (i = 0; i < caps_size; i++) {
     structure = gst_caps_get_structure (caps, i);
     if (gst_structure_has_field (structure, "channels"))
-    gst_structure_fixate_field_nearest_int (structure,
-        "channels", GST_AUDIO_DEF_CHANNELS);
+      gst_structure_fixate_field_nearest_int (structure,
+          "channels", GST_AUDIO_DEF_CHANNELS);
     else
       gst_structure_set (structure, "channels", G_TYPE_INT,
           GST_AUDIO_DEF_CHANNELS, NULL);
     if (gst_structure_has_field (structure, "rate"))
-    gst_structure_fixate_field_nearest_int (structure,
-        "rate", GST_AUDIO_DEF_RATE);
+      gst_structure_fixate_field_nearest_int (structure,
+          "rate", GST_AUDIO_DEF_RATE);
     else
       gst_structure_set (structure, "rate", G_TYPE_INT, GST_AUDIO_DEF_RATE,
           NULL);
   }
   caps = gst_caps_fixate (caps);
@@ -2035,15 +2193,15 @@
   if (!caps || !gst_audio_info_from_caps (&info, caps))
     goto caps_error;
 
   GST_OBJECT_LOCK (dec);
   dec->priv->ctx.info = info;
+  dec->priv->ctx.caps = caps;
   GST_OBJECT_UNLOCK (dec);
 
   GST_INFO_OBJECT (dec,
       "Chose default caps %" GST_PTR_FORMAT " for initial gap", caps);
-  gst_caps_unref (caps);
 
   return TRUE;
 
 caps_error:
   {
@@ -2065,10 +2223,11 @@
   if (!GST_AUDIO_INFO_IS_VALID (&dec->priv->ctx.info)) {
     if (!gst_audio_decoder_negotiate_default_caps (dec)) {
       GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
       GST_ELEMENT_ERROR (dec, STREAM, FORMAT, (NULL),
           ("Decoder output not negotiated before GAP event."));
+      gst_event_unref (event);
       return FALSE;
     }
     needs_reconfigure = TRUE;
   }
   needs_reconfigure = gst_pad_check_reconfigure (dec->srcpad)
@@ -2113,14 +2272,15 @@
     if (flowret == GST_FLOW_OK) {
       send_pending_events (dec);
       ret = gst_audio_decoder_push_event (dec, event);
     } else {
       ret = FALSE;
+      gst_event_unref (event);
     }
   }
   return ret;
-  }
+}
 
 static GList *
 _flush_events (GstPad * pad, GList * events)
 {
   GList *tmp;
@@ -2204,16 +2364,16 @@
         }
       }
 
       /* prepare for next segment */
       /* Use the segment start as a base timestamp
-         * in case upstream does not come up with anything better
-         * (e.g. upstream BYTE) */
-        if (format != GST_FORMAT_TIME) {
-          dec->priv->base_ts = seg.start;
-          dec->priv->samples = 0;
-        }
+       * in case upstream does not come up with anything better
+       * (e.g. upstream BYTE) */
+      if (format != GST_FORMAT_TIME) {
+        dec->priv->base_ts = seg.start;
+        dec->priv->samples = 0;
+      }
 
       /* and follow along with segment */
       dec->priv->in_out_segment_sync = FALSE;
       dec->input_segment = seg;
       dec->priv->pending_events =
@@ -2298,13 +2458,13 @@
         dec->priv->taglist_changed = FALSE;
         GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 
         /* No tags, go out of here instead of fall through */
         if (!event) {
-        ret = TRUE;
-        break;
-      }
+          ret = TRUE;
+          break;
+        }
       }
 
       /* fall through */
     }
     default:
@@ -2568,11 +2728,11 @@
     caps = gst_audio_decoder_proxy_getcaps (decoder, NULL, filter);
 
   GST_LOG_OBJECT (decoder, "Returning caps %" GST_PTR_FORMAT, caps);
 
   return caps;
-      }
+}
 
 static gboolean
 gst_audio_decoder_sink_query_default (GstAudioDecoder * dec, GstQuery * query)
 {
   GstPad *pad = GST_AUDIO_DECODER_SINK_PAD (dec);
@@ -2593,11 +2753,11 @@
       gint64 src_val, dest_val;
 
       gst_query_parse_convert (query, &src_fmt, &src_val, &dest_fmt, &dest_val);
       GST_OBJECT_LOCK (dec);
       res = __gst_audio_encoded_audio_convert (&dec->priv->ctx.info,
-                  dec->priv->bytes_in, dec->priv->samples_out,
+          dec->priv->bytes_in, dec->priv->samples_out,
           src_fmt, src_val, &dest_fmt, &dest_val);
       GST_OBJECT_UNLOCK (dec);
       if (!res)
         goto error;
       gst_query_set_convert (query, src_fmt, src_val, dest_fmt, dest_val);
@@ -2805,11 +2965,11 @@
             GST_TIME_FORMAT " max %" GST_TIME_FORMAT, live,
             GST_TIME_ARGS (min_latency), GST_TIME_ARGS (max_latency));
 
         GST_OBJECT_LOCK (dec);
         /* add our latency */
-          min_latency += dec->priv->ctx.min_latency;
+        min_latency += dec->priv->ctx.min_latency;
         if (max_latency == -1 || dec->priv->ctx.max_latency == -1)
           max_latency = -1;
         else
           max_latency += dec->priv->ctx.max_latency;
         GST_OBJECT_UNLOCK (dec);
@@ -3499,11 +3659,11 @@
       dec->priv->taglist = gst_tag_list_ref ((GstTagList *) tags);
       dec->priv->decoder_tags_merge_mode = mode;
     }
 
     GST_DEBUG_OBJECT (dec, "setting decoder tags to %" GST_PTR_FORMAT, tags);
-  dec->priv->taglist_changed = TRUE;
+    dec->priv->taglist_changed = TRUE;
   }
   GST_AUDIO_DECODER_STREAM_UNLOCK (dec);
 }
 
 /**
@@ -3561,11 +3721,11 @@
  * gst_audio_decoder_get_allocator:
  * @dec: a #GstAudioDecoder
  * @allocator: (out) (allow-none) (transfer full): the #GstAllocator
  * used
  * @params: (out) (allow-none) (transfer full): the
- * #GstAllocatorParams of @allocator
+ * #GstAllocationParams of @allocator
  *
  * Lets #GstAudioDecoder sub-classes to know the memory @allocator
  * used by the base class and its @params.
  *
  * Unref the @allocator after use it.
