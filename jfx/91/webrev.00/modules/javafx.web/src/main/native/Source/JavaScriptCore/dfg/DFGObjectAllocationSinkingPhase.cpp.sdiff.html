<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGObjectAllocationSinkingPhase.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGOSRExitPreparation.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOperations.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGObjectAllocationSinkingPhase.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 823     {
 824         m_heap.assertIsValid();
 825         ASSERT(m_heap.takeEscapees().isEmpty());
 826 
 827         Allocation* target = nullptr;
 828         HashMap&lt;PromotedLocationDescriptor, LazyNode&gt; writes;
 829         PromotedLocationDescriptor exactRead;
 830 
 831         switch (node-&gt;op()) {
 832         case NewObject:
 833             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Object);
 834             target-&gt;setStructures(node-&gt;structure());
 835             writes.add(
 836                 StructurePLoc, LazyNode(m_graph.freeze(node-&gt;structure().get())));
 837             break;
 838 
 839         case NewFunction:
 840         case NewGeneratorFunction:
 841         case NewAsyncGeneratorFunction:
 842         case NewAsyncFunction: {
<span class="line-modified"> 843             if (isStillValid(node-&gt;castOperand&lt;FunctionExecutable*&gt;()-&gt;singletonFunction())) {</span>
 844                 m_heap.escape(node-&gt;child1().node());
 845                 break;
 846             }
 847 
 848             if (node-&gt;op() == NewGeneratorFunction)
 849                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::GeneratorFunction);
 850             else if (node-&gt;op() == NewAsyncFunction)
 851                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncFunction);
 852             else if (node-&gt;op() == NewAsyncGeneratorFunction)
 853                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncGeneratorFunction);
 854             else
 855                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::Function);
 856 
 857             writes.add(FunctionExecutablePLoc, LazyNode(node-&gt;cellOperand()));
 858             writes.add(FunctionActivationPLoc, LazyNode(node-&gt;child1().node()));
 859             break;
 860         }
 861 
 862         case NewRegexp: {
 863             target = &amp;m_heap.newAllocation(node, Allocation::Kind::RegExpObject);
 864 
 865             writes.add(RegExpObjectRegExpPLoc, LazyNode(node-&gt;cellOperand()));
 866             writes.add(RegExpObjectLastIndexPLoc, LazyNode(node-&gt;child1().node()));
 867             break;
 868         }
 869 
 870         case CreateActivation: {
<span class="line-modified"> 871             if (isStillValid(node-&gt;castOperand&lt;SymbolTable*&gt;()-&gt;singletonScope())) {</span>
 872                 m_heap.escape(node-&gt;child1().node());
 873                 break;
 874             }
 875             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Activation);
 876             writes.add(ActivationSymbolTablePLoc, LazyNode(node-&gt;cellOperand()));
 877             writes.add(ActivationScopePLoc, LazyNode(node-&gt;child1().node()));
 878             {
 879                 SymbolTable* symbolTable = node-&gt;castOperand&lt;SymbolTable*&gt;();
 880                 LazyNode initialValue(m_graph.freeze(node-&gt;initializationValueForActivation()));
 881                 for (unsigned offset = 0; offset &lt; symbolTable-&gt;scopeSize(); ++offset) {
 882                     writes.add(
 883                         PromotedLocationDescriptor(ClosureVarPLoc, offset),
 884                         initialValue);
 885                 }
 886             }
 887             break;
 888         }
 889 
 890         case PutStructure:
 891             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
</pre>
<hr />
<pre>
1251                             escapingOnEdge.add(entry.key, entry.value);
1252                     }
1253                     callback(escapingOnEdge, block-&gt;terminal());
1254                 }
1255             }
1256         };
1257 
1258         if (m_sinkCandidates.size()) {
1259             // If we&#39;re moving an allocation to `where` in the program, we need to ensure
1260             // we can still walk the stack at that point in the program for the
1261             // InlineCallFrame of the original allocation. Certain InlineCallFrames rely on
1262             // data in the stack when taking a stack trace. All allocation sites can do a
1263             // stack walk (we do a stack walk when we GC). Conservatively, we say we&#39;re
1264             // still ok to move this allocation if we are moving within the same InlineCallFrame.
1265             // We could be more precise here and do an analysis of stack writes. However,
1266             // this scenario is so rare that we just take the conservative-and-straight-forward
1267             // approach of checking that we&#39;re in the same InlineCallFrame.
1268 
1269             forEachEscapee([&amp;] (HashMap&lt;Node*, Allocation&gt;&amp; escapees, Node* where) {
1270                 for (Node* allocation : escapees.keys()) {
<span class="line-modified">1271                     InlineCallFrame* inlineCallFrame = allocation-&gt;origin.semantic.inlineCallFrame;</span>
1272                     if (!inlineCallFrame)
1273                         continue;
<span class="line-modified">1274                     if ((inlineCallFrame-&gt;isClosureCall || inlineCallFrame-&gt;isVarargs()) &amp;&amp; inlineCallFrame != where-&gt;origin.semantic.inlineCallFrame)</span>
1275                         m_sinkCandidates.remove(allocation);
1276                 }
1277             });
1278         }
1279 
1280         // Ensure that the set of sink candidates is closed for put operations
1281         // This is (2) as described above.
1282         Vector&lt;Node*&gt; worklist;
1283         worklist.appendRange(m_sinkCandidates.begin(), m_sinkCandidates.end());
1284 
1285         while (!worklist.isEmpty()) {
1286             for (Node* identifier : dependencies.get(worklist.takeLast())) {
1287                 if (m_sinkCandidates.add(identifier).isNewEntry)
1288                     worklist.append(identifier);
1289             }
1290         }
1291 
1292         if (m_sinkCandidates.isEmpty())
1293             return hasUnescapedReads;
1294 
</pre>
<hr />
<pre>
2249         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2250             dataLog(&quot;Recovering &quot;, location, &quot; at &quot;, where, &quot;\n&quot;);
2251         ASSERT(location.base()-&gt;isPhantomAllocation());
2252         Node* base = getMaterialization(block, location.base());
2253         Node* value = resolve(block, location);
2254 
2255         NodeOrigin origin = where-&gt;origin.withSemantic(base-&gt;origin.semantic);
2256 
2257         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2258             dataLog(&quot;Base is &quot;, base, &quot; and value is &quot;, value, &quot;\n&quot;);
2259 
2260         if (base-&gt;isPhantomAllocation()) {
2261             return PromotedHeapLocation(base, location.descriptor()).createHint(
2262                 m_graph, origin.takeValidExit(canExit), value);
2263         }
2264 
2265         switch (location.kind()) {
2266         case NamedPropertyPLoc: {
2267             Allocation&amp; allocation = m_heap.getAllocation(location.base());
2268 
<span class="line-removed">2269             Vector&lt;RegisteredStructure&gt; structures;</span>
<span class="line-removed">2270             structures.appendRange(allocation.structures().begin(), allocation.structures().end());</span>
2271             unsigned identifierNumber = location.info();
2272             UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
2273 













2274             std::sort(
2275                 structures.begin(),
2276                 structures.end(),
2277                 [uid] (RegisteredStructure a, RegisteredStructure b) -&gt; bool {
2278                     return a-&gt;getConcurrently(uid) &lt; b-&gt;getConcurrently(uid);
2279                 });
2280 
2281             RELEASE_ASSERT(structures.size());
2282             PropertyOffset firstOffset = structures[0]-&gt;getConcurrently(uid);
2283 
2284             if (firstOffset == structures.last()-&gt;getConcurrently(uid)) {
2285                 Node* storage = base;
2286                 // FIXME: When we decide to sink objects with a
2287                 // property storage, we should handle non-inline offsets.
2288                 RELEASE_ASSERT(isInlineOffset(firstOffset));
2289 
2290                 StorageAccessData* data = m_graph.m_storageAccessData.add();
2291                 data-&gt;offset = firstOffset;
2292                 data-&gt;identifierNumber = identifierNumber;
2293 
</pre>
<hr />
<pre>
2365             for (Node* node : *block) {
2366                 switch (node-&gt;op()) {
2367                 case FilterCallLinkStatus:
2368                 case FilterGetByIdStatus:
2369                 case FilterPutByIdStatus:
2370                 case FilterInByIdStatus:
2371                     if (node-&gt;child1()-&gt;isPhantomAllocation())
2372                         node-&gt;removeWithoutChecks();
2373                     break;
2374                 default:
2375                     break;
2376                 }
2377             }
2378         }
2379     }
2380 
2381     // This is a great way of asking value-&gt;isStillValid() without having to worry about getting
2382     // different answers. It turns out that this analysis works OK regardless of what this
2383     // returns but breaks badly if this changes its mind for any particular InferredValue. This
2384     // method protects us from that.
<span class="line-modified">2385     bool isStillValid(InferredValue* value)</span>
2386     {
<span class="line-modified">2387         return m_validInferredValues.add(value, value-&gt;isStillValid()).iterator-&gt;value;</span>
2388     }
2389 






2390     SSACalculator m_pointerSSA;
2391     SSACalculator m_allocationSSA;
2392     NodeSet m_sinkCandidates;
2393     HashMap&lt;PromotedHeapLocation, SSACalculator::Variable*&gt; m_locationToVariable;
2394     HashMap&lt;Node*, SSACalculator::Variable*&gt; m_nodeToVariable;
2395     HashMap&lt;PromotedHeapLocation, Node*&gt; m_localMapping;
2396     HashMap&lt;Node*, Node*&gt; m_escapeeToMaterialization;
2397     InsertionSet m_insertionSet;
2398     CombinedLiveness m_combinedLiveness;
2399 
<span class="line-modified">2400     HashMap&lt;InferredValue*, bool&gt; m_validInferredValues;</span>
2401 
2402     HashMap&lt;Node*, Node*&gt; m_materializationToEscapee;
2403     HashMap&lt;Node*, Vector&lt;Node*&gt;&gt; m_materializationSiteToMaterializations;
2404     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_materializationSiteToRecoveries;
2405     HashMap&lt;Node*, Vector&lt;std::pair&lt;PromotedHeapLocation, Node*&gt;&gt;&gt; m_materializationSiteToHints;
2406 
2407     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_locationsForAllocation;
2408 
2409     BlockMap&lt;LocalHeap&gt; m_heapAtHead;
2410     BlockMap&lt;LocalHeap&gt; m_heapAtTail;
2411     LocalHeap m_heap;
2412 
2413     Node* m_bottom = nullptr;
2414 };
2415 
2416 }
2417 
2418 bool performObjectAllocationSinking(Graph&amp; graph)
2419 {
2420     return runPhase&lt;ObjectAllocationSinkingPhase&gt;(graph);
</pre>
</td>
<td>
<hr />
<pre>
 823     {
 824         m_heap.assertIsValid();
 825         ASSERT(m_heap.takeEscapees().isEmpty());
 826 
 827         Allocation* target = nullptr;
 828         HashMap&lt;PromotedLocationDescriptor, LazyNode&gt; writes;
 829         PromotedLocationDescriptor exactRead;
 830 
 831         switch (node-&gt;op()) {
 832         case NewObject:
 833             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Object);
 834             target-&gt;setStructures(node-&gt;structure());
 835             writes.add(
 836                 StructurePLoc, LazyNode(m_graph.freeze(node-&gt;structure().get())));
 837             break;
 838 
 839         case NewFunction:
 840         case NewGeneratorFunction:
 841         case NewAsyncGeneratorFunction:
 842         case NewAsyncFunction: {
<span class="line-modified"> 843             if (isStillValid(node-&gt;castOperand&lt;FunctionExecutable*&gt;())) {</span>
 844                 m_heap.escape(node-&gt;child1().node());
 845                 break;
 846             }
 847 
 848             if (node-&gt;op() == NewGeneratorFunction)
 849                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::GeneratorFunction);
 850             else if (node-&gt;op() == NewAsyncFunction)
 851                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncFunction);
 852             else if (node-&gt;op() == NewAsyncGeneratorFunction)
 853                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncGeneratorFunction);
 854             else
 855                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::Function);
 856 
 857             writes.add(FunctionExecutablePLoc, LazyNode(node-&gt;cellOperand()));
 858             writes.add(FunctionActivationPLoc, LazyNode(node-&gt;child1().node()));
 859             break;
 860         }
 861 
 862         case NewRegexp: {
 863             target = &amp;m_heap.newAllocation(node, Allocation::Kind::RegExpObject);
 864 
 865             writes.add(RegExpObjectRegExpPLoc, LazyNode(node-&gt;cellOperand()));
 866             writes.add(RegExpObjectLastIndexPLoc, LazyNode(node-&gt;child1().node()));
 867             break;
 868         }
 869 
 870         case CreateActivation: {
<span class="line-modified"> 871             if (isStillValid(node-&gt;castOperand&lt;SymbolTable*&gt;())) {</span>
 872                 m_heap.escape(node-&gt;child1().node());
 873                 break;
 874             }
 875             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Activation);
 876             writes.add(ActivationSymbolTablePLoc, LazyNode(node-&gt;cellOperand()));
 877             writes.add(ActivationScopePLoc, LazyNode(node-&gt;child1().node()));
 878             {
 879                 SymbolTable* symbolTable = node-&gt;castOperand&lt;SymbolTable*&gt;();
 880                 LazyNode initialValue(m_graph.freeze(node-&gt;initializationValueForActivation()));
 881                 for (unsigned offset = 0; offset &lt; symbolTable-&gt;scopeSize(); ++offset) {
 882                     writes.add(
 883                         PromotedLocationDescriptor(ClosureVarPLoc, offset),
 884                         initialValue);
 885                 }
 886             }
 887             break;
 888         }
 889 
 890         case PutStructure:
 891             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
</pre>
<hr />
<pre>
1251                             escapingOnEdge.add(entry.key, entry.value);
1252                     }
1253                     callback(escapingOnEdge, block-&gt;terminal());
1254                 }
1255             }
1256         };
1257 
1258         if (m_sinkCandidates.size()) {
1259             // If we&#39;re moving an allocation to `where` in the program, we need to ensure
1260             // we can still walk the stack at that point in the program for the
1261             // InlineCallFrame of the original allocation. Certain InlineCallFrames rely on
1262             // data in the stack when taking a stack trace. All allocation sites can do a
1263             // stack walk (we do a stack walk when we GC). Conservatively, we say we&#39;re
1264             // still ok to move this allocation if we are moving within the same InlineCallFrame.
1265             // We could be more precise here and do an analysis of stack writes. However,
1266             // this scenario is so rare that we just take the conservative-and-straight-forward
1267             // approach of checking that we&#39;re in the same InlineCallFrame.
1268 
1269             forEachEscapee([&amp;] (HashMap&lt;Node*, Allocation&gt;&amp; escapees, Node* where) {
1270                 for (Node* allocation : escapees.keys()) {
<span class="line-modified">1271                     InlineCallFrame* inlineCallFrame = allocation-&gt;origin.semantic.inlineCallFrame();</span>
1272                     if (!inlineCallFrame)
1273                         continue;
<span class="line-modified">1274                     if ((inlineCallFrame-&gt;isClosureCall || inlineCallFrame-&gt;isVarargs()) &amp;&amp; inlineCallFrame != where-&gt;origin.semantic.inlineCallFrame())</span>
1275                         m_sinkCandidates.remove(allocation);
1276                 }
1277             });
1278         }
1279 
1280         // Ensure that the set of sink candidates is closed for put operations
1281         // This is (2) as described above.
1282         Vector&lt;Node*&gt; worklist;
1283         worklist.appendRange(m_sinkCandidates.begin(), m_sinkCandidates.end());
1284 
1285         while (!worklist.isEmpty()) {
1286             for (Node* identifier : dependencies.get(worklist.takeLast())) {
1287                 if (m_sinkCandidates.add(identifier).isNewEntry)
1288                     worklist.append(identifier);
1289             }
1290         }
1291 
1292         if (m_sinkCandidates.isEmpty())
1293             return hasUnescapedReads;
1294 
</pre>
<hr />
<pre>
2249         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2250             dataLog(&quot;Recovering &quot;, location, &quot; at &quot;, where, &quot;\n&quot;);
2251         ASSERT(location.base()-&gt;isPhantomAllocation());
2252         Node* base = getMaterialization(block, location.base());
2253         Node* value = resolve(block, location);
2254 
2255         NodeOrigin origin = where-&gt;origin.withSemantic(base-&gt;origin.semantic);
2256 
2257         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2258             dataLog(&quot;Base is &quot;, base, &quot; and value is &quot;, value, &quot;\n&quot;);
2259 
2260         if (base-&gt;isPhantomAllocation()) {
2261             return PromotedHeapLocation(base, location.descriptor()).createHint(
2262                 m_graph, origin.takeValidExit(canExit), value);
2263         }
2264 
2265         switch (location.kind()) {
2266         case NamedPropertyPLoc: {
2267             Allocation&amp; allocation = m_heap.getAllocation(location.base());
2268 


2269             unsigned identifierNumber = location.info();
2270             UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
2271 
<span class="line-added">2272             Vector&lt;RegisteredStructure&gt; structures;</span>
<span class="line-added">2273             for (RegisteredStructure structure : allocation.structures()) {</span>
<span class="line-added">2274                 // This structure set is conservative. This set can include Structure which does not have a legit property.</span>
<span class="line-added">2275                 // We filter out such an apparently inappropriate structures here since MultiPutByOffset assumes all the structures</span>
<span class="line-added">2276                 // have valid corresponding offset for the given property.</span>
<span class="line-added">2277                 if (structure-&gt;getConcurrently(uid) != invalidOffset)</span>
<span class="line-added">2278                     structures.append(structure);</span>
<span class="line-added">2279             }</span>
<span class="line-added">2280 </span>
<span class="line-added">2281             // Since we filter structures, it is possible that we no longer have any structures here. In this case, we emit ForceOSRExit.</span>
<span class="line-added">2282             if (structures.isEmpty())</span>
<span class="line-added">2283                 return m_graph.addNode(ForceOSRExit, origin.takeValidExit(canExit));</span>
<span class="line-added">2284 </span>
2285             std::sort(
2286                 structures.begin(),
2287                 structures.end(),
2288                 [uid] (RegisteredStructure a, RegisteredStructure b) -&gt; bool {
2289                     return a-&gt;getConcurrently(uid) &lt; b-&gt;getConcurrently(uid);
2290                 });
2291 
2292             RELEASE_ASSERT(structures.size());
2293             PropertyOffset firstOffset = structures[0]-&gt;getConcurrently(uid);
2294 
2295             if (firstOffset == structures.last()-&gt;getConcurrently(uid)) {
2296                 Node* storage = base;
2297                 // FIXME: When we decide to sink objects with a
2298                 // property storage, we should handle non-inline offsets.
2299                 RELEASE_ASSERT(isInlineOffset(firstOffset));
2300 
2301                 StorageAccessData* data = m_graph.m_storageAccessData.add();
2302                 data-&gt;offset = firstOffset;
2303                 data-&gt;identifierNumber = identifierNumber;
2304 
</pre>
<hr />
<pre>
2376             for (Node* node : *block) {
2377                 switch (node-&gt;op()) {
2378                 case FilterCallLinkStatus:
2379                 case FilterGetByIdStatus:
2380                 case FilterPutByIdStatus:
2381                 case FilterInByIdStatus:
2382                     if (node-&gt;child1()-&gt;isPhantomAllocation())
2383                         node-&gt;removeWithoutChecks();
2384                     break;
2385                 default:
2386                     break;
2387                 }
2388             }
2389         }
2390     }
2391 
2392     // This is a great way of asking value-&gt;isStillValid() without having to worry about getting
2393     // different answers. It turns out that this analysis works OK regardless of what this
2394     // returns but breaks badly if this changes its mind for any particular InferredValue. This
2395     // method protects us from that.
<span class="line-modified">2396     bool isStillValid(SymbolTable* value)</span>
2397     {
<span class="line-modified">2398         return m_validInferredValues.add(value, value-&gt;singleton().isStillValid()).iterator-&gt;value;</span>
2399     }
2400 
<span class="line-added">2401     bool isStillValid(FunctionExecutable* value)</span>
<span class="line-added">2402     {</span>
<span class="line-added">2403         return m_validInferredValues.add(value, value-&gt;singleton().isStillValid()).iterator-&gt;value;</span>
<span class="line-added">2404     }</span>
<span class="line-added">2405 </span>
<span class="line-added">2406 </span>
2407     SSACalculator m_pointerSSA;
2408     SSACalculator m_allocationSSA;
2409     NodeSet m_sinkCandidates;
2410     HashMap&lt;PromotedHeapLocation, SSACalculator::Variable*&gt; m_locationToVariable;
2411     HashMap&lt;Node*, SSACalculator::Variable*&gt; m_nodeToVariable;
2412     HashMap&lt;PromotedHeapLocation, Node*&gt; m_localMapping;
2413     HashMap&lt;Node*, Node*&gt; m_escapeeToMaterialization;
2414     InsertionSet m_insertionSet;
2415     CombinedLiveness m_combinedLiveness;
2416 
<span class="line-modified">2417     HashMap&lt;JSCell*, bool&gt; m_validInferredValues;</span>
2418 
2419     HashMap&lt;Node*, Node*&gt; m_materializationToEscapee;
2420     HashMap&lt;Node*, Vector&lt;Node*&gt;&gt; m_materializationSiteToMaterializations;
2421     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_materializationSiteToRecoveries;
2422     HashMap&lt;Node*, Vector&lt;std::pair&lt;PromotedHeapLocation, Node*&gt;&gt;&gt; m_materializationSiteToHints;
2423 
2424     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_locationsForAllocation;
2425 
2426     BlockMap&lt;LocalHeap&gt; m_heapAtHead;
2427     BlockMap&lt;LocalHeap&gt; m_heapAtTail;
2428     LocalHeap m_heap;
2429 
2430     Node* m_bottom = nullptr;
2431 };
2432 
2433 }
2434 
2435 bool performObjectAllocationSinking(Graph&amp; graph)
2436 {
2437     return runPhase&lt;ObjectAllocationSinkingPhase&gt;(graph);
</pre>
</td>
</tr>
</table>
<center><a href="DFGOSRExitPreparation.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOperations.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>